[{"title":"HAProxy编译安装","url":"/2016/07/18/2016/HAProxy%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"简介\nHAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。百度百科\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nhaproxy\n1.6.7\n点击下载\n\n\n\n步骤\n需要系统先初始化开发环境\n\nyum install -y gcc gcc-c++ zlib-devel make\n编译安装haproxytar xf haproxy-1.6.7.tar.gzcd haproxy-1.6.7make -j4 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1make install PREFIX=/usr/local/haproxymkdir /etc/haproxycp examples/content-sw-sample.cfg /etc/haproxy/haproxy.conf\n需要注意的地方是 TARGET=linux2628 这个是根据内核版本来定的 具体如何使用看源码目录下的README文件\n简单来说 只要你的内核版本大于2.6.28的 都可以使用TARGET=linux2628\n\n编译安装是非常简单的 至此haproxy就编译安装完成了 剩下的就是看haproxy如何使用了 \n附录四层和七层负载均衡的区别常见的负载均衡方式 除了硬件负载均衡设备 还有软件的负载均衡产品 比如Nginx, LVS, HAProxy等\n软件的方式又分为基于操作系统的和基于第三方软件的 比如LVS需要内核模块的支持 HAProxy则不需要\n\nHAProxy可以实现TCP(四层)和HTTP(七层)应用的负载均衡 而早期Nginx只支持HTTP应用的负载均衡\n不过Nginx在新版本1.9.0之后 也支持了TCP的代理和负载均衡 在1.9.13后支持了UDP代理和负载均衡\n\n四层负载均衡也被称为四层交换机 主要通过修改数据包中目标IP地址和端口改为后端服务器的IP地址和端口\n然后直接转发给该后端服务器 这样一个负载均衡的请求就完成了 并没有对数据包中的数据内容做修改\n而负载均衡器只不过完成了一个类似路由的转发动作 在某些负载均衡策略下 甚至会修改报文的源地址\n以保证数据包可以正确的传输\n\n而七层负载均衡器又被称为七层交换机 位于应用层 此时负载均衡器可以支持多种应用协议 \n常见的有HTTP, FTP, SMTP等 七层负载均衡器不仅可以根据IP+端口的方式负载均衡 还可以根据内容\n比如一个网站有为手机适配的页面和电脑适配的页面 可以分析HTTP的头部User-Agent信息 来智能跳转\n而这些能力是在四层是无法实现的\n","categories":["HAProxy"],"tags":["代理服务器","负载均衡"]},{"title":"Apache编译安装","url":"/2016/09/21/2016/Apache%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"简介Apache是世界使用排名第一的Web服务器软件。它可以运行在几乎所有广泛使用的计算机平台上，由于其跨平台和安全性被广泛使用，是最流行的Web服务器端软件之一。它快速、可靠并且可通过简单的API扩充，将Perl/Python等解释器编译到服务器中。同时Apache音译为阿帕奇，是北美印第安人的一个部落，叫阿帕奇族，在美国的西南部。也是一个基金会的名称、一种武装直升机等等\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\npcre\n8.39\n点击下载\n\n\nopenssl\n1.0.1s\n点击下载\n\n\napr\n1.5.2\n点击下载\n\n\napr-util\n1.5.4\n点击下载\n\n\nhttpd\n2.4.23\n点击下载\n\n\n\n步骤\n需要系统先初始化开发环境\n\nyum install -y make gcc gcc-c++ perl tar bzip2 vim\n编译安装apr和apr-util\napr 和 apr-util 是 httpd 的运行依赖\n\n# apr-1.5.2tar xf apr-1.5.2.tar.bz2cd apr-1.5.2 ./configure --prefix=/usr/local/aprmake -j4 &amp;&amp; make install# apr-util-1.5.4tar xf apr-util-1.5.4.tar.bz2cd apr-util-1.5.4./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr/make -j4 &amp;&amp; make install\n编译安装pcre\npcre是一个perl的正则表达式库 httpd的rewrite需要用到\n\ntar xf pcre-8.39.tar.bz2cd pcre-8.39./configure --prefix=/usr/local/pcremake -j4 &amp;&amp; make install\n编译安装openssl\nOpenSSL 是一个强大的安全套接字层密码库 搭建https的网站需要用到\n\ntar xf openssl-1.0.1s.tar.gzcd openssl-1.0.1s./config  -fPIC no-sharedmake depend &amp;&amp; make install\n编译安装httpdtar xf httpd-2.4.23.tar.bz2cd httpd-2.4.23./configure --prefix=/usr/local/httpd \\--enable-ssl --enable-cgi  \\--enable-rewrite  --enable-so \\--with-pcre --with-apr=/usr/local/apr \\--with-apr-util=/usr/local/apr-util/ \\--with-pcre=/usr/local/pcre/ \\--with-ssl=/usr/local/ssl \\--with-mpm=event --with-zlibmake -j4 &amp;&amp; make install\n运行httpd\nhttpd默认运行用户是daemon 若不存在需要先创建 也可以在配置文件中重新指定运行用户\n\n修改配置文件vim /usr/local/httpd/conf/httpd.conf添加：ServerName localhost不添加这行配置 httpd服务也是可以正常启动的 但是会弹出提示然后就可以启动httpd服务了/usr/local/httpd/bin/httpd检查httpd是否正常监听netstat -anpt |grep httpdtcp    0   0 :::80           :::*            LISTEN      51272/httpd通过浏览器访问服务器 看是否出现了大大的 It works!\n附录httpd的主要目录作用\nls /usr/local/httpd/\nbin  build  cgi-bin  conf  error  htdocs  icons  include  logs  man  manual  modules\n\nbin:        存放着apache提供的一些小工具和httpd主程序\ncgi-bin:    存放cgi脚本的目录\nconf:       存放httpd的配置文件 主配置文件为httpd.conf\nhtdocs:     web的默认根目录 存放网页文件\nlogs:       存放着httpd的访问日志 错误日志 以及pid文件\nmodules:    存放着httpd动态编译的模块 比如刚才的openssl就被编译为了mod_ssl.so\n","categories":["Apache"],"tags":["Apache"]},{"title":"LNMP环境部署","url":"/2016/07/19/2016/LAMP%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/","content":"简介\nLinux+Apache+Mysql/MariaDB+Perl/PHP/Python一组常用来搭建动态网站或者服务器的开源软件，本身都是各自独立的程序，但是因为常被放在一起使用，拥有了越来越高的兼容度，共同组成了一个强大的Web应用程序平台。随着开源潮流的蓬勃发展，开放源代码的LAMP已经与J2EE和.Net商业软件形成三足鼎立之势，并且该软件开发的项目在软件方面的投资成本较低，因此受到整个IT界的关注。从网站的流量上来说，70%以上的访问流量是LAMP来提供的，LAMP是最强大的网站解决方案．\n\n环境\n本教程中的各服务搭建在不同的服务器上 当然也可以搭建在同一个服务器上\n\n主机环境\n\n\n身份\n系统\nIP\n\n\n\n\nApache 服务器\nCentOS 6.7\n172.18.0.4\n\n\nMySQL 服务器\nCentOS 6.7\n172.18.0.2\n\n\nPHP-fpm 服务器\nCentOS 6.7\n172.18.0.3\n\n\n\n软件环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nApache\n2.4.23\n点击下载\n\n\nMySQL\n5.6.28\n点击下载\n\n\nPHP\n5.6.19\n点击下载\n\n\n\n步骤\nhttpd和php结合的方式有两种 一种是和nginx相同的 通过php-fpm启动监听的方式 然后转发php页面请求给php-fpm服务 还有一种就是php编译为httpd模块的方式提供php页面的解析能力\n\n编译安装各组件\n\n\n服务器\n安装文档地址\n\n\n\n\nApache\n点击打开文档内容\n\n\nMySQL\n点击打开文档内容\n\n\nPHP-fpm\n点击打开文档内容\n\n\n\nhttpd + php-fpm\n这个是httpd通过fast-cgi方式和php-fpm搭配\n\n配置PHP-fpm打开编辑php-fpm.conf\nvim /usr/local/php/etc/php-fpm.conf\n\n修改listen监听地址为0.0.0.0:9000\nlisten = 0.0.0.0:9000 \n\n配置仅允许连接的客户机 默认运行所有主机连接 172.0.0.7是Nginx服务器的IP\nlisten.allowed_clients = 172.17.0.7\n\n然后启动PHP-fpm的服务\nservice php-fpm start\n修改httpd配置文件打开编辑httpd.conf\nvim /usr/local/httpd/conf/httpd.conf\n\n修改 DocumentRoot 路径为&quot;/var/www/html&quot; 这个是网站根目录 \n紧接着的 Directory 配置段也修改为 &lt;Directory &quot;/var/www/html&quot;&gt;\n\n去掉mod_proxy.so和mod_proxy_fcgi.so之前的注解 让httpd启动时加载这两个模块\nLoadModule proxy_module modules/mod_proxy.so\nLoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so \n\n然后添加配置段 让php页面交给php-fpm去解析\n&lt;FilesMatch \\.php$&gt;\n     SetHandler &quot;proxy:fcgi://172.18.0.3:9000&quot;\n&lt;/FilesMatch&gt;\n\n然后定位DirectoryIndex配置项 添加index.php\nDirectoryIndex index.php index.html\n\n最后启动httpd服务\n/usr/local/httpd/bin/httpd\n\n下面有详细的方法检测是否搭配成功\nhttpd + php模块\n接下来开始介绍如何将php编译为httpd的模块方式搭配php和httpd\n\n将php编译为httpd模块\n将php编译为httpd模块方式和php-fpm模式的编译唯一的区别就是将–enable-fpm替换为–with-apxs2=/usr/local/httpd/bin/apxs\n\ntar xf php-5.6.19.tar.xzcd php-5.6.19./configure \\--prefix=/usr/local/php \\--with-apxs2=/usr/local/httpd/bin/apxs \\--with-mcrypt \\--with-zlib --enable-mbstring \\--with-openssl --with-mysql \\--with-mysqli --with-mysql-sock \\--with-gd --with-jpeg-dir=/usr/lib \\--enable-gd-native-ttf  \\--enable-pdo --with-pdo-mysql \\--with-gettext --with-curl \\--with-pdo-mysql --enable-sockets \\--enable-bcmath --enable-xml \\--with-bz2 --enable-zip \\--with-freetype-dir=/usr \\--with-mcrypt=/usr/local/mcryptmake -j4 &amp;&amp; make install\nls /usr/local/httpd/modules/libphp5.so\n可以看到 在httpd的modules目录下 已经出现了libphp5.so这个模块了\n接下来依然要给php模块提供个配置文件 \n\ncp ./php.ini-production /usr/local/php/lib/php.ini\n修改httpd配置文件\nphp模块方式对httpd.conf的修改和php-fpm方式是完全不同的\n\ncd到httpd的conf目录 可以发现多出来一个httpd.conf.bak的文件 \n这个是php安装期间 对httpd.conf做出修改后的备份 其实做的修改也仅仅是添加和启用了libphp5这个模块\nLoadModule php5_module        modules/libphp5.so\n\n如果沿用的是刚才的php-fpm模式的配置文件 需要先清理掉&lt;FilesMatch \\.php$&gt;配置段\n如果是全新的配置 同样修改网站根目录和添加index.php 这里不再赘述\n\n添加如下两行配置\nAddType application/x-httpd-php  .php\nAddType application/x-httpd-php-source  .phps\n\n最后启动httpd服务\n/usr/local/httpd/bin/httpd\n验证是否搭配成功\n请注意 如果php-fpm和httpd服务不在同一个服务器 可以将网站根目录通过nfs共享访问 或者克隆一份web页面放到两台服务器相同的路径下\n\nMySQL创建远程登录用户 php 允许所有地址连接 密码 php123grant all privileges on . to “php”@”%” identified by “php123”;\n在/var/www/html中编写index.php\n    &lt;?php\n        phpinfo();\n    ?&gt;\n\n在/var/www/html中编写dbtest.php\n    &lt;?php \n        $link=mysql_connect(&quot;172.18.0.2&quot;,&quot;php&quot;,&quot;php123&quot;); \n        if(!$link) echo &quot;连接错误!&quot;; \n        else echo &quot;可以连接!&quot;; \n    ?&gt;\n\n分别访问两个php文件\nhttp://172.18.0.4/  和  http://172.18.0.4/dbtest.php\n若浏览器出现大大的PHP Version 5.6.19 则index.php被正常识别\n访问dbtest.php若出现 &quot;可以连接!&quot; 则数据库连接成果\n\n以下是用curl访问dbtest.php的结果\n# curl http://172.18.0.4/dbtest.php\n可以连接\n附录可以看到 LAMP 和 LNMP 在php-fpm上是非常相似的 \n推荐使用php-fpm的方式 这样比php模块更节省服务器资源\n\n因为httpd的高并发能力比Nginx弱很多 所以高并发环境下推荐使用LNMP\n","categories":["LAMP"],"tags":["mysql","php","apache","zabbix"]},{"title":"LNMP环境部署","url":"/2016/04/01/2016/LNMP%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2/","content":"简介\nNMP代表的就是：Linux系统下Nginx+MySQL+PHP这种网站服务器架构。Linux是一类Unix计算机操作系统的统称，是目前最流行的免费操作系统。代表版本有：debian、centos、ubuntu、fedora、gentoo等。Nginx是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP代理服务器。Mysql是一个小型关系型数据库管理系统。PHP是一种在服务器端执行的嵌入HTML文档的脚本语言。这四种软件均为免费开源软件，组合到一起，成为一个免费、高效、扩展性强的网站服务系统。百度百科\n\n环境\n本教程中的各服务搭建在不同的服务器上 当然也可以搭建在同一个服务器上\n\n主机环境\n\n\n身份\n系统\nIP\n\n\n\n\nNginx 服务器\nCentOS 6.7\n172.17.0.7\n\n\nMySQL 服务器\nCentOS 6.7\n172.17.0.2\n\n\nPHP-fpm 服务器\nCentOS 6.7\n172.17.0.6\n\n\n\n软件环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nNginx\n1.9.13\n点击下载\n\n\nMySQL\n5.6.28\n点击下载\n\n\nPHP\n5.6.19\n点击下载\n\n\n\n步骤编译安装各组件\n\n\n服务器\n安装文档地址\n\n\n\n\nNginx\n点击打开文档内容\n\n\nMySQL\n点击打开文档内容\n\n\nPHP-fpm\n点击打开文档内容\n\n\n\n搭配组合\n他们之间的搭配其实就是通过修改配置文件能互连起来 协调工作如果跨主机搭建需要让Nginx和PHP-fpm能访问相同的web网页目录或者只将PHP的页面放到PHP-fpm服务能访问到了路径即可因为Nginx收到PHP页面的请求会将请求转发给PHP-fpm去处理 自己并不处理PHP的页面但是如果其他的静态资源等 还是需要放到Nginx能访问到的路径实验中 已经通过NFS共享方式让Nginx和PHP-fpm挂载相同的/var/www/html目录\n\n配置PHP-fpm打开编辑php-fpm.conf\nvim /usr/local/php/etc/php-fpm.conf\n\n修改listen监听地址为0.0.0.0:9000\nlisten = 0.0.0.0:9000 \n\n配置仅允许连接的客户机 默认运行所有主机连接 172.0.0.7是Nginx服务器的IP\nlisten.allowed_clients = 172.17.0.7\n\n然后启动PHP-fpm的服务\nservice php-fpm start\n配置Nginx打开编辑nginx.conf\nvim /usr/local/nginx/conf/nginx.conf\n\n更改网站根路径和添加php页面的识别\nlocation / {                                                          \n        root   /var/www/html;                                             \n        index  index.html index.htm index.php;                            \n    }\n\n去掉php段的注释 并按实际环境修改以下内容\nlocation ~ \\.php$ {                                                   \n        root           /var/www/html;                                     \n        fastcgi_pass   172.17.0.6:9000;                                   \n        fastcgi_index  index.php;                                         \n        fastcgi_param  SCRIPT_FILENAME  /var/www/html$fastcgi_script_name;\n        include        fastcgi_params;                                    \n    }\n\n重启或通知Nginx重新加载配置文件\n/usr/local/nginx/sbin/nginx -s reload\n配置MySQLMySQL创建远程登录用户 php 只允许 172.17.0.6连接 密码 php123\ngrant all privileges on *.* to &quot;php&quot;@&quot;172.17.0.6&quot; identified by &quot;php123&quot;;\n验证是否搭配成功在/var/www/html中编写index.php\n    &lt;?php\n        phpinfo();\n    ?&gt;\n\n在/var/www/html中编写dbtest.php\n    &lt;?php \n        $link=mysql_connect(&quot;172.17.0.2&quot;,&quot;root&quot;,&quot;123.com&quot;); \n        if(!$link) echo &quot;连接错误!&quot;; \n        else echo &quot;可以连接!&quot;; \n    ?&gt;\n\n分别访问两个php文件\nhttp://172.17.0.7/  和  http://172.17.0.7/dbtest.php\n若浏览器出现大大的PHP Version 5.6.19 则index.php被正常识别\n访问dbtest.php若出现 &quot;可以连接!&quot; 则数据库连接成果\n\n以下是用curl访问dbtest.php的结果\n[root@45c4f07c6049 etc]# curl http://172.17.0.7/dbtest.php\nOK!可以连接\n附录搭建好LNMP后 好多用到PHP运行环境的页面就可以在上面运行了 \n比如zabbix的web管理界面\n","categories":["LNMP"],"tags":["mysql","php","zabbix","nginx"]},{"title":"MySQL数据误删恢复记录","url":"/2016/04/19/2016/MySQL%E6%95%B0%E6%8D%AE%E8%AF%AF%E5%88%A0%E6%81%A2%E5%A4%8D%E8%AE%B0%E5%BD%95/","content":"简介\n由于程序出错 导致MySQL数据库三天内的数据混乱 现在需要删除三天内错误的数据 因为大意 where语句条件忘记添加引号 导致条件不生效 删除了表中所有的数据 现在需要通过binlog日志将此表的数据恢复\n\n环境\n生产环境 MySQL-5.5.15 已经开启二进制日志\n\nmysql&gt; show variables like &apos;log_bin&apos;;\n+---------------+-------+\n| Variable_name | Value |\n+---------------+-------+\n| log_bin       | ON    |\n+---------------+-------+\n1 row in set (0.01 sec)\n步骤\n大体的数据恢复思路是：\n\n先查询MySQL已经读写到的二进制日志 然后刷新二进制到新的日志文件 \n读取二进制日志 过滤出关于要恢复表的信息 \n将所有对要恢复表的操作信息保存为sql文件 \n然后将sql文件导入MySQL 完成数据恢复\n\n\n查询已经写到的二进制位置通过 show master status; 查看当前写入到的二进制日志文件\n[root@localhost /]# mysql -uroot -p\nEnter password: \nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 236859\nServer version: 5.5.14-log MySQL Community Server (GPL)\n\nCopyright (c) 2000, 2012, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.\n\nmysql&gt; show master status;\n+------------------+----------+--------------+------------------+\n| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000037 | 40435151 |              |                  |\n+------------------+----------+--------------+------------------+\n1 row in set (0.00 sec)\n刷新二进制日志文件执行 flush logs; 刷新二进制日志 可以看到 已经打来了一个新的文件开始写入了二进制日志文件的路径一般在数据库目录下\nmysql&gt; flush logs;\nQuery OK, 0 rows affected (0.02 sec)\n\nmysql&gt; show master status;\n+------------------+----------+--------------+------------------+\n| File             | Position | Binlog_Do_DB | Binlog_Ignore_DB |\n+------------------+----------+--------------+------------------+\n| mysql-bin.000038 |      107 |              |                  |\n+------------------+----------+--------------+------------------+\n1 row in set (0.00 sec)\n使用mysqlbinlog工具查看二进制日志\nmysqlbinlog程序就是MySQL 二进制日志文件的查看工具了 先从从二进制中找到最后执行删除指令的语句\n\n最后记录删除操作的二进制日志文件为mysql-bin.000037 要恢复的表存在与dbinfo库中\n[root@localhost data]# mysqlbinlog -d dbinfo mysql-bin.000037 | \\\ngrep &apos;delete&apos; -B1 |grep zf_total_increment -B1 \n\nSET TIMESTAMP=1460950871/*!*/;\ndelete  from zf_total_increment where insert_time &gt; 2016-04-16\n这里看到了执行删除语句的时间戳是 1460950871 现在需要将它转换为日期时间\nmysql&gt; select FROM_UNIXTIME(1460950871);\n+---------------------------+\n| FROM_UNIXTIME(1460950871) |\n+---------------------------+\n| 2016-04-18 11:41:11       |\n+---------------------------+\n1 row in set (0.00 sec)\n恢复的时候当然不能把这一句也恢复了 否则刚恢复完毕又被删除了继续找到建表的日期 因为表并没有被删除 根据情况 可以先truncate下表 这样就不用重新创建了\n[root@localhost data]# mysqlbinlog -d dbinfo mysql-bin.000009|grep zf_total_increment -B1|head \nSET TIMESTAMP=1389259355/*!*/;\nDROP TABLE IF EXISTS `zf_total_increment` /* generated by server */\n--\nSET TIMESTAMP=1389259355/*!*/;\nCREATE TABLE `zf_total_increment` (\n--\n-- ----------------------------\n-- Records of zf_total_increment\n-- ----------------------------\nINSERT INTO `zf_total_increment` VALUES (......)\n\nmysql&gt; select FROM_UNIXTIME(1389259355);\n+---------------------------+\n| FROM_UNIXTIME(1389259355) |\n+---------------------------+\n| 2014-01-09 17:22:35       |\n+---------------------------+\n1 row in set (0.00 sec)\n可以看到 在同一时刻进行了删除已存在的表 创建表 插入第一条语句 那么就从这里开始恢复zf_total_increment这个表的数据存在与mysql-bin.000009到mysql-bin.000037中 需要挨个恢复\n由于我并非要恢复所有的数据 原本就是要删除这几天的数据 所以只将数据恢复到2016-04-16之前如果是完全恢复的话 千万不要将delete语句的时间也恢复了 可以恢复到这个时间前一秒钟都行最好可以恢复到这条语句的前一个位置 \n[root@localhost data]# mkdir recovery\n[root@localhost data]# mysqlbinlog -d dbinfo \\\n--start-datetime=&apos;2014-01-09 17:22:35&apos; \\\n--stop-datetime=&apos;2016-04-16 00:00:00&apos; mysql-bin.000009 | \\\ngrep zf_total_increment &gt;&gt; recovery/zf_total_increment.sql\n这样 mysql-bin.000009中所有关于zf_total_increment的语句都被追加到zf_total_increment.sql中了接下来继续将mysql-bin.000010 到 mysql-bin.0000037中的也继续恢复\n如果恢复的文件太多 可以使用脚本 等所有的日志都跑完了 最终的目标表的数据就都被保存为sql文件\n[root@localhost recovery]# head zf_total_increment.sql \nDROP TABLE IF EXISTS `zf_total_increment` /* generated by server */\nCREATE TABLE `zf_total_increment` (\n-- Records of zf_total_increment\nINSERT INTO `zf_total_increment` VALUES (......)\n查看这个文件 发现删除和创建语句也在其中 由于创建语句并没有写在一行 所以并不完整由于过滤的时候只过滤一行 导致写在下一行的 /*!*/; 丢失 下面用sed工具修正\n[root@localhost recovery]# sed -i &apos;1,3d&apos; zf_total_increment.sql \n[root@localhost recovery]# sed -i &apos;s/$/;/g&apos; zf_total_increment.sql \n最后就可以将这个sql文件导入MySQL执行了\n[root@localhost recovery]# mysql -uroot -p123456 dbinfo &lt; zf_total_increment.sql\n最后查看数据库 这个表的数据是否已经完全恢复了呢 这个sql文件也可以作为备份 供以后使用\n附录\n以下是mysqlbinlog支持的常用选项\n\n--database=db_name, -d db_name      只列出该数据库的条目 只用本地日志\n–-host=host_name, -h host_name      获取指定主机上的MySQL服务器的二进制日志\n–-user=user_name, -u user_name      远程主机需要用于连接的用户名\n–-password[=password], -p[password] 远程主机需要输入密码 注意-p和密码间不能有空格\n–-port=port_num, -P port_num        连接远程主机使用的端口号\n–-read-from-remote-server, -R       如果未给出该选项 任何远程连接的选项都被忽略\n\n--result-file=name, -r name         输出到给定的文件\n--start-datetime=datetime           从二进制中的日志某个日期开始读取往后的日志\n--stop-datetime=datetime            读取二进制中的日志某个日期为止\n--start-postition=N                 从二进制中的某个位置开始读取 (# at 1 中的1就是N)\n--stop-postition=N                  读取到二进制中的某个位置为止\n–-disable-logs-bin,-D               如果直接将日志传给MySQL执行 此选项禁用二进制日志\n如果数据库配置的有主从同步的话 不可以禁用二进制日志方式恢复否则可能因为没有二进制日志的产生 slave库并没有恢复数据\nmysqlbinlog打印出来的数据是可以直接导入mysql的如果想把当时INSERT语句的执行日期也记录 就需要把SET TIMESTAMP也保留下\n也可以通过以下方式直接将数据恢复到MySQL\nmysqlbinlog mysql-bin.000009 \\ \n--start-position=7492 --stop-position=647724 \\\n|grep zf_total_increment -B1 -A1 |mysql -uroot -p123456 dbinfo\n这个例子通过事务在日志中的位置来恢复的 grep的 -B1 参数同时保留了SET TIMESTAMP语句然后直接通过管道符提交给MySQL MySQL选择要恢复到的库\n每一个二进制日志文件的position都是从新开始 如果在多个文件内恢复 可能就不如datetime方便了但是可以精确到每一条语句上 datetime的话 可能1秒内就有好多条语句\n","categories":["MySQL"],"tags":["数据恢复","mysqlbinlog"]},{"title":"Busybox构建最小容器","url":"/2016/04/21/2016/Busybox%E6%9E%84%E5%BB%BA%E6%9C%80%E5%B0%8F%E5%AE%B9%E5%99%A8/","content":"简介\nBusyBox 是一个集成了一百多个最常用linux命令和工具的软件。BusyBox 包含了一些简单的工具，例如ls、cat和echo等等，还包含了一些更大、更复杂的工具，例grep、find、mount以及telnet。有些人将 BusyBox 称为 Linux 工具里的瑞士军刀。简单的说BusyBox就好像是个大工具箱，它集成压缩了 Linux 的许多工具和命令，也包含了 Linux 系统的自带的shell。百度百科\n\n环境\nbusybox编译安装方式和编译内核的方式一样 所以需要安装make, ncurses, gcc支持\n\nubuntu: apt-get install make gcc libncurses5-dev\ncentos: yum install make gcc ncurses-devel\n\n\n\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nBusybox\n1.24.2\n下载地址\n\n\n\n步骤配置Busybox编译选项tar xf busybox-1.24.2.tar.bz2cd busybox-1.24.2make menuconfig\n这时 将打开busybox编译的配置页面 为了方便起见 打算静态编译Busybox\n    Busybox Settings  ---&gt;          # 这里是对busybox的设置\n--- Applets                         # 以下的都是对小程序的配置\n    Archival Utilities  ---&gt;\n    Coreutils  ---&gt;\n    Console Utilities  ---&gt;\n    Debian Utilities  ---&gt;\n    Editors  ---&gt;\n    Finding Utilities  ---&gt; \n    Init Utilities  ---&gt;\n    Login/Password Management Utilities  ---&gt;\n静态编译Busybox属于Busybox的设定 上下键将光标选定Busybox Settings 回车进入\nGeneral Configuration  ---&gt;             # 这里是通用配置\nBuild Options  ---&gt;                     # 这里是编译选项\nDebugging Options  ---&gt; \nInstallation Options (&quot;make install&quot; behavior)  ---&gt;    \nBusybox Library Tuning  ---&gt;\n选择Build Options 回车进入\n[*] Build BusyBox as a static binary (no shared libs)       # 在这里\n[ ] Force NOMMU build (NEW)\n[*] Build with Large File Support (for accessing files &gt; 2 GB) (NEW)\n()  Cross Compiler prefix (NEW)\n()  Path to sysroot (NEW)\n()  Additional CFLAGS (NEW)\n()  Additional LDFLAGS (NEW)\n()  Additional LDLIBS (NEW)\n光标处在Build BusyBox as a static binary处 空格键选择 [ ]变成了[*]然后左右键切换光标到exit 回车回到上一个页面 选择 General Configuration 回车进入\n[*] Show applet usage messages (NEW)\n[*]   Show verbose applet usage messages (NEW)\n[*]   Store applet usage messages in compressed form (NEW)\n[*] Support --install [-s] to install applet links at runtime (NEW)\n[ ] Don&apos;t use /usr (NEW)\n[*] Enable locale support (system needs locale for this to work)    # 在这里\n[*] Support Unicode (NEW)\n[ ]   Use libc routines for Unicode (else uses internal ones) (NEW)\n[ ]   Check $LC_ALL, $LC_CTYPE and $LANG environment variables (NEW)\n(63)  Character code to substitute unprintable characters with (NEW)\n在 Enable locale support  处摁空格进行勾选 启动locale支持 然后一路的exit 直到以下界面\nDo you wish to save your new configuration? \n\n        &lt; Yes &gt;      &lt;  No  &gt;   \n选择 &lt; Yes &gt; 后页面将会退出 配置也就完成了 \n修改源代码 提供中文显示支持\n默认busybox不支持中文字符显示 接下来修改源代码 提供中文显示支持\n\nvim ./libbb/printable_string.c\n找到31,32行 删除或注释这两行找到45行 将”if (c &lt; ‘ ‘ || c &gt;= 0x7f)”注释”|| c &gt;= 0x7f”\n29                 if (c &lt; &apos; &apos;)\n30                         break;\n31         //      if (c &gt;= 0x7f)\n32         //              break;\n\n45          if (c &lt; &apos; &apos;/* || c &gt;= 0x7f*/)\n46                  *d = &apos;?&apos;;\n开始编译安装makemake install\n这时 busybox已经编译好了 就是当前目录下的busybox文件 检测一下busybox是否可以显示中文\nroot@ubuntu:~/busybox-1.24.2# touch 中文测试\nroot@ubuntu:~/busybox-1.24.2# ./busybox ls 中文测试\n中文测试\nroot@ubuntu:~/busybox-1.24.2# ldd ./busybox\n    not a dynamic executable\n\n可以看到 中文名称的文件被正常显示 同时这个程序是个没有依赖的二进制文件\n执行make install后 会将busybox和小程序的软链接都安装到当前目录中的_install/目录中 接下来就是打包为一个能正常启动docker容器\n打包为docker镜像\n如果只是编译安装Busybox的话 到这里就完了 下面是如何将Busybox制作为rootfs\n\nroot@ubuntu:~/busybox-1.24.2# cd _install/\nroot@ubuntu:~/busybox-1.24.2/_install# ls\nbin  linuxrc  sbin  usr\n进入_install目录 可以看到已经存在几个busybox安装 小程序链接所存在的必须目录\nroot@ubuntu2:~/busybox-1.24.2/_install# ls -lh bin |head \ntotal 2.6M\nlrwxrwxrwx 1 root root    7 Apr 20 22:24 ash -&gt; busybox\nlrwxrwxrwx 1 root root    7 Apr 20 22:24 base64 -&gt; busybox\n-rwxr-xr-x 1 root root 2.6M Apr 20 22:24 busybox\nlrwxrwxrwx 1 root root    7 Apr 20 22:24 cat -&gt; busybox\nlrwxrwxrwx 1 root root    7 Apr 20 22:24 catv -&gt; busybox\nlrwxrwxrwx 1 root root    7 Apr 20 22:24 chattr -&gt; busybox\nlrwxrwxrwx 1 root root    7 Apr 20 22:24 chgrp -&gt; busybox\nlrwxrwxrwx 1 root root    7 Apr 20 22:24 chmod -&gt; busybox\nlrwxrwxrwx 1 root root    7 Apr 20 22:24 chown -&gt; busybox\n可以看到 其实所有的命令都是软链接到busybox程序的 执行不同的命令 就有不同的效果\nroot@ubuntu:~/busybox-1.24.2/_install# bin/date\nWed Apr 20 23:07:48 EDT 2016\nroot@ubuntu:~/busybox-1.24.2/_install# bin/uname -a\nLinux ubuntu 4.2.0-16-generic #19-Ubuntu SMP Thu Oct 8 15:35:06 UTC 2015 x86_64 GNU/Linux\n原理非常简单 busybox程序通过判断 $0 也就是自身的名字是什么 来执行相应的功能 默认也可以通过将命令作为 $1 传入busybox\nroot@ubuntu:~/busybox-1.24.2/_install# bin/busybox date\nWed Apr 20 23:11:01 EDT 2016\nroot@ubuntu:~/busybox-1.24.2/_install# bin/busybox uname -a\nLinux ubuntu 4.2.0-16-generic #19-Ubuntu SMP Thu Oct 8 15:35:06 UTC 2015 x86_64 GNU/Linux\n当前目录下的文件夹还缺少了很多Linux根文件系统存在的文件夹 现在创建这些文件夹\nmkdir etc lib64 mnt proc run tmp var dev home lib media opt root sysmkdir var/&#123;log,opt,spool,run&#125;mkdir usr/&#123;include,lib,share,src,local&#125;mkdir usr/local/&#123;bin,sbin,include,lib,share,src&#125;cp /etc/&#123;passwd,shadow,gshadow,group&#125; etc/chmod a+wrxt tmp/\nroot@ubuntu:~/busybox-1.24.2/_install# ls\nbin  etc   lib    linuxrc  mnt  proc  run   sys  usr\ndev  home  lib64  media    opt  root  sbin  tmp  var\n现在再看 好像已经像那么回事了 接下来就是将这个rootfs打包为docker镜像\nroot@ubuntu:~/busybox-1.24.2/_install# tar -cf /dev/stdout *|docker import - busybox:1.24.2\nsha256:5b5e476a877a87b5c4c976a2a6db1782c2d89e8177e6f4d9658127320d27c1cb\nroot@ubuntu:~/busybox-1.24.2/_install# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             SIZE\nbusybox             1.24.2              5b5e476a877a        10 seconds ago      2.635 MB\n通过tar命令 将归档数据传入标准输出 通过管道符提交给docker去导入 然后命名新镜像为busybox:1.24.2 可以看到已经导入成功了 大小仅仅2.635 MB\n测试Busybox运行效果\n从busybox镜像启动一个新的容器 进行简单的命令测试 以后打包服务为docker镜像时就可以使用这个镜像为基础了\n\nroot@ubuntu:~/busybox-1.24.2/_install# docker run -ti --rm busybox:1.24.2 sh\n/ # ifconfig eth0\neth0      Link encap:Ethernet  HWaddr 02:42:AC:12:00:07  \n          inet addr:172.18.0.7  Bcast:0.0.0.0  Mask:255.255.0.0\n          inet6 addr: fe80::42:acff:fe12:7/64 Scope:Link\n          UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n          RX packets:6 errors:0 dropped:0 overruns:0 frame:0\n          TX packets:6 errors:0 dropped:0 overruns:0 carrier:0\n          collisions:0 txqueuelen:0 \n          RX bytes:508 (508.0 B)  TX bytes:508 (508.0 B)\n\n/ # ls /\nbin      etc      lib      linuxrc  mnt      proc     run      sys      usr\ndev      home     lib64    media    opt      root     sbin     tmp      var\n附录Busybox容器通过远程连接访问\nbuxybox自带了telnetd小程序 这样就可以通过telnet工具远程登录这个容器了\n\n/ # telnetd             # 启telnetd程序 可以看到已经正常监听23端口\n/ # netstat -anpt\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address       Foreign Address      State      PID/Program name    \ntcp        0      0 :::23               :::*                 LISTEN     8/busybox\n/ # adduser busybox     # 然后添加一个远程登录的用户名 默认是禁止root登录\nChanging password for busybox\nNew password: \nBad password: too weak\nRetype password: \nPassword for busybox changed by root\n添加用户的同时会让你更改用户密码 接下来就可以试试用telnet工具远程登录到这个容器了\nroot@ubuntu:~# telnet 172.18.0.7\nTrying 172.18.0.7...\nConnected to 172.18.0.7.\nEscape character is &apos;^]&apos;.\n\nea68afe67966 login: busybox\nPassword: \n~ $ date\nThu Apr 21 03:50:10 UTC 2016\n~ $\n如果想切换到root用户 需要给busybox添加suid权限 在上一个本地会话中完成添加 \n/ # chmod +s /bin/busybox\n/ # vi /etc/passwd              # 由于不存在bash 切换root时会出错 所以需要更改root的默认shell\n    root:x:0:0:root:/root:/bin/sh\n/ # passwd root                 # 给root配置一个复杂些的密码\nChanging password for root\nNew password: \nRetype password: \nPassword for root changed by root\n/ # \n然后回到telnet登录的会话中 用 su 命令切换到root用户 切换成功\n~ $ su\nPassword: \n/home/busybox #\n不仅telnetd服务 busybox还提供了httpd, udhcpd, tftpd, ntpd, dnsd等服务 还包括了linux常用的三四百条命令 真的是麻雀虽小五脏俱全  这样 一个功能强大 大小仅2.6MB的docker镜像就制作完成了\n","categories":["Docker"],"tags":["busybox","docker"]},{"title":"HAProxy常用配置详解","url":"/2016/07/18/2016/HAProxy%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3/","content":"简介\nHAProxy的安装非常简单 但是配置文件方面就比较复杂了 在安装路径下的doc目录下 有官方详细的使用文档。其实常用的配置也并不多 只要掌握了这些 HAProxy就可以很好的使用了\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nhaproxy\n1.6.7\n点击下载\n\n\n\n步骤\n根据功能和用途 HAProxy配置文件主要由五个部分组成 有些部分并不是必须的 可以根据实际情况使用\n\n1. global部分             设置全局配置参数\n2. defaults部分           默认参数配置部分\n3. frontend部分           设置接受用户请求的前端虚拟节点\n4. backend部分            设置后端服务器集群的配置\n5. listen部分             frontend和backend部分的结合体 \nglobal部分global\n        maxconn         10000\n        log             127.0.0.1 local0 info\n        uid             200\n        gid             200\n        chroot          /var/empty\n        daemon\n        nbproc          1\n        pidfile         /var/run/haproxy.pid\n\nmaxconn: 设定每个HAProxy进程可接受的最大并发连接数 (相当于ulimit -n的设置)\nlog: 全局的日志配置 127.0.0.1 local0表示使用本机的rsys-log服务中的local0日志设备\n    还支持四种日志级别 err, warning, info, debug\nlog-send-hostname: 在syslog信息的首部添加当前主机名 可以自定义字符串 默认当前主机名\nuid/gid: 运行HAProxy进程的uid和gid 也可以用user/group代替\nchroot: 限定运行用户的访问目录\ndaemon: 设置HAProxy进程后台运行\nnbproc: 服务启动时创建的进程数 创建多个进程 可以减少每个进程的任务队列 但是可能使服务不稳定\npidfile: pid文件位置 启动用户必须有可写权限\nstats: 用户访问统计数据的接口\nnode: 定义当前节点的名称 用于HA场景中多haproxy进程共享同一个IP地址时\ndefaults部分defaults\n        mode            http\n        retries         3\n        timeout connect 10s\n        timeout client  20s\n        timeout server  30s\n        timeout check   5s\n\nmode: 设置HAProxy实例默认运行模式 有tcp http health三个可选值\n    tcp: 在此模式下 只做数据转发 不对七层报文做检查\n    http: 会对七层报文做检查分析\n    health: 此模式基本已被废弃\nretries: 设置后端服务器连接失败重试次数 超过次数 HAProxy标记此服务器不可用\ntimeout connect: 成功连接到一台服务器最长等待时间\ntimeout client: 设置连接客户端发送数据最长等待时间 默认单位毫秒 可以使用其他单位后缀\ntimeout server: 设置服务器回应客户最长等待时间 默认单位毫秒 可以使用其他单位后缀\ntimeout check: 设置对后端服务器检查超时时间 默认单位毫秒 可以使用其他单位后缀\nfrontend部分frontend www\n        bind            *:80\n        mode            http\n        option          httplog\n        option          forwardfor\n        option          httpclose\n        log             global\n        default_backend htmpool\n\n通过frontend关键字定义了一个名为www的前端虚拟节点\nbind: 只能用在frontend和listen部分 用户定义一个或多个监听的套接字 端口还可以是个段 比如80-100\noption httplog: 开启日志记录HTTP请求\noption forwardfor: 请求头中添加X-Forwardfor-For记录 可以让后端服务器获取用户真实IP\noption httpclose: 完成一次连接请求后 HAProxy将主动关闭此TCP连接\nlog global: 使用global中定义的日志选项配置格式\ndefaults_backend: 制定默认的后端服务器池 htmpool将在backend中定义\nbackend部分backend htmpool\n        mode            http\n        option redispatch\n        option abortonclose\n        balance         roundrobin\n        cookie          SERVERID\n        option httpchk GET /\n        server web1 192.168.4.233:80 cookie server1 weight 6 check inter 2000 rise 2 fall 3\n        server web2 192.168.4.234:80 cookie server2 weight 6 check inter 2000 rise 2 fall 3\n\noption redispatch: 用于cookie保持环境下 如果后端服务器异常 将客户请求强制定向到另一台正常服务器\noption abortonclose: 服务器负载很高的情况下 自动结束当前队列中处理时间比较长的连接\nbalance: 定义负载均衡算法 HAProxy支持多种负载均衡算法 常用的如下几种\n    roundrobin: 基于权重进行轮询的调度算法\n    static-rr: 也是基于权重进行轮询的调度算法 不过为静态方法 在运行时调整其服务器权重不会生效\n    source: 基于请求源IP的算法 可以使同一个客户端的IP请求始终由一台服务器处理\n    leastconn: 将新的连接请求转发到最有最少连接数目的后端服务器 长会话的环境中比较适用\n    uri: 此算法会对部分或整个URI进行hash运算 再经过与服务器的总权重相除 转发到匹配的服务器\n    uri-param: 根据URL路径中的参数转发 可以保证同一用户的请求始终分发到同一台服务器上\n    hdr: 根据http头进行转发 如果http头名称不存在 则使用roundrobin算法进行策略转发\ncookie: 表示允许向cookie插入SERVERID 每台服务器的SERVERID可由server关键字定义\noption httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt;: 表示启用HTTP的服务状态检测功能 method支持以下几种方式\n    OPTIONS GET HEAD 一般的健康检查只需要采用HEAD方式 只查看Response的状态码是否是200就可以了\n    uri则是要检测的URL地址 version指定检测时的HTTP版本号 默认HTTP/1.0\nserver &lt;name&gt; &lt;address&gt;[:port] [param*]: 这个则是定义多台后端服务器了 \n    name: 为后端服务器指定一个名称\n    address: 后端真实服务器的IP\n    port: 后端真实服务器监听的端口号\n    param*: 为后端服务器设定的一系列参数 常用参数如下\n        check: 表示对后端服务器执行健康检查\n        inter: 设置监控状态检测的时间 单位是毫秒\n        rise: 由故障状态转移到正常状态需要成功检查的次数 rise 2表示2次检查成功 此服务器才可用\n        fall: 由正常状态转移到故障状态需要失败检查的次数\n        cookies: 目的在于实现持久连接的功能 cookie server1 表示web1的serverid为server1\n        weight: 后端服务器的权重 默认1 最大256 设置0不参与负载均衡 权重越大 被选中的概率越大\n        backup: 不参与负载均衡 只有在所有服务器都不可用的情况下才启用\nlisten部分\nfrontend和backend部分的结合体 它们中的指令 listen中都能用 新版的haproxy为了兼容旧版的才保留了listen部分 目前haproxy中 两种配置方式选一个即可\n\nlisten admin_stats\n    bind 0.0.0.0:9188\n    mode http\n    log 127.0.0.1 local0 err\n    stats refresh 30s\n    stats uri /haproxy-status\n    stats realm welcome login\\ Haproxy\n    stats auth admin:admin~!@\n    stats hide-version\n    stats admin if TRUE\n\nstats refresh: 监控统计页面的自动刷新时间\nstats uri: 监控统计页面的访问路径\nstats realm: 访问统计页面时的文本提示信息\nstats auth: 认证登陆的用户名和密码\nstats hide-version: 隐藏版本信息\nstats admin: 通过此选择 可以在监控页面上手工启用或禁用后端服务器\n附录HAProxy的日志配置策略\n默认情况下 HAProxy为了节省读写的I/0所消耗的性能 没有自动配置日志输出功能 但是为了方便维护和调试 还是需要开启的\n\n确定系统已经安装rsyslog\nyum install -y rsyslog\n\n添加配置文件 vim /etc/rsyslog.d/haproxy.conf\n    $ModLoad imudp\n    $UDPServerRun 514\n    local0.* /var/log/haproxy.conf\n\n通过UDP 514端口接收日志 然后还要修改/etc/sysconfig/rsyslog\n修改为: SYSLOGD_OPTIONS=&quot;-c 2 -r -m 0&quot;\n\n然后重启rsyslog服务即可\nservice rsyslog restart\n这里只讲解了HAProxy常用的配置方法 如果想深入了解其他配置项 可以查阅官方文档官方文档位置: /usr/local/haproxy/doc/haproxy/\n","categories":["HAProxy"],"tags":["代理服务器","负载均衡"]},{"title":"MySQL编译安装","url":"/2016/04/01/2016/MySQL%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"简介\nMySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，目前属于 Oracle 旗下公司。MySQL 最流行的关系型数据库管理系统，在 WEB 应用方面MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一。MySQL是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。MySQL所使用的 SQL 语言是用于访问数据库的最常用标准化语言。MySQL 软件采用了双授权政策，它分为社区版和商业版，由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。由于其社区版的性能卓越，搭配 PHP 和 Apache 可组成良好的开发环境百度百科\n\n环境\n初始化系统编译环境 选择合适的MySQL版本进行下载 实验用CentOS 6.7 编译安装 MySQL-5.6.28MySQL5.7对cmake最低版本要求是2.8.2 如果cmake版本不够 需升级cmake \n\nyum -y install make gcc-c++ gcc cmake bison-devel ncurses-devel perl\n\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nmysql\n5.5.47\n点击下载\n\n\nmysql\n5.6.28\n点击下载\n\n\nmysql\n5.7.11\n点击下载\n\n\n\n步骤开始编译\nMySQL 5.5和5.6版本编译过程差不多 5.7版本开始依赖boost库链接中5.7的下载地址是已经包含了boost头文件的源码包\n\ntar xf mysql-5.6.28.tar.gzcd mysql-5.6.28cmake  \\-DCMAKE_INSTALL_PREFIX=/usr/local/mysql    \\-DMYSQL_DATADIR=/usr/local/mysql/data    \\-DSYSCONFDIR=/etc   \\-DWITH_MYISAM_STORAGE_ENGINE=1 \\-DWITH_INNOBASE_STORAGE_ENGINE=1 \\-DWITH_MEMORY_STORAGE_ENGINE=1 \\-DWITH_READLINE=1 \\-DMYSQL_UNIX_ADDR=/var/lib/mysql/mysql.sock \\-DMYSQL_TCP_PORT=3306 \\-DENABLED_LOCAL_INFILE=1 \\-DWITH_PARTITION_STORAGE_ENGINE=1 \\-DEXTRA_CHARSETS=all \\-DDEFAULT_CHARSET=utf8 \\-DDEFAULT_COLLATION=utf8_general_ci \\# -DWITH_BOOST=boost       # 注意 MySQL5.7需要开启此选项make -j4                   # MySQL编译是个比较慢的过程 这里启动四个进程去并行编译make install               # MySQL被安装到/usr/local/mysql中\n配置运行环境useradd mysql -M -s /sbin/nologin       # 创建mysql运行用户 默认同时创建组chown -R mysql:mysql /usr/local/mysql   # 更改mysql基础目录的所有者cd /usr/local/mysqlscripts/mysql_install_db --datadir=/usr/local/mysql/data/ --user=mysql# MySQL5.7版本通过 mysqld --initialize 进行初始化数据库# bin/mysqld --initialize --user=mysql --datadir=/usr/local/mysql/data/# 初始化后会生成一个随机的密码 记住这个随机密码# [Note] A temporary password is generated for root@localhost: h&lt;iJP&gt;aU2C,9echo /usr/local/mysql/lib &gt; /etc/ld.so.conf.d/mysql5.6.confldconfig -v |grep /usr/local/mysql/lib   # 查看/usr/local/mysql/lib是否被加入到系统运行库中echo 'export PATH=$PATH:/usr/local/mysql/bin' &gt; /etc/profile.d/mysql5.6.shsource /etc/profile                      # 将mysql等命令加入到环境变量 并立即生效cp support-files/my-default.cnf /etc/my.cnf         # 提供配置文件 cp support-files/mysql.server /etc/init.d/mysqld    # 提供mysqld服务控制脚本\nvim /etc/my.cnf                     # 修改如下内容\n\nbasedir = /usr/local/mysql          # mysql基础目录\ndatadir = /usr/local/mysql/data     # mysql数据库目录\nport = 3306                         # 服务监听端口\n启动服务/etc/init.d/mysqld startservice mysqld startmysqld_safe &amp;               # 三种方式均可启动服务\n如果服务启动失败 查看MySQL错误日志\n默认路径为：/usr/local/mysql/data/`hostname`.err\n输入mysql 查看是否正常连接\n\n[root@8be3d6481fd9 data]# mysql\nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 2\nServer version: 5.6.28 Source distribution\n\nCopyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.\n\nmysql&gt; \n\n\nMySQL5.7 需要通过这个随机密码登录 而且登录后必须修改密码才能正常使用\n\n[root@8be3d6481fd9 data] # mysql -uroot -p\nEnter password: \nWelcome to the MySQL monitor.  Commands end with ; or \\g.\nYour MySQL connection id is 2\nServer version: 5.7.11\n\nCopyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved.\n\nOracle is a registered trademark of Oracle Corporation and/or its\naffiliates. Other names may be trademarks of their respective\nowners.\n\nType &apos;help;&apos; or &apos;\\h&apos; for help. Type &apos;\\c&apos; to clear the current input statement.\n\nmysql&gt;set password=password(&apos;yourpassword&apos;);\n\n下次就可以通过新密码登录了 &quot;set password=password(&apos;&apos;);&quot; 可以配置空密码\n附录MySQL授权远程登录用户 这样就可以在其他主机远程登录MySQL了\ngrant all privileges on *.* to &quot;user&quot;@&quot;%&quot; identified by &quot;password&quot;;\n\nMySQL忘记登录密码处理\n先停掉原来的服务 通过跳过授权表 不使用网络连接启动mysql\nmysqld_safe --user=mysql --skip-grant-tables --skip-networking &amp;\n\n直接通过mysql命令登录 然后修改mysql.user表的信息\nupdate mysql.user set password=password(&apos;yourpasswd&apos;) where user=&apos;root&apos;;\n\nMySQL5.7 的密码字段为authentication_string\nupdate mysql.user set authentication_string=password(&apos;yourpasswd&apos;) where user=&apos;root&apos;;\n\n通过修改/etc/my.cnf可以修改mysql的数据库目录等位置 修改完数据库位置后可能需要重新初始化数据库\n","categories":["MySQL"],"tags":["mysql","关系型数据库","LNMP"]},{"title":"Nginx服务控制","url":"/2016/05/16/2016/nginx%E6%9C%8D%E5%8A%A1%E6%8E%A7%E5%88%B6/","content":"简介\nNginx可以通过向主进程发送信号的方式进行控制 甚至可以完成在不停止服务的情况下 对程序进行重启 升级 甚至回滚操作\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nnginx\n1.9.13\n点击下载\n\n\n\n步骤启动Nginx\nNginx的启动很简单 如果配置了环境变量 可以直接通过nginx命令启动 也可以通过绝对路径启动\n\n/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf\n参数 “-c” 指定了配置文件的路径 如果不使用 “-c” 参数的话 nginx 会默认加载编译选项 --conf-path=PATH 中指定的路径\n关闭Nginx\n在早期 Nginx的关闭一般通过发送系统信号给Nginx主程序的方式来停止Nginx 之后的版本 Nginx添加了 “-s” 参数可以对Nginx主程序进行控制 通过信号的方式 需要先找到Nginx master进程的PID号 或者通过查看 nginx.pid文件来获取Nginx主进程的PIDNginx能处理的停止信号有两种 一种是 QUIT  当Nginx接受到这个信号时 会处理完当前所有的请求 并有序的关闭服务另一种是 TERM 或 INT  Nginx收到这两种信号 会尽可能快的停止web服务 不保证处理完所有请求当然 还有一种Nginx不可控的信号 KILL  会强制杀死Nginx的进程\n\nPID=`ps aux |grep nginx |grep master |awk '&#123;print $2&#125;'`PID=`cat /var/run/nginx/nginx.pid`echo $PID\n通过以上方法 即可获取Nginx主程序的PID号了 接下来就是通过kill命令向Nginx发送信号\nkill -QUIT $PID             # 安全从容的退出kill -INT $PID              # 尽可能快的退出 kill $PID                   # 尽可能快的退出 因为默认kill发送的是TERM信号kill -KILL $PID             # 强制杀死\n较高版本的Nginx的 “-s” 参数也可以对Nginx进行控制 Nginx会读取nginx.pid文件来获取master进程的PID 然后向这个PID发送信号\n/usr/local/nginx/sbin/nginx -s quit         # 安全从容的退出 实质上还是发送QUIT信号/usr/local/nginx/sbin/nginx -s stop         # 尽可能快的退出 实质上发送TREM或INT信号\nNginx平滑重启\n在Nginx运行过程中 如果修改了配置文件 但是又不想停止Nginx再重启让配置文件生效 也可以通过发送信号的方式 通知Nginx重新读取配置文件\n\n/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf\n修改nginx配置文件后 可以通过 -t 参数对配置文件进行检测 如果不通过 -c 指定配置文件 会检查默认的配置文件 当检查通过 就可以通知Nginx主进程重新读取了\nkill -HUP $PID              # 通过HUP信号 可以通知Nginx主进程重新读取配置文件/usr/local/nginx/sbin/nginx -s reload       # 同理 reload也是向Nginx主进程发送HUP信号\nNginx在收到HUP信号时 回先解析配置文件 如果解析成功 就应用新的配置文件 之后 Nginx运行新的工作进程 并从容关闭旧的工作进程 等所有的请求处理完毕后 旧的工作进程被关闭 \nNginx平滑升级\n如果想给正在运行中的Nginx升级版本 或者添加/删除服务模块 可以在服务不间断的情况下 对Nginx进行升级\n\n\n备份原本的nginx二进制 为了意外恢复 并使用新的二进制程序代替了以前的位置\n向Nginx主程序发送USR2信号\n旧版的Nginx主程序将nginx.pid重命名为nginx.pid.oldbin 然后执行新版本的Nginx可执行程序 将新的PID写入nginx.pid文件\n当前新旧两个Nginx进程会同时提供服务 还需要手动关闭旧Nginx主进程 仅保留新的Nginx主进程\n\nmv /usr/local/nginx/sbin/&#123;nginx,nginx.old&#125;cp objs/nginx /usr/local/nginx/sbin/nginx       # 默认nginx编译后在源码包的objs目录中 也可以直接make install覆盖安装kill -USR2 $PID             # 向Nginx主进程的PID号发送USR2信号\n现在可以看到 新旧两个Nginx主进程在同时提供服务 发送 WINCH 信号 可以通知Nginx主进程从容的关闭工作进程(worker process) 这时将只剩下新的Nginx的工作进程提供服务kill -WINCH $PID\n如果一段时间 新Nginx工作正常 就可以向旧版Nginx发送退出信号 结束掉旧Nginx的主进程了 旧进程退出后还会移除nginx.pid.oldbin文件kill $OLD_PID\n如果运行一段时间 发现并不是理想中的那种工作状态 那么可以发送 HUP 信号向旧Nginx主进程 让其重新打开工作进程 接着向新Nginx主进程发送 QUIT 信号 从容关闭主进程 最后恢复旧nginx的二进制文件kill -HUP $OLD_PIDkill -QUIT $PIDmv /usr/local/nginx/sbin/&#123;nginx.old,nginx&#125;      # 不要忘记恢复旧的二进制文件\nNginx日志控制\nNginx的访问日志会记录客户端的每次一请求 所以在用户量大的情况下 会很容易变得很大 也可以通过发送信号的方式进行控制日志 而不用关闭Nginx服务\n\nNginx主进程启动后 便会一直打开access.log日志文件 当服务器被长时间的访问 这个日志会越来越大 不利于日后的清理 由于这个日志文件被Nginx一直处于打开的状态 冒然删除这个日志文件并不是个很好的方法 而且删除后 Nginx还会向该文件的inode节点写入日志数据 因此 文件即使被删除 文件系统空间也不会释放 这样就只有重启Nginx才能释放空间并读写新的日志了\n因此 管理access.log的方式不应该用直接删除文件的方式 如果对日志内容不在意 可以直接清空文件echo &gt; /usr/local/nginx/logs/access.log\n还有一个更好的方式 就是让Nginx重新打开一个新的文件进行读取 先将原来的access.log重命名 因为重命名并不会更改文件的inode节点 所以不会影响Nginx程序的日志写入 接着发送 USR1 信号 Nginx主程序将打开一个新的access.log文件开始写入kill -USR1 $PID/usr/local/nginx/sbin/nginx -s reopen           # 重新打开日志文件 和 USR1 同理\n附录\nNginx支持的信号汇总\n\n\n\n\n信号类型\n功能\n\n\n\n\nTREM 或 INT\n快速关闭Nginx服务\n\n\nQUIT\n从容关闭Nginx服务\n\n\nHUP\n通知Nginx重新读取配置文件\n\n\nUSR1\n重新打开日志文件 常用于日志分割\n\n\nUSR2\n平滑升级可执行程序\n\n\nWINCH\n从容关闭工作进程\n\n\n\n","categories":["Nginx"],"tags":["nginx"]},{"title":"Nginx编译安装","url":"/2016/03/31/2016/nginx%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"简介\nNginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。由俄罗斯的程序设计师Igor Sysoev所开发，供俄国大型的入口网站及搜索引擎Rambler使用。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、新浪、网易、腾讯等。百度百科\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\npcre\n8.38\n点击下载\n\n\nopenssl\n1.0.1s\n点击下载\n\n\nnginx\n1.9.13\n点击下载\n\n\n\n步骤\n需要系统先初始化开发环境\n\nyum install -y gcc gcc-c++ zlib-devel make\n解压pcre源码\nNginx的 HTTP rewrite module 依赖pcre库 所以所以nginx需要pcre的源码\n\ntar xf pcre-8.38.tar.bz2\n解压备用 无需编译\n解压openssl源码tar xf openssl-1.0.1s.tar.gz\n解压备用 无需编译\n编译安装Nginxtar xf nginx-1.9.13.tar.gzcd nginx-1.9.13./configure --prefix=/usr/local/nginx \\--pid-path=/var/run/nginx/nginx.pid \\--lock-path=/var/lock/nginx.lock \\--user=nginx --group=nginx \\--with-http_ssl_module \\--with-http_flv_module \\--with-stream \\--with-http_stub_status_module \\--with-http_gzip_static_module \\--with-openssl=/usr/local/ssl \\--http-client-body-temp-path=/var/tmp/nginx/client/ \\--http-proxy-temp-path=/var/tmp/nginx/proxy/ \\--http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \\--http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \\--http-scgi-temp-path=/var/tmp/nginx/scgi \\--with-pcre=../pcre-8.38 \\          # pcre源码的路径--with-openssl=../openssl-1.0.1s    # openssl源码的路径make -j4 &amp;&amp; make install            # nginx被安装到/usr/local/nginx中\n运行Nginx\nNginx 默认运行用户是nginx 所以需要先创建nginx用户和组。还需要创建Nginx运行需要的一些目录才能将Nginx正常启动\n\nuseradd nginx -M -s /sbin/nologinmkdir -p /var/tmp/nginx/client//usr/local/nginx/sbin/nginx\n检查nginx是否正常启动web服务\nnetstat -anpt |grep nginx\ntcp     0     0 0.0.0.0:80     0.0.0.0:*      LISTEN     33170/nginx\n\n通过浏览器访问服务器 看是否出现了Welcome to nginx!\n附录/usr/local/nginx/sbin/nginx -h\nnginx version: nginx/1.9.13\nUsage: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives]\n\nOptions:\n  -?,-h         : 展示帮助\n  -v            : 展示版本后退出\n  -V            : 展示版本和配置信息后退出\n  -t            : 测试配置文件后退出\n  -T            : 测试配置文件后展示出来 然后退出\n  -q            : 在配置测试过程中抑制非错误消息\n  -s signal     : 向主线程发送信号: stop, quit, reopen, reload\n  -p prefix     : 设置主目录 (default: /usr/local/nginx/)\n  -c filename   : 设置配置文件 (default: conf/nginx.conf)\n  -g directives : 设置全局指令的配置文件\n","categories":["Nginx"],"tags":["代理服务器","负载均衡","LNMP","web服务器"]},{"title":"Nginx编译参数详解","url":"/2016/05/16/2016/nginx%E7%BC%96%E8%AF%91%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/","content":"简介\n主要介绍Nginx编译安装的可选项 以后对Nginx进行升级 或者功能拓展都可以查阅 查找合适的模块\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nnginx\n1.9.13\n点击下载\n\n\n\n步骤tar xf nginx-1.9.13.tar.gzcd nginx-1.9.13./configure --help\n--help                             打印帮助信息\n\n--prefix=PATH                      Nginx安装路径 默认 /usr/local/nginx\n--sbin-path=PATH                   Nginx可执行文件安装路径 默认 &lt;prefix&gt;/sbin/nginx\n--modules-path=PATH                Nginx动态模块安装路径 默认 &lt;prefix&gt;/modules\n--conf-path=PATH                   Nginx配置文件的路径 默认 &lt;prefix&gt;/conf/nginx.conf\n--error-log-path=PATH              nginx.conf中没有指定的情况下 错误日志默认路径 &lt;prefix&gt;/logs/error.log\n--pid-path=PATH                    nginx.conf中没有指定的情况下 pid文件默认路径 &lt;prefix&gt;/logs/nginx.pid\n--lock-path=PATH                   nginx.lock文件的路径\n\n--user=USER                        nginx.conf中没有指定的情况下 Nginx使用的用户 默认 nobody\n--group=GROUP                      nginx.conf中没有指定的情况下 Nginx使用的用户组 默认 nobody\n\n--build=NAME                       指定编译的名字\n--builddir=DIR                     指定编译的目录\n\n--with-select_module               允许select模式 根据configure检测 如果没有更好的 select将是默认方式\n--without-select_module            不允许select模式\n--with-poll_module                 允许poll模式\n--without-poll_module              不允许poll模式\n\n--with-threads                     允许线程池支持\n\n--with-file-aio                    允许file aio支持 (文件异步读写模型)\n--with-ipv6                        启动 ipv6 支持\n\n--with-http_ssl_module             提供HTTPS支持\n--with-http_v2_module              支持HTTP2协议\n--with-http_realip_module          获取客户机真实IP模块 \n--with-http_addition_module        添加在响应之前或之后追加内容的模块\n--with-http_xslt_module            通过XSLT模板转换XML应答\n--with-http_xslt_module=dynamic    通过XSLT模板转换XML应答 编译为动态模块\n--with-http_image_filter_module    传输JPEG/GIF/PNG 图片的一个过滤器\n--with-http_image_filter_module=dynamic       同上 编译为动态模块\n--with-http_geoip_module           获取IP所属地的模块\n--with-http_geoip_module=dynamic   获取IP所属地的模块 编译为动态模块\n--with-http_sub_module             允许替换响应中的一些文本\n--with-http_dav_module             开启WebDAV扩展动作模块\n--with-http_flv_module             提供flv播放服务的模块\n--with-http_mp4_module             提供mp4播放服务的模块\n--with-http_gunzip_module          提供gunzip压缩的模块\n--with-http_gzip_static_module     在线实时压缩输出数据流 能有效节省带宽\n--with-http_auth_request_module    客户子请求的认证基础\n--with-http_random_index_module    随机目录索引\n--with-http_secure_link_module     检查客户请求链接 可以用于下载防盗链\n--with-http_degradation_module     允许在内存不足的情况下返回204或444码\n--with-http_slice_module           切片模块\n--with-http_stub_status_module     Nginx工作状态统计模块\n\n--without-http_charset_module      禁用重新编码web页面模块\n--without-http_gzip_module         禁用在线实时压缩输出数据流\n--without-http_ssi_module          禁用服务器端包含模块\n--without-http_userid_module       禁用用户ID模块 该模块为用户通过cookie验证身份\n--without-http_access_module       禁用访问模块 对于指定的IP段 允许访问配置\n--without-http_auth_basic_module   禁用基本的认证模块\n--without-http_autoindex_module    禁用目录自动索引模块\n--without-http_geo_module          禁用Geo模块\n--without-http_map_module          禁用Map模块 该模块允许你声明map区段\n--without-http_split_clients_module 禁用基于某些条件将客户端分类模块\n--without-http_referer_module      禁用 过滤请求 拒绝报头中Referer值不正确的请求的模块\n--without-http_rewrite_module      禁用url重写模块\n--without-http_proxy_module        禁用http代理模块\n--without-http_fastcgi_module      禁用fastcgi模块\n--without-http_uwsgi_module        禁用uwsgi模块\n--without-http_scgi_module         禁用scgi模块\n--without-http_memcached_module    禁用Memcached模块\n--without-http_limit_conn_module   禁用连接限制模块\n--without-http_limit_req_module    禁用限制用户连接总和的模块\n--without-http_empty_gif_module    禁用empty_gif模块\n--without-http_browser_module      禁用Browser模块\n--without-http_upstream_hash_module    以下是禁用负载均衡相关的一些模块\n--without-http_upstream_ip_hash_module\n--without-http_upstream_least_conn_module\n--without-http_upstream_keepalive_module\n--without-http_upstream_zone_module\n\n--with-http_perl_module            通过此模块 nginx可以直接使用perl\n--with-http_perl_module=dynamic    编译为动态模块\n--with-perl_modules_path=PATH      设定模块路径\n--with-perl=PATH                   设定perl库文件路径\n\n--http-log-path=PATH               设定http访问日志路径\n--http-client-body-temp-path=PATH  设定http客户端请求临时文件路径\n--http-proxy-temp-path=PATH        设定http代理临时文件路径\n--http-fastcgi-temp-path=PATH      设定http fastcgi临时文件路径\n--http-uwsgi-temp-path=PATH        设定http uwsgi临时文件路径\n--http-scgi-temp-path=PATH         设定http scgi临时文件路径\n\n--without-http                     禁用http server功能\n--without-http-cache               禁用http cache功能\n\n--with-mail                        启用POP3/IMAP4/SMTP代理模块支持\n--with-mail=dynamic                编译为动态模块\n--with-mail_ssl_module             启用加密的邮箱代理模块\n--without-mail_pop3_module         禁用pop3模块\n--without-mail_imap_module         禁用imap模块\n--without-mail_smtp_module         禁用smtp模块\n\n--with-stream                      启动tcp/udp代理模块\n--with-stream=dynamic              编译为动态模块\n--with-stream_ssl_module           启动加密的tcp/udp代理模块\n--without-stream_limit_conn_module \n--without-stream_access_module     \n--without-stream_upstream_hash_module\n--without-stream_upstream_least_conn_module\n--without-stream_upstream_zone_module\n\n--with-google_perftools_module     启用google_perftools模块 优化高并发性能\n--with-cpp_test_module             启用ngx_cpp_test_module支持\n\n--add-module=PATH                  启用拓展模块 指定路径\n--add-dynamic-module=PATH          启用动态拓展模块\n\n--with-cc=PATH                     指定c编译器路径\n--with-cpp=PATH                    指定C预处理路径\n--with-cc-opt=OPTIONS              设置C编译器参数\n--with-ld-opt=OPTIONS              设置链接文件参数\n--with-cpu-opt=CPU                 指定编译的CPU 可选值:\n                                   pentium, pentiumpro, pentium3, pentium4,\n                                   athlon, opteron, sparc32, sparc64, ppc64\n\n--without-pcre                     禁用pcre库 (正则表达式)\n--with-pcre                        启用pcre库\n--with-pcre=DIR                    指定pcre库文件目录\n--with-pcre-opt=OPTIONS            在编译时为pcre库设置附加参数\n--with-pcre-jit                    构建pcre提供jit编译支持\n\n--with-md5=DIR                     指向md5库文件目录\n--with-md5-opt=OPTIONS             在编译时为md5库设置附加参数\n--with-md5-asm                     使用md5汇编源\n\n--with-sha1=DIR                    指向sha1库目录\n--with-sha1-opt=OPTIONS            在编译时为sha1库设置附加参数\n--with-sha1-asm                    使用sha1汇编源\n\n--with-zlib=DIR                    指向zlib库目录\n--with-zlib-opt=OPTIONS            在编译时为zlib设置附加参数\n--with-zlib-asm=CPU                为指定的CPU使用zlib汇编源进行优化\n\n--with-libatomic                   为原子内存的更新操作的实现提供一个架构\n--with-libatomic=DIR               指向libatomic_ops安装目录\n\n--with-openssl=DIR                 指向openssl源码目录\n--with-openssl-opt=OPTIONS         在编译时为openssl设置附加参数\n\n--with-debug                       启用debug信息\n附录\n只需要在编译nginx时添加相应的选项就可以了 Nginx详细编译安装教程\n\n","categories":["Nginx"],"tags":["nginx"]},{"title":"PHP模块拓展","url":"/2016/07/12/2016/php%E6%A8%A1%E5%9D%97%E6%8B%93%E5%B1%95/","content":"简介\n在PHP开发环境中可能发现项目依赖一些先前并没有编译进入的模块 或者需要用到一些第三方模块 那么该如何对PHP进行动态的拓展模块 而不用重新编译PHP呢\n\n环境\n实验已安装环境为PHP 5.5.33版本 \n\n\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nphp\n5.5.33\n下载地址\n\n\nphp\n5.6.19\n下载地址\n\n\nphp\n7.0.4\n下载地址\n\n\nmemcache\n3.0.8\n下载地址\n\n\n\n步骤\n如果后期的开发需要用到php的其他模块 或者第三方模块 那就需要对php进行模块升级模块安装的方式有两种 在linux 可以选择将模块编译入php程序中 也可以作为单独的so文件让php加载\n\n准备好php的源码包 要和当前php版本一致 下面用第三方模块memcache和自带模块soap做示例\n编译安装自带模块soap\n解压了PHP的源码包后 进入到源码包目录的ext目录下 这个是PHP自带的所有模块\n\ntar xf php-5.5.33.tar.xzcd php-5.5.34/ext/soap//usr/local/php/bin/phpize./configure --with-php-config=/usr/local/php/bin/php-configmake &amp;&amp; mkdir /usr/local/php/extensions/cp modules/soap.so /usr/local/php/extensions/\n可以看到 ext目录下 有非常多的模块文件夹 进入soap目录中后 先执行phpize脚本才会生成configure文件\n之后指定php-config的位置来进行生成Makefile文件 最后生成的二进制so文件在modules目录内\n为什么不直接make install呢 因为make install安装到的目录感觉并不是非常方便管理\n在php安装目录下建立一个文件夹 可以将所有的二进制so文件都放入到这个文件夹内\n\n接下来就是让php加载这个模块了 修改php.ini文件 添加以下配置\n\nextension_dir = &quot;/usr/local/php/extensions&quot;\nextension=soap.so\n\n先是配置好拓展模块的目录 然后下面启用的模块就可以只写模块名了 否则需要写模块的完整路径\n\n[root@e1adb08f8c82 lib]# /usr/local/php/bin/php -m |grep soap\nsoap\n[root@e1adb08f8c82 lib]#\n\n可以看到 php已经出现了soap这个模块 不放心的话 也可以通过phpinfo页面看看有没有soap模块\n\n还有一种方法安装soap模块就是重新编译php 添加 --enable-soap 配置项即可 这里不再赘诉\n编译安装第三方memcache模块\nphp所有的第三方模块都可以在 http://pecl.php.net/ 找到 这里以memcache为例\n\ntar xf memcache-3.0.8.tgz/usr/local/php/bin/phpize ./configure --with-php-config=/usr/local/php/bin/php-configcp modules/memcache.so /usr/local/php/extensions/\n接下来也是修改php.ini文件 将memcache.so加载就可以了\nextension=memcache.so\n\n[root@e1adb08f8c82 lib]# /usr/local/php/bin/php -m |grep memcache\nmemcache\n[root@e1adb08f8c82 lib]#\n\n可以看到 memcache也成功的出现在 php的模块中 \n附录不同版本的php模块是不能够通用的 反之如果环境相同的php 那么模块就不用重复编译了\n模块不通用的原因是因为 不同版本的PHP 可能使用的API不相同\n\n[root@e1adb08f8c82 memcache-3.0.8]# /usr/local/php/bin/phpize \nConfiguring for:\nPHP Api Version:         20121113\nZend Module Api No:      20121212\nZend Extension Api No:   220121212\n\n正如每次执行phpize脚本中显示的那样\n","categories":["PHP"],"tags":["php","LNMP","php-fpm"]},{"title":"Dnsmasq安装配置","url":"/2016/04/06/2016/dnsmasq%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE/","content":"简介\nDNSmasq是一个小巧且方便地用于配置DNS和DHCP的工具，适用于小型网络，它提供了DNS功能和可选择的DHCP功能。它服务那些只在本地适用的域名，这些域名是不会在全球的DNS服务器中出现的。DHCP服务器和DNS服务器结合，并且允许DHCP分配的地址能在DNS中正常解析，而这些DHCP分配的地址和相关命令可以配置到每台主机中，也可以配置到一台核心设备中（比如路由器），DNSmasq支持静态和动态两种DHCP配置方式。百度百科\n\n环境\ndnsmasq几乎没有额外的依赖 只需要系统安装好编译环境即可\n\n\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\ndnsmasq\n2.75\n下载地址\n\n\n\n步骤编译安装tar xf dnsmasq-2.75.tar.xzcd dnsmasq-2.75make &amp;&amp; make install                            # dnsmasq主程序在/usr/local/dnsmasqcp dnsmasq.conf.example /etc/dnsmasq.conf       # 配置文件\n一般到这就编译完成了 如果有特殊需求 可以通过修改Makefile文件实现\nvim Makefile\n    PREFIX        = /usr/local/dnsmasq      # 安装的位置\n    BINDIR        = $(PREFIX)/sbin\n    MANDIR        = $(PREFIX)/share/man\n    LOCALEDIR     = $(PREFIX)/share/locale\n    BUILDDIR      = $(SRC)\n    DESTDIR       =\n    CFLAGS        = -Wall -W -O2\n    LDFLAGS       = -s -static              # 去掉编译debug信息 采用静态编译 \n\n    注意 并不是所有平台修改过Makefile后都可以正常编译\n用法详解\ndnsmasq程序虽小 可五脏俱全 可以用来做DNS DHCP TFTP服务器 甚至可以用作PXE装机用打开/etc/dnsmasq.conf配置文件 可以看到所有的选项和说明 通过man 8 dnsmasq 可以看到更详细的内容为了方便配置不同的服务 将不同服务的配置文件分开 开启conf-dir=/etc/dnsmasq.d/,*.conf配置项这样 dnsmasq就会在启动的时候加载/etc/dnsmasq.d/内的*.conf文件了\n\nvim /etc/dnsmasq.conf\n修改如下内容\nconf-dir=/etc/dnsmasq.d/,\\*.conf\nDNS服务\ndnsmasq默认会启动dns服务 并读取系统的/etc/resolv.conf和/etc/hosts/etc/resolv.conf中的nameserver会被dnsmasq作为上行DNS server在遇到dnsmasq找不到的记录就像上行服务器发出请求 然后将结果返回客户机下面是dnsmasq中DNS功能一些常用的配置项\n\nport=53                                # port设置为0 会关闭dns功能\nresolv-file=/etc/dnsmasq.resolv.conf   # 从另一个文件获取上行DNS服务器地址\naddn-hosts=/etc/dnsmasq.hosts.conf     # 从另一个文件获取主机名IP地址映射\nno-resolv                              # 禁用resolv 不获取上行DNS服务器 同时resolv-file失效\nno-hosts                               # 不使用系统的hosts文件 仅使用addn-hosts配置的\nlisten-address=127.0.0.1               # 配置监听地址\ninterface=lo                           # 配置监听网卡接口\nexcept-interface=eth0                  # 配置不监听的网卡接口\n\n如果配置了resolv-file dnsmasq就不会去读取系统的/etc/resolv.conf\n而配置了addn-hosts dnsmasq会同时读取系统的/etc/hosts和配置指定的文件\n\n为了能让系统能使用自己启动的DNS服务 并且不影响访问外网等操作 可以将系统的resolv.conf的nameserver改为127.0.0.1 然后在resolv-file指定的文件写入上行DNS服务器\n\nvim /etc/dnsmasq.d/dns.conf\n写入如下内容\nresolv-file=/etc/dnsmasq.resolv.conf\naddn-hosts=/etc/dnsmasq.hosts.conf\necho 'nameserver 127.0.0.1' &gt; /etc/resolv.conf              # 系统使用本地的DNS服务器echo 'nameserver 180.76.76.76' &gt; /etc/dnsmasq.resolv.conf   # dnsmasq去查询的DNS服务器echo '127.0.0.1 test' &gt; /etc/dnsmasq.hosts.conf             # 测试dns解析效果/usr/local/dnsmasq/sbin/dnsmasq -d                          # 默认后台运行 -d 可以阻止\n接下来用ping命令检查域名解析服务是否正常了\nroot@ubuntu:/etc/dnsmasq.d# ping -c4 test \nPING test (127.0.0.1) 56(84) bytes of data.\n64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.050 ms\n64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=0.037 ms\n64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=0.034 ms\n64 bytes from localhost (127.0.0.1): icmp_seq=4 ttl=64 time=0.033 ms\n\n--- test ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3996ms\nrtt min/avg/max/mdev = 0.033/0.037/0.050/0.009 ms\n用dig命令检查 可以清楚的看到解析的A记录\nroot@ubuntu:/etc/dnsmasq.d# dig @127.0.0.1 test\ntest.            0    IN    A    127.0.0.1\n也可以用nslookup命令检查 Windows平台的话 需要将127.0.0.1改为dnsmasq所在服务器的IP\nroot@ubuntu:/etc/dnsmasq.d# nslookup test 127.0.0.1\nServer:        127.0.0.1\nAddress:    127.0.0.1#53\n\nName:    test\nAddress: 127.0.0.1\n以后只需要将需要解析的IP和名称写入/etc/dnsmasq.resolv.conf文件就可以了，不过美中不足的一点就是 每次修改了配置文件 都需要重新启动dnsmasq服务。\nDHCP服务\nDHCP服务在dnsmasq中的配置非常简单 甚至只用一行配置就可以启动一个正常工作的DHCP服务器一下是DHCP服务的常用配置项\n\ndhcp-range=192.168.1.50,192.168.1.100,12h               # 起始 结束 还有租约时间\ndhcp-range=192.168.0.50,192.168.0.150,255.255.255.0,12h # 网段\ndhcp-host=aa:bb:cc:dd:ee:ff,192.168.1.50                # mac地址 IP\ndhcp-host=00:0e:7b:ca:1c:6e,daunbook,192.168.0.12       # mac地址 主机名 IP\ndhcp-option=3,192.168.0.1                               # 默认网关\ndhcp-option=option:router,1.2.3.4                       # 默认网关 和上面的一样\ndhcp-option=option:ntp-server,192.168.0.4,10.10.0.5     # ntp服务地址\ndhcp-option=option:dns-server,180.76.76.76              # dns服务器地址\nno-dhcp-interface=eth0                                  # 不提供dhcp的接口\n\n其中只要有dhcp-range或者dhcp-host的配置 dhcp服务就会启动 接下来 添加dhcp的配置项 并检测dhcp服务是否正常分配IP\n\n# 由于只能给同网段的主机分配IP 所以这里需要在网卡上绑定一个子接口ifconfig ens32:0 192.168.100.1/24            # 网卡名称根据实际情况来定vim /etc/dnsmasq.d/dhcp.conf\n写入如下内容\ndhcp-range=192.168.100.10,192.168.100.20,12h  # 这里使用和当前局域网不同的网段\ndhcp-option=option:router,192.168.100.1  # 自己同时作为网关\n/usr/local/dnsmasq/sbin/dnsmasq -d\n可以清楚的看到dnsmasq的输出有DHCP的一些信息\ndnsmasq-dhcp: DHCP, IP range 192.168.100.10 -- 192.168.100.20, lease time 12h\n接下来检测DHCP服务是否能正常提供服务，在另外一台机器上 强行使用dhclient命令为网卡获取动态IP。\n[root@localhost ~]# dhclient -v ens32:0\nInternet Systems Consortium DHCP Client 4.2.5\nCopyright 2004-2013 Internet Systems Consortium.\nAll rights reserved.\nFor info, please visit https://www.isc.org/software/dhcp/\n\nListening on LPF/ens32/00:0c:29:44:eb:ec\nSending on   LPF/ens32/00:0c:29:44:eb:ec\nSending on   Socket/fallback\nDHCPREQUEST on ens32 to 255.255.255.255 port 67 (xid=0xba1741)\nDHCPACK from 192.168.100.1 (xid=0xba1741)\nbound to 192.168.100.19 -- renewal in 19449 seconds.\n可以看到从192.168.100.1获取了192.168.100.19这个IP 同时DHCP server端有这次请求信息。\ndnsmasq-dhcp: DHCPREQUEST(ens32) 192.168.100.19 00:0c:29:44:eb:ec \ndnsmasq-dhcp: DHCPACK(ens32) 192.168.100.19 00:0c:29:44:eb:ec\n也可以先将网卡配置为DHCP获取IP 然后重启 看看是否获取到了配置的IP段的IP 以及网关是否正确\nTFTP服务\ntftp是简单文件传输协议 有区别与一般的ftp服务 tftp使用UDP的69端口 一般用作小文件传输 下面就是如何用dnsmasq配置tftp服务\n\nenable-tftp                     # 表示启动tftp服务\ntftp-root=/tftp                 # 配置tftp的文件根目录\nvim /etc/dnsmasq.d/tftp.conf\n写入如下内容\nenable-tftp\ntftp-root=/tftp\nmkdir /tftpecho &apos;hello&apos; &gt; /tftp/test           # 添加测试文件/usr/local/dnsmasq/sbin/dnsmasq -d\n启动dnsmasq后 可以看到tftp服务也启动了\ndnsmasq-tftp: TFTP root is /tftp\n接下来验证tftp服务是否正常工作 通过tftp命令连接tftp服务 如果没有tftp命令 自行安装相应的包\nroot@ubuntu:/tmp# tftp 127.0.0.1            # 连接本地的tftp服务\ntftp&gt; get test                              # 获取刚才写入的test文件\nReceived 7 bytes in 0.0 seconds\ntftp&gt; quit                                  # quit命令退出交互\nroot@ubuntu:/tmp# cat test                  # 查看获取的文件\nhello                                       # 内容没有问题\ntftp是一个非常简单的文件传输协议 只有文件上传下载功能 列出目录之类的功能就不用想了，支持的命令也非常少 可以在ftfp的交互界面 通过输入?来查询支持的命令 或许有些命令 服务端也并不支持。\n附录用dnsmasq部署pxe自动装机\n由于dnsmasq包含了DHCP和TFTP 所以用dnsmasq搭建pxe自动装机服务是完全可行的 而且只需要简简单单的几项配置就可以了\n\nenable-tftp\ntftp-root=/tftp\ndhcp-boot=pxelinux.0\ndhcp-range=192.168.100.10,192.168.100.20,12h\n记得要将pxe装机需要的pxelinux.0等文件放到tftp-root配置的目录下，还要注意给客户分配的网段要根据实际情况分配。\n","categories":["Dnsmasq"],"tags":["dns","dhcp","tftp","pxe"]},{"title":"PHP-fpm 编译安装","url":"/2016/04/01/2016/php-fpm%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"简介\nPHP（外文名:PHP: Hypertext Preprocessor，中文名：“超文本预处理器”）是一种通用开源脚本语言。语法吸收了C语言、Java和Perl的特点，利于学习，使用广泛，主要适用于Web开发领域。PHP 独特的语法混合了C、Java、Perl以及PHP自创的语法。它可以比CGI或者Perl更快速地执行动态网页。用PHP做出的动态页面与其他的编程语言相比，PHP是将程序嵌入到HTML（标准通用标记语言下的一个应用）文档中去执行，执行效率比完全生成HTML标记的CGI要高许多；PHP还可以执行编译后代码，编译可以达到加密和优化代码运行，使代码运行更快。百度百科\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nphp\n5.5.33\n下载地址\n\n\nphp\n5.6.19\n下载地址\n\n\nphp\n7.0.4\n下载地址\n\n\nlibmcrypt\n2.5.8\n下载地址\n\n\n\n步骤\n初始化系统编译环境 选择合适的PHP版本 实验用CentOS 6.7 编译安装 php-5.6.19\n\nyum -y install make gcc-c++ gcc bzip2-devel libjpeg-turbo-devel \\\nlibpng-devel freetype-devel curl-devel mysql-devel libxml2-devel\n编译安装libmcrypt\nPHP依赖libmcrypt yum源的基础仓库没有libmcrypt的开发包 如果想yum安装 可以拓展epel仓库\n\ntar xf libmcrypt-2.5.8.tar.gzcd libmcrypt-2.5.8./configure --prefix=/usr/local/mcryptmake &amp;&amp; make install\n开始编译PHPtar xf php-5.6.19.tar.xzcd php-5.6.19./configure \\--prefix=/usr/local/php \\--enable-fpm  --with-mcrypt \\--with-zlib --enable-mbstring \\--with-openssl --with-mysql \\--with-mysqli --with-mysql-sock \\--with-gd --with-jpeg-dir=/usr/lib \\--enable-gd-native-ttf  \\--enable-pdo --with-pdo-mysql \\--with-gettext --with-curl \\--with-pdo-mysql --enable-sockets \\--enable-bcmath --enable-xml \\--with-bz2 --enable-zip \\--with-freetype-dir=/usr \\--with-mcrypt=/usr/local/mcryptmake -j4 &amp;&amp; make install\n配置运行环境mkdir /etc/phpcp ./php.ini-production /usr/local/php/lib/php.inicp /usr/local/php/etc/&#123;php-fpm.conf.default,php-fpm.conf&#125;cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpm\n启动服务service php-fpm start               # 任意方式启动即可/etc/init.d/php-fpm start/usr/local/php/sbin/php-fpm --daemonize\n[root@45c4f07c6049 etc]# netstat -anpt |grep php-fpm\ntcp    0   0 127.0.0.1:9000      0.0.0.0:*      LISTEN    49135/php-fpm\n\nphp-fpm默认使用nobody用户运行 监听127.0.0.1:9000端口\n如果想在前端显示调试信息等 可以将 --daemonize 换成 --nodaemonize \n这些配置会覆盖掉php-fpm.conf中的配置 \n附录一般php-fpm能正常监听 就没问题了 不同与Apache的模块方式\nfpm方式是通过Fastcgi方式提供服务的 web服务器将需要处理的php页面请求\n转发给php-fpm的监听端口 php-fpm将处理好的数据再返回给web服务器\n所以php-fpm方式是和web服务器无关的 只要你的web服务器支持Fastcgi\n就都可以将php页面转发给php-fpm处理 想要验证 可以搭配Nginx等服务器解析php页面试试\n","categories":["PHP"],"tags":["php","LNMP","php-fpm"]},{"title":"Python爬虫入门","url":"/2016/07/25/2016/Python%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8/","content":"简介\n网络爬虫是一个自动提取网页的程序，它为搜索引擎从万维网上下载网页，是搜索引擎的重要组成。比如百度 google等搜索引擎通过程序爬取你的个人网站，然后建立索引 这样别人就可以通过搜索关键字找到你的网站了。爬虫的意义不仅如此 还可以做更多好玩的事情。\n\n\n步骤\n用Python写网络爬虫是非常简单的 大致需要学习以下知识点\n\n\n了解HTTP协议 以及HTML标签等\n掌握Python的基本语法\n学习Python的urllib, urllib2等模块\n学习正则表达式 或者XPath\n使用Python爬虫框架帮助开发\n\n学习网络爬虫 也有人称之为网络蜘蛛 互联网是一张大网 每个人都可以在上面搭建网站 平常我们用的百度搜索的所有内容 都是百度曾经访问过的内容 然后保存下来 建立了索引 这样才能供用户查询 能快速的找到自己想要的资源 而百度去访问这些网站资源 肯定不可能人工手动去访问然后记录 背后都是一个一个的程序去抓取网页 然后根据这个网页继续往下抓取 直到收集到需要的信息 就像一个爬虫或蜘蛛 在这张大网上爬来爬去一样 来自互联网的流量 有不小的一部分并不是人为访问的 而是各大搜索引擎的爬虫程序 \n可以写爬虫的语言非常多 但是因为python的简单 方便 越来越多的人使用python来写爬虫 也出现了各种优秀的爬虫框架 下面将由浅入深 一步一步的学习 如和使用python来写一个爬虫\n了解HTTP协议\nHTTP 全称 HyperText Transfer Protocol(超文本传输协议)，设计之初就是为了提供一种收发HTML页面的方法 下面详细看看一个URL是如何组成的\n\nURL的含义\nURL是URI的子集 关于URI的相关内容 这里不再解释 具体可以问度娘。URL 全称Universal Resource Identifier(统一资源定位符) 结构组成如下\n\n比如我们看这样一个URL \nhttp://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.28.tar.gz\n\nhttp://部分是协议部分还有类似的https, ftp, mailto, file等 作用是让程序知道如和处理要打开的资源\ndev.mysql.com 部分是主机名或者IP 还可以加端口号 用:隔开 比如dev.mysql.com:8080 默认的端口是80\n/get/Downloads/MySQL-5.6/mysql-5.6.28.tar.gz 就是服务器上的文件资源基于web根目录的绝对路径了\n一次完整的HTTP请求\n浏览器输入URL 比如 http://www.baidu.com/\n向DNS服务器查询www.baidu.com的IP地址 然后连接这个IP地址的80端口 \n如果成功连接到了80端口 浏览器发起http请求(Request) 通过GET方法 访问服务器的/\n服务器收到请求 如果是静态资源 比如图片之类的 读取文件后相应(Response)给客户端\n如果请求的是.jsp或者.php等脚本 将由相应的后端程序处理 然后将生成的html页面返回给客户端\n一次请求完成 服务端主动关闭连接 客户端解析获取的html页面 然后继续发起其他资源的请求\n如果请求失败 服务器会有一个返回码 正常状态的返回码都是200 比如还有较为常见的404等\n\nHTTP协议\nHTTP协议的重点就在客户机发送的Request 和服务端返回的Response上 他们是按照怎样的格式发送的呢\n\nRequest：\nGET /login.html HTTP/1.1\nHost: www.abc.com\nConnection: keep-alive\nReferer: www.abc.com\nUser-Agent: Python-urllib/2.7\n\nGET 是HTTP方法 常用的还有POST方法 通过GET方法传递的参数直接编码为URL的一部分 \n比如/login.html?user=username&amp;passwd=password 请求login.html的同时传递了user和passwd两个参数\n而POST方法则不会 所以POST适合于密码传输 而且POST传递的数据没有大小限制 适合传递较大的文件\n\nReferer字段标识这个请求时从哪个链接上发起的 服务端可以通过此字段设置防盗链 也是爬虫需要注意的\nUser-Agent字段是客户机标识自己的身份 有时候服务端会限制一些User-Agent的访问 但是爬虫可以伪装\nResponse：\nHTTP/1.1 200 OK\nDate: Mon, 25 Jul 2016 12:59:31 GMT\nContent-Length: 10901\nContent-Type: text/html\n\n200的返回的状态码 OK是简单的描述 常见的400以上的错误为客户端请求的错误 500以上为服务端错误\nContent-Length字段告诉客户端响应内容主体的大小\nContent-Type字段告诉客户端返回内容的类型 比如图片的就是image/png 还有非常多的类型\n\nRequest和Response的还有非常多的字段 暂时先简单了解下即可 下面开始进入正题\nurllib库的基本使用\n用爬虫挖掘数据的三个步骤: 获取网页数据 --&gt; 从数据中检索需要的数据 --&gt; 将数据保存入库先来研究爬虫的第一步 获取网页数据。python获取网页数据的标准库有urllib2 还有一些非常好用的第三方库 比如requests库 python的urllib库有两个 一个是urllib 另一个是urllib2 这两个库并不是可以互相替代的关系 反而是互补的关系 下面看一个最简单的爬虫\n\n第一个简单的爬虫import urllib2response = urllib2.urlopen(\"http://www.baidu.com/\")print response.codeprint response.read()\n200\n&lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;content-type&quot; ......\n\nurllib2.urlopen类可以发起一个request的请求 用它打开链接就相当于浏览器请求一样\nresponse.code是响应的状态码 response.read()则读取了访问baidu后获取的网页源代码\n下面看看urlopen()类的常用参数\nurllib2.urlopen(url, data=None, timeout=socket)\nurl参数 顾名思义 就是要访问的地址 这个参数还可以是一个urllib2.Request的对象 下面会讲到\n默认urlopen使用了GET方法 如果给urlopen提供了data参数 则urlopen将使用POST方法提交数据\ntimeout则是访问超时时间 超过多长时间后如果还没有等到服务器响应数据 则抛出URLError异常\n手动构造Request\n手动构造Request的好处就是自己可以添加或修改Request的字段 比如修改User-Agent把自己伪装为浏览器去访问页面 urllib2访问网页的默认User-Agent是Python-urllib/2.7\n\nimport urllib2request = urllib2.Request(\"http://www.baidu.com/\")response = urllib2.urlopen(request)print response.read()\nRequest类允许用户自定义请求头部(header), 同样Request默认使用的也是GET方法 下面看看Request用法 \nurllib2.Request(url, data=None, headers=&#123;&#125;)\n如果给Request提供了data的值 那么请求将变成POST\nHeaders信息修改\n为了直观的看到headers的变化 我们先用socket模块 模拟一个web服务器出来\n\n#!/usr/bin/env pythonimport sockets = socket.socket(socket.AF_INET,socket.SOCK_STREAM)s.bind(('0.0.0.0',8080))s.listen(5)print 'Listen on 0.0.0.0:8080...'try:    while True:        conn,addr = s.accept()        print conn.recv(99999)        conn.send('HTTP/1.1 200 OK\\r\\nContent-Type: text/html\\r\\n\\r\\n&lt;h1&gt;Hello!&lt;/h1&gt;')        conn.close()except:    s.close()\n将这个脚本启动 先确定8080端口未被占用 或者自行修改端口 接着尝试用urllib2打开这个地址\n\nGET / HTTP/1.1\nAccept-Encoding: identity\nHost: 192.168.4.233:8080\nConnection: close\nUser-Agent: Python-urllib/2.7\n\n可以看到脚本输出了这样的信息 这个就是服务接受到urlopen发送的数据 可以看到是GET请求\n有很多web网站为了防止爬虫的访问 做了User-Agent检查 如果发现不是正规浏览器访问的就会拒绝掉\n那么现在尝试着修改下User-Agent的值\nimport urllib2headers = &#123;    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 BIDUBrowser/8.5 Safari/537.36'    &#125;request = urllib2.Request('http://192.168.4.233:8080',headers=headers)response = urllib2.urlopen(request)\n可以将创立好的headers字典传递给Request的headers参数 也可以创建完Request对象后 手动将headers字典赋值给request.headers属性 或者通过request对象的add_header方法添加\nrequest.headers = headers       # 或者request.add_header('User-Agent','Mozilla/5.0 (Windows NT 10.0; WOW64)......')\n以上两种方法是等效的 但是不同的是 add_header只能一次添加一个头部字段 而通过传递字典可以添加多个比如我们可以针对做了防盗链处理的网站服务器 在request中添加Referer字段 表明示从那个页面发起访问的\nimport urllib2headers = &#123;    'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64)......',    'Referer': '192.168.4.233:8080'    &#125;request = urllib2.Request('http://192.168.4.233:8080',headers=headers)response = urllib2.urlopen(request)\n接下来可以看到打印的headers中的User-Agent已经改变了 而且多了Referer字段\n\nGET / HTTP/1.1\nAccept-Encoding: identity\nHost: 192.168.4.233:8080\nReferer: 192.168.4.233:8080\nConnection: close\nUser-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64)......\n\n各大浏览器的User-Agent的值可以通过百度查询得到 也可以在浏览器中 通过开发者模式的network里查到\nGET和POST方法传递数据\n如果仅仅访问静态页面 简单的GET请求数据就可以了 但是现在大多的网站都是动态网站 需要向服务器传递一些数据才能获取想要的页面 比如有些页面必须登陆才可以浏览等 下面就看看如何使用urllib发送GET和POST请求\n\n接下来就需要使用urllib模块中的urlencode方法对数据进行编码为适合在HTTP上传输的类型了\nGET方法：\nimport urllib, urllib2values = &#123;'user':'myusername','passwd':'11223344'&#125;data = urllib.urlencode(values)url = 'http://192.168.4.233:8080/login?'request = urllib2.Request(url+data)response = urllib2.urlopen(request)print response.read()\nGET /login?passwd=11223344&amp;user=myusername HTTP/1.1\nAccept-Encoding: identity\nHost: 192.168.4.233:8080\nConnection: close\nUser-Agent: Python-urllib/2.7\n\n最后我们实际请求的URL是 http://192.168.4.233:8080/login?passwd=11223344&amp;user=myusername\n用?分隔服务器资源和向资源传递的参数 参数中用key=value的方式 两个key之间用&amp;隔开\n如果value中有特殊字符了 比如空格 = 等特殊字符怎么处理 详细资料可以看urlencode和urldecode\n\nGET方法直接将需要传递的数据构造为URL的一部分 如果传送密码这样敏感的数据当然是不可以的\n接下来就用到POST方法了\nPOST方法：\nimport urllib, urllib2values = &#123;'user':'myusername','passwd':'11223344'&#125;data = urllib.urlencode(values)url = 'http://192.168.4.233:8080/login'     # 因为不是GET方法 所以不需要?号分隔了request = urllib2.Request(url,data)         # 注意是逗号隔开的 实际上是将data传递给了参数dataresponse = urllib2.urlopen(request)print response.read()\n可以看到这回构造的request和GET方法构造的有很大不同\n\nPOST /login HTTP/1.1\nAccept-Encoding: identity\nContent-Length: 31\nHost: 192.168.4.233:8080\nContent-Type: application/x-www-form-urlencoded\nConnection: close\nUser-Agent: Python-urllib/2.7\n\npasswd=11223344&amp;user=myusername\n\n可以看到 多了Content-Length和Content-Type两个字段 一个说明内容的长度 一个说明内容类型\n而且数据内容并不是直接显示在URL中的 这样就适合传送比较大的数据或者比较敏感的数据\n\n还有一点需要注意 POST请求传递的数据可以是任意格式的 并不一定非要是通过urlencode编码后的数据\n比如直接传输一个二进制文件 request = urllib2.Request(url,data=open(&apos;/bin/bash&apos;,&apos;rb&apos;).read())\n\n还有一个比较重要的地方就是Content-Type 这个字段决定了服务器或者客户端如和处理接收到的内容\n如果传送的二进制数据 不确定类型的话 可以将Content-Type更改为application/octet-stream\n具体其他类型的数据的Content-Type可以查阅 &quot;HTTP Content-type 对照表&quot;\n使用Proxy访问网页\n有些网站为了防止被爬虫程序 或者被Ddos攻击等 限定了单位时间内对服务器的请求次数 但是道高一尺魔高一丈 爬虫程序还是有方式绕过限制的 那就是使用代理\n\nimport urllib2def setProxy(addr):    proxy_handler = urllib2.ProxyHandler(&#123;\"http\" : addr&#125;)    opener = urllib2.build_opener(proxy_handler)    urllib2.install_opener(opener)request = urllib2.Request('http://cip.cc/')request.add_header('User-Agent','curl')print urllib2.urlopen(request).read()print '-------------proxy-------------'setProxy('122.96.xx.xxx:8080')print urllib2.urlopen(request).read()\nIP    : 124.65.xxx.xx\n地址    : 中国  北京市\n运营商    : 联通\n数据二    : 北京市 | 联通\nURL    : http://www.cip.cc/124.65.xx.xx\n\n-------------proxy-------------\nIP    : 122.96.xx.xxx\n地址    : 中国  江苏省  南京市\n运营商    : 联通\n数据二    : 江苏省南京市 | 联通\nURL    : http://www.cip.cc/122.96.xx.xxx\n\ncip.cc是个可以查询出口公网IP地址的网站 并且对curl工具的访问做了优化 所以模拟为curl工具访问\nproxy_handler是使用代理的处理器 build_opener添加配置好的proxy_handler代理器 返回一个对象\n这个对象也有个open方法 这个方法可以像urllib2.urlopen一样使用 不同的是只有open才会使用代理\ninstall_opener则会创建一个全局使用的opener 也就是说 urllib2.urlopen的默认行为也会使用代理\n\n来看下面的例子\nimport urllib2proxy_handler = urllib2.ProxyHandler(&#123;\"http\" : '122.96.xx.xxx:8080'&#125;)opener = urllib2.build_opener(proxy_handler)request = urllib2.Request('http://cip.cc/')request.add_header('User-Agent','curl')print urllib2.urlopen(request).read()print '-------------opener-------------'print opener.open(request).read()\nIP    : 124.65.xxx.xx\n地址    : 中国  北京市\n运营商    : 联通\n数据二    : 北京市 | 联通\nURL    : http://www.cip.cc/124.65.xx.xx\n\n-------------opener-------------\nIP    : 122.96.xx.xxx\n地址    : 中国  江苏省  南京市\n运营商    : 联通\n数据二    : 江苏省南京市 | 联通\nURL    : http://www.cip.cc/122.96.xx.xxx\n\n可以看到效果是完全相同的 只不过opener.open是局部的 而urllib2.urlopen是全局的\n通过install_opener则可以把opener.open安装为全局的 build_opener还可以安装多个不同的Handler\n开启Debug日志\n开启urllib的Debug日志后 每次完成一次与服务器交互 都会将打印出request和response信息 这样更方便调试错误\n\nimport urllib2proxy_handler = urllib2.ProxyHandler(&#123;\"http\" : '122.96.xx.xxx:8080'&#125;)http_handler = urllib2.HTTPHandler(debuglevel=1)opener = urllib2.build_opener(proxy_handler, http_handler)request = urllib2.Request('http://cip.cc/')request.add_header('User-Agent','curl')print opener.open(request).read()\n同时给build_opener传入了两个处理器 执行opener.open的时候 可以发现两个处理器都生效了 以下是返回数据\n\nsend: &apos;GET http://cip.cc/ HTTP/1.1\\r\\nAccept-Encoding: identity\\r\\nHost: cip.cc\\r\\nConnection: close\\r\\nUser-Agent: curl\\r\\n\\r\\n&apos;\nreply: &apos;HTTP/1.1 200 OK\\r\\n&apos;\nheader: Server: nginx\nheader: Date: Tue, 26 Jul 2016 04:57:13 GMT\nheader: Content-Type: text/html; charset=UTF-8\nheader: Transfer-Encoding: chunked\nheader: Connection: close\nheader: Vary: Accept-Encoding\nIP    : 122.96.xx.xxx\n地址    : 中国  江苏省  南京市\n运营商    : 联通\n数据二    : 江苏省南京市 | 联通\nURL    : http://www.cip.cc/122.96.xx.xxx\n\nsend就是发送的request 而reply就是服务器的response了 如果是https页面 则需要设置HTTPSHandler\nurllib2.build_opener(proxy_handler, http_handler, urllib2.HTTPSHandler(debuglevel=1))\n使用cookie模拟登陆\nHTTP协议是无状态的 也就是说你这次的请求 和下次的请求并没有联系 那么这样子 服务器怎么区分用户的身份呢 那么就是cookie的作用了可以这样理解 当用户登录网站成功了 网站就给这个用户下发一个令牌 也就是cookie 下次用户再访问网站的其他页面的时候 就顺便带上令牌 那么服务器端只要区分不同的令牌就知道用户的身份了所以 cookie是一个非常方便 又同时非常危险的东西 比如我在局域网中 抓取到某人登陆某网站的cookie 然后我就可以直接使用该cookie访问这个网站 那么就实现了免密码登陆了 这也是为什么很多敏感的网站cookie的有效期这么短 下次访问就有可能需要重新登陆的原因了 下面就看看urllib如和处理cookie和cookie模拟登陆的吧\n\n使用已有的cookie登陆百度：\n已登录网站的cookie可以通过开发者模式获取 这里以Chrome内核的浏览器为例 360浏览器等都相同\n一般F12都可以直接打开开发者模式 然后点击 Network 刷新下你已经登陆了的百度的首页 \n然后看到Network -&gt; Name块出现了一堆请求的资源 找到www.baidu.com 打开后就可以看到Headers了\n找到Request Headers中的Cookie字段 可以看到一大堆的字符串 这个字符串是经过加密的 复制下来\nimport urllib2request = urllib2.Request('http://www.baidu.com/')request.add_header('Cookie','BD_CK_SAM=1; H_PS_645EC=0c53pNyqSabVK%2BP......')result = urllib2.urlopen(request).read()open('baidu.html','w').write(result)\n可以将url换成tieba.baidu.com 然后去访问百度贴吧 看看保存到本地的网页是不是已经登陆状态呢\n这就是最简单的用cookie模拟登陆的方法了 但是我们不可能每次都通过这种方式获取cookie吧\n这就需要用程序实现如和使用账号密码登陆 然后保存cookie 然后用cookie访问其他页面\n使用账号密码登陆：\n这个环节其实是非常复杂的 因为现在的大多网站 为了避免爬虫等工具 登陆需要短信验证 验证码验证等\n而且密码可能被先经过算法加密后才上传的 甚至登陆的步骤还有非常多的坑 开发者模式以后将经常用到\n这里的例子使用了公司内部的网站实现数据自动提交\nimport urllibimport urllib2import cookielibcookie = cookielib.CookieJar()cookie_handler = urllib2.HTTPCookieProcessor(cookie)opener = urllib2.build_opener(cookie_handler)login_info = urllib.urlencode(&#123;'sysName':'aabbcc','sysPsw':'112233'&#125;)resp = opener.open('http://16.190.x.xxx/sysLoginAction.jsp',data=login_info,timeout=20)post_data = 'city1=%C8%FD%D1%C7&amp;zt1=%B9%CA%D5%CF%A3%ACrds%C8%EB%BF%E2%CD%A3%D6%B9'post_url = 'http://16.190.1.207/thesisFlatRoot/save_info1.jsp?ls=0'resp = opener.open(post_url,data=post_data,timeout=20)\n代码没有任何的异常捕捉 就假设可以正常的执行完毕 这里引入了新库 cookielib\n这个库是专门处理cookie的库 同样也是安装给opener 然后模拟登陆后带着获取的cookie去提交数据\n这个login_info是通过开发者模式中 手动登录一次网站 然后分析想后端服务器POST的什么数据\n而post_data则是每天的任务中点击提交按钮实际上POST上去的数据 通过脚本就不用每天登陆提交了\nCookieJar是将cookie保存到一个变量中的 还可以将Cookie保存到文件中 这样就不用每次都登陆了\n将cookie保存到文件\n保存cookie到文件的对象是FileCookieJar 我们使用它的子类MozillaCookieJar来实现\nimport urllib2,cookielibcookie_file = 'cookie.txt'cookie = cookielib.MozillaCookieJar(cookie_file)cookie_handler = urllib2.HTTPCookieProcessor(cookie)opener = urllib2.build_opener(cookie_handler)response = opener.open(\"http://www.baidu.com/\")cookie.save(ignore_discard=True, ignore_expires=True)\nignore_discard的意思是即使cookies将被丢弃也将它保存下来\nignore_expires的意思是如果在该文件中cookies已经存在 则覆盖原文件写入\n可以看到当前目录出现了cookie.txt 接下来就是看看如何从文件中读取cookie了\n从文件中读取cookie\n从文件中读取cookie可以免去每次执行脚本都重新登陆一次 除非cookie过期的情况下才需要重新登录\nimport urllib2,cookielibcookie = cookielib.MozillaCookieJar()cookie.load('cookie.txt', ignore_discard=True, ignore_expires=True)opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))response = opener.open(\"http://www.baidu.com/\")\n这样如果cookie.txt中保存的是你登陆百度后的cookie 那么下次通过cookie.txt就可以直接登陆百度了\n现在数据获取方面的工作已经差不多了 数据获取还有一个比较优秀的requests库 可以自行研究下\n接下来就是如何从网页数据中提取我们需要的信息了\n正则表达式\n在编写处理字符串的程序或网页时 经常会有查找符合某些复杂规则的字符串的需要 正则表达式就是用于描述这些规则的工具 换句话说 正则表达式就是记录文本规则的代码 下面看看正则表达式的常用项\n\n常用元字符\n\n\n代码\n说明\n\n\n\n\n.\n匹配除换行符以外的任意字符\n\n\n\\w\n匹配字母或数字或下划线或汉字\n\n\n\\s\n匹配任意的空白符\n\n\n\\d\n匹配数字\n\n\n^\n匹配字符串的开始\n\n\n$\n匹配字符串的结束\n\n\n\n常用限定符\n\n\n代码\n说明\n\n\n\n\n*\n重复零次或更多次\n\n\n+\n重复一次或更多次\n\n\n?\n重复零次或一次\n\n\n{n}\n重复n次\n\n\n{n,}\n重复n次或更多次\n\n\n{n,m}\n重复n到m次\n\n\n\n常用的反义代码\n\n\n代码\n说明\n\n\n\n\n\\W\n匹配任意不是字母，数字，下划线，汉字的字符\n\n\n\\S\n匹配任意不是空白符的字符\n\n\n\\D\n匹配任意非数字的字符\n\n\n\\B\n匹配不是单词开头或结束的位置\n\n\n[^x]\n匹配除了x以外的任意字符\n\n\n[^aeiou]\n匹配除了aeiou这几个字母以外的任意字符\n\n\n\n常用分组语法\n\n\n代码\n说明\n\n\n\n\n(exp)\n匹配exp,并捕获文本到自动命名的组里\n\n\n(?”name”exp)\n匹配exp,并捕获文本到名称为name的组里\n\n\n(?:exp)\n匹配exp,不捕获匹配的文本，也不给此分组分配组号\n\n\n(?=exp)\n匹配exp前面的位置\n\n\n(?&lt;=exp)&lt; span=””&gt;\n匹配exp后面的位置\n\n\n(?!exp)\n匹配后面跟的不是exp的位置\n\n\n(?\n匹配前面不是exp的位置\n\n\n(?#comment)\n提供注释让人阅读\n\n\n\n懒惰限定符\n\n\n代码\n说明\n\n\n\n\n*?\n重复任意次，但尽可能少重复\n\n\n+?\n重复1次或更多次，但尽可能少重复\n\n\n??\n重复0次或1次，但尽可能少重复\n\n\n{n,m}?\n重复n到m次，但尽可能少重复\n\n\n{n,}?\n重复n次以上，但尽可能少重复\n\n\n\n简单用法\n用最简单的例子 看看正则表达式在网页中如何匹配需要的信息\n\n&lt;html lang=\"cn\"&gt;    &lt;head&gt;        &lt;title&gt;regex&lt;/title&gt;        &lt;meta charset=\"utf-8\"&gt;&lt;/meta&gt;    &lt;/head&gt;    &lt;body alink=\"red\" bgcolor=\"black\" vlink=\"yellow\" text=\"blue\"&gt;        &lt;h1&gt;subject&lt;/h1&gt;        &lt;hr size=\"10px\" width=\"50%\" /&gt;        &lt;a href=\"http://127.0.0.1:5000/a.html\"&gt;            &lt;img src=\"img/123.jpg\" width=\"140\" height=\"100\" alt=\"image\"/&gt;        &lt;/a&gt;        &lt;a href=\"http://127.0.0.1/b.html\"&gt;page1&lt;/a&gt;&lt;br /&gt;        &lt;a href=\"http://127.0.0.1/c.html\"&gt;page2&lt;/a&gt;    &lt;/body&gt;&lt;/html&gt;\n在python中 正则表达式的库是re库 现在只需要简单掌握re.findall的用法\nimport reprint re.findall(r'&lt;title&gt;(.*?)&lt;/title&gt;',html)\nre.findall的用法是 re.findall(pattern, string, flags)\n\n匹配的结果是 [&apos;regex&apos;] 这是一个列表 如果有多个符合条件的字符串 都会出现在列表内\nhtml就是上面的那段html代码 r&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos; 就是用来匹配网页title的正则表达式\n这里用到了()分组匹配 匹配被&lt;title&gt;和&lt;/title&gt;包裹的内容 .*?则是非贪婪模式匹配\n如果需要匹配的字符有元字符等特殊字符 就需要用 \\ 进行转义 比如匹配baidu.com就需要 baidu\\.com\n\n因为\\是转义字符 如果要匹配\\字符或者\\b(数字) 就需要写成 \\\\ 和 \\\\b 这样带来了非常多的不便\n所以在字符串的前面加入 r&apos;&apos; 表示原生字符串 就可以写成 r&apos;\\&apos; 和 r&apos;\\b&apos; 这样就完美的解决了问题 \nimport rere.findall('&lt;a href=\".*?\"&gt;.*?&lt;/a&gt;',html)re.findall('&lt;a href=\"(.*?)\"&gt;(.*?)&lt;/a&gt;',html)\n匹配的结果是\n[&apos;&lt;a href=&quot;http://127.0.0.1/b.html&quot;&gt;page1&lt;/a&gt;&apos;, &apos;&lt;a href=&quot;http://127.0.0.1/c.html&quot;&gt;page2&lt;/a&gt;&apos;]\n[(&apos;http://127.0.0.1/b.html&apos;, &apos;page1&apos;), (&apos;http://127.0.0.1/c.html&apos;, &apos;page2&apos;)]\n\n现在能深深的体会到()的重要性了吧 会对()内的字符串自动分组 但是有个奇怪的地方 好像有个链接丢失了\nhtml中一共有三个&lt;a&gt;标签 但是只匹配到两个 仔细观察发现 第一个&lt;a&gt;标签和闭合标签&lt;/a&gt;不在同一行\n\n因为 . 这个元字符匹配除换行符以外的任意字符  因为第一个&lt;a&gt;和&lt;/a&gt;被换行符隔断了 所以匹配不到\n这时就需要用到flags这个参数了 比如re.I 忽略大小写 re.S 使 . 元字符完全匹配任何字符\nimport rere.findall('&lt;a href=\"(.*?)\"&gt;(.*?)&lt;/a&gt;',html,re.S)\n[(&apos;http://127.0.0.1:5000/a.html&apos;, &apos;\\n            &lt;img src=&quot;img/123.jpg&quot; ......\n\n可以看到 所有的&lt;a&gt;标签都被匹配到了\nre还有许多的匹配方法 比如re.finditer  re.sub  re.search  re.match等 可以自行学习\n实战爬取数据\n现在获取网页数据的方式和正则表达式都已经有了一定的了解 那就开始实际的爬取些有意思的东西\n\n千趣网专题爬取\n千趣网是个分享有意思新闻的网站 不需要登陆就可以浏览内容 也没有什么防爬措施 所以先拿它练手\n\n#!/usr/bin/env python# -*- coding:utf-8 -*-import reimport urllib2HOST = 'http://www.qianqu.cc'       # 要爬的网站def getHTML(url):                   # 获取网页源码    request = urllib2.urlopen(url,timeout=5)    return request.read()def makeUrl(baseUrl):               # 用来构造每一页的URL地址    def getPageNum():               # 获取每个专栏有多少页        html = getHTML(baseUrl.format(1))        return int(re.findall(r'pages: (.*?),',html,re.S)[0])    for i in range(1,getPageNum()+1):        yield baseUrl.format(i)     # 返回一个可迭代的对象来节省内存def getTitle(url):                  # 获取一页有多少文章 返回文章的标题和URL    request = urllib2.urlopen(url)    html = request.read()    div = re.findall(r'&lt;div class=\"article\"&gt;(.*?)&lt;/div&gt;',html,re.S)    for i in div:        try:            result = re.findall(r'&lt;a href=\"(.*?)\".*&lt;/a&gt;.*&lt;p&gt;(.*?)&lt;/p&gt;.*',i,re.S)[0]        except:            raise StopIteration        yield (HOST+result[0],result[1])def getContext(url):                # 根据获取到的文章URL检索出内容    request = urllib2.urlopen(url)    html = request.read()    div = re.findall(r'&lt;div class=\"contentText\"&gt;(.*?)&lt;/div&gt;',html,re.S)[0]    div = div.replace('&amp;nbsp;','')    text = ''    for i in re.split('&lt;.*?&gt;',div):        text += i+'\\n' if i else ''    return text.replace('点击阅读全文','')def main():                     # 将函数组合起来进行工作 最后返回一个包含URL,标题,文章的字典    urlPool = makeUrl('http://www.qianqu.cc/tech/page/&#123;&#125;')    for i in urlPool:        for x in getTitle(i):            news = &#123;                'url':x[0].decode('utf-8'),             # 由于网页源码是utf-8编码 所以需要先解码                'title':x[1].decode('utf-8'),                'text':getContext(x[0]).decode('utf-8')            &#125;            yield newsif __name__ == '__main__':      # 这个里面看你想如和处理收集到的数据了     for i in main():            # 可以打印出来 也可以存数据库        raw_input('Enter key continue ...')        print i['title']        print i['text']\n千趣有许多专题 比如生活啊 科技啊之类的 这里以科技为例 现在分析下爬取内容的思路\n\ndef getHTML(url):\n定义一个获取网页源码的函数 因为千趣网没有反爬措施 所以就非常简单的发送请求 然后返回内容\n如果爬取其他网站发现失败 可以试着修改User-Agent等必要的字段试试\n\ndef makeUrl(baseUrl):\n先进行分析千趣科技模块的URL 发现URL是http://www.qianqu.cc/tech 往下翻还有许多页数\n所以就需要一个函数能自动生成这些页数的URL 想获取一共有多少页 还需要对网页内容进行分析\n发现在页面的一段javascript脚本中 pages: 208, 而这个刚好就是这个科技专题的页码数\n定义一个getPageNum()的函数 用正则表达式检索出这个数字 然后提供makeUrl去生成URL\n\ndef getTitle(url):\n接下来就是请求makeUrl生成的URL 获取每一个URL中有多少个文章的标题和文章的URL\n在chrome内核的浏览器 Ctrl + U 打开页面的源代码 通过分析发现 每个文字标题都是通过&lt;div&gt;布局的 \n这样就可以先捕获每个标题所在的div 然后再进行二次匹配出需要的标题和文字的URL\n\ndef getContext(url):\n接下来就是获取标题内容页的数据了\n对内容中的数据重新处理 去掉多余的HTML标签 并且去掉空格 和没有用处的字符串\n\ndef main():\n将需要的函数组合起来 开始工作 并最后返回一个字典\n字典有三个字段 分别是url title 和text 对应着文章url 文章标题还有文章内容\n\n可以发现 这个爬虫脚本还是有非常多可以改进的地方 比如没有异常处理等等 \n最后就是考虑如何处理这些数据了这里只是简单的打印了出来 最好的方法当然是保存到数据库\n将数据保存入数据库\n从千趣网抓取的数据可以选择存放到Nosql 比如mongodb redis等数据库中 也可以存放到普通的数据库 比如mysql sqlite3中 下面以python自带的标准库sqlite3为例\n\nif __name__ == '__main__':    import sqlite3,time    with sqlite3.connect('qianqu.sqlite3') as conn:        db = conn.cursor()        create_table = 'create table if not exists qianqu (id integer primary key autoincrement,title varchar(128),url varchar(128),text text)'        db.execute(create_table)        insert_sql = u'insert into qianqu (url,title,text) values (?,?,?)'        for i in main():            db.execute(insert_sql,(i['url'],i['title'],i['text']))            conn.commit()            print i['url']+' OK!'            time.sleep(1)\n只需要将if __name__ 的部分改为这样就可以了 \n这里导入sqlite3的库 然后用with管理一个sqlite3数据库的连接 然后按照字典key去建表\n为了防止爬取速度太快 导致对方服务器可能封锁IP 所以就每1秒爬取一次 然后将数据写入数据库中\n\n到这里 对python写爬虫已经有一个大致的学习了 这里没有用到任何的第三方库 都是用标准库实现的\n程序还有很多不完善的地方 比如如果中途断开了 那么脚本往数据库插入数据又得重新开始\n附录Python爬虫进阶\n如果想进一步的提高自己的爬虫水平 就需要学习一些第三方库和一些优秀的爬虫框架了 下面做了一个总结\n\n数据获取类\n\n\n模块\n说明\n\n\n\n\nrequests\n一个非常好用的网络库\n\n\npycurl\nlibcurl的绑定 非常强大\n\n\nurllib3\nHTTP库 安全连接池 支持文件post 可用性高\n\n\ntornado\n高效的非阻塞web框架 可以做HTTP Client\n\n\naiohttp\nasyncio的HTTP客户端/服务器\n\n\n\n数据解析工具\n\n\n模块\n说明\n\n\n\n\nlxml\nC语言编写高效HTML/XML处理库 支持XPath\n\n\ncssselect\n解析DOM树和CSS选择器\n\n\npyquery\n解析DOM树和jQuery选择器\n\n\nBeautifulSoup\n低效但方便的HTML/XML处理库\n\n\nhtml5lib\n根据WHATWG规范生成HTML/ XML文档的DOM\n\n\nxmltodict\n一个可以让你在处理XML时感觉像在处理JSON一样的模块\n\n\n\n爬虫框架\n\n\n模块\n说明\n\n\n\n\ngrad\n网络爬虫框架(基于pycurl/multicur)\n\n\nscrapy\n网络爬虫框架(基于twisted)\n\n\npyspider\n一个强大的爬虫系统\n\n\ncola\n一个分布式爬虫框架\n\n\n\n数据库驱动\n\n\n模块\n说明\n\n\n\n\nmysqlclient\npython的mysql驱动\n\n\npsycopg2\npython的postgresql驱动\n\n\npymongo\npython的mongodb驱动\n\n\nredis\npython的redis驱动\n\n\n\n其他工具\n\n\n模块\n说明\n\n\n\n\nPhantomJS\n无界面的,可脚本编程的WebKit浏览器引擎\n\n\nSelenium\n自动化测试工具\n\n\n\n","categories":["Python"],"tags":["网络爬虫","Python"]},{"title":"Nginx配置文件详解","url":"/2016/05/17/2016/nginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3/","content":"简介\nNginx丰富的功能实现 都是通过配置文件完成的 Nginx配置文件的结构非常简单易懂 而且又十分强大 下面就是Nginx配置文件的结构说明 以及一些常用配置项的解释\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nnginx\n1.9.13\n点击下载\n\n\n\n步骤Nginx配置文件结构\nNginx配置文件是一个纯文本文件 默认位置位于 /conf/nginx.conf 配置文件内容是以block的形式组织 每个block用 {} 表示 block内可以包含block 其关系如下:\n\n+--------------------------------+\n|              main              |      main 全局配置 pid文件位置 运行用户等配置\n|    +-----------------------+   |\n|    |        events         |   |      events 设定Nginx工作模式 比如epoll select等\n|    +-----------------------+   |\n|  +---------------------------+ |\n|  |            HTTP           | |      HTTP核心模块\n|  | +-----------------------+ | |\n|  | |         server        | | |      server 每一个server都可以视为一个虚拟主机\n|  | | +-------------------+ | | |\n|  | | |      location     | | | |      location 匹配网页位置\n|  | | +-------------------+ | | |\n|  | | +-------------------+ | | |\n|  | | |      location     | | | |      一个server可以存在多个不同的location\n|  | | +-------------------+ | | |\n|  | +-----------------------+ | |\n|  | +-----------------------+ | |\n|  | |         server        | | |      多个server就可以启动多个虚拟主机\n|  | +-----------------------+ | |\n|  +---------------------------+ |\n+--------------------------------+\nNginx配置文件参数#user  nobody;                          # 默认运行用户 编译时未指定的话为nobody\nworker_processes  4;                    # Nginx主进程要开启多少个工作进程 一般为当前CPU核心数\nworker_cpu_affinity 0001 0010 0100 1000;   # 将每个进程绑定到CPU的每个核心上 可以略提高性能\n\n#error_log  logs/error.log;             # 错误日志的位置 默认是安装目录下的logs/error.log\n#error_log  logs/error.log  notice;     # 可以在日志后面添加纪录级别 \n#error_log  logs/error.log  info;       # 可选项有: [debug|info|notice|warn|error|crit]\n\n#pid        logs/nginx.pid;             # pid文件路径 nginx -s 控制服务就是从这里读取主进程的PID\nworker_rlimit_nofile 65535;             # 指定文件描述符数量 增大可以让Nginx处理更多连接\n                                    # 还需要增大系统允许进程打开文件描述符的上限 ulimit -n 65536\n\nevents {\n    use epoll;                          # Nginx默认会选择最适合的工作模式 linux一般为epoll\n                                        # 支持:[select | poll | kqueue | epoll | /dev/poll]\n    worker_connections  65535;          # Nginx每个工作进程最大的连接数\n}                                       # 最大客户连接数为 worker_processes * worker_connections \n\n\nhttp {\n    include       mime.types;         # 其他的block配置 可以通过include导入 这样可以很方便管理配置\n    default_type  application/octet-stream; # 响应类型未定义content-type时 文件默认类型为二进制流 \n                                            # mime.types中包含文件扩展名与文件类型映射表\n\n    #log_format  main  &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos;\n    #                  &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos;\n    #                  &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;;\n                                      # 定义access.log日志的格式 main为格式名称 \n\n    access_log  logs/access.log  main;      # 默认access.log的位置 以及使用main中定义的格式\n\n    client_max_body_size     20m;           # 设置允许客户上传大小\n    client_header_buffer_size   32k;        # 客户端请求 header_buffer大小 默认1k\n    large_client_header_buffers  4 32k;     # 指定客户请求header_buffer的缓存最大数量和大小\n\n    sendfile        on;                     # 开启高效的文件传输模式\n    tcp_nopush      on;                     # 开启tcp_nopush和tcp_nodelay用于防止网络阻塞\n    tcp_nodelay     on;\n\n    #keepalive_timeout  0;\n    keepalive_timeout  65;                  # 客户端连接后保持连接的超时时间\n    client_header_timeout  10;              # 设置客户端请求头读取超时时间 \n                                            # 超时将返回Request time out (408)\n    client_body_timeout    10;              # 设置客户端请求主体读取超时时间  超时也将返回408\n    send_timeout           10;              # 指定响应客户端的超时时间\n                                            # 如果超过这个时间 客户端没有任何活的 Nginx将关闭连接\n\n    gzip  on;                               # 开启还是关闭gzip模块 on表示开启 实时压缩输出数据流\n    gzip_min_length  1k;                    # 允许压缩页面最小字节数 小于1k的文件可能越压越大\n    gzip_buffers     4  16k;                # 申请4个单位16KB的内存做压缩结果流缓存 默认源文件大小\n    gzip_http_version  1.1;                 # 用于识别HTTP协议版本 默认 1.1\n    gzip_comp_level  2;                     # 压缩等级 1 表示最快压缩 但压缩比最小 9反之\n    gzip_types  text/plain application/x-javascript text/css application/xml;   # 指定压缩类型\n    gzip_vary  on;                          # 让前端的缓存服务器缓存经过gzip压缩的页面\n\n    server {                                # server段就是虚拟主机的配置\n        listen       80;                    # 监听所有IP的80端口 可以指定单个IP\n        server_name  localhost;             # 用来指定IP地址或域名 多个域名间用空格分开\n\n        #charset koi8-r;                    # 用于设置网页默认编码\n\n        #access_log  logs/host.access.log  main;    # 每一个虚拟主机也可以定义单独的access.log\n\n        location / {                        # URL地址匹配设置\n            root   /var/www/html;           # 网页根目录\n            index  index.html index.htm;    # 默认首页地址 会先寻找index.html 然后往后\n        }\n\n        location ~ .*\\.(gif|jpg|jpeg|png|bmp|swf)$  {   # 匹配以这些格式结尾的请求\n            root    /var/www/static;                    # 匹配到的请求从这个目录找文件\n            expires 30d;                                # 客户端缓存静态文件过期时间30天\n        }\n\n\n        error_page  404              /404.html;         # 自定义404页面 /404.html为root指定的位置\n\n        # redirect server error pages to the static page /50x.html\n        #\n        error_page   500 502 503 504  /50x.html;        # 自定义50x页面 到/50x.html\n        location = /50x.html {                          # 匹配50x页面的请求\n            root   html;                                # 匹配到的请求从这个目录找文件\n        }\n\n        # proxy the PHP scripts to Apache listening on 127.0.0.1:80\n        #\n        location ~ \\.php$ {                             # 匹配php页面的请求\n            index index.php                             # 默认索引index.php\n            proxy_pass   http://127.0.0.1               # 匹配到的请求转发到本机80端口处理\n        }\n\n        location ~ \\.jsp$ {                             # 匹配jsp页面的请求\n            index index.jsp                             # 默认索引index.jsp\n            proxy_pass   http://127.0.0.1:8080          # 匹配到的请求转发到本机8080端口处理\n        }\n\n        location /status {                              # 匹配status的请求\n            stub_status on;                             # 开启Nginx工作状态统计\n            access_log    logs/status.log;              # 状态统计页面访问日志\n            auth_basic    &quot;Nginx Status&quot;;               # 自定义提醒 认证界面会显示\n            auth_basic_user_file    /var/www/htpasswd;  # 认证密码文件 htpasswd工具由httpd提供\n        }                                               # 访问http://host/status 就可以看到状态统计了\n\n        # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000\n        #\n        #location ~ \\.php$ {                    # FastCGI模式\n        #    root           /var/www/html;      # php页面根目录\n        #    fastcgi_pass   127.0.0.1:9000;     # FastCGI监听地址 也可以使用unix套接字监听地址\n        #    fastcgi_index  index.php;          # 索引文件\n        #    fastcgi_param  SCRIPT_FILENAME  /var/www/html$fastcgi_script_name;  # php脚本全路径\n        #    include        fastcgi_params;\n        #}\n\n        # deny access to .htaccess files, if Apache&apos;s document root\n        # concurs with nginx&apos;s one\n        #\n        #location ~ /\\.ht {                     # 匹配ht开头的文件\n        #    deny  all;                         # 规则是全部拒绝\n        #}\n    }\n\n\n    # another virtual host using mix of IP-, name-, and port-based configuration\n    #\n    #server {                                            # 另一台虚拟主机\n    #    listen       8000;                              \n    #    listen       somename:8080;\n    #    server_name  somename  alias  another.alias;\n\n    #    location / {\n    #        root   html;\n    #        index  index.html index.htm;\n    #    }\n    #}\n\n\n    # HTTPS server\n    #\n    #server {                                           # 配置https网站\n    #    listen       443 ssl;                          # 监听443端口 ssl加密\n    #    server_name  localhost;\n\n    #    ssl_certificate      cert.pem;                 # 证书需要用openssl生成 nginx需要添加ssl模块\n    #    ssl_certificate_key  cert.key;                 # 证书key\n\n    #    ssl_session_cache    shared:SSL:1m;\n    #    ssl_session_timeout  5m;\n\n    #    ssl_ciphers  HIGH:!aNULL:!MD5;\n    #    ssl_prefer_server_ciphers  on;\n\n    #    location / {\n    #        root   html;\n    #        index  index.html index.htm;\n    #    }\n    #}\n\n}\n附录\nNginx还有其他配置块 比如upstream (负载均衡) 或者其他模块提供的功能 这里只说明一些常用的配置块\n\n","categories":["Nginx"],"tags":["nginx"]},{"title":"Redis散列类型","url":"/2016/05/25/2016/redis%E6%95%A3%E5%88%97%E7%B1%BB%E5%9E%8B/","content":"简介\nRedis 是采用字典结构以键值对的形式存储数据的，而散列类型（hash）的键值也是一种字典结构，其存储了字段（field）和字段值的映射，但字段值只能是字符串，不支持其他数据类型，换句话说，散列类型不能嵌套其他的数据类型。一个散列类型键可以包含最多232最少1个字段\n\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nredis\n3.2.0\n点击下载\n\n\n\n简单认识散列类型散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示对象的属性，而字段值则存储属性值。需要注意 散列类型的字段值只能是字符串类型 不能嵌套其他类型\n键:ID              字段              字段值\n          +----&gt;   color   -----&gt;    white\ncar:1 ----+----&gt;   name    -----&gt;    Ferraris\n          +----&gt;   price   -----&gt;    10 million\n散列类型的字段可以随意拓增或者减少 所以散列类型的结构只是人为的约定\n常用命令下面将详细说明操作Redis散列类型的相关命令\n赋值与取值HSET key field value                # 赋值\nHGET key field                      # 取值\n127.0.0.1:6379&gt; HSET car:1 color white\n(integer) 1\n127.0.0.1:6379&gt; HSET car:1 name Ferraris\n(integer) 1\n127.0.0.1:6379&gt; HSET car:1 price &apos;10 million&apos;\n(integer) 1\n127.0.0.1:6379&gt; HGET car:1 color\n&quot;white&quot;\n127.0.0.1:6379&gt; HGET car:1 name\n&quot;Ferraris&quot;\n127.0.0.1:6379&gt; HGET car:1 price\n&quot;10 million&quot;\n127.0.0.1:6379&gt;\nHSET不区分插入和更新操作 修改数据时不用事先判断字段是否存在插入或修改一个字段时 当字段不存在 HSET命令返回1 否则返回0\n127.0.0.1:6379&gt; HSET car:1 color blue\n(integer) 0\n127.0.0.1:6379&gt; HGET car:1 color\n&quot;blue&quot;\n127.0.0.1:6379&gt;\n和字符串类似 当需要给多个字段同时设定值 或获取值 也有相应的命令\nHMSET key field value [field value ...]      # 同时赋值\nHGET key field                               # 同时取值\n127.0.0.1:6379&gt; HMSET car:2 color red name Bentley price &apos;3 million&apos;\nOK\n127.0.0.1:6379&gt; HMGET car:2 color name price\n1) &quot;red&quot;\n2) &quot;Bentley&quot;\n3) &quot;3 million&quot;\n127.0.0.1:6379&gt;\n如果事先不知道这个car:2有哪些字段 那么如何获取这个key中所有的字段和值呢\nHGETALL key             # 获取所有字段值\n127.0.0.1:6379&gt; HGETALL car:2\n1) &quot;color&quot;\n2) &quot;red&quot;\n3) &quot;name&quot;\n4) &quot;Bentley&quot;\n5) &quot;price&quot;\n6) &quot;3 million&quot;\n127.0.0.1:6379&gt;\n还可以单独获取字段名或字段值\nHKEYS key           # 只获取字段名\nHVALS key           # 只获取字段值\n127.0.0.1:6379&gt; HKEYS car:1\n1) &quot;name&quot;\n127.0.0.1:6379&gt; HKEYS car:2\n1) &quot;color&quot;\n2) &quot;name&quot;\n3) &quot;price&quot;\n4) &quot;date&quot;\n127.0.0.1:6379&gt; HVALS car:1\n1) &quot;Ferraris&quot;\n127.0.0.1:6379&gt; HVALS car:2\n1) &quot;red&quot;\n2) &quot;Bentley&quot;\n3) &quot;3 million&quot;\n4) &quot;2016-05-22&quot;\n127.0.0.1:6379&gt; \n判断字段是否存在HEXISTS key field            # 判断字段是否存在\n127.0.0.1:6379&gt; HEXISTS car:1 date\n(integer) 0\n127.0.0.1:6379&gt; HSET car:1 date &apos;2016-05-22&apos;\n(integer) 1\n127.0.0.1:6379&gt; HEXISTS car:1 date\n(integer) 1\n127.0.0.1:6379&gt;\n当字段不存在返回0 字段存在 返回1\n字段不存在时赋值HSETNX key field value      # 字段不存在时赋值\n127.0.0.1:6379&gt; HSETNX car:2 color black\n(integer) 0\n127.0.0.1:6379&gt; HGET car:2 color\n&quot;red&quot;\n127.0.0.1:6379&gt; HSETNX car:2 date &apos;2016-05-22&apos;\n(integer) 1\n127.0.0.1:6379&gt; HGET car:2 date\n&quot;2016-05-22&quot;\n127.0.0.1:6379&gt;\n可以看到 如果字段存在 赋值失败 并返回0 如果不存在 赋值成功 返回1\n字段值自增自减HINCRBY key field increment     # 字段值自增\n127.0.0.1:6379&gt; HINCRBY car id 1\n(integer) 1\n127.0.0.1:6379&gt; HGET car id\n&quot;1&quot;\n127.0.0.1:6379&gt; HINCRBY car id 2\n(integer) 3\n127.0.0.1:6379&gt; HGET car id\n&quot;3&quot;\n127.0.0.1:6379&gt;\n字段值的自增和字符串的自增道理相同 因为没有自减 所以可以用自增 -1 来实现\n删除字段HDEL key field [field ...]      # 删除指定的一个或多个字段\n127.0.0.1:6379&gt; HDEL car:1 price date\n(integer) 2\n127.0.0.1:6379&gt; HGETALL car:1\n1) &quot;color&quot;\n2) &quot;blue&quot;\n3) &quot;name&quot;\n4) &quot;Ferraris&quot;\n127.0.0.1:6379&gt; HDEL car:1 price color\n(integer) 1\n127.0.0.1:6379&gt;\nHDEL会返回删除成功的字段个数\n获取字段数量HLEN key            # 获取字段数量\n127.0.0.1:6379&gt; HLEN car:1\n(integer) 1\n127.0.0.1:6379&gt; HLEN car:2\n(integer) 4\n127.0.0.1:6379&gt;\n附录命令总结HSET key field value                    给键的字段赋值\nHGET key field                          获取键的字段值\nHMSET key field value [field value ...] 同时赋值\nHGET key field                          同时取值\nHGETALL key                             获取所有字段值\nHKEYS key                               只获取字段名\nHVALS key                               只获取字段值\nHEXISTS key field                       判断字段是否存在\nHSETNX key field value                  字段不存在时赋值\nHINCRBY key field increment             字段值自增\nHDEL key field [field ...]              删除指定的一个或多个字段\nHLEN key                                获取字段数量\n","categories":["Redis"],"tags":["Redis"]},{"title":"Redis数据库编译安装","url":"/2016/05/17/2016/redis%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"简介\nRedis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。百度百科\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nredis\n3.2.0\n点击下载\n\n\n\n步骤编译安装\nredis的编译安装非常简单 只需要安装 make 和 gcc 开发工具即可\n\nyum install make gcctar xf redis-3.2.0.tar.gzcd redis-3.2.0make -j4make PREFIX=/usr/local/redis install\n通过PREFIX=/usr/local/redis可以指定redis安装路径 默认安装到/usr/local/bin/中\n提供配置文件并启动redis\nredis的启动非常方便 有很多默认配置 不使用配置文件也可以启动 但是想要灵活配置就比较不方便了\n\ncp redis.conf /etc/redis.conf/usr/local/redis/bin/redis-server /etc/redis.conf\n如果如图下所示 那么就启动成功了 redis默认在前台运行 Ctrl+c 停止\n                _._                                                  \n           _.-``__ &apos;&apos;-._                                             \n      _.-``    `.  `_.  &apos;&apos;-._           Redis 3.2.0 (00000000/0) 64 bit\n  .-`` .-```.  ```\\/    _.,_ &apos;&apos;-._                                   \n (    &apos;      ,       .-`  | `,    )     Running in standalone mode\n |`-._`-...-` __...-.``-._|&apos;` _.-&apos;|     Port: 6379\n |    `-._   `._    /     _.-&apos;    |     PID: 3173\n  `-._    `-._  `-./  _.-&apos;    _.-&apos;                                   \n |`-._`-._    `-.__.-&apos;    _.-&apos;_.-&apos;|                                  \n |    `-._`-._        _.-&apos;_.-&apos;    |           http://redis.io        \n  `-._    `-._`-.__.-&apos;_.-&apos;    _.-&apos;                                   \n |`-._`-._    `-.__.-&apos;    _.-&apos;_.-&apos;|                                  \n |    `-._`-._        _.-&apos;_.-&apos;    |                                  \n  `-._    `-._`-.__.-&apos;_.-&apos;    _.-&apos;                                   \n      `-._    `-.__.-&apos;    _.-&apos;                                       \n          `-._        _.-&apos;                                           \n              `-.__.-&apos;  \n如果不使用配置文件 可以通过命令行参数方式运行redis-server\n/usr/local/redis/bin/redis-server /etc/redis.conf --daemonize yes --port 1212\n\n这个的意思就是在后台运行 监听端口1212 默认是监听6379 \n可以更改redis.conf中的 daemonize 值为yes 这样 redis-server通过配置文件启动就默认在后台运行了\n如果在指定了配置文件又使用了命令行参数的情况 命令行参数会覆盖配置文件中的相同项\nredis客户端连接\nredis-cli便是redis-server的客户端连接工具 同时 redis还有很多其他语言的API接口\n\n/usr/local/redis/bin/redis-cli -h 127.0.0.1 -p 6379\n\nredis-cli 默认会连接本机的6379端口 所以如果服务监听在127.0.0.1:6379 redis-cli可以直接连接\nredis是基于key-value的数据库 下面就测试一下redis工作的是否正常\n\n127.0.0.1:6379&gt; set a 100\nOK\n127.0.0.1:6379&gt; get a\n&quot;100&quot;\n127.0.0.1:6379&gt; \n\nredis的使用非常简单 所有的命令也一共就一百多条 常用的更少 通过set命令给 a 赋值 100\n然后通过 get 命令获取 a 的值 可以看到 a 的值被正确获取 redis服务正常工作\n附录redis各程序功能redis-benchmark         # redis性能测试工具\nredis-check-aof         # aof日志检查工具\nredis-check-rdb         # rdb日志检查工具\nredis-cli               # redis服务客户端\nredis-server            # redis服务程序\nredis-sentinel          # redis哨兵 用于集群检查主从状态 实际上这个是redis-server的软链接\nredis支持的键值数据类型\n字符串类型\n散列类型\n列表类型\n集合类型\n有序集合类型\n\n","categories":["Redis"],"tags":["nosql","redis"]},{"title":"Redis字符串类型","url":"/2016/05/20/2016/redis%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B/","content":"简介\n字符串类型是 Redis 中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据。你可以用其存储用户的邮箱、JSON 化的对象甚至是一张图片。一个字符串类型键允许存储的数据的最大容量是512 MB\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nredis\n3.2.0\n点击下载\n\n\n\n步骤命令返回值\n与redis-server交互 当执行一条命令后 redis-server都会有一个命令返回值 redis-server的返回值类型有五种 下面分别说明\n\n1. 状态回复\n状态回复是最简单的一种回复 比如向Redis发送SET命名设置某个键值时 Redis会回复OK表示成功\n127.0.0.1:6379&gt; SET a 1\nOK\n127.0.0.1:6379&gt; PING\nPONG\n127.0.0.1:6379&gt;\n\n2. 错误回复\n当命令不存在或者命令格式有错误的情况下 Redis会返回错误回复\n127.0.0.1:6379&gt; SET\n(error) ERR wrong number of arguments for &apos;set&apos; command\n127.0.0.1:6379&gt;\n\n3. 整数回复\n获取当前数据库中键的数量等 返回以(integer)开头的回复 这个便是整数回复\n127.0.0.1:6379&gt; dbsize\n(integer) 2\n127.0.0.1:6379&gt;\n\n4. 字符串回复\n字符串回复是最常用的一种回复类型 比如当获得一个键的值 Redis返回的便是一个字符串值\n127.0.0.1:6379&gt; get a\n&quot;1&quot;\n127.0.0.1:6379&gt;\n\n5. 多行字符串回复\n当请求的并非一个键的值 而是一个列表等 就会收到多行字符串回复 每行字符串都以一个序号开头\n127.0.0.1:6379&gt; keys *\n1) &quot;a&quot;\n2) &quot;b&quot;\n127.0.0.1:6379&gt;\n常用命令\n下面将详细说明操作Redis字符串类型的相关命令\n\n赋值与取值SET key value       # 赋值GET key             # 取值\n127.0.0.1:6379&gt; SET name xiaoming\nOK\n127.0.0.1:6379&gt; GET name\n&quot;xiaoming&quot;\n127.0.0.1:6379&gt;\n\n如果需要给多个键同时赋值和取值 Redis还提供了MSET MGET两个命令\nMSET key value [key value ...]      # 同时赋值MGET key [key ...]                  # 同时取值\n127.0.0.1:6379&gt; MSET a 1 b 2 c 3\nOK\n127.0.0.1:6379&gt; MGET a c b \n1) &quot;1&quot;\n2) &quot;3&quot;\n3) &quot;2&quot;\n127.0.0.1:6379&gt;\n\n用MSET 给a 赋值1 b赋值2 c赋值3 返回状态回复OK \n用MGET 先获取a的值 再获取c的值 最后获取b的值 返回一个多行字符串回复\n递增递减INCR key            # 递增\n当Redis存储的字符串是整数时 Redis提供了一个INCR的命令 其作用就是让当前键值递增\n127.0.0.1:6379&gt; INCR num\n(integer) 1\n127.0.0.1:6379&gt; INCR num\n(integer) 2\n127.0.0.1:6379&gt; INCR num\n(integer) 3\n127.0.0.1:6379&gt;\n\n当递增的key不存在时 Redis则自动创建这个key 并赋值为0 所以第一次递增后 就返回1了\n可以看到 返回值类型是整数回复 如果递增的对象不是一个整数会怎样呢\n\n127.0.0.1:6379&gt; INCR name\n(error) ERR value is not an integer or out of range\n127.0.0.1:6379&gt; \n\n可以看到 收到一条错误回复 如果想要递增指定的数字 这个就要引入第二条递增命令了\nINCRBY key increment            # 递增指定整数\n127.0.0.1:6379&gt; INCRBY num 10\n(integer) 13\n127.0.0.1:6379&gt; INCRBY num 3\n(integer) 16\n127.0.0.1:6379&gt;\n\n可以看到 INCR和INCRBY的区别就是 INCRBY可以自定义递增数量 而INCR 只能每次加一\n现在说说递减 递减其实也有专门的操作命令\nDECR key                        # 递减DECRBY key decrement            # 递减指定整数\n127.0.0.1:6379&gt; DECR num\n(integer) 15\n127.0.0.1:6379&gt; DECRBY num 5\n(integer) 10\n127.0.0.1:6379&gt;\n\n有没有想过 如果给INCRBY递增一个负数 或者给DECRBY递减一个负数会发生什么事情呢\n\n127.0.0.1:6379&gt; DECRBY num -10\n(integer) 20\n127.0.0.1:6379&gt; INCRBY num -5\n(integer) 15\n127.0.0.1:6379&gt;\n\n可以看到 正如所想的那样 负负得正还是成立的\n不仅整数可以递增 Redis还存在递增浮点数的命令\nINCRBYFLOAT num increment       # 递增指定浮点数\n127.0.0.1:6379&gt; INCRBYFLOAT num 1.4\n&quot;16.4&quot;\n127.0.0.1:6379&gt; INCRBYFLOAT num -3.2\n&quot;13.2&quot;\n127.0.0.1:6379&gt;\n向尾部追加值APPEND key value                # 向尾部追加值\n127.0.0.1:6379&gt; APPEND name 123abc\n(integer) 14\n127.0.0.1:6379&gt; GET name\n&quot;xiaoming123abc&quot;\n127.0.0.1:6379&gt;\n\n可以看到 APPEND 命令可以向字符串后面增加任意的字符串 返回增加后字符串长度\n获取字符串长度STRLEN key                      # 获取字符串长度\n127.0.0.1:6379&gt; SET hello hello\nOK\n127.0.0.1:6379&gt; STRLEN hello\n(integer) 5\n127.0.0.1:6379&gt; SET hello 你好\nOK\n127.0.0.1:6379&gt; STRLEN hello\n(integer) 6\n127.0.0.1:6379&gt;\n\nRedis可以存储所有编码的字符串 中文也不例外 \n例子中Redis接受的是UTF-8编码的中文 一个中文UTF-8编码长度是3 所以 &apos;你好&apos; 会返回6了\n位操作\n位操作是个很有意思的操作 操作的是这个字符串在内存中的比特位GETBIT key offset               # 获取偏移多少位后的值SETBIT key offset value         # 设置偏移多少位后的值BITCOUNT key [start end]        # 获取比特位是1的个数BITPOS key bit [start] [end]    # 获取第一个位值是0或1的位置\n\n大家都知道 一个字节由8个比特位组成 而一个英文字符又正好一个字节\n\n127.0.0.1:6379&gt; SET name abc\n\na b c的三个字母的ASCII码分别是97 98 99 那么转换为二进制则如下\n\n            a        b        c\n        01100001 01100010 01100011\n\n比特位获取索引从0开始 比如第0位是0 第1位是1 第2位也是1\n\n127.0.0.1:6379&gt; GETBIT name 2\n(integer) 1\n127.0.0.1:6379&gt; GETBIT name 7\n(integer) 1\n127.0.0.1:6379&gt; GETBIT name 8\n(integer) 0\n127.0.0.1:6379&gt; GETBIT name 9\n(integer) 1\n127.0.0.1:6379&gt;\n\nGETBIT是获取比特位的 那么SETBIT自然可以更改比特位的值 更改比特位后 自然也更改了这个字符\n分析a b c 三个字符的二进制数据 发现他们的区别在最后两位 01 10 11 那么修改这几个位的值试试\n\n127.0.0.1:6379&gt; SETBIT name 6 1\n(integer) 0\n127.0.0.1:6379&gt; GET name\n&quot;cbc&quot;\n127.0.0.1:6379&gt;\n\n将a的第6位修改为1 那么原本a的二进制就变成了01100011 也就是和c相同了 a被变成了c\n\nBITCOUNT用来统计一定范围内比特位为1的个数 name的值变为cbc后 比特位如下\n\n            c        b        c\n        01100011 01100010 01100011\n\n可以数出来 1的个数有11个 BITCOUNT还可以限定参与计算的字符范围\n\n127.0.0.1:6379&gt; BITCOUNT name\n(integer) 11\n127.0.0.1:6379&gt; BITCOUNT name 0 0\n(integer) 4\n127.0.0.1:6379&gt;\n\n第一个0是从第几个字符开始 第二个0是到第几个字符结束 0 0 就表示只有第一个字符c参与计算\n\nRedis 2.8.7版本以上才有BITPOS这个命令 可以获取指定键的第一个位值是0或者1的位置 也可以限定范围\n\n127.0.0.1:6379&gt; BITPOS name 1\n(integer) 1\n127.0.0.1:6379&gt; BITPOS name 0 1 2\n(integer) 8\n127.0.0.1:6379&gt;\n\n第一个命令 获取name中 位值为1的索引 可以看到 01100011中 位值为1的索引是1\n第二个命令 限定从索引为1的字符开始 到索引为2的字符 位值为0的索引 字符b的第一位就是0 索引是8\n附录\n命令总结\n\nSET key value                   赋值\nGET key                         取值\nMSET key value [key value …]    同时赋值\nMGET key [key …]                同时取值\nINCR key                        递增\nINCRBY key increment            递增指定整数\nDECR key                        递减\nDECRBY key decrement            递减指定整数\nINCRBYFLOAT num increment       递增指定浮点数\nAPPEND key value                向尾部追加值\nSTRLEN key                      获取字符串长度\nGETBIT key offset               获取偏移多少位后的值\nSETBIT key offset value         设置偏移多少位后的值\nBITCOUNT key [start end]        获取比特位是1的个数\nBITPOS key bit [start] [end]    获取第一个位值是0或1的位置\n","categories":["Redis"]},{"title":"Redis有序集合类型","url":"/2016/05/24/2016/redis%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E7%B1%BB%E5%9E%8B/","content":"简介\n有序集合类型 顾名思义 与集合类型的区别就是有序 这个有序是在集合类型的基础上 给每个元素关联了一个分数 按照分数进行排序\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nredis\n3.2.0\n点击下载\n\n\n\n步骤与列表类型的区别\n有序集合类型在某些方面和列表类型相似 但是还是有很大的区别\n\n与列表相似的地方:\n    1. 两者都是有序的\n    2. 两者都可以获取某一个范围的元素\n\n与列表不同的地方:\n    1. 列表通过链表实现 所以访问两端数据比较快 访问中间数据会较慢 \n    2. 而集合采用散列表和跳跃表 所以没有这个忧虑\n    3. 列表不能简单的调整某个元素的位置 但有序集合通过修改元素分数可以 \n    4. 有序集合比列表类型更耗费内存\n常用命令\n下面将详细说明操作Redis有序集合类型的相关命令\n\n增加元素ZADD key score member [score member …]      # 增加元素\n127.0.0.1:6379&gt; ZADD num 1 a 2 b 3 c\n(integer) 3\n127.0.0.1:6379&gt; ZADD num 2 a 2.5 d\n(integer) 1\n127.0.0.1:6379&gt;\n\n元素的分数可以修改 可以是小数 最后的排序方式就是按照分数排序的\n获取元素分数ZSCORE key member           # 获取元素分数\n127.0.0.1:6379&gt; ZSCORE num a\n&quot;2&quot;\n127.0.0.1:6379&gt; ZADD num 3 a \n(integer) 0\n127.0.0.1:6379&gt; ZSCORE num a\n&quot;3&quot;\n127.0.0.1:6379&gt;\n获取某个范围的元素ZRANGE key start stop [WITHSCORES]      # 获取某个索引范围的元素ZREVRANGE key start stop [WITHSCORES]   # 获取某个索引范围的元素 反序排序\n127.0.0.1:6379&gt; ZRANGE num 0 -1\n1) &quot;b&quot;\n2) &quot;d&quot;\n3) &quot;a&quot;\n4) &quot;c&quot;\n127.0.0.1:6379&gt; ZRANGE num 0 1 WITHSCORES\n1) &quot;b&quot;\n2) &quot;2&quot;\n3) &quot;d&quot;\n4) &quot;2.5&quot;\n127.0.0.1:6379&gt;\n\nZRANGE的用法和LRANGE的用法大致一样 只不过多了个 WITHSCORES 可以同时显示分数\n如果出现分数相同的情况 则按照 0 &lt; 9 &lt; A &lt; Z &lt; a &lt; z 规则排序\n\n127.0.0.1:6379&gt; ZREVRANGE num 0 -1\n1) &quot;c&quot;\n2) &quot;a&quot;\n3) &quot;d&quot;\n4) &quot;b&quot;\n127.0.0.1:6379&gt;\n\n可以看到 ZREVRANGE 与 ZRANGE 结果是相反的\n获取某个分数范围的元素ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]     # 获取某个分数范围的元素ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]  # 获取某个分数范围的元素 反序排序\n127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3\n1) &quot;d&quot;\n2) &quot;a&quot;\n3) &quot;c&quot;\n127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 (3\n1) &quot;d&quot;\n127.0.0.1:6379&gt; ZRANGEBYSCORE num (2.5 3\n1) &quot;a&quot;\n2) &quot;c&quot;\n127.0.0.1:6379&gt;\n\n如果不希望获取端点值 可以在端点分数前加 &quot;(&quot; 这样就可以把端点值排除在外了 无穷大可以用 +inf\n\n127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 LIMIT 0 2\n1) &quot;d&quot;\n2) &quot;a&quot;\n127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 LIMIT 1 2\n1) &quot;a&quot;\n2) &quot;c&quot;\n127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 LIMIT 1 3\n1) &quot;a&quot;\n2) &quot;c&quot;\n127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 LIMIT 0 3\n1) &quot;d&quot;\n2) &quot;a&quot;\n3) &quot;c&quot;\n127.0.0.1:6379&gt;\n\nWITHSCORES用法不在赘述 LIMIT是限制结果数量 LIMIT 1 2表示从结果的索引1开始 只要2个结果\nZREVRANGEBYSCORE的用法可以参考ZRANGE与ZREVRANGE的去别 也不再详细说明\n增加某个元素的分数ZINCRBY key increment member            # 增加某个元素的分数\n127.0.0.1:6379&gt; ZSCORE num a\n&quot;3&quot;\n127.0.0.1:6379&gt; ZINCRBY num 4 a\n&quot;7&quot;\n127.0.0.1:6379&gt; ZINCRBY num -2 a\n&quot;5&quot;\n127.0.0.1:6379&gt;\n\n如果指定的元素不存在 ZINCRBY同样会先创建 赋值为0后在增加分数\n获取集合中元素数量ZCARD key               # 获取集合中元素数量\n127.0.0.1:6379&gt; ZCARD num\n(integer) 4\n127.0.0.1:6379&gt; ZADD num 6 e \n(integer) 1\n127.0.0.1:6379&gt; ZCARD num\n(integer) 5\n127.0.0.1:6379&gt;\n获得指定分数范围内的元素个数ZCOUNT key min max          # 获得指定分数范围内的元素个数\n127.0.0.1:6379&gt; ZRANGE num 0 -1 WITHSCORES\n 1) &quot;b&quot;\n 2) &quot;2&quot;\n 3) &quot;d&quot;\n 4) &quot;2.5&quot;\n 5) &quot;c&quot;\n 6) &quot;3&quot;\n 7) &quot;a&quot;\n 8) &quot;5&quot;\n 9) &quot;e&quot;\n10) &quot;6&quot;\n127.0.0.1:6379&gt; ZCOUNT num (2.5 5\n(integer) 2\n127.0.0.1:6379&gt; ZCOUNT num 2.5 5\n(integer) 3\n127.0.0.1:6379&gt;\n\n获取分数为2.5到5之间元素个数 也可以使用 &quot;(&quot; 是否排查端点\n删除一个或多个元素ZREM key member [member …]      # 删除一个或多个元素\n127.0.0.1:6379&gt; ZREM num a b \n(integer) 2\n127.0.0.1:6379&gt; ZRANGE num 0 -1 \n1) &quot;d&quot;\n2) &quot;c&quot;\n3) &quot;e&quot;\n127.0.0.1:6379&gt;\n\n命令返回删除成功的元素数量\n按照排名范围删除元素ZREMRANGEBYRANK key start stop          # 按照排名范围删除元素\n127.0.0.1:6379&gt; ZREMRANGEBYRANK num 0 1\n(integer) 2\n127.0.0.1:6379&gt; ZRANGE num 0 -1 WITHSCORES\n1) &quot;e&quot;\n2) &quot;6&quot;\n127.0.0.1:6379&gt;\n\n按照索引范围去删除元素 返回删除成功的元素个数\n按照分数范围删除元素ZREMRANGEBYSCORE key min max        # 按照分数范围删除元素\n127.0.0.1:6379&gt; ZADD num 2 a 3 b 4 d\n(integer) 3\n127.0.0.1:6379&gt; ZREMRANGEBYSCORE num (2 4\n(integer) 2\n127.0.0.1:6379&gt; ZRANGE num 0 -1\n1) &quot;a&quot;\n2) &quot;e&quot;\n127.0.0.1:6379&gt;\n\n删除分数大于2 小于4的元素 返回删除成功的元素个数\n获得元素的排名ZRANK key member                # 获得元素的排名 正序排序ZREVRANK key member             # 获得元素的排名 反序排序\n127.0.0.1:6379&gt; ZRANK num a\n(integer) 0\n127.0.0.1:6379&gt; ZRANK num e\n(integer) 1\n127.0.0.1:6379&gt; ZREVRANK num e\n(integer) 0\n127.0.0.1:6379&gt; ZREVRANK num a\n(integer) 1\n127.0.0.1:6379&gt;\n\n排序从0开始 ZREVRANK会反序排序 \n集合运算ZINTERSTORE dest numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]  # 交集ZUNIONSTORE dest numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]  # 并集\nnumkeys是参与计算的键的个数 WEIGHTS是权重 \nAGGREGATE绝定最后结果集合的元素分数是取平均数还是最大最小值\n\n127.0.0.1:6379&gt; ZADD num1 1 a 2 b 3 c \n(integer) 3\n127.0.0.1:6379&gt; ZADD num2 1 b 2 c 3 d \n(integer) 3\n127.0.0.1:6379&gt; ZINTERSTORE tmp1 2 num1 num2 AGGREGATE SUM\n(integer) 2\n127.0.0.1:6379&gt; ZRANGE tmp1 0 -1 WITHSCORES \n1) &quot;b&quot;\n2) &quot;3&quot;\n3) &quot;c&quot;\n4) &quot;5&quot;\n127.0.0.1:6379&gt;\n\n结果分数是取参与运算元素分数的总数 num1中b的分数是2 num2中b的分数是1 最后结果是3\n如果不加AGGREGATE 默认也是去SUM值 所以可以不用加\n\nWEIGHTS参数设置每个集合的权重，每个集合在参与计算时元素的分数会被乘上该集合的权重\n\n127.0.0.1:6379&gt; ZINTERSTORE tmp2 2 num1 num2 WEIGHTS 1 10\n(integer) 2\n127.0.0.1:6379&gt; zrange tmp2 0 -1 WITHSCORES\n1) &quot;b&quot;\n2) &quot;12&quot;\n3) &quot;c&quot;\n4) &quot;23&quot;\n127.0.0.1:6379&gt; \n\nZUNIONSTORE与ZINTERSTORE用法相似 则不再赘述\n附录\n命令总结\n\nZADD key score member [score member …]              增加元素\nZSCORE key member                                   获取元素分数\nZRANGE key start stop [WITHSCORES]                  获取某个索引范围的元素\nZREVRANGE key start stop [WITHSCORES]               获取某个索引范围的元素 反序排序\nZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count]     获取某个分数范围的元素\nZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count]  获取某个分数范围的元素 反序排序\nZINCRBY key increment member                        增加某个元素的分数\nZCARD key                                           获取集合中元素数量\nZCOUNT key min max                                  获得指定分数范围内的元素个数\nZREM key member [member …]                          删除一个或多个元素\nZREMRANGEBYRANK key start stop                      按照排名范围删除元素\nZREMRANGEBYSCORE key min max                        按照分数范围删除元素\nZRANK key member                                    获得元素的排名 正序排序\nZREVRANK key member                                 获得元素的排名 反序排序\nZINTERSTORE dest numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]  交集\nZUNIONSTORE dest numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX]  并集\n","categories":["Redis"]},{"title":"Python3编译安装","url":"/2017/12/21/2017/Python3%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"简介\nPython是一种面向对象的解释型计算机程序设计语言，由荷兰人Guido van Rossum于1989年发明，第一个公开发行版发行于1991年。Python是纯粹的自由软件， 源代码和解释器CPython遵循GPL协议。Python的用处如今已经非常强大，人工智能、数据处理、Web后端、爬虫、运维等都能见到Python的身影。\n\n\n环境系统环境\n在 CentoOS 6.8 上编译的\n\n软件环境\n\n\n源码包\n版本\n下载地址\n\n\n\n\nPython\n3.6.4\n点击下载\n\n\n\n步骤安装依赖\nPython的某些模块可以按需编译 比如tkinter sqlite3等 如果不安装它的devel包 Python编译过程中将忽略此模块\n\nyum -y install make gcc gcc-c++ zlib-devel bzip2-devel gdbm-devel \\xz-devel tk-devel readline-devel sqlite-devel ncurses-devel openssl-devel\n开始编译\n解压源码包后进入源码目录\n\n./configure --enable-optimizations --prefix=/usr/local/python3 --enable-sharedsed -i &apos;s/test.regrtest/this/g&apos; Makefile        # 此步骤屏蔽单元测试（耗时太长）make -j4\n在make的过程中 如果有标准库中的模块依赖没有找到 标准输出会有显示 内容可能如下\nPython build finished successfully!\nThe necessary bits to build these optional modules were not found:\n_bz2                  _curses               _curses_panel      \n_dbm                  _gdbm                 _lzma              \n_sqlite3              _ssl                  _tkinter           \nreadline              zlib                                     \nTo find the necessary bits, look in setup.py in detect_modules() for the module&apos;s name.\n安装好相应的模块的devel包后 不需要重新configure 重新make即可\n安装使用make install echo &apos;export PATH=$PATH:/usr/local/python3/bin&apos; &gt; /etc/profile.d/python3.shecho &apos;/usr/local/python3/lib&apos; &gt; /etc/ld.so.conf.d/python3.confldconfigsource /etc/profile.d/python3.sh\n卸载\n删除安装目录就可以了\n\nrm -rf /usr/local/python3/rm -rf /etc/profile.d/python3.shrm -rf /etc/ld.so.conf.d/python3.conf\n附录如果不提前把Python的依赖安装好 虽然可以编译成功 但是会缺少不少的模块\n","categories":["Python"],"tags":["Python"]},{"title":"Redis服务管理及配置文件","url":"/2016/05/18/2016/redis%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%E5%8F%8A%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6/","content":"简介\nRedis启动后还需要对其进行管理 比如如何安全的关闭数据库 以及如何配置服务的监听地址 访问密码等下面将详细说明 Redis服务的简单管理 以及配置文件详解\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nredis\n3.2.0\n点击下载\n\n\n\n步骤启动和停止Redis\n启动Redis很简单 可执行程序路径后面跟配置文件路径就可以了 如果在前台运行Redis的话 Ctrl+c就可以很安全的关闭Redis了 那么如果在后台运行呢\n\n/usr/local/redis/bin/redis-server /etc/redis.conf --daemonize yes\n\n通过--daemonize yes或者直接修改配置文件中的daemonize为yes 让Redis默认后台运行\n\n[root@localhost ~]# netstat -anpt\ntcp    0   0 127.0.0.1:6379        0.0.0.0:*       LISTEN    3268/redis-server 1 \n\n可以看到 Redis已经监听在本机127.0.0.1的6379端口 PID号为3268 \n关闭Redis也非常简单 因为Redis能很好的处理TREM信号 所以可以直接 kill 3268\n同样 使用redis-cli客户端连接工具 向Redis服务发送SHUTDOWN命令也是可以安全关闭的\n\n/usr/local/redis/bin/redis-cli -h 127.0.0.1 -p 6379 SHUTDOWN\n\nredis的命令不区分大小写 但是建议命令大写\n如果服务监听在本机的127.0.0.1:6379 redis-cli可以直接连接 而不用指定主机和端口号\n当redis收到结束命令或TERM信号后 会断开所有客户端连接 然后将内存数据序列化到硬盘 最后完成退出\nRedis配置文件\nRedis的启动监听地址 监听端口 以及配置PID文件路径等 有非常多的启动参数 如果都在启动redis的时候传入 那么将非常麻烦 而通过配置文件的方式 将大大简化这个过程Redis的配置项还分两种 一种是只能在启动Redis的时候配置的 比如监听端口等 还有一种可以在命令行中动态修改的 比如日志记录级别等 以下是Redis配置文件中常用配置项\n\ninclude /path/to/other.conf     # 包含其他配置文件\n\n监听相关配置项\ntcp-backlog 511                 # TCP监听最大容纳数量 增大可以解决高并发下客户端连接缓慢问题\nunixsocket /tmp/redis.sock      # 非默认项 启动unix套接字监听 redis-cli -s /tmp/redis.sock连接\ntimeout 0                       # 客户端多长时间没有操作redis关闭连接 0表示不关闭\ntcp-keepalive 0                 # tcp 心跳包 防止一个死的对端连接 推荐设置为60秒\n\n一般配置项\ndaemonize no                    # Redis默认运行在前台 使用yes可以让Redis默认后台运行\npidfile /var/run/redis.pid      # pid文件位置\nloglevel notice                 # 日志记录级别 [debug | verbose | notice | warning]\nlogfile /tmp/redis.log          # 日志文件位置 默认是个空字符串 redis将日志打印到标准输出\nsyslog-enabled no               # 如果想把日志记录到系统日志 就改为yes\ndatabases 16                    # redis启动数据库空间个数 默认进入的是id为0空间 select dbID切换\n\n数据库快照配置项\nsave 900 1                      # 保存数据库到磁盘 900 秒内如果至少有 1 个 key 的值变化，则保存\nsave 300 10                     # 300 秒内如果至少有 10 个 key 的值变化，则保存\nsave 60 10000                   # 60 秒内如果至少有 10000 个 key 的值变化，则保存\nsave &quot;&quot;                         # 停用自动保存功能 不同的保存规则是可以都生效的\ndbfilename dump.rdb             # 保存数据的文件位置\nstop-writes-on-bgsave-error yes # 后台保存数据出错 redis强制关闭写操作\nrdbcompression yes              # 是否在保存数据时压缩 可以减少磁盘使用 但是增大CPU负载\nrdbchecksum yes                 # 是否校验rdb文件\ndir ./                          # dump.rdb就保存在dir目录中\n\n主从复制配置项\nslaveof 172.17.0.2 6379         # 作为172.17.0.2的从数据库\nmasterauth password             # 如果主数据库需要认证 密码写这里\nslave-serve-stale-data yes      # 如果与主失去联系 从是否要继续提供查询服务 数据可能不是最新\nslave-read-only yes             # 默认从数据库不支持写入操作 \nrepl-ping-slave-period 10       # 默认每10秒 从数据库发送ping命令道主数据库\nrepl-timeout 60                 # 主从复制过期时间 一定要比repl-ping-slave-period大\nrepl-diskless-sync no     # 默认情况下 复制是内存-&gt; 磁盘-&gt; 内存-&gt; slave端 yes后 将直接发到slave\nrepl-diskless-sync-delay 5      # 收到第一个请求时 等待多个slave一起来请求之间的间隔时间\nrepl-backlog-size 1mb           # 设置主从复制容量大小 slave断线重连 只恢复断开时丢失的数据\nrepl-backlog-ttl 3600           # 3600秒后 slave没有连接 master将释放backlog 0表示不释放\nslave-priority 100              # 集群中用 master挂了 slave提升为master的优先级\nmin-slaves-to-write 3           # 至少3个slave才允许向master写数据\nmin-slaves-max-lag 10           # 至少3个slave 并且ping心跳的超时不超过10秒 才允许向master写数据\n\n安全配置项\nrequirepass passwd              # 连接需要密码 redis-cli 需要通过auth命令 或 -a 参数指定密码登陆\nrename-command CONFIG &quot;&quot;        # 给命令重命名 如果重命名为空字符串 则屏蔽命令\n\n限制相关配置\nmaxclients 10000                # 最大连接客户端数量 超过的 redis将关闭新连接\nmaxmemory 1024mb                # 数据库最大占用1024mb内存 超过的话 将按照策略移除keys\nmaxmemory-policy noeviction     # 内存超过后默认移除key的策略\nmaxmemory-samples 5             # 调整算法的速度和精度 默认从五个键中找到一个使用最少的键\n\n以下是支持的策略:\n    volatile-lru -&gt;     使用 LRU 算法移除包含过期设置的 key\n    allkeys-lru  -&gt;     根据 LRU 算法移除所有的 key\n    volatile-random -&gt;  随机移除过期的key\n    allkeys-random  -&gt;  随机移除所有的key\n    volatile-ttl -&gt;     删除最近到期的key\n    noeviction   -&gt;     不让任何 key 过期，只是给写入操作返回一个错误\n\nAOF日志配置项\nappendonly no                   # 默认不启用aof日志\nappendfilename redis.aof        # aof日志名称 和rdb快照共享dir路径\nappendfsync everysec            # aof日志同步硬盘数据策略 (fsync)\n每次更改数据库内存后 AOF都会将命令记录到AOF文件 但是由于系统缓存机制 数据还并没真正写入硬盘\n系统默认30秒写入一次硬盘 如果在这期间 系统异常退出 将导致数据丢失 以下是redis的解决策略:\n    no        -&gt;        不进行主动同步操作\n    always    -&gt;        每次执行写入操作都进行一次同步\n    everysec  -&gt;        每秒执行一次主动同步操作\n\nno-appendfsync-on-rewrite no    # 是否在Redis重写aof文件期间调用fsync\nauto-aof-rewrite-percentage 100 # aof文件增长超过上次aof文件大小100% 重写aof文件 0 禁用\nauto-aof-rewrite-min-size 64mb  # 触发aof重写的大小限制 只有aof大小超过64mb 上一条才生效\naof-load-truncated yes          # redis在启动时可以加载被截断的AOF文件\n\nLua脚本配置项\nlua-time-limit 5000             # 一个lua脚本最长执行时间 0或负数无限执行 默认5000毫秒\n\nRedis集群配置项\ncluster-enabled yes             # 启用或禁用集群\ncluster-config-file nodes.conf     # 保存节点配置文件的路径 节点配置文件无须人为修改\ncluster-node-timeout 15000      # 集群节点超时 默认15000毫秒\ncluster-slave-validity-factor 10    # master失联多久 slave故障切换 0 表示一直尝试切换\ncluster-migration-barrier 1         # 一个master可以拥有的最小slave数量\ncluster-require-full-coverage yes   # 当一定比例的键空间没有被覆盖到 集群就停止任何查询操作\n\n慢查询日志配置项\nslowlog-log-slower-than 10000   # 配置记录慢查询日志的条件 单位是微妙 负值关闭 0记录所有\nslowlog-max-len 1024            # 记录慢查询日志最大条数\n\n延时监控配置项\nlatency-monitor-threshold 0     # redis延迟监控子系统在运行时 会抽样检测可能导致延迟的不同操作\n                                # 系统只记录超过设定值的操作 单位是毫秒 0表示禁用该功能  \n\n事件通知配置项\nnotify-keyspace-events &quot;&quot;       # 空字符串表示关闭键空间通知功能 支持以下字符任意组合\nK       -&gt;      键空间通知 所有通知以 __keyspace@ __ 为前缀\nE       -&gt;      键事件通知，所有通知以 __keyevent@ __ 为前缀\ng       -&gt;      DEL EXPIRE RENAME 等类型无关的通用命令的通知\n$       -&gt;      字符串命令的通知\nl       -&gt;      列表命令的通知\ns       -&gt;      集合命令的通知\nh       -&gt;      哈希命令的通知\nz       -&gt;      有序集合命令的通知\nx       -&gt;      过期事件 每当有过期键删除时通知\ne       -&gt;      键淘汰事件 每当有键因为maxmemory-policy 策略被淘汰时通知\nA       -&gt;      参数g$lshzxe 的别名\n\n高级配置\nhash-max-ziplist-entries 512    # 指定在超过一定的数量或者最大的元素超过某一临界值时\nhash-max-ziplist-value 64       # 采用一种特殊的哈希算法\nlist-max-ziplist-size -2        # 列表 集合 有序集合和哈希的一样\nlist-compress-depth 0\nset-max-intset-entries 512\nzset-max-ziplist-entries 128\nzset-max-ziplist-value 64\nhll-sparse-max-bytes 3000       # HyperLogLog稀疏表示限制设置\nactiverehashing yes             # 如果对延迟要求较高 则设为no 禁止重新hash 但可能会浪费很多内存\nclient-output-buffer-limit normal 0 0 0         # 客户端缓存限制 硬限制 软限制 以及软限制持续秒数\nclient-output-buffer-limit slave 256mb 64mb 60  # 当满足硬限制 或者 软限制和持续秒数 与客户端断开\nclient-output-buffer-limit pubsub 32mb 8mb 60\nhz 10                       # 内部函数执行的后台任务的频率 如清除过期数据 客户端超时链接等 1~500\n附录动态更改Redis配置\n连接到redis后 用CONFIG GET * 可以看到所有的配置 用CONFIG SET则可以对配置进行修改 但是 并不是所有的配置都能动态修改\n\n下面的例子 是用CONFIG SET 动态的给数据库添加认证密码\n\n127.0.0.1:6379&gt; CONFIG SET requirepass 123.com\nOK\n127.0.0.1:6379&gt; set a 100\n(error) NOAUTH Authentication required.\n127.0.0.1:6379&gt; auth 123.com\nOK\n127.0.0.1:6379&gt; set a 100\nOK\n127.0.0.1:6379&gt;\n\n可以看到 通过CONFIG GET已经可以看到刚才设置的密码\n127.0.0.1:6379&gt; CONFIG GET requirepass \n1) &quot;requirepass&quot;\n2) &quot;123.com&quot;\n127.0.0.1:6379&gt;\n\n由于已经配置了密码 下次登陆的时候 也可以直接用 -a 参数提供认证密码\n/usr/local/redis/bin/redis-cli -a 123.com\n","categories":["Redis"],"tags":["nosql","redis"]},{"title":"Galera集群编译安装","url":"/2017/08/06/2017/Galera%E9%9B%86%E7%BE%A4%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85/","content":"简介\nGalera是一种新型的高一致性MySQL集群架构，集成了Galera插件的MySQL集群，是一种新型的，数据不共享的，高度冗余的高可用方案。当有客户端要写入或者读取数据时，随便连接哪个实例都是一样的，读到的数据是相同的，写入某一个节点之后，集群自己会将新数据同步到其它节点上面，这种架构不共享任何数据，是一种高冗余架构。\n\n\n环境系统环境\n系统使用 CentOS 6.8\n\n软件环境\n\n\n源码包\n版本\n下载地址\n\n\n\n\nmysql-wsrep\nNone\n点此自行选择合适的版本下载\n\n\n\n步骤\n建议查看官方文档：http://galeracluster.com/documentation-webpages/installmysqlsrc.html\n\n安装编译环境yum -y install make gcc-c++ gcc cmake bison-devel ncurses-devel perl bison git automake \\autoconf libaio libaio-devel  scons  boost  boost-devel openssl-devel openssl check check-devel\n编译mysql\n自行下载集成wsrep补丁的MySQL后解压 这里使用MySQL 5.6的版本\n\ncmake  \\-DCMAKE_INSTALL_PREFIX=/usr/local/mysql    \\-DMYSQL_DATADIR=/usr/local/mysql/data    \\-DSYSCONFDIR=/etc   \\-DWITH_WSREP=ON -DWITH_INNODB_DISALLOW_WRITES=ON ./make -j10 &amp;&amp; make install\n编译galera插件git clone https://github.com/codership/galera.gitcd galerasconsstrip libgalera_smm.so      # 裁剪库文件无用的调试信息 减小文件体积mv libgalera_smm.so /usr/local/mysql/lib/plugin/# 编译过程耗时较长 可以继续下面的步骤\n初始化mysql运行环境useradd mysql -M -s /sbin/nologinchown -R mysql:mysql /usr/local/mysqlcp support-files/mysql.server /etc/init.d/mysqldchmod +x /etc/init.d/mysqldcd /usr/local/mysqlstrip bin/* lib/* lib/plugin/*      # 同样进行裁剪scripts/mysql_install_db --datadir=/usr/local/mysql/data/ --user=mysqlecho /usr/local/mysql/lib &gt; /etc/ld.so.conf.d/mysql5.6.confldconfig -v |grep /usr/local/mysql/lib   # 查看/usr/local/mysql/lib是否被加入到系统运行库中echo &apos;export PATH=$PATH:/usr/local/mysql/bin&apos; &gt; /etc/profile.d/mysql5.6.shsource /etc/profilemkdir -p /etc/mysql/conf.dmkdir /var/lib/mysql\n修改配置文件修改 /etc/my.cnf\n[mysql]\n!includedir /etc/mysql/conf.d/\n编辑 /etc/mysql/conf.d/my_galera.cnf\n[mysql]\n#设置mysql client default character\ndefault-character-set=utf8\nno-auto-rehash\nprompt=&quot;\\\\u@\\\\h:\\\\d \\\\r:\\\\m:\\\\s&gt;&quot;\n\n[mysqld]\nuser=mysql\nbind-address=0.0.0.0\ncharacter-set-server=utf8\ndefault-storage-engine=INNODB\ndefault-time-zone=&apos;+8:00&apos;\ndatadir=/usr/local/mysql/data/\nsocket=/usr/local/mysql/data/mysql.sock\nskip-name-resolve\n\n#slow query\nslow_query_log=on\nlog_output=FILE\nslow_query_log_file=slow_query.txt\nlong_query_time=1\n\nmax_connections=5000\ntable_open_cache=2048\nsort_buffer_size=8M\nthread_cache_size=16\n#query_cache_size=32M  #galera: Do not use query cache\n# Try number of CPU&apos;s*2 for thread_concurrency\nthread_concurrency=8\n\n#MyISAM\nkey_buffer_size=512M\nread_buffer_size=8M\nread_rnd_buffer_size=8M\n\n#InnoDB\ninnodb_buffer_pool_size=1G\ninnodb_additional_mem_pool_size=20M\n\n#galera innodb参数\nbinlog_format=ROW\ninnodb_autoinc_lock_mode=2\ninnodb_flush_log_at_trx_commit=0\ntransaction-isolation=READ-COMMITTED\n\n#galera cluster参数\nwsrep_provider=/usr/local/mysql/lib/plugin/libgalera_smm.so\nwsrep_provider_options=&quot;gcache.size=300M; gcache.page_size=1G&quot;\nwsrep_sst_method=rsync\nwsrep_sst_auth=wsrep_sst-user:123456\n\nwsrep_cluster_name=MyCluster\nwsrep_cluster_address=&quot;gcomm://&quot;\nwsrep_node_name=galera.node1\nwsrep_node_address=&quot;172.17.0.3&quot;\n注意：根据实际情况更改配置文件，第一个启动的节点wsrep_cluster_address的值为gcomm://，其他节点启动的时候要将这个值改为第一个节点的IP 比如gcomm://172.17.0.3。wsrep_node_address修改为自己的IP就好了\n启动集群\n先启动集群的第一个节点 也就是wsrep_cluster_address的值为gcomm://的那个节点，然后依次启动其他的就好了。\n\nservice mysqld start\n附录Galera集群好像并不是那么可靠。。。 机器的数据越多 性能的提升率就越低。\n参考文章：http://www.sohu.com/a/147032902_505779\n","categories":["MySQL"],"tags":["MySQL"]},{"title":"Zabbix3.0安装文档","url":"/2016/04/02/2016/zabbix3.0%E5%AE%89%E8%A3%85%E6%96%87%E6%A1%A3/","content":"简介\nzabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。zabbix能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题。zabbix由2部分构成，zabbix server与可选组件zabbix agent。zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能，它可以运行在Linux，Solaris，HP-UX，AIX，Free BSD，Open BSD，OS X等平台上百度百科\n\n环境\n在Linux下编译安装 zabbix3.0版对PHP最低版本要求是5.4 其他软件包无要求 \n\n主机环境\n\n\n身份\n系统\nIP\n\n\n\n\nMySQL 服务器\nCentOS 6.7\n172.17.0.2\n\n\nPHP-fpm 服务器\nCentOS 6.7\n172.17.0.3\n\n\nNginx 服务器\nCentOS 6.7\n172.17.0.4\n\n\nZabbix Server\nCentOS 6.7\n172.17.0.5\n\n\nZabbix Agent1\nCentOS 6.7\n172.17.0.6\n\n\nZabbix Agent2\nWindows\n172.17.0.7\n\n\n\n软件环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nphp\n5.6.19\n下载地址\n\n\nnginx\n1.9.13\n点击下载\n\n\nmysql\n5.6.28\n点击下载\n\n\nzabbix\n3.0.1\n点击下载\n\n\nzabbix agent win版\n3.0.0\n点击下载\n\n\n\n步骤搭建LNMP环境\n由于zabbix自带的web管理界面需要PHP环境 所以只需要提供一个PHP版本不低于5.4的web环境即可以下是在Linux上搭建LNMP环境\n\n\n\n\n服务器\n安装文档地址\n\n\n\n\nNginx\n点击打开文档内容\n\n\nMySQL\n点击打开文档内容\n\n\nPHP-fpm\n点击打开文档内容\n\n\nLNMP\n点击打开文档内容\n\n\n\n编译安装Zabbix\n需要系统先初始化开发环境 以及安装需要的程序开发包\n\nyum -y install gcc mysql-devel libxml2-devel net-snmp-devel libssh2-devel curl-devel\ntar xf zabbix-3.0.1.tar.gzcd zabbix-3.0.1./configure --prefix=/usr/local/zabbix \\--enable-server --enable-agent \\--with-mysql --with-net-snmp \\--with-libcurl --with-libxml2 --with-ssh2make -j4 &amp;&amp; make install\n配置zabbix server\n还需要给zabbix server配置防火墙安全策略 数据库 web服务等\n\n配置防火墙关闭或者配置服务器的iptables和SElinux策略\nservice iptables stop\nsetenforce 0\nvim /etc/selinux/config\n    修改SELINUX=disabled\n导入数据库mysql授权zabbix用户以及创建zabbix库\nmysql -uroot -h172.17.0.2 -p\nmysql&gt; grant all privileges on zabbix.* to zabbix@&quot;%&quot; identified by &quot;123.com&quot;;\nmysql&gt; create database zabbix default charset utf8;\nmysql -uzabbix -h172.17.0.2 -p123.com zabbix &lt; schema.sqlmysql -uzabbix -h172.17.0.2 -p123.com zabbix &lt; images.sqlmysql -uzabbix -h172.17.0.2 -p123.com zabbix &lt; data.sql\n启动zabbix服务修改zabbix_server.conf\nvim /usr/local/zabbix/etc/zabbix_server.conf\n\nDBName=zabbix\nDBHost=172.17.0.2        # 这里就是MySQL服务器的地址\nDBUser=zabbix\nDBPassword=123.com\nDBPort=3306\nListenPort=10051\nLogFile=/usr/local/zabbix/log/zabbix_server.log\nLogFileSize=100\nDebugLevel=2\nTimeout=30\nPidFile=/usr/local/zabbix/var/zabbix_server.pid\nStartPollers=20\nStartPollersUnreachable=5\nStartTrappers=5\nmkdir /usr/local/zabbix/&#123;log,var&#125;useradd -M -s /sbin/nologin zabbix\t\t# 创建zabbix运行用户chown -R zabbix:zabbix /usr/local/zabbix/cp misc/init.d/fedora/core/&#123;zabbix_server,zabbix_agentd&#125; /etc/init.d/chmod +x /etc/init.d/&#123;zabbix_server,zabbix_agentd&#125;\t\t#服务控制脚本# 修改/etc/init.d/zabbix_server 和 /etc/init.d/zabbix_agentd # 确保BASEDIR的路径正确 BASEDIR=/usr/local/zabbix/usr/local/zabbix/sbin/zabbix_server\t# 这里直接使用绝对路径启动程序\n检测zabbix_server是否正常启动监听 监听端口10051\n[root@7938190c2002 zabbix-3.0.1]# netstat -anpt |grep 10051\ntcp     0    0 0.0.0.0:10051       0.0.0.0:*        LISTEN      - \n\n如果没有正常启动服务 请查看日志 /usr/local/zabbix/log/zabbix_server.log\n配置web管理界面修改php-fpm服务的配置文件 修改为zabbix需要的值\nvim php.ini            # 本环境中 php.ini位置在/usr/local/php/lib/php.ini\n\n    date.timezone = Asia/Shanghai\n    post_max_size = 32M\n    max_execution_time = 300\n    max_input_time = 300\n    always_populate_raw_post_data = -1        # php5.6以上版本会出现这个\n\n重启php-fpm服务\nservice php-fpm restart\n# 注意 是将php目录复制到php-fpm能访问到的路径 根据实际情况决定# 本环境已经通过NFS让zabbix, nginx 和 php-fpm 共享/var/www/html目录cp -rf frontends/php/ /var/www/html/zabbixchmod -R 777 /var/www/html/zabbix/conf\t\t# php页面需要将配置信息写到这个目录\n打开浏览器 输入zabbix页面的地址 http://172.17.0.4/zabbix\n点击 Next step 进入 Check of pre-requisites 页面确定 Check of pre-requisites 一页都是绿色 然后 Next step\n进入 Configure DB connection 页面 输入mysql连接信息如果mysql服务在本地 可以输入使用默认的localhost 然后 Next step\n\n配置zabbix server的信息 输入zabbix server的IP地址 端口 还有名称如果zabbix server在本机 Host使用默认的localhost即可 然后 Next step\n\n确认一次信息是否有误 如果无误就 Next step 完成安装此时所有的信息保存在 /var/www/html/zabbix/conf/zabbix.conf.php 中\n\n进入登陆页面 初始用户名和密码是 admin/zabbix\n\n至此 zabbix server 安装安装完成 如果配置的有错误 还可以重新访问配置页面进行重新配置http://172.17.0.4/zabbix/setup.php\nweb管理界面中文支持zabbix官方提供了中文支持 但是需要修改php页面开启\nvim /var/www/html/zabbix/include/locales.inc.php \n找到 &apos;zh_CN&apos; =&gt; array(&apos;name&apos; =&gt; _(&apos;Chinese (zh_CN)&apos;),   &apos;display&apos; =&gt; false],\n修改 &apos;display&apos; =&gt; true\n在web管理界面 点击右上角的小人图标 或直接访问 http://172.17.0.4/zabbix/profile.php此时已经打开了zabbix的设置界面 语言选择中找到中文语言 如果中文选择是灰色说明当前系统并未支持zh_CN字符集 需要先安装zh_CN的支持才能正常选择中文\nlocaledef  -f UTF-8 -i zh_CN zh_CN.UTF8\n通过 locale -a 可以查看当前系统已经支持的字符集\n添加字符集后需要重启php-fpm服务 \n如果想应用以及配置好的字符集 可以通过配置环境变量:\nexport LANG=&apos;zh_CN.UTF-8&apos;\nexport LANGUANE=&apos;zh_CN.UTF-8&apos;\n如果想设置为系统默认字符集 可以将环境变量写入到配置文件\nCentOS系列: vim /etc/sysconfig/i18n\n其实只要将已经添加好中文字符集的其他机器的 locale-archive 文件替换到自己目录即可文件路径: /usr/lib/locale/locale-archive 但是这样 系统可能会缺乏相应的字体 所以并不推荐\n自带的中文字体可能会出现乱码 这时需要自己替换中文字体解决从Windows系统 c:\\windows\\fonts 或网上找一个自己喜欢的字体复制到 /var/www/html/zabbix/fonts/ 中 这里用 msyh.ttf\nsed -i &apos;s/DejaVuSans/msyh/g&apos; /var/www/html/zabbix/include/defines.inc.php\n将默认的 DejaVuSans 替换成自己的 msyh 然后刷新网页\n配置zabbix Agentd\n通过–enable-agent选项可以安装zabbix_agent 因此 zabbix_server安装的时候已经启用zabbix_agent不需另行安装 其他客户端安装则不需过多编译选项 只需启用–enable-agent即可\n\nLinux主机安装Agentd\n以下操作是在Zabbix Agent1主机上进行编译\n\nuseradd -M -s /sbin/nologin zabbixtar xf zabbix-2.2.10.tar.gzcd zabbix-2.2.10./configure --prefix=/usr/local/zabbix_agent --enable-agentmake &amp;&amp; make installmkdir /usr/local/zabbix_agent/&#123;log,var&#125;chown -R zabbix:zabbix /usr/local/zabbix_agent//usr/local/zabbix_agent/etc/zabbix_agentd.conf\nvim /usr/local/zabbix_agent/etc/zabbix_agentd.conf    \n\nLogFile=/usr/local/zabbix_agent/log/zabbix_agentd.log\nPidFile=/usr/local/zabbix_agent/var/zabbix_agentd.pid\nDebugLevel=3\nServer=127.0.0.1,172.17.0.5            # 配置允许连接的zabbix_server\nServerActive=127.0.0.1,172.17.0.5      # 配置允许主动连接的zabbix_server\nStartAgents=8\nHostname=localhost\nTimeout=30\nUnsafeUserParameters=1\n根据实际情况修改配置文件参数的值\n# 配置服务启动脚本在zabbix_server中已经介绍 agent端只需要zabbix_agentd脚本即可# /usr/local/zabbix/sbin/zabbix_agentd\t\t# Server端启动zabbix_agentd/usr/local/zabbix_agent/sbin/zabbix_agentd   \t# Agent端启动zabbix_agentd\n检测 10050 端口是否正常监听\n[root@13262019d57f ~]# netstat -anpt |grep 10050\ntcp     0    0 0.0.0.0:10050       0.0.0.0:*        LISTEN   -\n\nzabbix Agent端自我检测是否可以正常获取监控数据\n/usr/local/zabbix_agent/bin/zabbix_get -s 127.0.0.1 -k agent.ping\n\nzabbix Server端检测是否可以正常获取Agent端的数据\n/usr/local/zabbix/bin/zabbix_get -s 172.17.0.6 -k agent.ping\n\n都返回 1 则正常 这样就可以在web界面上添加server对agent的监控了\nWindows主机安装Agentd\n当前操作在Zabbix Agent2上进行 Zabbix Agent2是一台windows主机\n\n获取Windwos版zabbix-agent安装包\nzabbix_agents_3.0.0.win.zip\n\n解压文件到任意安装目录\n这里解压到 C:\\Program Files\\zabix\n\n配置文件的修改方法大体和Linux下相同\n编辑 C:\\Program Files\\zabix\\conf\\zabbix_agent.win.conf\n\n    Server=127.0.0.1,172.17.0.5\n    ServerActive=127.0.0.1,172.17.0.5\n    StartAgents=8\n    Hostname=windows\n    Timeout=30\n    UnsafeUserParameters=1\n\n将zabbix_agentd注册为服务\n以管理员身份运行cmd 到zabbix_agentd.exe的目录下 注意选好32位还是64位的exe\n&gt; zabbix_agentd.exe --install -c &quot;C:\\Program Files\\zabix\\conf\\zabbix_agent.win.conf&quot;\n因为路径中有空格 所以用双引号扩起 出现installed successfully则安装成功\n\n可以在服务管理界面启动和停止 &quot;zabbix agent&quot; 也可以用net命令控制\n管理员身份运行cmd 控制启动和关闭服务\n&gt; net start &quot;zabbix agent&quot;\n&gt; net stop &quot;zabbix agent&quot;\n\n服务端检测是否正常获取数据\n/usr/local/zabbix/bin/zabbix_get -s 172.17.0.7 -k agent.ping\n返回1 服务端正常获取数据\n附录常见故障处理编译配置报错检测依赖包是否正常安装 gcc等编译工具是否正常安装\n无法打开Web界面检查LNMP环境是否正常 以及是否配置了正确的防火墙规则等\nWeb界面出现 Zabbix server is not running …检测是否关闭Selinux \nsetenforce 0\n\n检测zabbix_server的IP地址和端口号在web界面中是否正确配置\n\n如果zabbix_server在本地 看主机是否正常解析localhost域名\n# telnet localhost 10051\n\n如果不能正常解析 \n# vim /var/www/html/zabbix/conf/zabbix.conf.php\n将$ZABBIX_SERVER = &apos;localhost&apos; 换成 &apos;127.0.0.1&apos; 或者修改host文件\n添加 localhost 到 127.0.0.1 的域名解析\n127.0.0.1   localhost localhost.localdomain localhost4 localhost4.localdomain4\n数据库mysql.sock文件无法找到如果MySQL服务器和php-fpm服务器在同一台主机 php-fpm可能会通过mysql.sock套接字和MySQL服务通信\n\n如果有如下错误提醒:\nDatabase error: Error connecting to database [Can&apos;t connect to local \nMySQL server through socket &apos;/var/lib/mysql/mysql.lock&apos;]\n\n确保/var/lib/mysql/mysql.lock存在 \n如果实际mysql.sock位置与报错中的位置不符 修改zabbix_server.conf中的DBSocket配置\nDBSocket的值要为真实mysql.sock的绝对路径 然后重启服务\n禁用guests账号 防止非法访问在web管理界面上操作\n管理 &gt;&gt; 用户 &gt;&gt; Guests &gt;&gt; 状态:停用的\nzabbix总览zabbix_get              server和agent之间数据获取\n    -s                  远程agent的主机名或IP地址\n    -p                  远程agent的端口 默认10050\n    -I                  如果有多块网卡 本机出去的IP地址\n    -k                  获取远程agent数据用的KEY\n\nzabbix_get -s 127.0.0.1 -p 10050 -k agent.ping\n\nzabbix_server           zabbix服务端的核心程序\nzabbix_proxy            abbix代理服务的程序 用于分布式监控proxy模式中\nzabbix_agent            用超级服务方式启动用的程序\nzabbix_agentd           独立进程方式启动用的程序\nzabbix_java_gateway     zabbix的java采集服务端\nzabbix_sender           将采集到的数据定时发送给zabbix_server\n","categories":["Zabbix"],"tags":["zabbix","LNMP","监控"]},{"title":"Subversion(SVN)安装使用","url":"/2017/12/22/2017/Subversion(SVN)%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/","content":"简介\nSVN是Subversion的简称，是一个开放源代码的版本控制系统，相较于RCS、CVS，它采用了分支管理系统，它的设计目标就是取代CVS。互联网上很多版本控制服务已从CVS迁移到Subversion。说得简单一点SVN就是用于多个人共同开发同一个项目，共用资源的目的\n\n\n环境系统环境\n是在 CentoOS 6.8 上部署的\n\n软件环境\n\n\n源码包\n版本\n下载地址\n\n\n\n\nSubversion\n1.9.7\n点击下载\n\n\nSqlite\n3.2.1\n点击下载\n\n\n\n步骤安装依赖yum install -y make gcc apr-devel apr-util-devel zlib-devel\n编译安装tar xf subversion-1.9.7.tar.bz2mkdir subversion-1.9.7/sqlite-amalgamation/tar xf sqlite-autoconf-3210000.tar.gz -C subversion-1.9.7/sqlite-amalgamation/./configure --prefix=/usr/local/subversionmake -j4 &amp;&amp; make installecho &apos;export PATH=$PATH:/usr/local/subversion/bin&apos; &gt; /etc/profile.d/subversion.shsource /etc/profile.d/subversion.sh\n配置和使用cd /data/svn/confecho &quot;svn = svn&quot; &gt; passwd        # 修改passwd文件 添加用户和密码 格式：user = password\n修改 authz 对svn用户配置访问权限 在文件末尾添加：\n[/]\nsvn = rw\n* = r\n修改 svnserve.conf 文件 [general]配置块添加以下内容\nanon-access = read\nauth-access = write\npassword-db = passwd\nauthz-db = authz\nrealm = mysvn\nsvnserve -d -r /date/ 启动svn服务-d daemon模式  -r指定svn根目录比如指定/data为根 那么访问svn目录就是svn://ip/svn了/data下可以用svnadmin创建多个不同的svn目录 每个目录的配置都可以不同也可以直接将-r 指定为/data/svn 那访问snv://ip 就直接访问这个目录了-X 前台启动 --listen-port 更改监听端口号 默认3690\n附录Windows的svn客户端可以使用TortoiseSVN官方地址：https://tortoisesvn.net/\n","categories":["SVN"],"tags":["SVN"]},{"title":"构建基于Busybox的Nginx服务容器","url":"/2016/04/22/2016/%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8EBusybox%E7%9A%84Nginx%E6%9C%8D%E5%8A%A1%E5%AE%B9%E5%99%A8/","content":"简介\n用docker容器进行打包服务非常方便 不需要考虑依赖的问题 只要把容器复制到其他有docker daemon的服务器就可以直接启动 并能很方便的利用Cgroup, Namespace技术实现资源控制和资源隔离这篇文档以Nginx为例 其他的像redis mysql php等服务也是可以使用这个方法进行打包为最精简的 只包含必须依赖的服务容器\n\n\n环境\n系统是ubuntu server 15.10版 用ubuntu系统作为docker服务的载体 如果非ubuntu15.10发行版 尽量保证内核版本在3.18以上 Nginx是在CentOS 6.7的容器中编译的 之后在ubuntu上完成打包在容器中编译Nginx只是我的个人习惯 不喜欢将主机环境乱安装一些不必要的包 保持清洁就好 编译什么的就交给容器去做吧\n\n主机环境\n\n\n身份\n系统\nIP\n\n\n\n\nDocker服务\nubuntu 15.10\n172.17.0.1\n\n\nDocker容器\nCentOS 6.7\n172.17.0.3\n\n\n\n软件环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nNginx\n1.9.15\n点击下载\n\n\nDocker\n1.9.1\n点击下载\n\n\nkernel\n4.2.0\n系统自带\n\n\n\n步骤以下是打包Nginx服务容器的基本思路\n\n选用Busybox环境作为基础\n在CentOS 容器中编译Nginx\n将Nginx的运行依赖库和Nginx程序复制到主机环境\n部署到Busybox构建的rootfs中\n导入Docker 查看是否正常运行\n\n构建Busybox最小容器\nBusybox构建文档：点击打开文档内容构建完毕之后 busybox-1.24.2/_install 就是我们需要当作容器基础的rootfs了 将它复制到随便一个目录 留用\n\ncp -rf busybox-1.24.2/_install/ rootfs\n编译安装Nginx\nNginx的编译文档：点击打开文档内容只需要做到文档中make -j4 也就是编译完成就可以了 之后的安装步骤就不按照文档的走了\n\n安装nginx到非默认根make DESTDIR=/nginx install\n通过DESTDIR更改安装Nginx的根位置 以/nginx目录作为nginx安装的根\n[root@localhost nginx-1.9.15]# ls /nginx/\nusr  var\n[root@localhost nginx-1.9.15]# tree /nginx/\n/nginx/\n├── usr\n│   └── local\n│       └── nginx\n│           ├── conf\n│           │   ├── fastcgi.conf\n│           │   ├── fastcgi.conf.default\n│           │   ├── fastcgi_params\n│           │   ├── fastcgi_params.default\n│           │   ├── koi-utf\n│           │   ├── koi-win\n│           │   ├── mime.types\ncd /nginx/mkdir lib lib64                     # 创建两个依赖库文件夹strip usr/local/nginx/sbin/nginx    # 裁剪nginx二进制的编译跟踪信息 缩减nginx体积\n复制Nginx运行依赖库\n接下来查看nginx程序的所有依赖\n\n[root@localhost nginx]# ldd usr/local/nginx/sbin/nginx \n    linux-vdso.so.1 =&gt;  (0x00007fff3caa3000)\n    libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f9bc2ff8000)\n    libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f9bc2ddb000)\n    libcrypt.so.1 =&gt; /lib64/libcrypt.so.1 (0x00007f9bc2ba3000)\n    libz.so.1 =&gt; /lib64/libz.so.1 (0x00007f9bc298d000)\n    libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f9bc25f9000)\n    /lib64/ld-linux-x86-64.so.2 (0x0000561c3968f000)\n    libfreebl3.so =&gt; /lib64/libfreebl3.so (0x00007f9bc23f5000)\n将依赖复制到刚才创建的lib或者lib64目录中 如果这个依赖库在系统的lib目录下 那么就复制到lib目录中cp /lib64/libdl.so.2 lib64/cp /lib64/libpthread.so.0 lib64/cp /lib64/libcrypt.so.1 lib64/cp /lib64/libz.so.1 lib64/cp /lib64/libc.so.6 lib64/cp /lib64/ld-linux-x86-64.so.2 lib64/cp /lib64/libfreebl3.so lib64/\n 由于Nginx运行需要使用普通用户 所以需要读取passwd文件 读取解析passwd文件需要用到libnss_files.so.2这个库 所以也需要复制这个库到lib64中\ncp /lib64/libnss_files.so.2 lib64/\n如果在ubuntu上编译的话libnss_files.so.2位置在/lib/x86_64-linux-gnu/libnss_files.so.2复制完成后lib64目录的内容应该如下所示：\n[root@localhost nginx]# ls lib64/\nld-linux-x86-64.so.2  libc.so.6   libfreebl3.so      libpthread.so.0\nlibcrypt.so.1         libdl.so.2  libnss_files.so.2  libz.so.1\n打包Nginx服务容器\nNginx以及Nginx的运行依赖都已经放到/nginx目录中了 将这个目录移动到和刚才的rootfs同一目录下 然后再创建两个目录 留用\n\nmkdir build target\n认识overlayFS\noverlay是一种联合挂载的文件系统 可以将几个不同的目录挂载到一个目录中 然后将所有的文件展示出来 而且在挂载的目录中对文件的操作并不会影响到其他目录中实际的文件同时 在新版本的docker中 overlay便是docker容器默认使用的存储驱动 但是overlay在内核大于3.18的版本中才被支持 所以尽量用使用较新内核版本的发行版来玩Docker因为overlay的这些特性 用来辅助制作Nginx服务容器岂不是很方便 因为在挂载的目录中的操作并不会影响基层目录的文件 这样就算误删了文件 也是可以恢复的\n\n现在看起来 应该是这个效果\nroot@ubuntu:~# ls -lh\ntotal 16K\ndrwxr-xr-x  9 root root 4.0K Apr 22 12:50 build     # overlay的工作目录\ndrwxr-xr-x  6 root root 4.0K Apr 22 15:34 nginx     # 刚才安装的Nginx目录\ndrwxr-xr-x 18 root root 4.0K Apr 22 11:52 rootfs    # busybox的目录\ndrwxr-xr-x  1 root root 4.0K Apr 22 12:50 target    # 这个就是联合挂载到的目标目录\n检查overlay驱动是否已经加载 否则加载overlay驱动lsmod |grep overlaymodprobe overlay\n如下所示 那么就可以使用overlay文件系统了 \nroot@ubuntu:~# lsmod |grep overlay\noverlay                49152  1\nroot@ubuntu:~# cat /proc/filesystems |grep overlay\nnodev    overlayfs\nnodev    overlay\n用rootfs和nginx做基层 其中rootfs是第一层 如果还有其他目录 依次用冒号隔开 build做为overlay工作目录  /tmp是overlay必须的一个空目录 将lowerdir中的目录都挂载到target目录上mount -t overlay overlay -o lowerdir=rootfs:nginx,upperdir=build,workdir=/tmp target/\n接下来可以看到target目录中 rootfs和nginx目录中的内容同时出现在target目录中\nroot@ubuntu:~# ls target/\nbin  etc   lib    linuxrc  mnt   root  sbin  tmp  var\ndev  home  lib64  media    proc  run   sys   usr\nroot@ubuntu:~# ls target/bin/busybox \ntarget/bin/busybox\nroot@ubuntu:~# ls target/usr/local/nginx/sbin/nginx \ntarget/usr/local/nginx/sbin/nginx\n如果系统刚好不支持overlay文件系统的话 思想原理是相同的 直接将rootfs和nginx目录中的文件都复制到target中吧\nChroot进行根切换\n接下来就是配置Nginx的运行环境了 这样才能保证Nginx打包为容器后能正常的运行通过chroot工具切换当前根到target目录中 这也算文件系统隔离一种的方式\n\nchroot target sh\n可以看到 进入到了一个不同的shell中 ls / 竟然发现了linuxrc文件 现在已经将根切换到target目录中了\n/ # ls /\nbin      etc      lib      linuxrc  mnt      root     sbin     tmp      var\ndev      home     lib64    media    proc     run      sys      usr\n根据执行Nginx的报错进行配置接下来的操作在这个根中进行 配置Nginx的运行环境 这些操作都是通过不断的执行nginx程序 查看nginx的报错总结的\nadduser nginx                       # 添加nginx用户 mkdir -p /var/tmp/nginx/client/     # 创建nginx运行需要的目录mkdir -p /var/www/html              # 以后将使用这个路径作为Nginx网页根目录ln -s /usr/local/nginx/sbin/nginx /usr/sbin/            # 添加nginx软链接到环境变量中ln -s /usr/local/nginx/conf/nginx.conf /etc/nginx.conf  # 添加配置文件软连接到/etc目录echo '&lt;h1&gt;hello nginx&lt;/h1&gt;' &gt; /var/www/html/index.html  # 创建一个索引文件\n再次运行nginx程序 这时候遇到了ginx: [emerg] open(“/dev/null”) failed的错误 原因是打不开这个设备文件 这个只能通过启动为一个Docker容器来解决了\n/ # /usr/local/nginx/sbin/nginx \nnginx: [emerg] open(&quot;/dev/null&quot;) failed (2: No such file or directory)\n修改Nginx配置文件剩下的就是修改nginx的配置文件了\nvi /etc/nginx.conf\n第一行添加 daemon off; 让nginx前台运行 这个必须添加\nhttp{}中添加 autoindex on; 运行目录索引 可以根据实际情况添加\nhttp{\n  server{\n    location / {\n        root   /var/www/html;           # root改为/var/www/html 可以根据实际情况更改\n        index  index.html index.htm;\n    }\n  }\n}\n将目录打包为Docker容器输入exit或者键入 Ctrl+d 就可以退出chroot 回到正常的根中了 接下来 将数据打包为Docker容器 可以看到 大小仅仅8Mcd target/tar -cf /dev/stdout *|docker import - nginx:1.9.15\nroot@ubuntu:~/target# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nnginx               1.9.15              99089cedcc48        3 seconds ago       8.071 MB\n启动容器 检查是否成功然后后台启动这个容器 并且查看容器IP 通过curl命令检查nginx是否正常运行 可以看到 成功返回 hello nginxdocker run -d --name nginx nginx:1.9.15 nginxdocker inspect --format '&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' nginx\nroot@ubuntu:~/target# docker run -d --name nginx nginx:1.9.15 nginx\n0db0d45152948339fb0c9a23e8dfba6798c650e24075d725ba2d3021eb3b801b\nroot@ubuntu:~/target# docker inspect --format &apos;{{.NetworkSettings.IPAddress}}&apos; nginx\n172.17.0.8\nroot@ubuntu:~/target# curl 172.17.0.8\n&lt;h1&gt;hello nginx&lt;/h1&gt;\nroot@ubuntu:~/target#\n这样 一个非常小 但是可以提供完整功能的Nginx服务容器就打包完成了 \noverlayFS文件误删的恢复如果在制作这个容器的过程中 不幸误删了target目录中的文件 还记的build这个文件吗rm -rf linuxrc\nroot@ubuntu:~/target# ls -l ../build/linuxrc \nc--------- 1 root root 0, 0 Apr 22 17:28 ../build/linuxrc\n可以看到 build目录中出现了一个主次设备号都为0的字符设备 只要删除了这个字符设备 文件就恢复了rm -rf ../build/linuxrc\nroot@ubuntu:~/target# ls\nbin  etc   lib    linuxrc  mnt   root  sbin  tmp  var\ndev  home  lib64  media    proc  run   sys   usr\n附录将Nginx容器镜像保存为文件\n如果想把这个容器共享给其他人使用 除了使用push到仓库中 还可以直接通过文件的方式共享\n\n配置一个默认启动命令\n导入这个Nginx服务容器之后 每次启动都需要手动输入nginx命令 这样显的比较麻烦 可以通过Dockerfile的方式给这个容器配置一个默认的启动命令\n\nvim Dockerfile\n键入以下内容：\nroot@ubuntu:~# cat Dockerfile \nFROM nginx:1.9.15\nCMD nginx\n\nnginx就是启动的命令 如果命令还带有参数 可以直接写出 例如 CMD nginx -s reload\ndocker build -t nginx .         # 给新镜像配置一个标签 记得不要忘记了最后的 .\nroot@ubuntu:~# docker build -t nginx .\nSending build context to Docker daemon 25.09 MB\nStep 1 : FROM nginx:1.9.15\n ---&gt; 99089cedcc48\nStep 2 : CMD nginx\n ---&gt; Running in 12b1a81d553c\n ---&gt; 114ba21e8f1c\nRemoving intermediate container 12b1a81d553c\nSuccessfully built 114ba21e8f1c\nroot@ubuntu:~# docker run -d nginx:latest\n0f3f39dd3aea5a16b10a470ffecca716b31d0deab5420b07ee86bd1180bc2256\n可以看到 启动这个新容器已经不需要输入nginx命令了 其实还有一个方法可以更改默认启动命令 通过直接修改镜像的配置文件可以看到 nginx:1.9.15镜像的ID是99089cedcc48 这只是完整ID的一部分 配置信息保存在/var/lib/docker/graph中\nroot@ubuntu:~# docker images\nREPOSITORY          TAG                 IMAGE ID            CREATED             VIRTUAL SIZE\nnginx               1.9.15              99089cedcc48        48 minutes ago      8.071 MB\ncd /var/lib/docker/graphcd 99089cedcc48*vim json\n这时就打开了这个镜像的配置文件 Cmd字段就是默认命令 还可以顺便改下comment信息\n&quot;comment&quot;:&quot;nginx 1.9.15&quot;,       # comment字段改为你想表达的信息\n&quot;Cmd&quot;:[&quot;yunfwe&quot;],               # Cmd字段有两个 第一个是作者信息\n&quot;Cmd&quot;:[&quot;nginx&quot;],                # 第二个才是启动命令\n\n如果运行命令有其他参数的话 用逗号隔开 例如 &quot;Cmd&quot;:[&quot;nginx&quot;,&quot;-s&quot;,&quot;reload&quot;],\n这样就相当于 nginx -s reload 了\n接下来使用docker history nginx:1.9.11 查看信息\n可以看到 CREATED BY 还有 COMMENT 是自己写的信息了\nroot@ubuntu:~# docker history 99089cedcc48\nIMAGE               CREATED             CREATED BY          SIZE                COMMENT\n99089cedcc48        58 minutes ago      yunfwe              8.071 MB           nginx 1.9.15\n\n顺便可以看到运行命令也已经是nginx了\nroot@ubuntu:~# docker inspect --format {{.Config.Cmd}} nginx:1.9.15\n{[nginx]}\n这两种修改默认启动命令方法的一个重要区别是 第二种在原本的镜像上修改 是不会产生新的层的 而用Dockerfile修改 相当于新建了一个层 这个层提供了默认启动命令 不信可以使用docker history验证一下\n保存为文件\n默认docker导出的是个tar归档 这里直接将归档压缩为gz包 文件命名规则是REPOSITORY_TAG-Type.tar.gz其中的Type是标识这个文件是由镜像保存的还是已经生成的容器导出的\n\ndocker save nginx:1.9.15 |gzip &gt; nginx_1.9.15-image.tar.gz\n要恢复的话也很简单 docker支持直接从gz压缩包中恢复导入新的镜像 这个镜像的标签可能会丢失 但是id号还在 给这个id好重新打个标签\ndocker load &lt; nginx_1.9.15-image.tar.gzdocker tag 99089cedcc48 nginx:1.9.15\n","categories":["Docker"],"tags":["nginx","busybox","docker","overlay"]},{"title":"Cordova混合开发环境搭建","url":"/2018/12/09/2018/Cordova%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA/","content":"\n简介\nCordova提供了一组设备相关的API，通过这组API，移动应用能够以JavaScript访问原生的设备功能，如摄像头、麦克风等。Cordova还提供了一组统一的JavaScript类库，以及为这些类库所用的设备相关的原生后台代码。Cordova支持如下移动操作系统：iOS, Android,ubuntu phone os, Blackberry, Windows Phone, Palm WebOS, Bada 和 Symbian。\n\n环境\n下面是在Windows平台编译安卓apk为例。如果是其他平台，本文档也有一定参考价值\n\n安装应用\n\n\n软件\n版本要求\n下载\n\n\n\n\nNode.js\n最新LTS版即可\n下载地址\n\n\njdk\n1.8 以上\n下载地址\n\n\nAndroid SDK\n最新版即可\n下载地址\n\n\ngradle\n最新版即可\n下载地址\n\n\nant\n最新版即可\n下载地址\n\n\n\n配置环境变量\n根据实际软件的安装目录配置环境变量\n\n\n\n\n变量名称\n值\n\n\n\n\nJAVA_HOME\nD:\\Application\\Java\\jdk1.8.0_101\n\n\nCLASSPATH\n.;%JAVA_HOME%\\lib\\dt.jar;%JAVA_HOME%\\lib\\tools.jar;\n\n\nANDROID_HOME\nD:\\Application\\android\\sdk\n\n\n\nPath环境变量中添加如下值\n\n验证环境变量java\n&gt; java -version\njava version &quot;1.8.0_101&quot;\nJava(TM) SE Runtime Environment (build 1.8.0_101-b13)\nJava HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode)\ngradle\n&gt; gradle -v\n\n------------------------------------------------------------\nGradle 5.0\n------------------------------------------------------------\n\nBuild time:   2018-11-26 11:48:43 UTC\nRevision:     7fc6e5abf2fc5fe0824aec8a0f5462664dbcd987\n\nKotlin DSL:   1.0.4\nKotlin:       1.3.10\nGroovy:       2.5.4\nAnt:          Apache Ant(TM) version 1.9.13 compiled on July 10 2018\nJVM:          1.8.0_101 (Oracle Corporation 25.101-b13)\nOS:           Windows 10 10.0 amd64\nant\n&gt; ant -v\nApache Ant(TM) version 1.10.5 compiled on July 10 2018\nTrying the default build file: build.xml\nBuildfile: build.xml does not exist!\nBuild failed\nnode.js\n&gt; node -v\nv10.13.0\n安装 Android SDK进入 Android SDK 的安装目录，执行 SDK Manager.exe ，安装如下模块：\n\n安装 Cordova\nnode.js 默认会将全局安装的模块还有下载的缓存放在C盘，可以通过更改配置文件来改变安装的位置。\n\n注意：根据 node.js 的实际安装位置或个人喜好酌情修改\n&gt; npm config set prefix &quot;D:\\Application\\nodejs&quot;\n&gt; npm config set cache &quot;D:\\Application\\nodejs\\node_cache&quot;\n接下来就可以安装 Cordova 了，使用默认的仓库安装会比较慢，可以考虑使用淘宝的镜像站来安装\nnpm config set registry &quot;https://registry.npm.taobao.org&quot;npm install -g cordova\n&gt; cordova -v\n8.1.2 (cordova-lib@8.1.1)\n如果没有报错，那么 cordova 就安装完了。\n开发创建应用\n接下来就用 Cordova 创建第一个应用程序，并打包为 Android APK。\n\n&gt; cordova create myapp\nCreating a new cordova project.\n这样一个初始项目目录就构建完成了，还需要添加相应的目标平台，比如 Android 还是 IOS。\n&gt; cordova platform ls\nInstalled platforms:\n\nAvailable platforms:\n  android ~7.1.1\n  browser ~5.0.1\n  ios ~4.5.4\n  osx ~4.0.1\n  windows ~6.0.0\n添加某个支持的平台使用 cordova platform add 命令，删除某个平台将 add 换成 rm 即可。\n&gt; cordova platform add android\nUsing cordova-fetch for cordova-android@~7.1.1\nAdding android project...\nCreating Cordova project for the Android platform:\n        Path: platforms\\android\n        Package: io.cordova.hellocordova\n        Name: HelloCordova\n        Activity: MainActivity\n        Android target: android-27\nAndroid project created with cordova-android@7.1.4\nAndroid Studio project detected\nAndroid Studio project detected\nDiscovered plugin &quot;cordova-plugin-whitelist&quot; in config.xml. Adding it to the project\nInstalling &quot;cordova-plugin-whitelist&quot; for android\n\n               This plugin is only applicable for versions of cordova-android greater than 4.0. If you have a previous platform version, you do *not* need this plugin since the whitelist will be built in.\n\nAdding cordova-plugin-whitelist to package.json\nSaved plugin info for &quot;cordova-plugin-whitelist&quot; to config.xml\n--save flag or autosave detected\nSaving android@~7.1.4 into config.xml file ...\n编译项目执行：cordova build android，如果编译成功，最后会出现 BUILD SUCCESSFUL 以及 apk 安装包的位置。默认是 DEBUG 模式的编译，如果是发行版可以使用 cordova build android --release\n注意：第一次编译的时候，Gradle 会下载一些依赖，这些依赖会安装在用户家目录下的 .gradle 目录中，这一步我也没有什么好的办法，只能祈祷网络好一点能赶紧下载完。编译后的 apk 都是没有签名的，如果是 release 模式编译的 apk，不签名的话是无法安装的。\n如果通过USB连接了安卓手机，则可以直接使用 cordova run android 命令将 apk 部署到手机上测试，手机需要打开USB调试模式，并允许通过 USB 安装 apk 包。\n打开效果如下：\n\n调试项目可以通过 Chrome 浏览器调试页面，或者直接使用 Chrome 浏览器配合真机调试\n使用浏览器调试首先安装浏览器平台的支持，然后使用浏览器调试页面。\n&gt; cordova platform add browser\nUsing cordova-fetch for cordova-browser@~5.0.1\nAdding browser project...\nCreating Cordova project for cordova-browser:\n        Path: D:\\Workspace\\myapp\\platforms\\browser\n        Name: HelloCordova\nInstalling &quot;cordova-plugin-whitelist&quot; for browser\n--save flag or autosave detected\nSaving browser@~5.0.4 into config.xml file ...\n然后执行 cordova run browser 会直接打开浏览器显示页面，这时候可以使用 F12 打开控制台调试了。\n\n使用浏览器调试真机将安卓手机通过USB连接电脑，并安装好驱动（Win10貌似自带驱动），然后打开USB调试模式并允许通过USB安装应用程序。执行 cordova run android 命令，这时手机上应该已经自动安装并打开了程序。\n通过 Chrome 浏览器打开页面 chrome://inspect/#devices，Devices 中已经出现了自己的手机机型以及一个 cordova 的 WebView 条目，然后点击 inspect:\n\n可以看到就跟调试普通页面一样，鼠标在不同的标签上划过，手机app上对应的标签也会高亮显示：\n\n附录一个获取设备信息的demo首先安装获取设备信息的 cordova 插件\n&gt; cordova plugin add cordova-plugin-device\nInstalling &quot;cordova-plugin-device&quot; for android\nAndroid Studio project detected\nInstalling &quot;cordova-plugin-device&quot; for browser\nAdding cordova-plugin-device to package.json\nSaved plugin info for &quot;cordova-plugin-device&quot; to config.xml\ncordova plugin add 命令会自动给已安装的所有平台都安装上指定的插件。\n删除项目目录下 www 目录中的所有文件，然后重新创建 index.html，写入以下内容：\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt;    &lt;title&gt;设备信息&lt;/title&gt;    &lt;style&gt;        * &#123;            margin: 0;            padding: 0;        &#125;        #content &#123;            position: fixed;            height: 90%;            width: 100%;            background-color: #c7c7c7;            text-align: center        &#125;        #btn &#123;            position: fixed;            bottom: 0;            width: 100%;            height: 10%;            border: 1px solid skyblue;            background-color: #fff;            font-size: 18px;        &#125;        #btn:active &#123;            background-color: skyblue;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=\"content\"&gt;    &lt;/div&gt;    &lt;button id=\"btn\"&gt;获取信息&lt;/button&gt;    &lt;script src=\"cordova.js\"&gt;&lt;/script&gt;    &lt;script&gt;        document.addEventListener(\"deviceready\", onDeviceReady, false);        function onDeviceReady() &#123;            var btn = document.getElementById(\"btn\")            var content = document.getElementById(\"content\")            btn.onclick = function()&#123;                content.innerHTML = \"\"                for (let i of ['cordova','model','platform','uuid',                            'version','manufacturer','serial'])&#123;                    let tmp = document.createElement(\"p\")                    tmp.innerText = i + ': ' + device[i]                    content.appendChild(tmp)                &#125;            &#125;        &#125;    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n运行：cordova run browser 在浏览器上点击获取信息的按钮，显示如下：\n\n运行：cordova run android 在手机上点击获取信息的按钮，显示如下：\n\n","categories":["Cordova"],"tags":["html5","cordova"]},{"title":"Leanote开源云笔记搭建","url":"/2018/01/02/2018/Leanote%E5%BC%80%E6%BA%90%E4%BA%91%E7%AC%94%E8%AE%B0%E6%90%AD%E5%BB%BA/","content":"简介\nLeanote是一款开源的云笔记和博客系统 可以很方便的搭建自己的云笔记。在自己的云主机上搭建了Leanote后 就可以抛弃某云笔记了。而且还自带一套博客系统 写好的笔记可以一键生成到博客空间。Leanote还支持注册（注册功能可以关闭）或者手动添加用户，可以让好友也一起用的哦。Github地址: https://github.com/leanote/leanote\n\n\n 安装步骤\n下载 leanote 二进制版。\n安装和启动 mongodb。\n导入初始数据。\n配置 leanote。\n运行 leanote。\n\n下载 leanote 二进制版\n下载地址: http://leanote.org/#download\n\n下载后将压缩包解压到目录中 linux为例\ntar xf leanote-linux-amd64-v2.6.bin.tar.gz -C /usr/local/ls /usr/local/leanote/\n 安装和启动 mongodb\n可以使用包管理器下载比如apt或者yum 也可以从mongodb官方下载二进制包\n\nwget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.0.1.tgztar xf mongodb-linux-x86_64-3.0.1.tgz -C /usr/local/mv /usr/local/&#123;mongodb-linux-x86_64-3.0.1,mongodb&#125;mkdir /usr/local/mongodb/data/usr/local/mongodb/bin/mongod --dbpath /usr/local/mongodb/data/ &amp;&gt;&gt;/tmp/mongod &amp;/usr/local/mongodb/bin/mongo&gt; show dbs      # 进入mongo cli后 查看所有库\n 导入初始数据\n初始数据存放在 /usr/local/leanote/mongodb_backup/leanote_install_data/ 中\n\n/usr/local/mongodb/bin/mongorestore -h localhost -d leanote --dir \\/usr/local/leanote/mongodb_backup/leanote_install_data/\n输出没有异常的话可以重新进入 mongo cli 然后 show dbs 看看是否存在leanote库了\n 配置 leanote\n默认leanote已经存在两个用户\n\n\n\n\n用户\n密码\n\n\n\n\nadmin\nabc123\n\n\ndemo@leanote.com\ndemo@leanote.com\n\n\n\n编辑 /usr/local/leanote/conf/app.conf 文件 修改app.secret 可以随便更改几个字符串\nvim /usr/local/leanote/conf/app.conf\n默认启动端口啥的 也看着改吧\n 运行 leanotecd /usr/local/leanote/bin/bash run.sh\n修改配置文件的http.addr为0.0.0.0可以外部访问leanote服务接下来就可以浏览器访问Leanote这个专为IT人员打造的云笔记系统了。\n备注Leanote官网：https://leanote.com/可以在官网下载Windows客户端 还可以登录到自己搭建的私网leanote服务器\n","categories":["Leanote"],"tags":["Leanote"]},{"title":"Linux挂载多分区的img镜像文件","url":"/2018/01/02/2018/Linux%E6%8C%82%E8%BD%BD%E5%A4%9A%E5%88%86%E5%8C%BA%E7%9A%84img%E9%95%9C%E5%83%8F%E6%96%87%E4%BB%B6/","content":"简介\n有时候想挂载一个img镜像文件到系统目录，发现无法挂载。使用fdisk命令查看镜像结构 发现有多个分区，这个时候需要将所有分区映射为设备文件后才可以挂载。这个用处好像不太多 这个问题是当时为了修改树莓派的ubuntu镜像文件才用的。或者想自己制作一个linux启动镜像的时候可以玩玩。\n\n\n环境\n当然是在linux下进行操作了\n\n步骤先看看loop设备已经映射了哪些镜像losetup -a\n将loop设备和img镜像绑定losetup /dev/loop0 ubuntu-16.04.3.img\n将loop0的所有分区映射出来kpartx -av /dev/loop0\nroot@ubuntu-Lenovo:/home/ubuntu# kpartx -av /dev/loop0 \nadd map loop0p1 (253:0): 0 262144 linear 7:0 8192\nadd map loop0p2 (253:1): 0 7540736 linear 7:0 270336\n将用到的分区挂载到目录mount /dev/mapper/loop0p2 /mnt/pi/\n需要注意的是映射的设备文件在/dev/mapper/目录下\n卸载umount /mnt/pi/losetup -d /dev/loop0\n后记img镜像里面装个系统 就可以使用qemu等虚拟机启动了 挺好玩的如果遇到无法umount的问题 可以直接使用 fuser -ka /mnt/pi/ 强制卸载\n","categories":["Linux"],"tags":["Linux"]},{"title":"ESP8266 WiFi开发板","url":"/2018/04/29/2018/ESP8266%20WiFi%E5%BC%80%E5%8F%91%E6%9D%BF/","content":"简介\nESP8266串口WIFI模块，超低成本（只需10RMB左右）的物联网开发板，而且有非常丰富的引脚，超低的功耗。ESP8266内部有一个完整的 32bit MCU 核心，主频支持80Mz和160Mz。这个模块支持 IEEE802.11 b/g/n 协议，完整的 TCP/IP 协议栈，可以为现有的设备添加联网功能。而且除了C语言，还可以使用 Python, JavaScript, Lua脚本语言来为ESP8266写程序，极大降低了学习ESP8266的门槛。\n\n\n环境在 Win10 下进行开发，因为更熟悉 Python 所以使用 MicroPython 来进行开发。\n硬件\nESP8266开发板 这里使用基于 ESP8266-12F 的 D1 WiFi UNO R3 开发板。\n数据线 普通安卓的数据线就可以，D1 开发板集成了 CH340 USB转TTL芯片。\n\n如果是其他系统的话，需要确保 CH340 的驱动有安装。\nD1 WiFi UNO R3 开发板：\n软件\nesptool 固件烧录工具\nPuTTY 串口连接工具\nesp8266 MicroPython固件 点此下载\n\n烧录固件esptool 需要Python运行环境的支持，所以需要提前安装 Python 然后配置好环境变量，或者也可以下载其他的固件烧写工具。\npip install esptool\n装好之后从设备管理器中查看端口，如果是linux环境，应该是 /dev/ttyUSB*，然后先使用 esptool.py 命令擦除固件数据。\nesptool.py --port COM4 erase_flash\nesptool.py v2.3.1\nConnecting....\nDetecting chip type... ESP8266\nChip is ESP8266EX\nFeatures: WiFi\nUploading stub...\nRunning stub...\nStub running...\nErasing flash (this may take a while)...\nChip erase completed successfully in 9.7s\nHard resetting via RTS pin...\n接着就可以将下载好的固件文件烧录到板子里了，固件的bin文件要选择实际的文件。\nesptool.py --port COM4 --baud 460800 write_flash --flash_size=detect 0 esp8266.bin\nesptool.py v2.3.1\nConnecting....\nDetecting chip type... ESP8266\nChip is ESP8266EX\nFeatures: WiFi\nUploading stub...\nRunning stub...\nStub running...\nChanging baud rate to 460800\nChanged.\nConfiguring flash size...\nAuto-detected Flash size: 4MB\nFlash params set to 0x0040\nCompressed 600888 bytes to 392073...\nWrote 600888 bytes (392073 compressed) at 0x00000000 in 8.8 seconds (effective 546.1 kbit/s)...\nHash of data verified.\n\nLeaving...\nHard resetting via RTS pin...\n烧录成功后就可以打开PuTTY，设置好COM口，波特率 115200 然后连接了。\n[开头这里乱码正常]#4 ets_task(40100130, 3, 3fff837c, 4)\nOSError: [Errno 2] ENOENT\n\nMicroPython v1.9.3-8-g63826ac5c on 2017-11-01; ESP module with ESP8266\nType &quot;help()&quot; for more information.\n&gt;&gt;&gt;\n使用MicroPython\n通过 MicroPython 的使用一些代码来认识下 ESP8266 的硬件\n\nMicroPython 简单认识MicroPython 使用Python3的语法，使用 help(&#39;modules&#39;) 命令可以看到支持的所有模块，\n&gt;&gt;&gt; help(&apos;modules&apos;)\n__main__          http_client_ssl   sys               urandom\n_boot             http_server       time              ure\n_onewire          http_server_ssl   uasyncio/__init__ urequests\n_webrepl          inisetup          uasyncio/core     urllib/urequest\napa102            json              ubinascii         uselect\narray             lwip              ucollections      usocket\nbtree             machine           uctypes           ussl\nbuiltins          math              uerrno            ustruct\ndht               micropython       uhashlib          utime\nds18x20           neopixel          uheapq            utimeq\nerrno             network           uio               uzlib\nesp               ntptime           ujson             webrepl\nexample_pub_button                  onewire           umqtt/robust      webrepl_setup\nexample_sub_led   os                umqtt/simple      websocket\nflashbdev         port_diag         uos               websocket_helper\nframebuf          select            upip\ngc                socket            upip_utarfile\nhttp_client       ssd1306           upysh\nPlus any modules on the filesystem\n&gt;&gt;&gt;\n其中跟板子硬件相关的模块主要是 esp 和 machine，其他大多就是与网络有关的模块了，可以看出来还是比较丰富的。简单的测试了下，对Python3的语法支持还是比较完善的，除了基本的数据类型和语法甚至 lambda表达式、列表解析、装饰器、生成器也都支持。\n具体使用查看 MicroPython官方文档\n查看资源信息内存信息可以使用 micropython.mem_info() 获取\n&gt;&gt;&gt; import micropython\n&gt;&gt;&gt; micropython.mem_info()\nstack: 2112 out of 8192\nGC: total: 35968, used: 9744, free: 26224\nNo. of 1-blocks: 48, 2-blocks: 24, max blk sz: 264, max free sz: 1132\n8K的栈，35K的堆。。。不过这资源对于它也是够了。\nFlash大小可以使用 esp.flash_size() 获取\n&gt;&gt;&gt; import esp\n&gt;&gt;&gt; str(esp.flash_size()/1024/1024) + &apos; MB&apos;\n&apos;4.0 MB&apos;\n4MB的存储空间，除去系统占用的只是存放一些简单的程序脚本也完全够用了。\n测试MCU的速度ESP8266内置的MCU主频支持80MHz和160MHz，那么测试下这样的速度到底有多快呢。\n在终端使用 Ctrl + e 进入代码粘贴模式，然后 Ctrl + d 提交或者 Ctrl + c 取消，然后键入以下代码。\nimport timeimport machineimport micropythondef toTime(tus):    ts = [' us', ' ms', ' s']    for t in ts:        if tus &lt; 1000:return str(tus)+t        tus = tus / 1000    @micropython.nativedef loop(count):    t1 = time.ticks_us()    for i in range(count):        pass    t2 = time.ticks_us()-t1    print('Loop %s times for %s'%(count, toTime(t2)))def loop_start(count=10000):    cur_freq = machine.freq()    machine.freq(80000000)    freq = lambda :str(int(machine.freq()/1000000))    print('Present freq: %sMHz' % freq())    loop(count)    machine.freq(160000000)    print('Present freq: %sMHz' % freq())    loop(count)    machine.freq(cur_freq)\n&gt;&gt;&gt; loop_start()\nPresent freq: 80MHz\nLoop 10000 times for 30.567 ms\nPresent freq: 160MHz\nLoop 10000 times for 15.299 ms\n&gt;&gt;&gt;\n代码提交后调用 loop_start() 方法，可以看到在默认的 80MHz 下和调节到 160MHz 下的空循环10000次需要多长时间，差不多每次循环使用不到16微妙。其中 micropython.native 装饰器能让代码以机器码的速度运行，如果好奇的话可以试试没有这个装饰器的执行速度。\n将板子重启后，修改代码去掉那个加速的装饰器，然后重新提交代码执行测试（重启后可能得退出PuTTY后重连才能操作），可以看到速度慢了十几倍。\n&gt;&gt;&gt; loop_start()\nPresent freq: 80MHz\nLoop 10000 times for 460.035 ms\nPresent freq: 160MHz\nLoop 10000 times for 230.091 ms\n&gt;&gt;&gt;\n网络功能\n既然它是WiFi开发板，那么最大的特点应该是可以接入WiFi网络，并且通过网络和其他设备交换数据。\n\n连接WiFi终端执行 help() 函数会显示一个基础的连接WiFi的方法，现在就来连接到一个WiFi试试。这里为了测试方便，用笔记本开了个热点给开发板用。\nESP8266跟连接WiFi相关的库是 network 库，先来看看这个库的使用\nimport networkwlan = network.WLAN(network.STA_IF) # 创建一个WiFi对象wlan.active(True)       # 激活接口wlan.scan()             # 扫描目标wlan.isconnected()      # 检查是否已经连接wlan.connect('zhzz', '12365470') # 连接到WiFiwlan.config('mac')      # 获取接口的mac地址wlan.ifconfig()         # 获取接口的IP/掩码/网关/DNS信息\nESP8266如果断线会自动重连，ifconfig() 方法不仅可以查看当前IP，还可以配置静态IP，只需要将 IP/netmask/gw/DNS 作为一个元组或列表传入即可。比如:\nwlan.ifconfig((&apos;192.168.137.2&apos;,&apos;255.255.255.0&apos;,&apos;192.168.137.1&apos;,&apos;119.29.29.29&apos;))\n修改后会立即生效，如果在 wlan.connect() 之前就配置好了静态IP，这样就不会再向路由器发起DHCP请求了。\nC:\\Users\\yunfwe\\Desktop&gt;ping 192.168.137.2\n\n正在 Ping 192.168.137.2 具有 32 字节的数据:\n来自 192.168.137.2 的回复: 字节=32 时间=1ms TTL=255\n来自 192.168.137.2 的回复: 字节=32 时间=3ms TTL=255\n来自 192.168.137.2 的回复: 字节=32 时间=1ms TTL=255\n来自 192.168.137.2 的回复: 字节=32 时间=1ms TTL=255\n\n192.168.137.2 的 Ping 统计信息:\n    数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，\n往返行程的估计时间(以毫秒为单位):\n    最短 = 1ms，最长 = 3ms，平均 = 1ms\n只要连接WiFi成功后，再次重启开发板也会自动连接，不过配置的静态IP就丢失了，需要重新配置。如果不想让开发板在启动的时候自动连接WiFi，可以在使用后执行 wlan.active(False)。但是开发板还是保存了WiFi的连接信息，想彻底清除这个连接信息可以执行 wlan.connect(&#39;&#39;,&#39;&#39;)。\n如果想看到更多的连接细节，可以启用系统的调式功能\nimport espesp.osdebug(0)      # 将调试信息重定向到UART(0)esp.osdebug(None)   # 关闭调试信息\nAP模式ESP8266除了可以连接WiFi外，还可以作为一个AP来使用\nwlan.disconnect()   # 先断开先前的连接wlan.active(False)  # 取消激活接口ap = network.WLAN(network.AP_IF)    # 创建AP对象ap.active(True)     # 激活APap.config(essid='esp8266',password='12345678',     authmode=network.AUTH_WPA2_PSK)          # AP的SSID和密码，认证方式使用wpa2# ap.config(essid='esp8266',authmode=network.AUTH_OPEN)   # 或者创建没有密码的WiFi\n如果想更改AP模式分配的网段，也可以使用 ap.ifconfig() 来设置。这个时候用手机或者电脑就可以连接到此设备了。\n同时，ESP8266还支持 AP+STA 模式，这样就可以充当一个无线中继器了。还有 SmartConfig 技术，可以实现不连接开发板的情况下自动配置开发板连接WiFi，可惜比较遗憾的是，MicroPython 上并没有实现或者找到如何实现这样的功能。。。\nWebREPLESP8266 还提供了一个在浏览器上远程打开 MicroPython 提示符的功能就是 WebREPL，而且在这个页面上还可以实现上传文件等功能，把自己写好的代码上传到开发板，然后让它开机运行。\n打开这个功能非常简单，首先配置这个服务\nimport webrepl_setup\n执行后会询问你是否开机自启，输入 E 允许开机自启后需要配置一个连接密码来提高安全性，之后问你是否重启，输入 y 重启后可以看到提示符多了一行信息\nWebREPL daemon started on ws://0.0.0.0:8266\nStarted webrepl in normal mode\nOSError: [Errno 2] ENOENT\n\nMicroPython v1.9.3-8-g63826ac5c on 2017-11-01; ESP module with ESP8266\nType &quot;help()&quot; for more information.\n&gt;&gt;&gt;\n这个时候 可以打开官方提供的连接页面：点此打开，输入IP和端口，连接成功后如下\n还记得刚才写的测试MCU速度的脚本吗，现在把这个脚本也加入到系统里吧，这样每次开机后都可以使用这个测试的功能了。\n把刚才的程序代码写入到一个名叫 mcu.py 的文件，在终端执行如下代码import osos.listdir('/')\n可以看到，一共有两个文件，一个是 boot.py，一个是 webrepl.cfg.py，其中 boot.py 会在开机的时候自动运行，webrepl.cfg.py 里面记录的就是Web上连接的时候需要的密码了。现在将 boot.py 下载下来，然后修改这个文件，在最后一行添加 from mcu import loop_start，然后将 mcu.py 和 boot.py 上传回去，然后重启板子。\n&gt;&gt;&gt; os.listdir(&apos;/&apos;)\n[&apos;boot.py&apos;, &apos;webrepl_cfg.py&apos;, &apos;mcu.py&apos;]\n&gt;&gt;&gt; loop_start()\nPresent freq: 80MHz\nLoop 10000 times for 30.56 ms\nPresent freq: 160MHz\nLoop 10000 times for 15.296 ms\n&gt;&gt;&gt;\n可以看到，loop_start() 函数在启动的时候就会自动导入了，也就是说 mcu.py 被自动运行了，利用 boot.py 这样就可以实现开机的时候自动为WiFi配置静态IP了。\nUDP/TCP能使用UDP/TCP进行通讯，这才是物联网的第一步，MicroPython 上的 socket 模块提供了对网络套接字的支持。下面用几个例子来看看如何使用。\n广播自己的IP地址开发板连接上WiFi了，但是你并不知道板子的IP怎么办，除了登陆路由器来查看它的IP，还可以让它主动告诉你啊。\n下面看代码：import timeimport socketimport networkdef broadcast_ip():    wlan = network.WLAN(network.STA_IF)    while not wlan.isconnected():        time.sleep(1)    s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)    for i in range(3):        s.sendto(b'Hi! i am ESP8266!', ('255.255.255.255',2001))        time.sleep(1)\n将此代码保存为 ip.py 然后修改 boot.py 文件末尾添加：from ip import broadcast_ipbroadcast_ip()\n这里选择了向整个局域网内的2001端口发送UDP广播，也可以定点向某台主机发送，但是如果自己的IP也是DHCP获取的，那么可能下一次就又得该代码了。\n然后编写接收端的代码，接收端的代码在自己的电脑上运行。\nimport sockets = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)s.bind(('',2001))print('Start listen on: 0.0.0.0:2001')while True:    d, a = s.recvfrom(1024)    print(\"From: %s:%s\\tMessage: %s\" % (a[0], a[1], d.decode()))\n然后保存为 find_esp8266.py 并启动脚本，接着重启开发板，几秒钟后可以看到收到开发板发来的消息了。\nC:\\Users\\yunfwe\\Desktop&gt;python find_esp8266.py\nStart listen on: 0.0.0.0:2001\nFrom: 192.168.137.197:4097      Message: Hi! i am ESP8266!\nFrom: 192.168.137.197:4097      Message: Hi! i am ESP8266!\nFrom: 192.168.137.197:4097      Message: Hi! i am ESP8266!\n获取NAT出口的公网IP局域网内的主机都是通过NAT方式共享一个公网IP来访问互联网的，那么怎么获取自己出口的这个IP呢？如果自己有台公网上的服务器，让ESP8266向它发个包就知道了，可是大多数人都是没有公网上的服务器的，这样还可以利用第三方提供的查询服务。\n这里使用搜狐的查询接口: 点此打开，通过原始TCP套接字手动构建一个 HTTP 请求来访问数据\nimport jsonimport socketdef get_nat_ip():    s = socket.socket(socket.AF_INET, socket.SOCK_STREAM)    ip = socket.getaddrinfo('pv.sohu.com',0)[0][-1][0]    s.connect((ip,80))    request  = b'GET /cityjson?ie=utf-8 HTTP/1.1\\r\\n'    request += b'Host: pv.sohu.com\\r\\n\\r\\n'    size = s.send(request)    header, data = s.recv(1024).decode().split('\\r\\n\\r\\n')    data = data.split('=')[1][1:-1]    data = json.loads(data)    s.close()    print('NAT IP: %s' % data['cip'])get_nat_ip()\n在板子上执行看看吧！\n硬件IO通过网络来控制硬件，这样才能构建出各种智能硬件，先看看这块板子的引脚说明\n引脚说明IC 内部引脚D0(RX)串口接收GPIO3D1(TX)串口发送GPIO1D2I/O，不支持中断、PWM、I2C、以及1-wireGPIO16D3/SCL/D15I/O，默认模式下I2C的SCLGPIO5D4/SDA/D14I/O，默认模式下I2C的SDAGPIO4D5/SCK/D13I/O，SPI的时钟GPIO14D6/MISO/D11I/O，SPI的MISOGPIO12D7/MOSI/D11I/O，SPI的MOSIGPIO13D8I/O，上拉，低电平时进入FLASH模式GPIO0D9/TX1I/O，上拉GPIO2D10/SSI/O，下拉，SPI时默认的片选(SS)GPIO15A0AD输入，0-3.3VADC\n\n\n所有的IO工作电平为 3.3V，可瞬间承受 5V\n除D2外，所有 I/O 都支持中断，PWM，I2C，和 1-wire\n\nGPIOESP8266-12F 板载了一颗蓝光的LED灯，就试试用代码控制这个灯吧。这颗灯会在 GPIO2 输出为高电平的时候灭掉，输出为低电平的时候亮起来，这样通过控制 GPIO2 口的电平高低就可以控制这颗LED的亮灭了。\nESP8266 跟硬件控制相关的库是 machine，下面看看用 MicroPython 如何控制 GPIO\nfrom machine import Pinled = Pin(2, Pin.OUT)   # 将GPIO的2号引脚设置为输出led.value(1)            # 将这个引脚设置为输出高电平led.value(0)            # 将这个引脚设置为输出低电平led.on()                # 相当于led.value(1)led.off()               # 相当于led.value(0)led.value()             # 获取当前的电平值\n可以看到，执行 led = Pin(2, Pin.OUT) 的时候，本来灭着的LED灯突然亮了，接着执行 led.value(1) 的时候，LED灯灭了，这个时候 GPIO2 引脚输出的是高电平，如果在这个引脚上接一个LED灯或者其他设备，这个设备就开始工作了。\nD1 WiFi UNO R3 这块板子上还板载了一颗接在 GPIO 14号引脚的LED灯，也可以通过 GPIO 直接控制这颗灯的亮灭，利用这个灯做一个 Blink LED 吧。\nimport timefrom machine import Pinled = Pin(14,Pin.OUT, value=1)  # 创建时初始值为1while True:    led.on()    time.sleep(0.5)    led.off()    time.sleep(1)\n这颗LED灯已经开始以亮 0.5 秒，灭 1 秒的频率无限的闪下去了。\nPWM通过设置 GPIO 口的输出电平，只能控制灯的亮灭，那有没有什么办法可以调节灯的亮度呢，那就是 PWM。那什么是 PWM 呢？还记得刚才让 LED 灯闪烁的例子吗，亮 0.5 秒，灭 1 秒，这样的频率肉眼很容易就观察出来了。那么如果减少这个休眠的时间，亮 1 毫秒，灭 2 毫秒，这样的频率，人的肉眼几乎就观察不出来了，而且看到的就是LED只有原来的 1/3 的亮度了。这里就引出了一个概念：占空比 通电时间占总时间的比例。而 PWM 就是调节这个的。\n下面使用PWM测试下 GPIO14 上的这颗LED灯\nfrom machine import Pin, PWMled = PWM(Pin(14))      # 对 GPIO14 进行PWM控制led.freq()              # 获取当前的频率led.freq(1000)          # 调整当前的频率led.duty()              # 获取当前的占空比led.duty(1000)          # 现在LED应该是满亮led.duty(500)           # 现在LED应该是半亮led.duty(10)            # 现在LED应该是微亮led.deinit()            # 关闭对 GPIO14 的PWM控制\n利用这个性质可以做出一个好看的呼吸灯特效，下面看代码\nfrom time import sleep_msfrom machine import Pin, PWMled = PWM(Pin(2), freq=1000, duty=0)while True:    for i in range(0,1001,10):        led.duty(i)        sleep_ms(20)    for i in range(1000,0,-10):        led.duty(i)        sleep_ms(10)led.deinit()\nTimerESP8266的内存实在太小了，因此 MicroPython 并没有为ESP8266实现多线程的功能，那么如果想通过网络来控制呼吸灯应该怎么做到呢？可以试试用定时器。\n定时器类似于 JavaScript 的 setTimeout 和 setInterval，因为它们实现的功能是一摸一样的。MicroPython 的 machine.Timer() 会在给定的时间段执行一次或者周期性的执行这个回掉函数，下面看看具体是如何使用的。\nfrom machine import Timert1 = Timer(-1)      # 传给构造器一个ID，如果这个ID是-1，会初始化一个虚拟定时器t1.init(period=5000, mode=Timer.ONE_SHOT, callback=lambda t:print(1))t2 = Timer(0)t2.init(period=2000, mode=Timer.PERIODIC, callback=lambda t:print(2))t2.deinit()         # 取消定时器。\n参数 period 是每个周期的时间，单位是毫秒。mode 是运行模式，是只运行一次还是周期性运行。callback 则是到了这个时间周期然后执行的函数。如果这个 period 时间非常短的话，而且周期性的运行一个函数，这个函数将自己的数据保存在全局环境中，等到下个运行周期到了再继续处理数据，如果存在多个不同回掉函数的定时器，切换速度非常快的情况下，不就相当于多个函数在同时运行了吗。定时器每次调用回掉函数的时候，还会将自己本身作为参数传给回掉函数。\n下面看代码，运用上面所学的网络套接字，呼吸灯，还有定时器的知识来完成一个可以在局域网甚至公网来控制的呼吸灯。\nimport timeimport socketimport machineimport networkwlan = network.WLAN(network.STA_IF)wlan.active(True)wlan.ifconfig(('192.168.1.10', '255.255.255.0', '192.168.1.1', '119.29.29.29'))wlan.connect('SSID', 'PASSWORD')ap = network.WLAN(network.AP_IF)ap.active(False)led_timer = machine.Timer(1)keep_alive_timer = machine.Timer(2)net_control_timer = machine.Timer(3)led = machine.PWM(machine.Pin(2), freq=1000, duty=0)up = 1count = 0def breathing_light(t):    global led, up, count    if up == 1:        count += 3        led.duty(count)        if count &gt; 1000:            up = 0    if up == 0:        count -= 3        led.duty(count)        if count == 3:            up = 1def keep_alive(t):    global s    s.sendto(b'ESP8266-msg: live',('1.1.1.1',2002))def net_control(t):    global s,led_timer,led    try:        data,addr = s.recvfrom(5)    except:        return    print('From: %s:%s\\tRecv: %s' % (addr[0],addr[1],data.decode()))    if data in [b'on',b'start']:        led_timer.init(period=10, mode=machine.Timer.PERIODIC, callback=breathing_light)    elif data == b'stop':        led_timer.deinit()    elif data == b'off':        led_timer.deinit()        led.duty(0)while wlan.isconnected():    time.sleep_ms(200)s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)s.setblocking(0)s.bind(('0.0.0.0',2002))keep_alive_timer.init(period=10000, mode=machine.Timer.PERIODIC, callback=keep_alive)net_control_timer.init(period=10, mode=machine.Timer.PERIODIC, callback=net_control)print('Running...')\n将代码中的连接 WiFi 的SSID和PASSWORD换成实际的，keep_alive 函数主要是保持一条与公网主机的UDP通道，如果没有公网主机可以注释掉下面 keep_alive_timer 定时器的语句。程序启动了一个UDP端口，接受来自局域网主机的控制，如果存在公网主机，也可以在公网主机上向开发板发送数据。UDP套接字设置为了非阻塞模式，然后定时器每10毫秒会询问一次是否收到UDP数据，如果收到了 on 或者 start 数据，就启动呼吸灯的定时器，呼吸灯定时器的回掉函数将当前的状态保存在了全局变量中，执行一次更改亮度的操作后就退出了，等待下个10毫秒继续执行。这样多个定时器如果存在互相调用，就不会因为发生阻塞而影响其他定时器的运行了。\n当ESP8266和公网建立通信后，那么可以玩的地方更多了，比如接收温湿度传感器的数据，然后监控环境温度并定期将温度上传到服务器，或者接入微信公众平台用微信来控制单片机，这些就又是一个很大的话题了。\n附录板子还在继续折腾中。。。等折腾出其他好玩的了继续更新\n\n","categories":["IoT"],"tags":["esp8266"]},{"title":"Hadoop入门笔记","url":"/2018/02/04/2018/Hadoop%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","content":"简介\nHadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。Hadoop实现了一个分布式文件系统，简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的硬件上；而且它提供高吞吐量来访问应用程序的数据，适合那些有着超大数据集的应用程序。Hadoop的核心设计是：HDFS、YARN和MapReduce。HDFS为海量的数据提供了存储，YARN提供资源调度，而MapReduce则为海量的数据提供了计算.\n\n\n环境系统环境\n为了避免防火墙等影响 默认已经关闭iptables和selinux\n\n\n\n\n身份\n系统\n主机名\nIP\n\n\n\n\nHadoop master\nubuntu 16.04\nmaster\n10.0.0.3\n\n\nHadoop slave1\nubuntu 16.04\nslave1\n10.0.0.4\n\n\nHadoop slave2\nubuntu 16.04\nslave2\n10.0.0.5\n\n\nHadoop slave3\nubuntu 16.04\nslave3\n10.0.0.6\n\n\n\n软件环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nHadoop\n2.7.5\n点击下载\n\n\njdk\n1.8.0_161\n点击下载\n\n\n\n步骤安装Hadoop\n下载的是官方编译好的二进制包 所以就不用再重新编译了。注意：下面的操作需要在所有主机上进行 或者配置好一台后rsync同步到其他主机\n\n下载和解压# 软件包在windows上下载并上传到了Linux上 注意jdk下载需要先接受许可协议tar xf hadoop-2.7.5.tar.gz -C /usr/local/mv /usr/local/&#123;hadoop-2.7.5,hadoop&#125;tar xf jdk-8u161-linux-x64.tar.gz -C /usr/local/\n配置集群环境\n集群环境为启动和使用Hadoop集群所需要的配置\n\n配置jdk环境变量\n将以下内容写入到 /etc/profile.d/jdk.sh\n\nexport JAVA_HOME=/usr/local/jdk1.8.0_161\nexport PATH=$JAVA_HOME/bin:$PATH \nexport CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar\n\n修改 /usr/local/hadoop/etc/hadoop/hadoop-env.sh\n\n找到   export JAVA_HOME=${JAVA_HOME}\n修改为 export JAVA_HOME=/usr/local/jdk1.8.0_161\n配置hadoop环境变量\n将以下内容写入到 /etc/profile.d/hadoop.sh\n\nexport HADOOP_HOME=/usr/local/hadoop\nexport PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH\n使环境变量立即生效\n运行命令：\n\nsource /etc/profile\n配置主机名解析\n将以下内容写入到/etc/hosts\n\n10.0.0.3    master\n10.0.0.4    slave1\n10.0.0.5    slave2\n10.0.0.6    slave3\nWindows上也顺便更改下hosts文件 以便于后面的访问集群hosts文件位置：C:\\Windows\\System32\\drivers\\etc\\hosts因为系统目录权限问题 可以将hosts文件拖到桌面修改后再拖回去覆盖了原文件即可\n\n认识HDFS\nHDFS的全称是 “Hadoop分布式文件系统” ，可以简单理解为由用户进程模拟的一块大硬盘，为大数据处理提供了基础的数据存储服务，下面先看看HDFS是怎么一回事，再探究它到底是个什么东东。\n\n启动HDFS\nHadoop由三部分组成 HDFS则是其最基层的一部分。\n\n配置文件语法\nHadoop的配置文件在/usr/local/hadoop/etc/hadoop/中，配置文件使用xml语法\n\n&lt;property&gt;                   &lt;!-- 属性 --&gt;\n    &lt;name&gt;&lt;/name&gt;            &lt;!-- 名称 --&gt;\n    &lt;value&gt;&lt;/value&gt;          &lt;!-- 值 --&gt;\n&lt;/property&gt;                  \n配置项需要写在配置文件的&lt;configuration&gt;&lt;/configuration&gt;代码块中\n配置文件简单介绍\nHadoop可能需要经常改动的配置文件有四个，下面简单说说这四个都是干嘛用的，具体用到的配置文件，后面会详细说明。\n\n\n\n\n配置文件\n说明\n\n\n\n\ncore-site.xml\nHadoop Core的配置项\n\n\nhdfs-site.xml\nHDFS的配置项 比如配置HDFS数据存储位置等\n\n\nyarn-site.xml\nyarn资源调度器的配置 比如yarn监听的地址等\n\n\nmapred-site.xml\nMapReduce计算引擎的相关配置\n\n\n\n修改配置文件\nHDFS的配置文件为hdfs-site.xml 打开发现&lt;configuration&gt;&lt;/configuration&gt;中是空的。其实Hadoop已经为HDFS的各种参数配置了默认值，用户重写进配置文件的值会覆盖掉Hadoop默认的。启动HDFS集群需要让各slave节点知道要连接谁，而这个配置是在core-site.xml中。\n\n\n将所有节点的 core-site.xml 修改为如下内容\n\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;fs.defaultFS&lt;/name&gt;\n        &lt;value&gt;hdfs://master:9000&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n配置hdfs的slave都连接master的9000端口\n启动HDFS集群\nHDFS集群分为 NameNode 和 DataNode ，其中NameNode为master节点 DataNode为slave节点NameNode的作用就像一本书的目录 记录每一个文件存放在哪个slave节点上。而DataNode则是存放数据用的了。\n\n启动前需要先对namenode进行目录格式化在master节点上执行NameNode格式化命令和启动的命令hadoop namenode -formathadoop-daemon.sh start namenode\n在所有slave节点上执行启动DataNode的命令hadoop-daemon.sh start datanode\n使用jps命令可以看到当前启动的java进程，可以看到master节点跑着的是NameNode进程，而slave节点跑着的是DataNode进程\n验证是否启动成功\nHDFS启动成功后 master会监听9000端口，并且还会监听50070端口，这个端口是HDFS的web管理界面。\n\n可以使用命令的方式查看集群各节点的运行状况hdfs dfsadmin -report\n也可以在web界面上直观的看到HDFS集群的状况浏览器访问：http://master:50070 然后点击 Datanodes 可以看到三个slave正常在线\n如果还想继续增加slave节点 只需要更改了slave节点的配置文件后启动就可以了。HDFS的总容量会随着节点的增多而增多 拓展性是不是非常好呢。但是随着节点的增加又一个问题出现了 现在slave节点拓展到一千多台了 我该怎么启动这个集群呢？\n集中式管理HDFS集群\nHadoop官方已经提供了一个批量启动和关闭HDFS集群的脚本了 而且以后用的更多的也是这些脚本。但是使用脚本之前 还需要做一些小配置。\n\n配置ssh密钥认证\n这一步配置master节点到其他slave节点的ssh密钥认证，其实就是master节点替你登陆到各slave节点启动DateNode了\n\n此步骤只在master上进行\nssh-keygenssh-copy-id root@master     # 没错 自己也要免密码登陆自己ssh-copy-id root@slave1ssh-copy-id root@slave2ssh-copy-id root@slave3\n配置完成后可以ssh验证在master上是否可以免密码登陆所有slave节点了\n配置slave节点\n只有告诉了master有哪些slave节点 master才会帮助你启动或停止它们修改 /usr/local/hadoop/etc/hadoop/slaves 如下\n\nslave1\nslave2\nslave3\n如果有localhost这条记录需要删掉 这样master节点就不会也被当作slave节点了\n停止HDFS集群\n因为HDFS集群已经是启动状态了 那就先试试停止它们吧\n\n在master上执行stop-dfs.sh\n再在各节点执行jps命令看看是不是NameNode和DataNode已经停止了呢\n启动HDFS集群\n停止使用的是stop-dfs.sh命令 那启动就肯定是start-dfs.sh喽\n\nstart-dfs.sh\n再用jps命令看看 是不是所有节点各自的服务都启动了呢但是master上的进程好像不太一样 多了一个SecondaryNameNode，那么这个进程是做什么的呢\n这个进程是帮助NameNode更好的工作 解决NameNode运行中可能出现的一些问题的 这也是NameNode容错的一种机制，具体作用可以查阅官方文档或搜索引擎。\n接下来 就该看看这个HDFS该怎么用了吧 既然是一种分布式文件系统 那么它体现在哪里呢？\nHDFS的文件操作\n先简单介绍下HDFS文件的存储方式。将文件上传到HDFS中后 HDFS会将文件按照128M为一块进行分块存储。每一块又默认会复制三次 然后存放在三个不同的节点上。这样如果有某台机器宕机了 就还可以从其他节点拿到这一块文件，所以提供了文件冗余机制，并且HDFS还会将宕机节点丢失的块再复制一份到其他节点 保证每一块都存在三份。 \n\n\nHDFS的特性：文件分块 文件冗余 容易拓展\n\n命令行管理HDFS中的文件\n通过java程序或者其他语言的HDFS库就可以操作HDFS中的文件了。在Linux上也提供了一些命令去操作HDFS\n\nhadoop fs -ls /                 # 查看HDFS集群根目录的文件 应该是空的hadoop fs -mkdir /hadoop        # 创建/hadoop目录hadoop fs -put /tmp/hadoop-2.7.5.tar.gz /hadoop     # 将这个文件上传到/hadoop目录中hadoop fs -ls /hadoop           # 这个时候应该可以看到上传的文件了hadoop fs -put /etc/profile.d/jdk.sh /      # 将jdk.sh 上传到根目录hadoop fs -cat /jdk.sh          # 有没有发现这些命令和Linux的命令都差不多呢hadoop fs -rm /jdk.sh           # 把jdk.sh删除hadoop fs -rm -r -f /hadoop     # 和rm命令一样 也是可以带-r -f 参数的哦hadoop fs -put /tmp/jdk-8u161-linux-x64.tar.gz /    # 把jdk上传上去 以便下面的测试hadoop fs -get /jdk-8u161-linux-x64.tar.gz /root/   # 把文件下载到root的家目录hadoop fs -help                 # 查看所有支持的操作\nHDFS是不允许对文件进行更改的 所以如果非要修改 只能把文件下载下来修改后再上传\nWeb界面浏览HDFS中的文件\n为什么说是浏览呢 因为Web界面内是没法对文件进行操作的 只能看\n\n浏览器打开：http://master:50070  首页的Summary中可以看到集群的状态\n因为HDFS会把一个文件分块后复制三份存放在不同的节点上 jdk的大小是180多M 三倍大小差不多就是547M了\n点击 Utilities 中的 Browse the file system 就可以看到集群中的文件了\n点击文件名称 可以查看文件的更多信息。HDFS的块大小为128M, jdk文件自然被分成了两块 每一块都存放在了三个节点上\nHDFS的配置\n默认HDFS会将文件复制三份 但是你觉得数据并不是那么重要 复制两份就满足数据冗余的需求了，那么如何更改这个配置呢\n\n查阅官方文档\n学习一个技术最好的方法就是查阅它的官方文档，官方文档永远是第一手资料。\n\n打开Hadoop的官方首页：http://hadoop.apache.org/然后左侧栏点开 Documentation 找到自己的版本：http://hadoop.apache.org/docs/r2.7.5/左侧栏的最下方有个Configuration 既然是对HDFS进行配置 那肯定是看 hdfs-default.xml 的了点开后可以看到茫茫多的配置 这些配置都是HDFS的默认配置 只用修改相应的值就可以了。既然是复制 那就看看和复制有关的配置，在网页中搜索 &quot;replication&quot;\ndfs.replication 就是我们要更改的目标了\n修改 hdfs-site.xm\n只需要修改master节点的 hdfs-site.xml 就可以了\n\n修改为如下：\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;dfs.replication&lt;/name&gt;\n        &lt;value&gt;2&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\n保存退出后重启集群stop-dfs.shstart-dfs.sh\n接下来再测试下是否文件只复制2份了 上传一个新文件到HDFS中hadoop fs -put /tmp/hadoop-2.7.5.tar.gz /\n浏览器查看文件信息\n可以看到 hadoop-2.7.5.tar.gz 只被复制了2份，并且文件的每一份都尽量平均的分散在集群的不同slave中。block0存放在slave2和slave3上，block1存放在slave1和slave3上，那么如果slave1宕机了 HDFS会做哪些操作呢\nslave1宕机模拟\n只要slave1和master不能正常通信就可以了，可以停掉slave1的datanode服务 或者开启slave1的防火墙阻止通信都可以。master会定期检测slave的状况 只有发现slave挂了后才会将缺少的文件再复制一份到其他节点。这个默认周期是300000毫秒 也就是5分钟。如果不想等待这么长时间 可以修改hdfs-site.xml，配置 dfs.namenode.heartbeat.recheck-interval 的值为10000 也就是10秒\n\n在slave1上运行：hadoop-daemon.sh stop datanode\n过一阵子刷新浏览器 可以看到slave1已经离线了，并且又在slave2上复制了一份\n测试完后记得重新启动 slave1hadoop-daemon.sh start datanode\n刷新浏览器可以看到 slave1又上线了\n修改数据存储路径\nHDFS文件的数据块最终还是要真实存在硬盘上的，HDFS的默认数据存放路径为/tmp/下 这显然不是一个好主意\n\nNameNode的数据存储位置定义在 dfs.namenode.name.dir 默认值为 file://${hadoop.tmp.dir}/dfs/nameDataNode的数据存储位置定义在 dfs.datanode.data.dir 默认值为 file://${hadoop.tmp.dir}/dfs/data\n我们将数据目录修改到 /data/dfs 下master节点配置如下：\n&lt;property&gt;\n    &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt;\n    &lt;value&gt;file:///data/dfs/name&lt;/value&gt;\n&lt;/property&gt;\nslave节点全部配置如下：\n&lt;property&gt;\n    &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt;\n    &lt;value&gt;file:///data/dfs/data&lt;/value&gt;\n&lt;/property&gt;\n以下操作在master上进行stop-dfs.sh                     # 停止集群mkdir -p /data/dfs/name         # 创建相应目录hadoop namenode -format         # 重新格式化\n接下来在slave节点上创建目录mkdir -p /data/dfs/data\n然后master上重新启动HDFS集群吧start-dfs.sh\nHDFS的内容就先到这里吧 更多的配置项在以后用到的时候慢慢学习和了解 遇到不懂得地方记得查阅官方文档哦\n\nYARN资源调度器\nYARN是开源项目Hadoop的一个资源管理系统，最初设计是为了解决Hadoop中MapReduce计算模型中的资源管理问题，但是现在它已经是一个更加通用的资源管理系统，可以把MapReduce计算模型作为一个应用程序运行在YARN系统之上，通过YARN来管理资源。如果你的应用程序也需要借助YARN的资源管理功能，你也可以实现YARN提供的编程API，将你的应用程序运行于YARN之上，将资源的分配与回收统一交给YARN去管理，可以大大简化资源管理功能的开发。当前，也有很多应用程序已经可以构建于YARN之上，如Storm、Spark等计算模型。\n\nYARN的基本概念\n有了HDFS的基本概念 理解YARN也比较简单了 HDFS是将文件分布式存储在不同的slave节点上，而YARN是将任务拆分到不同的计算节点上。\n\nHadoop第一代中是没有YARN的概念的，Hadoop第二代开始专门将资源调度抽取出来了 所以才有了YARN。Hadoop第一代中 只有HDFS和一个MapReduce计算模型。但是MapReduce发展中发现了一些局限性，比如不支持内存模型、流式模型等计算模型。在Hadoop第二代的时候对这个问题进行了改进 在HDFS之上抽象出了一个资源调度模型，这个资源调度模型就是YARN（Yet Another Resource Negotiator）。\nYARN对集群的内存、CPU资源进行调度，将计算任务按照算法分发到集群节点。有了这个抽象层 就可以在之上能跑的就不只有MapReduce了，还有各种各样的计算模型，比如Spark、Storm等。YARN只做调度 不参与计算。\nYARN的master上运行ResourceManager，slave上运行NodeManager。YARN和HDFS是低耦合的，可以部署在一个集群中 也可以分开部署在两个集群中。把NodeManager和DataNode部署在同一个节点上，可以使NodeManager读取HDFS的效率更高 所以一般都将NodeManager和DataNode部署在一起。而ResourceManager和NameNode都比较吃内存，所以最好分开部署。实验中将ResourceManager和NameNode部署到了一起。\n用户编写好计算的任务程序 然后去请求ResourceManager，ResourceManager将用户的任务拆分，然后分发到NodeManager节点进行计算，计算节点再从HDFS中获取数据。下面就看看YARN如何配置和启动。\n配置YARN集群修改YARN的配置文件修改所有节点的yarn-site.xml文件\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt;\n        &lt;value&gt;master&lt;/value&gt;\n    &lt;/property&gt;\n    &lt;property&gt;  \n        &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt;  \n        &lt;value&gt;mapreduce_shuffle&lt;/value&gt;  \n    &lt;/property&gt;  \n    &lt;property&gt;\n        &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt;\n        &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\nyarn.resourcemanager.hostname 指明ResourceManager在master上 只修改这一个 YARN集群就可以起来了。下面两个配置是NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序。\n启动YARN集群\nYARN的启动和HDFS的启动类似 可以单个启动 也可以集群化方式启动\n\n单独启动YARN节点master节点上执行yarn-daemon.sh start resourcemanager        # 启动ResourceManageryarn-daemon.sh stop resourcemanager         # 停止ResourceManager\nslave节点上执行yarn-daemon.sh start nodemanager            # 启动NodeManageryarn-daemon.sh stop nodemanager             # 停止NodeManager\n集群化启动master节点上执行start-yarn.sh           # 启动整个YARN集群stop-yarn.sh            # 停止整个YARN集群\nWeb界面查看集群状态\nResourceManager启动后 会在8088端口提供一个web界面，通过这个web界面可以看到节点状态，任务运行状态等\n\n浏览器访问：http://master:8088/\nYARN起来后怎么测试效果呢 那就跑个MapReduce计算看看吧\n\nMapReduce计算模型\nMapReduce最早是由Google公司研究提出的一种面向大规模数据处理的并行计算模型和方法。Hadoop的设计思想也来源自Google的几篇论文，MapReduce的论文里提到 MapReduce的灵感来自于函数式语言Lisp中的内置函数map和reduce。对于熟悉Python语言的人 应该都知道Python的两个内置函数 map 和 reduce，如果对着两个函数的运用也比较熟练的话，MapReduce计算模型也很容易理解了。下面就来看看利用MapReduce思想 是怎么解决数据处理中的问题的\n\n第一个MapReduce程序\n一个很简单的例子 统计一个文本文件中每个单词出现的次数。首先 先配置好MapReduce吧\n\n修改配置文件\nmapred-site.xml是MapReduce计算模型的配置文件。MapReduce和YARN也是低耦合的，跑MapReduce计算并不一定需要YARN，当然YARN上面并不只能跑MapReduce。这里就使用YARN来调度MapReduce使用的计算资源。\n\n修改master节点的mapred-site.xml文件\nmapred-site.xml文件不存在 所以需要先复制一份cp /usr/local/hadoop/etc/hadoop/&#123;mapred-site.xml.template,mapred-site.xml&#125;vim /usr/local/hadoop/etc/hadoop/mapred-site.xml\n&lt;configuration&gt;\n    &lt;property&gt;\n        &lt;name&gt;mapreduce.framework.name&lt;/name&gt;\n        &lt;value&gt;yarn&lt;/value&gt;\n    &lt;/property&gt;\n&lt;/configuration&gt;\nmapreduce.framework.name 指定了MapReduce在YARN这个框架上跑，如果不配置就默认在本地单机上跑。\n运行wordcount任务\n/usr/local/hadoop/share/hadoop/mapreduce 中有一个 hadoop-mapreduce-examples-2.7.5.jar里面包含了一些官方给出里例子 wordcount就是其中的一个\n\n创建测试文本\n新建一个文件tmp.txt 然后写入以下内容：\nhello world\nhello python\nhello java\nhello java\nhi python\nhi c\nhi c++\nhi lua\nhello lua\n为了效果明显点 可以将这些内容多次写入到test.txt文件while :; do cat tmp.txt &gt;&gt; test.txt ; done\n这里已经获得了一个30M大小的文件了\nroot@slave1:~# ls -lh test.txt \n-rw-r--r-- 1 root root 30M Feb  8 08:34 test.txt\n上传到HDFS中hadoop fs -put test.txt /\n开始测试吧！cd /usr/local/hadoop/share/hadoop/mapreducehadoop jar hadoop-mapreduce-examples-2.7.5.jar wordcount /test.txt /testout\n简单讲解下这条命令的意思 -jar 是运行这个jar包，wordcount是运行jar包中 wordcount这个类 /test.txt 是输入文件 /testout 是输出目录，一定要注意 /testout 一定要不存在才行。\n现在可以看到命令的输出\nWeb界面也可以看到任务的运行状态\n点击任务的ID 就可以看到这个任务是跑在了哪些节点上哦。因为30M对于Hadoop来说简直太小了 所以只分配了两个节点就够了。这个任务中 可以看到两个Maps进程都跑在slave1上 一个Reduces进程跑在slave3上\nPS: 任务可以在任何节点跑 但是想要使用YARN进行资源调度的话 也需要修改相应节点的mapred-site.xml文件，否则就成了本地单机版的MapReduce了。ResourceManager节点重启后 所有的任务记录也都会丢失哦。\n查看任务结果\n还记得输出目录 /testout 吗 结果就在那里\n\n先看一看/testout下有什么吧\nroot@master:~# hadoop fs -ls /testout\nFound 2 items\n-rw-r--r--   2 root supergroup          0 2018-02-08 08:53 /testout/_SUCCESS\n-rw-r--r--   2 root supergroup         95 2018-02-08 08:53 /testout/part-r-00000\n_SUCCESS是表示这个任务执行成功part-r-00000 就是结果了 如果是个结果集的话 还会有part-r-00001、part-r-00002 …那就看看这个文件的内容吧\nroot@master:~# hadoop fs -cat /testout/part-r-00000\nc        360944\nc++        360944\nhello    1804720\nhi        1443776\njava    721888\nlua        721888\npython    721888\nworld    360944\n可以看到每一个单词出现的次数都被统计出来了，那么它是怎么实现的呢？\nMapReduce的运行原理\nMapReduce的内部工作方式是怎样的呢？它是怎么解决单词统计这个任务的呢？\n\nMap 和 Reduce举个简单的例子：顾客想知道他经常去的图书馆里有多少本书，于是找到了老板。“Hi! 老板 我想知道你的图书馆里有多少本书”“好嘞 我让手下去数一数”一共有二十个书架 领导分配了十个人去数，第一个人数1,2书架，第二个人数3,4书架以此类推等数完后将结果交给另外一个人去汇总 把每个书架的结果累加起来汇总完后 将结果给了老板后 老板告诉顾客有多少本书\n这个例子中 顾客 就是开发者老板呢 就像是YARN进行工作调度所有的书就像是HDFS中存储的数据工人的工作就是所谓的Map了 而汇总统计的那个人做的工作 就是ReduceMap呢 就是将数据整理 归类 将复杂的数据变得简单有结构Reduce呢 就是拿到同类的数据后进行处理 计算\n再讲一个做水果沙拉的例子：一堆不同种类的水果 要做成水果沙拉挑出一个 是香蕉 好 切成块挑出一个 是苹果 好 切成块挑出一个 是梨 好 切成块挑完也切完了 好 混在一起做成水果沙拉挑和切的动作 就可以看作Map，最后将所有的水果块做成水果沙拉 就可以看作是Reduce的过程了\nMap和Reduce 只是一种思想 并不局限于一种固定的解决问题的模式 如何玩转这种思想 得到自己想要的结果 就是一门艺术了。这就是我所理解的MapReduce。\nwordcount程序的实现\n回到正题 看看这个自带的wordcount程序的实现是怎么样的呢\n\n1. 输入（input） 将文档输入到Map进程\n\nhello world\nhello python\nhello java\nhello java\n\n2. 拆分（split） 将每一行都转为key-value形式\n\n0 - hello world\n1 - hello python\n2 - hello java\n3 - hello java\n\n3. 映射（map）将每一行的每一个单词都形成一个新的key-value对\n\nhello 1\nworld 1\nhello 1\npython 1\nhello 1\njava 1\nhello 1\njava 1\n\n4. 派发（shuffle）将key相同的扔到一起去\n\nhello 1 1 1 1\nworld 1\npython 1\njava 1 1\n\n5. 缩减（reduce）将同一个key的结果相加起来\n\nhello 4\nworld 1\npython 1\njava 2\n\n6. 输出（output）将缩减之后的结果输出\n自己写一个MapReduce程序\nMap和Reduce的过程 是可以用户自定义的 那我们就自己实现一个统计字数的程序仍到Hadoop上跑吧不会写java不怕 hadoop-streaming-2.7.5.jar 这个包 提供了使用其他语言来写MapReduce程序的方法，这里用Python来实现。\n\nMap\n编写 mapper.py 文件\n\n#!/usr/bin/env pythonimport sysfor line in sys.stdin:    words = line.split()    for w in words:        print(w+' '+'1')\n1. 从标准输入获取数据 然后按行读取\n    hello world\n\n2. 然后使用空白字符分割为一个列表\n    [&quot;hello&quot;,&quot;world&quot;]\n\n3. 将列表中的每一个元素都转为key-value，并且写入到标准输出\n    hello 1\n    world 1\n\n4. 继续从标准输入读取下一行 直到结束\nReduce\n编写 reducer.py 文件\n\n#!/usr/bin/env pythonimport sysresult = &#123;&#125;for line in sys.stdin:\tkey,value = line.split()\tif key in result:\t\tresult[key] += int(value)\telse:\t\tresult[key] = int(value)for k,v in result.items():\tprint(k+'\\t'+str(v))\n1. 创建一个保存结果的字典  result\n2. 从标准输入中读取一行\n    hello 1\n\n3. 使用空白字符分割为一个列表 然后赋值给key和value\n    key = hello, value = 1\n\n4. 如果key存在result中了 那么他的值就加上变量value的值\n   如果key不存在result中 那么创建这个key 并将变量value赋值给它\n   {&quot;hello&quot;: 1}\n\n5. 继续从标准输入读取下一行 直到结束\n6. 将结果格式化写入到标准输出\n运行自己的MapReduce程序\n需要将两个脚本拷贝到所有节点相同的目录哦 因为不知道哪个节点会被调度运算\n\nchmod +x mapper.py reducer.pyscp mapper.py reducer.py root@slave1:/tmpscp mapper.py reducer.py root@slave2:/tmpscp mapper.py reducer.py root@slave3:/tmp\n使用 hadoop-streaming 跑起来吧！cd /usr/local/hadoop/share/hadoop/tools/lib     # 这个jar包的路径# 注意：下面两行是一条命令hadoop jar hadoop-streaming-2.7.5.jar -input /test.txt \\-output /pyout -mapper /tmp/mapper.py -reducer /tmp/reducer.py\n命令参数什么的就不用说了吧 使用也是非常简单PS: 前期想测试下自己写的程序 可以使用管道模拟 比如 cat test.txt | ./mapper.py | ./reducer.py\n也可以试试Linux的命令作为 mapper 和 reducer 的处理程序哦 比如hadoop jar hadoop-streaming-2.7.5.jar -input /test.txt \\-output /linuxout -mapper /usr/bin/sort -reducer /usr/bin/uniq\n跑完了 有没有很开心呢\n接下来该看看结果是否和自带的wordcount一样呢\nroot@slave1:~# hadoop fs -ls /pyout\nFound 2 items\n-rw-r--r--   2 root supergroup          0 2018-02-08 15:44 /pyout/_SUCCESS\n-rw-r--r--   2 root supergroup         95 2018-02-08 15:44 /pyout/part-00000\nroot@slave1:~# hadoop fs -cat /pyout/part-00000\nhi        1443776\nc++        360944\nc        360944\nworld    360944\njava    721888\nlua        721888\npython    721888\nhello    1804720\nwordcount果然是大数据的Hello World学习到这里 也算是进入大数据的大门了 接下来就学习更高级的内容吧\n附录学习过的资料\n马士兵老师hadoop2.7入门系列\nHDFS-百度百科\nYARN-百度百科\nHadoop之MapReduce运行原理\n关于MapReduce的理解\n\n遇到的问题\n如果主节点重新格式化了 子节点也需要将数据目录中的文件都删除\n遇到会持续更新。。。\n\n","categories":["Hadoop"],"tags":["Hadoop","大数据"]},{"title":"Lua入门笔记","url":"/2018/01/12/2018/Lua%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0/","content":"简介\nLua是一门脚本语言 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。Lua由标准C编写而成，几乎在所有操作系统和平台上都可以编译，运行。Lua并没有提供强大的库，这是由它的定位决定的。所以Lua不适合作为开发独立应用程序的语言。Lua 有一个同时进行的JIT项目，提供在特定平台上的即时编译功能。\n\n\nLua特征\n轻量级 使用标准C语言开发 编译后才100多K\n可拓展 lua没有庞大的标准库，但是可以灵活使用宿主语言的功能\n支持面向过程和函数式编程\n自动内存管理 闭包 提供多线程（更像是协程）\n\n应用场景\n游戏开发\n独立应用脚本\nWeb应用脚本\n程序拓展或插件（Nginx, MySQL proxy）\n安全系统 如入侵检测系统\n\nLua安装Linux编译安装lua依赖readline.h ubuntu系统安装libreadline-dev \nwget http://www.lua.org/ftp/lua-5.3.4.tar.gztar xf lua-5.3.4.tar.gzcd lua-5.3.4make linuxmake install\ncd src &amp;&amp; install -p -m 0755 lua luac /usr/local/bin\ncd src &amp;&amp; install -p -m 0644 lua.h luaconf.h lualib.h lauxlib.h lua.hpp /usr/local/include\ncd src &amp;&amp; install -p -m 0644 liblua.a /usr/local/lib\ncd doc &amp;&amp; install -p -m 0644 lua.1 luac.1 /usr/local/man/man1\nLua向系统安装了这些文件 接下来就可以使用Lua命令了\nHello World用hello world作为lua第一个脚本的开始\nlua也有一个交互式解释器 也可以写为后缀为.lua的文件来执行代码\nvim hello.lua\n写入\nprint(&quot;Hello world!&quot;)\n执行lua hello.lua\nLua的注释单行注释单行注释是两个减号\n-- 单行注释\n多行注释--[[\n多行注释\n多行注释\n--]]\n标示符Lua中的标示符和其他语言的标示符都基本一致\n关键字\n\n\n关键字\n关键字\n关键字\n关键字\n\n\n\n\nand\nbreak\ndo\nelse\n\n\nelseif\nend\nfalse\nfor\n\n\nfunction\nif\nin\nlocal\n\n\nnil\nnot\nor\nrepeat\n\n\nreturn\nthen\ntrue\nuntil\n\n\nwhile\n\n\n\nLua中的约定：以下划线开头的大写字母 被保留用于Lua的内部全局变量\n数据类型Lua有8个基本类型\n\n\n\n数据类型\n描述\n\n\n\n\nnil\n表示无效值 空值\n\n\nboolean\n只有两个值：true和false\n\n\nnumber\n表示双精度类型的实浮点数\n\n\nstring\n字符串 可以用单引号也可以双引号\n\n\nfunction\n由C或者Lua编写的函数\n\n\nuserdata\n表示任意存储在变量中的C数据结构\n\n\nthread\n表示执行的独立线程，用于执行协同程序\n\n\ntable\nLua 中的表（table）其实是一个”关联数组”\n\n\n\n使用type函数测试给定的值是什么类型 比如：print(type(1))print(type(&quot;hello&quot;))print(type(false))print(type(&#123;&#125;))\nnil (空)nil类型表示没有任何有效值 nil类型只有一个值:nil\n将全局变量或table表里的变量赋值nil 相当于删除了这个变量\nboolean (布尔)boolean型只有两个值：true 和 false\nLua只把false和nil看作是假 其他都为真！！！就算是0也是真！！！\nnumber (数字)Lua的number只有一种类型：double类型 所有的数字都是double类型的\nstring (字符串)单行字符串可以用双引号或者单引号表示多行字符串用 [[string]] 表示 相当于python的三引号\n如果一个数字型的字符串与数字进行运算 Lua会将字符串转为number！与JavaScript相反\nLua的字符串拼接使用”..” 两个点 比如：print(&quot;str&quot;..1)print(2 ..3 ..4)\n如果两个数字做字符串拼接 数字后面一定要带个空格 否则解释器会解释错\nLua使用#来计算字符串的长度 就像是python的len()一样str = &quot;Hello world!&quot;print(#str)print(#&quot;lua&quot;)\ntable (表)Lua的table类型比较有意思 像是python的字典，列表，集合的合体table类型的索引可以是数字 也可以是字符串Lua的数字索引是从1开始的！！！tbl1 = &#123;&#125;tbl2 = &#123;&quot;a&quot;,&quot;b&quot;,&quot;c&quot;&#125;tbl3 = &#123;a=1,b=2&#125;print(tbl2[1])print(tbl3[&quot;a&quot;])\na = &#123;&#125;a[&quot;key&quot;] = &quot;value&quot;a[1] = 2print(a[&quot;key&quot;])print(a[1])\nLua取table中的数据可以用[] 如果key是字符串类型 还可以用.比如：tbl1 = &#123;key=&quot;a&quot;&#125;print(tbl1.key)\nfunction (函数)Lua的函数跟JavaScript的函数很像 用function声明 还可以当作参数传给其他函数\nfunction map(fn, tab)    count = 1    ltab = &#123;&#125;    for k,v in pairs(tab) do            ltab[k] = fn(v)    end    return ltabendmap(function(x)        return x*x    end,    &#123;2,3,4,5&#125;)    for k,v in pairs(rst) do    print(&quot;new: &quot;..k..&quot;=&quot;..v)end\nthread (线程)Lua里的线程其实就是协程\nuserdata (自定义类型)userdata 是一种用户自定义数据，用于表示一种由应用程序或 C/C++ 语言库所创建的类型，可以将任意 C/C++ 的任意数据类型的数据（通常是 struct 和 指针）存储到 Lua 变量中调用。\n变量默认情况下 Lua的变量总是全局的 不需要声明就可以直接赋值。访问一个不存在的变量会返回nil，想删除一个变量 将其赋值为nil就可以了Lua有三种变量：全局变量 本地变量 表中的域Lua除非用local声明为局部变量 否则都为全局变量\n应该尽量使用局部变量\n\n避免变量冲突\n访问局部变量的速度更快\n\no = 10              --&gt; 全局变量function say()   local o = 100    --&gt; 局部变量   print(o)endprint(o)\n变量赋值Lua的变量赋值也比较灵活a,b,c = 1,2,3   --&gt; a=1,b=2,c=3a,b = b,a       --&gt; swap a for ba,b = 1,2,3     --&gt; a=1,b=2 3 was dropa,b,c = 1,2     --&gt; a=1,b=2,c=nilprint(a,b,c)\nLua循环while 循环while (condition)\ndo\n    statements\nend\nfor 循环数值for循环for var=exp1,exp2,exp3 do\n    statements\nend\nvar从exp1变化到exp2，每次变化以exp3为步长递增var，并执行一次”执行体”。exp3是可选的，如果不指定，默认为1。for i=10,1,-1 do    print(i)end\n泛型for循环泛型for循环通过一个迭代器函数来遍历所有值\nfor k,v in pairs(table) do\n    statements\nend\n\nfor i,v in ipairs(list) do\n    statements\nend\n\n在lua中pairs与ipairs两个迭代器的用法相近，但有一点是不一样的：\n\npairs可以遍历表中所有的key，并且除了迭代器本身以及遍历表本身还可以返回nil;\n\n但是ipairs则不能返回nil,只能返回数字0，如果遇到nil则退出。它只能遍历到表中出现的第一个不是整数的key\nrepeat…until 循环类似于C的do while循环 先做后判断\nrepeat\n    statements\nuntil(condition)\nbreak 跳出循环如果遇到break 就终止循环 很不幸的是 Lua没有continue，但是可以用嵌套循环模拟\nfor i = 1, 10 do    repeat        if i == 5 then            break        end        print(i)    until trueend\n流程控制if 语句if (condition)\nthen\n    statements\nend\nif…else 语句if (condition)\nthen\n    statements\nelse\n    statements\nend\n函数Lua的函数定义格式如下\nscope function name(arg1,arg2,...)\n    statements\n    return result\n\nscope 定义函数作用域\nname  函数名\narg   参数\nstatements  函数内部语句\nreturn  返回值\n多返回值Lua可以一次返回多个值 同样需要多个参数来接收\ns,e = string.find(&quot;www.hinote.ga&quot;,&quot;hinote&quot;)print(s,e)\n可变参数将Lua的参数放入一个叫arg的表中 #arg计算有多少个arg的值用”…”来表示函数有可变参数\nfunction args(...)    local arg = &#123;...&#125;    print(#arg)end\nLua 运算符设定A=10, B=20\n算数运算符\n\n\n操作符\n描述\n实例\n\n\n\n\n+\n加法\nA+B=30\n\n\n-\n减法\nA-B=-10\n\n\n*\n乘法\nA*B=200\n\n\n/\n除法\nB/A=2\n\n\n%\n取余\nB%A=0\n\n\n^\n乘幂\nA^2=100\n\n\n\n关系运算符\n\n\n操作符\n描述\n实例\n\n\n\n\n==\n等于\n(A == B) 为 false\n\n\n~=\n不等于\n(A ~= B) 为 true\n\n\n&gt;\n大于\n(A &gt; B) 为 false\n\n\n&lt;\n小于\n(A &lt; B) 为 true\n\n\n>=\n大于等于\n(A &gt;= B) 返回 false\n\n\n&lt;=\n小于等于\n(A &lt;= B) 返回 true\n\n\n\n逻辑运算符A=true, B=false\n\n\n\n操作符\n描述\n实例\n\n\n\n\nand\n逻辑与操作符\n(A and B) 为 false\n\n\nor\n逻辑或操作符\n(A or B) 为 true\n\n\nnot\n逻辑非操作符\nnot(A and B) 为 true\n\n\n\n其他运算符A=”Hello”, B=”World”|操作符|描述|实例||-|-|-||..|连接两个字符串|A..B 返回 “Hello World”||#|返回字符串或表的长度|#A 返回 5|\n算数优先级^\nnot    - (unary)\n*      /\n+      -\n..\n&lt;      &gt;      &lt;=     &gt;=     ~=     ==\nand\nor\n字符串字符串常用方法\n\n\n方法\n用途\n\n\n\n\nstring.upper\n字符串转为全大写\n\n\nstring.lower\n字符串转为全小写\n\n\nstring.gsub\n字符串替换\n\n\nstring.find\n字符串查找\n\n\nstring.reverse\n字符串反转\n\n\nstring.format\n格式化字符串\n\n\nstring.char\n将ascii转为字符串\n\n\nstring.byte\n将字符串转为ascii\n\n\nstring.len\n计算字符串长度\n\n\nstring.rep\n返回字符串的N个拷贝\n\n\n..\n连接两个字符串\n\n\nstring.gmatch\n迭代器的方式匹配正则表达式\n\n\nstring.match\n只寻找源字符串的第一个匹配\n\n\n\n数组一维数组arr = &#123;&quot;Hello&quot;, &quot;World&quot;&#125;\n多维数组arr = &#123;&quot;Hello&quot;,&#123;&quot;Hello&quot;,&quot;Lua&quot;&#125;&#125;\n迭代器泛型for迭代器泛型 for 在自己内部保存迭代函数，实际上它保存三个值：迭代函数、状态常量、控制变量。\n泛型 for 迭代器提供了集合的 key/value 对，语法格式如下：for k, v in pairs(t) do    print(k, v)end\n下面我们看看泛型 for 的执行过程：\n\n首先，初始化，计算in后面表达式的值，表达式应该返回泛型 for 需要的三个值：迭代函数、状态常量、控制变量；与多值赋值一样，如果表达式返回的结果个数不足三个会自动用nil补足，多出部分会被忽略。\n第二，将状态常量和控制变量作为参数调用迭代函数（注意：对于for结构来说，状态常量没有用处，仅仅在初始化时获取他的值并传递给迭代函数）。\n第三，将迭代函数返回的值赋给变量列表。\n第四，如果返回的第一个值为nil循环结束，否则执行循环体。\n第五，回到第二步再次调用迭代函数\n\n无状态迭代器无状态的迭代器是指不保留任何状态的迭代器，因此在循环中我们可以利用无状态迭代器避免创建闭包花费额外的代价。\n每一次迭代，迭代函数都是用两个变量（状态常量和控制变量）的值作为参数被调用，一个无状态的迭代器只利用这两个值可以获取下一个元素。这种无状态迭代器的典型的简单的例子是ipairs，它遍历数组的每一个元素\n多状态迭代器很多情况下，迭代器需要保存多个状态信息而不是简单的状态常量和控制变量，最简单的方法是使用闭包，还有一种方法就是将所有的状态信息封装到table内，将table作为迭代器的状态常量，因为这种情况下可以将所有的信息存放在table内，所以迭代函数通常不需要第二个参数。\ntable (表)table是Lua的一种数据结构来帮助我们创建不同的数据类型Lua也是通过table来解决模块、包、和对象的\n表的常用操作\n\n\n方法\n用途\n\n\n\n\ntable.concat\n类似于python字符串的join\n\n\ntable.insert\n在数组的指定位置插入一个值\n\n\ntable.remove\n移除数组中的一个值\n\n\ntable.sort\n对给定的table升序排序\n\n\n\n模块与包Lua5.1开始 加入了标准的模块管理机制Lua的模块是由变量和函数等元素组成的table, 最后返回这个table就可以了test.luamodule = &#123;&#125;function module.max(x,y)    if (x &gt; y) then        return x    else        return y    endendreturn module\n引入也很简单require(&quot;test&quot;)module.max(2,3)         --&gt; 引入的是模块return的名字test = require(&quot;test&quot;)  --&gt; 也可以这样将模块重命名test.max(2,3)\n模块加载路径Lua内使用package.path可以看到默认的搜索路径如果找不到lua模块 则会去调用C库 使用package.cpath可以查看\n也可以使用环境变量LUA_PATH来设置lua的搜索路径C库的环境变量是LUA_CPATH\n元表 (Matatable)感觉像是python类的魔法方法，可以自己修改table的各种行为，比如两个table相加，又有点像JavaScript的原型链\n高级话题 以后再研究\n协程Lua 协同程序(coroutine)与线程比较类似：拥有独立的堆栈，独立的局部变量，独立的指令指针，同时又与其它协同程序共享全局变量和其它大部分东西。\n基本语法\n\n\n方法\n描述\n\n\n\n\ncoroutine.create\n创建coroutine,参数是一个函数\n\n\ncoroutine.resume\n重启coroutine，和create配合使用\n\n\ncoroutine.yield\n挂起coroutine，将coroutine设置为挂起状态\n\n\ncoroutine.status\n查看coroutine的状态\n\n\ncoroutine.wrap\n也是创建一个coroutine\n\n\ncoroutine.running\n返回正在运行的coroutine\n\n\n\n高级话题 用到的时候再研究\n文件IOLua的IO库用于读取和处理文件 分为简单模式和完全模式\n\n简单模式 拥有一个当前输入和输出文件，并且提供针对文件的相关操作\n它以一种面对对象的形式，将所有的文件操作定义为文件句柄的方法\n\n打开文件操作语句如下file = io.open (filename [, mode])\n其中mode和python的文件打开方式一摸一样 不再多说\n简单模式读取文件内容file = io.open(&quot;/etc/passwd&quot;,&quot;r&quot;)io.input(file)      --&gt; 设置输入文件为fileio.read(10)         --&gt; 读取10个字节 默认是读取一行io.close(file)      --&gt; 关闭文件\n写入文件内容file = io.open(&quot;/tmp/lua&quot;,&quot;a&quot;)  --&gt; 如果是w模式 文件存在则会清空文件io.output(file)io.write(&quot;Hello\\n&quot;)io.close(file)\nio.read有多种参数\n\n\n模式\n描述\n\n\n\n\n“*n”\n读取一个数字并返回它\n\n\n“*a”\n读取全部内容\n\n\n“*l”\n读取下一行 默认行为\n\n\nnumber\n按照字节读取\n\n\n\n其他的io方法\n\n\n方法\n描述\n\n\n\n\nio.tmpfile\n返回一个临时文件 “a”模式打开\n\n\nio.type(file)\n检测obj是否是个可用的文件句柄\n\n\nio.flush\n向文件写入缓冲中的所有数据\n\n\nio.lines\n返回一个迭代函数 每次调用返回一行\n\n\n\n完全模式通常我们会在同一时间处理多个文件 简单模式就不够用了\n文件读写f1 = io.open(&quot;/etc/passwd&quot;,&quot;r&quot;)f1:read()     --&gt; 没看错 就是:  f1:close()f2 = io.open(&quot;/tmp/lua&quot;,&quot;w&quot;)f2:write(&quot;Hi!\\n&quot;)f2:close()\n其他方法\n\n\n模式\n描述\n\n\n\n\nfile:seek\n获取和设置当前文件指针\n\n\nfile:flush\n将缓冲区输入写入到文件\n\n\n\n错误处理assert 和 errorfunction add(a,b)   assert(type(a) == &quot;number&quot;, &quot;a 不是一个数字&quot;)   assert(type(b) == &quot;number&quot;, &quot;b 不是一个数字&quot;)   return a+bendadd(10)\n实例中assert首先检查第一个参数，若没问题，assert不做任何事情；否则，assert以第二个参数作为错误信息抛出。function add(a,b)   error(&quot;错误了&quot;)   return a+bendadd(10)\nerror更像是python的raise 主动抛出一个异常\npcall 和 xpcallLua中处理错误，可以使用函数pcall来包装需要执行的代码。\npcall传入需要运行的函数和函数的参数，如果函数运行的有错误就返回false 否则返回true 所以可以用if进行判断和处理\npcall(function(i) print(i) end, 33)pcall(function(i) print(i) error(&quot;error&quot;) end, 33)\nxpcall可以接收一个错误处理函数来查看错误发生时的调用栈\nxpcall(function(i) print(i) error(&apos;error..&apos;) end, function() print(debug.traceback()) end, 33)\nxpacall的第二个参数是传入了一个错误处理函数 可以在这个函数中使用debug库获取错误的额外信息了\n\ndebug.debug 提供一个Lua提示符 让用户来检查错误的原因\ndebug.traceback 根据调用栈来构建一个扩展的错误信息\n\ndebug 调试\n未完待续。。。\n\n垃圾回收\n未完待续。。。\n\n面向对象\n未完待续。。。\n\n","categories":["Lua"],"tags":["Lua"]},{"title":"Redis集合类型","url":"/2016/05/24/2016/redis%E9%9B%86%E5%90%88%E7%B1%BB%E5%9E%8B/","content":"简介\n集合和列表有很多相似的地方 但是很容易将他们区分开 集合的元素有唯一性 而且元素是无序的。集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算\n\n环境\n\n\n软件名称\n版本号\n下载地址\n\n\n\n\nredis\n3.2.0\n点击下载\n\n\n\n步骤常用命令\n下面将详细说明操作Redis集合类型的相关命令\n\n增加和删除元素SADD key member [member ...]        # 向一个集合添加元素SREM key member [member ...]        # 从一个集合删除元素\n127.0.0.1:6379&gt; SADD num 1 2 2 3\n(integer) 3\n127.0.0.1:6379&gt; SREM num 1 1 2\n(integer) 2\n127.0.0.1:6379&gt;\n\nSADD执行成功会返回添加成功的个数 因为2相同 所以只有一个被添加 SREM也同样 返回被成功删除的个数\n获取集合内所有元素SMEMBERS num            # 获取集合内所有元素\n127.0.0.1:6379&gt; SMEMBERS num\n1) &quot;3&quot;\n127.0.0.1:6379&gt; SADD num 2 2\n(integer) 1\n127.0.0.1:6379&gt; SMEMBERS num\n1) &quot;2&quot;\n2) &quot;3&quot;\n\n可以看到 num中只剩下3了 而且添加两个元素2 最后num中也只有一个2\n判断元素是否在集合中SISMEMBER num 2         # 判断元素是否在集合中\n127.0.0.1:6379&gt; SISMEMBER num 2\n(integer) 1\n127.0.0.1:6379&gt; SISMEMBER num 1\n(integer) 0\n127.0.0.1:6379&gt;\n\n如果命中了 则返回1 否则返回0\n集合运算SDIFF key1 [key2 ...]           # 计算差集SINTER key1 [key2 ...]          # 计算交集SUNION key1 [key2 ...]          # 计算并集\nSDIFF计算多个集合的差集 会想计算key1与key2的差集 然后将这个结果与key3继续计算 交集并集也同理\n\n127.0.0.1:6379&gt; SADD num1 1 2 3\n(integer) 3\n127.0.0.1:6379&gt; SADD num2 2 3 4\n(integer) 3\n127.0.0.1:6379&gt; SDIFF num1 num2\n1) &quot;1&quot;\n127.0.0.1:6379&gt; SDIFF num2 num1\n1) &quot;4&quot;\n127.0.0.1:6379&gt;\n\nnum1与num2的差集运算表示属于num1 且不属于num2的元素 反之亦然\n\n127.0.0.1:6379&gt; SINTER num1 num2\n1) &quot;2&quot;\n2) &quot;3&quot;\n127.0.0.1:6379&gt;\n\nSINTER 计算num1和num2的交集 \n\n127.0.0.1:6379&gt; SUNION num1 num2\n1) &quot;1&quot;\n2) &quot;2&quot;\n3) &quot;3&quot;\n4) &quot;4&quot;\n127.0.0.1:6379\n\nSUNION 计算num1和num2的合集\n获取集合中元素个数SCARD key               # 获取集合中元素个数\n127.0.0.1:6379&gt; SMEMBERS num1\n1) &quot;1&quot;\n2) &quot;2&quot;\n3) &quot;3&quot;\n127.0.0.1:6379&gt; SCARD num1\n(integer) 3\n127.0.0.1:6379&gt;\n\nSCARD 返回一个集合中元素个数\n存储集合运算后的结果SDIFFSTORE dest key [key …]          # 将差集运算的结果保存为destSINTERSTORE dest key [key …]         # 将交集运算的结果保存为destSUNIONSTORE dest key [key …]         # 将并集运算的结果保存为dest\n127.0.0.1:6379&gt; SUNIONSTORE all num1 num2\n(integer) 4\n127.0.0.1:6379&gt; SMEMBERS all\n1) &quot;1&quot;\n2) &quot;2&quot;\n3) &quot;3&quot;\n4) &quot;4&quot;\n127.0.0.1:6379&gt;\n\n和SDIFF唯一区别就是不将结果返回 而是将结果保存为新的集合 只返回新集合元素个数 其余两个道理相同\n随机获得集合中的元素SRANDMEMBER key [count]         # 随机获得集合中的元素\ncount非必选项 用于每次获取多少个随机元素 count的正负体现的意义也不同 \ncount &gt; 0 时 随机获取count个元素 但是元素不会出现重复获取的情况 也就是都是唯一的\ncount &lt; 0 时 随机获取count的绝对值个元素 元素可能被重复获取 \n如果count的值大于集合中的元素个数 则SRANDMEMBER会返回集合中的全部元素\n\n127.0.0.1:6379&gt; SRANDMEMBER all \n&quot;1&quot;\n127.0.0.1:6379&gt; SRANDMEMBER all \n&quot;2&quot;\n127.0.0.1:6379&gt; SRANDMEMBER all 6\n1) &quot;1&quot;\n2) &quot;2&quot;\n3) &quot;3&quot;\n4) &quot;4&quot;\n127.0.0.1:6379&gt; SRANDMEMBER all -6\n1) &quot;2&quot;\n2) &quot;1&quot;\n3) &quot;1&quot;\n4) &quot;3&quot;\n5) &quot;2&quot;\n6) &quot;2&quot;\n127.0.0.1:6379&gt;\n从集合中弹出一个元素SPOP key            # 从集合中弹出一个元素\n127.0.0.1:6379&gt; SPOP all\n&quot;4&quot;\n127.0.0.1:6379&gt; SMEMBERS all\n1) &quot;1&quot;\n2) &quot;2&quot;\n3) &quot;3&quot;\n127.0.0.1:6379&gt; SPOP all\n&quot;1&quot;\n127.0.0.1:6379&gt; SMEMBERS all\n1) &quot;2&quot;\n2) &quot;3&quot;\n127.0.0.1:6379&gt;\n\n由于集合是无序的 所以SPOP会随机弹出一个值\n附录\n命令总结\n\nSADD key member [member ...]            向一个集合添加元素\nSREM key member [member ...]            从一个集合删除元素\nSMEMBERS num                            获取集合内所有元素\nSISMEMBER num 2                         判断元素是否在集合中\nSDIFF key1 [key2 ...]                   计算差集\nSINTER key1 [key2 ...]                  计算交集\nSUNION key1 [key2 ...]                  计算并集\nSCARD key                               获取集合中元素个数\nSDIFFSTORE dest key [key …]             将差集运算的结果保存为dest\nSINTERSTORE dest key [key …]            将交集运算的结果保存为dest\nSUNIONSTORE dest key [key …]            将并集运算的结果保存为dest\nSRANDMEMBER key [count]                 随机获得集合中的元素\nSPOP key                                从集合中弹出一个元素\n","categories":["Redis"]},{"title":"Bottle 轻量级Web框架","url":"/2018/07/12/2018/Bottle%20%E8%BD%BB%E9%87%8F%E7%BA%A7Web%E6%A1%86%E6%9E%B6/","content":"简介\nBottle 是一个快速、简单、轻量级的 Python Web 框架，Bottle 作为一个单独的文件模块分发，而且除了标准库没有任何第三方依赖，但是麻雀虽小五脏俱全，所以非常适合第一次接触 Python Web 开发的新手入门学习使用。Bottle 支持URL映射、模板引擎、访问表单、文件上传等功能。内建 HTTP 开发服务器，而且还支持 Paste, Gevent, gunicorn 等高性能 WSGI 服务器。本文通过阅读官方文档 并结合自己的实际测试编写而成。\n\n使用快速安装体验Bottle 的安装非常简单，可以通过 easy_install bottle 或者使用 pip install bottle 来安装，甚至可以直接下载 Bottle.py (最新版，非稳定版) 放到程序目录下来使用。Bottle 可以运行在 Python2.5+ 和 Python3.x 上。\n目前 Bottle 稳定版为 0.12.13，开发版为 0.13-dev。点此打开Github地址\n看一个简单的例子：import bottleapp = bottle.Bottle()@app.route('/hello/&lt;name&gt;')def index(name):    return bottle.template('&lt;b&gt;Hello &#123;&#123;name&#125;&#125;&lt;/b&gt;!', name=name)app.run(host=\"localhost\", port=8080)\n启动脚本：\n(python3) root@ubuntu:~# python demo.py\nBottle v0.12.13 server starting up (using WSGIRefServer())...\nListening on http://localhost:8080/\nHit Ctrl-C to quit.\n使用浏览器或者 curl 测试：\nroot@ubuntu:~# curl http://127.0.0.1:8080/hello/yunfwe        \n&lt;b&gt;Hello yunfwe&lt;/b&gt;!\n如果学过 Flask 框架，可以发现它们的语法非常相似。\n教程安装Bottle 不依赖任何第三方库，所以可以直接将 bottle.py 下载到项目目录中使用，但这通常下载的是最新开发版。\n$ wget https://github.com/defnull/bottle/raw/master/bottle.py\n如果更喜欢稳定版，可以在 PyPi 上获取，推荐使用 pip 包管理器来安装，或者使用 easy_install 也可以。\n$ sudo pip install bottle\n$ sudo easy_install bottle\nBottle 支持 Python2.5 或者更高版本才能正常运行，如果你没有权限在系统范围内安装，可以使用 Python虚拟环境 virtualenv。\nHello World安装成功后，从最简单的 “Hello World” 示例开始吧！\nimport bottleapp = bottle.Bottle()@app.route('/hello')def hello():    return 'Hello World!'if __name__ == '__main__':    app.run(host='localhost', port=8080, debug=True, reloader=True)\n运行此代码，访问 http://localhost:8080/hello，将在浏览器中看到 “Hello World!”，下面是它的工作原理：\n使用 app.route() 装饰器装饰的函数 hello()，与 app.route() 传入的路径参数 /hello 做绑定，当浏览器请求 URL 时，如果匹配了这个路径，将调用这个路径所绑定的函数，并将函数的返回值发送回浏览器，就是这么简单。路由是这个框架最重要的概念，你可以根据需求定义任何数量的路由。\n最后一行的 app.run() 会启动一个内置的开发服务器，它根据传递的参数在 localhost 上的 8080 端口启动服务，直到你通过 Ctrl-C 停止这个服务。debug=True 会以调试模式启动服务，在开发过程中是非常有用，但是在程序发布后应该是关闭的。reloader=True 也是在开发时非常有用的一个小技巧，Bottle 会自动检测当前脚本是否更新，如果有更新会自动帮你重新运行程序，这样就免去每次改了代码，需要手动停止程序再重新启动程序的过程，这个配置在生产环境也应该是关闭的。\n请求路由上一章中，我们只构建了一个只有一条路由，而且非常简单的 Web 应用程序。多个 app.route() 都可以绑定到通一个回调函数上，看下面的例子：\n@app.route('/')@app.route('/hello/&lt;name&gt;')def hello(name='yunfwe'):    return bottle.template('Hello &#123;&#123;name&#125;&#125;!\\n', name=name)\n浏览器访问：\nroot@ubuntu:~# curl http://127.0.0.1:8080/\nHello yunfwe!\nroot@ubuntu:~# curl http://127.0.0.1:8080/hello/bottle\nHello bottle!\n这个示例告诉我们两件事：可以将多个路由绑定到同一个函数上，并且可以向URL添加通配符，并通过关键字参数访问它们。\n动态路由包含通配符的路由称为动态路由，并且可以匹配满足条件的所有URL。简单的通配符由尖括号中的名称组成，例如：&lt;name&gt;。路由 /hello/&lt;name&gt; 会匹配 /hello/alice 以及 /hello/bob 等，如果遇到了下一个斜杆 / 则不会匹配，例如：/hello/mr/smith。\n每个通配符都将匹配到的部分作为关键字参数传递给路由绑定的回调函数，所以回调函数应该提供参数接收它们，否则将会抛出异常。通过动态路由，可以设计出漂亮而且有意义的URL，下面是一些示例：\n@app.route('/wiki/&lt;pagename&gt;')def show_wiki_page(pagename):    pass@app.route('/&lt;action&gt;/&lt;user&gt;')def user_api(action, user):    pass\n过滤器还可以使用过滤器来定义更具体的通配符，在将URL匹配到的部分传递给回调函数前通过过滤器来转换它们。\n当前内置的几个过滤器：\n\n:int 仅匹配正整数，并将值转为整数后传递给回调\n:float 类似于 :int，将值转为浮点数后传递给回调\n:path 以非贪婪的方式匹配包含斜杠字符在内的所有字符，并且可以用于匹配多个路径段\n:re[:exp] 允许使用自定义的正则表达式匹配，匹配的值不会被修改或者转换。\n\n示例：@app.route('/int/&lt;val:int&gt;')def test_int(val):    return str(val) + '\\n'@app.route('/float/&lt;val:float&gt;')def test_float(val):    return str(val) + '\\n'@app.route('/path/&lt;val:path&gt;')def test_path(val):    return str(val) + '\\n'@app.route('/re/&lt;val:re:[a-z]+&gt;')def test_re(val):    return str(val) + '\\n'\n结果：\nroot@ubuntu:~# curl http://127.0.0.1:8080/int/123\n123\nroot@ubuntu:~# curl http://127.0.0.1:8080/float/1.1\n1.1\nroot@ubuntu:~# curl http://127.0.0.1:8080/path/usr/local/\nusr/local/\nroot@ubuntu:~# curl http://127.0.0.1:8080/re/abcdef\nabcdef\nHTTP请求方法HTTP协议为不同的任务定义了几种请求方法，GET 方法是 Bottle 路由的默认方法，如果需要处理其他方法，比如 POST, PUT, DELETE 等方法，需要添加一个 method 参数到 app.route() 装饰器上，或者使用 app.get(), app.post(), app.put(), app.delete() 这四个备选装饰器。\nPOST 方法常用于 HTML 表单提交，下面示例演示如何使用 POST 处理登陆表单。\nimport bottleapp = bottle.Bottle()# 或者使用 @app.route('/login')@app.get('/login')  def login():    return '''        &lt;form action=\"/login\" method=\"post\"&gt;            Username: &lt;input name=\"username\" type=\"text\" /&gt;            Password: &lt;input name=\"password\" type=\"password\" /&gt;            &lt;input value=\"Login\" type=\"submit\" /&gt;        &lt;/form&gt;'''# 或者使用 @app.route('/login', method='POST')@app.post('/login') def do_login():    username = bottle.request.forms.get('username')    password = bottle.request.forms.get('password')    if username == 'root' and password == '123456':        return \"&lt;p&gt;Your login information was correct.&lt;/p&gt;\\n\"    else:        return \"&lt;p&gt;Login failed.&lt;/p&gt;\\n\"if __name__ == '__main__':    app.run(host='localhost', port=8080, debug=True, reloader=True)\n使用浏览器或者 curl 验证结果：\nroot@ubuntu:~# curl http://127.0.0.1:8080/login -X GET\n        &lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt;\n            Username: &lt;input name=&quot;username&quot; type=&quot;text&quot; /&gt;\n            Password: &lt;input name=&quot;password&quot; type=&quot;password&quot; /&gt;\n            &lt;input value=&quot;Login&quot; type=&quot;submit&quot; /&gt;\n        &lt;/form&gt;\nroot@ubuntu:~# curl http://127.0.0.1:8080/login -X POST --data &apos;username=root&amp;password=654321&apos;\n&lt;p&gt;Login failed.&lt;/p&gt;\nroot@ubuntu:~# curl http://127.0.0.1:8080/login -X POST --data &apos;username=root&amp;password=123456&apos;\n&lt;p&gt;Your login information was correct.&lt;/p&gt;\n或者还可以在一个回调函数里同时处理 GET 和 POST 请求，需要传给 method 参数一个列表，将需要的 HTTP 方法加入到列表中 例如：method=[&#39;GET&#39;, &#39;POST&#39;]，然后在回调函数中通过 bottle.request.method 来判断当前请求的方法：\nimport bottleapp = bottle.Bottle()@app.route('/login', method=['GET', 'POST'])def login():    if bottle.request.method == 'GET':        return '''        &lt;form action=\"/login\" method=\"post\"&gt;            Username: &lt;input name=\"username\" type=\"text\" /&gt;            Password: &lt;input name=\"password\" type=\"password\" /&gt;            &lt;input value=\"Login\" type=\"submit\" /&gt;        &lt;/form&gt;'''    if bottle.request.method == 'POST':        username = bottle.request.forms.get('username')        password = bottle.request.forms.get('password')        if username == 'root' and password == '123456':            return \"&lt;p&gt;Your login information was correct.&lt;/p&gt;\\n\"        else:            return \"&lt;p&gt;Login failed.&lt;/p&gt;\\n\"if __name__ == '__main__':    app.run(host='localhost', port=8080, debug=True, reloader=True)\n特殊方法：HEAD 和 ANY\nHEAD 方法和 GET 方法类似，但是 HEAD 方法并不返回消息体，只返回 HTTP 协议头部信息。HEAD 方法常用来测试链接的有效性。当对 Bottle 的 GET 路由使用 HEAD 方法访问时，Bottle 会正常按照 GET 请求处理，但是并不会返回消息体（回调函数的返回结果）。\nANY 方法会匹配所有请求方法，但也只会在没有定义其他更具体的路由时。这对于将请求重定向到更具体的子应用程序的代理路由很有用。\n显式路由配置如果不想使用装饰器的方式来定义路由，可以显式的将某个函数传递给某个路由，下面看一个简单的例子：\nimport bottleapp = bottle.Bottle()def hello():    return 'Hello World!'app.route('/', 'GET', hello)\n或者使用一个工厂函数：\nimport bottledef hello():    return 'Hello World!'def setup_routing(app, urls):    for u in urls:        app.route(*u)urls = [    ('/', 'GET', hello),]app = bottle.Bottle()setup_routing(app, urls)\n错误页面如果出现任何问题，Bottle 会显示一个包含错误信息但非常简单的错误页面，可以通过 app.error() 装饰器来覆盖特定 HTTP 状态码的默认页面：\n@app.error(404)def error404(error):    return 'Nothing here, Sorry!\\nError Message: %s\\n' % str(error)\n当访问一个未定义的页面时：\nroot@ubuntu:~# curl http://127.0.0.1:8080/abc\nNothing here, Sorry!\nError Message: (404, &quot;Not found: &apos;/abc&apos;&quot;)\n还可以捕捉 abort() 主动抛出的错误：\n@app.route('/abort')def test_abort():    bottle.abort(500, ' Server error')@app.error(500)def error500(error):    return 'Error Message: %s\\n' % str(error)\nroot@ubuntu:~# curl http://127.0.0.1:8080/abort\nError Message: (500, &apos; Server error&apos;)\n生成响应在存 WSGI 中，一个标准的 WSGI 应用必须返回可迭代的字符串。而 Bottle 更灵活，支持多种类型，并且会自动添加一个合适的 Content-Type 头部。下面是路由绑定的回调函数允许返回的类型列表：\n\ndict：返回字典类型的数据会自动转换为 JSON 字符串，并设置 Content-Type 类型为 application/json。\n空字符串，False，None或其他非真值：会产生一个空输出，并将 Content-Length 设置为 0。\nUnicode：会使用 Content-Type 中指定的编码（默认UTF-8）自动编码，然后将其视为普通字符串。\nByte：字节类型，Bottle 将整个字节串作为一个整体返回，并且根据长度设置 Content-Length。\nHTTPError或HTTPResponse：返回一个 HTTPError 或 HTTPResponse 的实例，如果是 HTTPError，则会运行错误处理程序\n文件对象：具有 .read() 方法的所有内容都被视为文件对象，并传递给定义在 WSGI 服务框架中的 wsgi.file_wrapper 可调用对象。一些 WSGI 服务器可以利用更优的系统调用(sendfile) 来高效的传输文件。Content-Length 或 Content-Type 都不会自动设置。\n迭代器和生成器：只要是可以产生或迭代 Unicode, Byte, HTTPError, HTTPResponse 类型，就可以在回调函数中使用。\n\n下面看一些示例：\n@app.route('/dict')def test_dict():    return &#123;'msg':'hello bottle'&#125;@app.route('/false')def test_false():    return False@app.route('/unicode')def test_unicode():    return u'喵喵喵'@app.route('/byte')def test_byte():    return b'abcabc'@app.route('/response')def test_response():    return bottle.HTTPResponse(body='hello bottle', status=200)@app.route('/file')def test_file():    return open('/etc/issue','rb')@app.route('/generators')def test_generators():    for i in range(10):        yield str(i)\n结果：\nroot@ubuntu:~# curl http://127.0.0.1:8080/dict\n{&quot;msg&quot;: &quot;hello bottle&quot;}\nroot@ubuntu:~# curl http://127.0.0.1:8080/false\nroot@ubuntu:~# curl http://127.0.0.1:8080/unicode\n喵喵喵\nroot@ubuntu:~# curl http://127.0.0.1:8080/byte\nabcabc\nabcabcroot@ubuntu:~# curl http://127.0.0.1:8080/response\nhello bottle\nroot@ubuntu:~# curl http://127.0.0.1:8080/file\nUbuntu 16.04.5 LTS \\n \\l\nroot@ubuntu:~# curl http://127.0.0.1:8080/generators\n0123456789\n更改默认编码Bottle 使用 Content-Type 标头的字符集参数来决定如何对 Unicode 字符串进行编码。此标头默认为 text/html;charset=UTF8，并且可以使用 bottle.response.content_type 来进行修改。例如：\n@app.route('/gbk')def get_latin():    bottle.response.content_type = 'text/html; charset=gbk'    return u'这些文字将使用gbk编码'\n处理静态文件Bottle 没有像 Flask 一样默认提供了静态文件路由，必须手动添加路由和回调来控制要提供的文件。虽然你可以直接返回一个文件对象，Bottle 提供的 static_file() 以一种安全和方便的方式提供文件访问，默认会自动检测文件拓展类型，并提供合适的 mimetype。浏览器对于文本文件，图像文件等可能会直接浏览而不是下载，这时可以使用 download=True 来使浏览器强制下载文件。如果想指定客户端拿到的文件名，可以使用 download=filename，客户端将自动将文件保存为传给 download 的文件名。\n@app.route('/static/filepath:path')def server_static(filepath):    return bottle.static_file(filepath, root='/your/static/files/path')\n指定静态文件的根目录时一定要小心，如果使用了相对路径，很有可能并不是你想象得那样。可以试试使用 os.path.dirname(os.path.abspath(__file__)) 巧妙的获取脚本所在目录。\nHTTP错误和重定向调用 bottle.abort() 函数是生成 HTTP 错误页面的快捷方法。\n@app.route('/restricted')def restricted():    bottle.abort(401, \"Sorry, access denied.\")\n如果将客户端重定向到其他URL，可以使用 bottle.redirect()，它会发送 303 See Other，并且添加 Location 头部来告诉客户端新的地址在哪。你还可以提供不同的 HTTP 状态码作为重定向函数的第二个参数。\n@app.route('/old')def old():    bottle.redirect(\"/new\")@app.route('/new')def new():    return 'New page.'\nroot@ubuntu:~# curl http://127.0.0.1:8080/old -L\nNew page.\nresponse 对象响应的元数据，比如 HTTP 状态码、响应标头 还有 Cookie 存储在 bottle.response 对象中。你可以直接或使用预定义的方法操作这些元数据，直到它们被传输到浏览器。这里介绍最常见的用例和功能。\n状态码HTTP 状态码控制浏览器的行为，默认值为 200 OK。可以通过设置 bottle.response.status 来更改状态吗，在大多数情况下不需要手动设置，但使用 abort() 或者返回 HTTPResponse 实例时需要提供状态码。\n响应头\n修改响应头，比如添加 Cache-Control 或者修改 Content-Type 可以通过 bottle.response.set_header() 和 bottle.response.add_header() 来修改。它们接受两个参数，一个标头名，一个值。这两个方法的区别是，set_header() 会覆盖已有的标头名，而 add_header() 则会继续添加一个即使已存在的标头。\nCookieCookie 是一种用户客户端跟踪技术，Bottle 中可以通过 bottle.request.get_cookie() 和 bottle.response.set_cookie() 获取和设置 Cookie。\n@app.route('/cookie')def test_cookie():    if bottle.request.get_cookie(\"visited\"):        return \"Welcome back! Nice to see you again\\n\"    else:        bottle.response.set_cookie(\"visited\", \"yes\")        return \"Hello there! Nice to meet you\\n\"\n使用 curl 测试访问，第一次将 Cookie 保存到文件，第二次带上 Cookie 去访问：\nroot@ubuntu:~# curl http://127.0.0.1:8080/cookie -c cookie.txt\nHello there! Nice to meet you\nroot@ubuntu:~# curl http://127.0.0.1:8080/cookie -b cookie.txt\nWelcome back! Nice to see you again\nset_cookie() 方法接受许多其他关键字参数来控制 Cookie 的生存期和行为，这里介绍一些常用的设置：\n\nmax_age：表示 Cookie 创建后多久过期，单位为秒。如果为 0，表示立即过期，为 -1 表示关闭窗口后 Cookie 就过期。\nexpires：指定一个 Cookie 的过期时间点，值是 UNIX 时间戳，现在已被 max_age 取代。\ndomain：允许读取 Cookie 的域，可以使多个web服务器共享 Cookie。\npath：指定与 Cookie 关联在一起的网页。默认情况下 Cookie 会与创建它的页面，以及该页面下的子页面关联。\nsecure：限制 Cookie 使用 HTTPS 连接，默认不限制。\nhttponly：限制客户端 JavaScript 读取 Cookie。\n\n如果没有设置 Cookie 有效期，则默认在页面会话结束后立即过期，在使用 Cookie 时应该考虑下面这些问题：\n\n在大多数浏览器中，Cookie 的大小限制为 4K 的文本\n有些用户将浏览器设置为不接受 Cookie。\nCookie 存储在客户端，不以任何方式加密，攻击者可能通过 XSS 漏洞窃取用户的 Cookie。\nCookie 很容易伪造，不要过于相信 Cookie。\n\nCookie 签名\n如上所述，恶意客户很容易伪造 Cookie，Bottle 可以对 Cookie 进行签名加密，以防止这种伪造。你只需在 set_cookie() 和 get_cookie() 时通过 secret 参数提供密钥签名。如果 cookie 未签名，或者签名不匹配，get_cookie() 将返回 None：\n@app.route('/cookie')def test_cookie():    if bottle.request.get_cookie(\"visited\", secret='qweasd'):        return \"Welcome back! Nice to see you again\\n\"    else:        bottle.response.set_cookie(\"visited\", \"yes\", secret='qweasd')        return \"Hello there! Nice to meet you\\n\"\n接下来用 curl 验证结果\nroot@ubuntu:~# cat cookie.txt \n# Netscape HTTP Cookie File\n# http://curl.haxx.se/docs/http-cookies.html\n# This file was generated by libcurl! Edit at your own risk.\n\n127.0.0.1    FALSE    /    FALSE    0    visited    yes\nroot@ubuntu:~# curl http://127.0.0.1:8080/cookie -b cookie.txt\nHello there! Nice to meet you\nroot@ubuntu:~# curl http://127.0.0.1:8080/cookie -c cookie.txt\nHello there! Nice to meet you\nroot@ubuntu:~# curl http://127.0.0.1:8080/cookie -b cookie.txt\nWelcome back! Nice to see you again\nroot@ubuntu:~# cat cookie.txt \n# Netscape HTTP Cookie File\n# http://curl.haxx.se/docs/http-cookies.html\n# This file was generated by libcurl! Edit at your own risk.\n\n127.0.0.1    FALSE    /    FALSE    0    visited    &quot;!7Bk4nXY6kRKp8QWKVN4ZWQ==?gASVEwAAAAAAAACMB3Zpc2l0ZWSUjAN5ZXOUhpQu&quot;\n可以看到，之前的 cookie.txt 文件里，visited 字段的值是明文的，带着旧的 Cookie 访问服务，服务已经不承认旧的 Cookie 了。之后重新保存新的 Cookie，才可以继续使用。而新的 cookie.txt 文件里，visited 字段的值已经是加密后的。\nCookie 将所有信息都保存到了客户端，这样是极不安全的，对应的有比较安全的 Session 技术，将用户信息保存在服务端，通过在 Cookie 中保存一个 SessionID，然后使用 SessionID 来获取用户信息。可惜 Bottle 并没有实现 Session，想在 Bottle 中使用 Session 技术，还需要利用第三方实现。\n请求数据Cookie, HTTP 标头, HTML &lt;form&gt; 字段和其他请求数据可以通过全局的 request 对象获取。即使在多线程多客户端连接的环境，这个特殊的对象也始终引用当前请求。\n该对象是 BaseRequest 的子类，它有丰富的访问数据的 API，我们这里介绍最常用的。\nFormsDictBottle 使用一种特殊类型的字典来存储表单数据和 Cookie。FormsDict 的行为就像一个普通字典，但是有一些额外的功能，使你使用的更方便。\n属性访问：字典中的所有值都可以作为属性访问，这些虚拟属性返回 Unicode 字符串，即使该值丢失或者 Unicode 解码失败。这种情况下，字符串为空，但仍存在：\nname = bottle.request.cookies.namename = bottle.request.cookies.getunicode('name') # encoding='utf-8' (default)try:    name = bottle.request.cookies.get('name', '').decode('utf-8')except UnicodeError:    name = u''\n每个键多个值：FormsDict 是 MultiDict 的子类，可以为每个键存储多个值。标准字典访问方法只能返回单个值，但 getall() 方法返回指定键的所有值的列表。\nfor choice in request.forms.getall('multiple_choice'):    do_something(choice)\nWTForms支持：一些库（例如WTForms）希望将 Unicode 字典作为输入，FormsDict.decode() 会自动解码所有值并返回自身的副本，同时保留每个键的所有值和功能。\nCookie前面已经讲到使用 set_cookie() 和 get_cookie() 来设置和获取 Cookie，客户端发送的所有 Cookie 还可以通过 FormsDict 获取，下面看一个简单的例子：\n@app.route('/count')def counter():    count = int(bottle.request.cookies.get('counter','0'))    count += 1    bottle.response.set_cookie('counter', str(count))    return 'Count: %d\\n' % count\n使用 curl 或者浏览器不停的刷新页面，可以看到计数器一直在增加：\nroot@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt\nCount: 1\nroot@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt\nCount: 2\nroot@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt\nCount: 3\nroot@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt\nCount: 4\nroot@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt\nCount: 5\nHTTP 标头客户端发送的所有 HTTP 标头都存储在 WSGIHeaderDict 中，可以通过 BaseRequest.headers 属性访问。WSGIHeaderDict 的键基本上都是不区分大小写的。\n@app.route('/headers')def headers():    return bottle.request.headers.get('User-Agent') + '\\n'\n打印出客户端标识：\nroot@ubuntu:~# curl http://127.0.0.1:8080/headers\ncurl/7.47.0\nHTML 表单处理在 HTML 中，典型的 &lt;form&gt; 看起来像这样：\n&lt;form action=\"/login\" method=\"post\"&gt;    Username: &lt;input name=\"username\" type=\"text\" /&gt;    Password: &lt;input name=\"password\" type=\"password\" /&gt;    &lt;input value=\"Login\" type=\"submit\" /&gt;&lt;/form&gt;\naction 属性指定将接收表单数据的 URL，method 定义要使用的 HTTP 方法。用 method=&quot;get&quot; 返回的表单，可以使用 BaseRequest.query 来接收，但 GET 请求并不是安全的，所以在返回用户名和密码用 POST 方法。通过 POST 返回的表单存储在 BaseRequest.forms。服务端代码可能如下所示：\n@app.post('/login') def do_login():    username = bottle.request.forms.get('username')    password = bottle.request.forms.get('password')    if username == 'root' and password == '123456':        return \"&lt;p&gt;Your login information was correct.&lt;/p&gt;\\n\"    else:        return \"&lt;p&gt;Login failed.&lt;/p&gt;\\n\"\n还有其他几个属性可以用于访问表单数据，下面给出一个整体概述：\n\n\n\n属性\nGET 表单字段\nPOST 表单字段\n文件上传\n\n\n\n\nBaseRequest.query\nyes\nno\nno\n\n\nBaseRequest.forms\nno\nyes\nno\n\n\nBaseRequest.files\nno\nno\nyes\n\n\nBaseRequest.params\nyes\nyes\nno\n\n\nBaseRequest.GET\nyes\nno\nno\n\n\nBaseRequest.POST\nno\nyes\nyes\n\n\n\n文件上传为了支持文件上传，我们需要修改 &lt;form&gt; 标签。首先需要添加标签 enctype=&quot;multipart/form-data&quot; 来告诉浏览器如何编码，然后添加 &lt;input type=&quot;file&quot; /&gt; 来让用户选择文件：\n&lt;form action=\"/upload\" method=\"post\" enctype=\"multipart/form-data\"&gt;  Select a file: &lt;input type=\"file\" name=\"upload\" /&gt;  &lt;input type=\"submit\" value=\"Start upload\" /&gt;&lt;/form&gt;\nBottle 使用 BaseRequest.files 存储上传的文件以及一些有关上传的元数据，它是 FileUpload 的实例。下面是个服务端保存上传的文件的示例：\n@app.route('/upload', method='POST')def do_upload():    upload = bottle.request.files.get('upload')    filename = upload.filename    upload_root = \"/tmp\"    upload.save(upload_root)    return filename + '\\n'\n使用 curl 测试上传文件\nroot@ubuntu:~# curl http://127.0.0.1:8080/upload -F &quot;upload=@/etc/issue&quot;\nissue\nroot@ubuntu:~# cat /tmp/issue \nUbuntu 16.04.5 LTS \\n \\l\nFileUpload.filename 会对文件名清理和规范化，以防止文件名中出现不支持的字符或路径导致错误。如果想访问未经修改的文件名，可以通过访问 FileUpload.raw_filename。\nFileUpload.save 将文件安全高效的存储到硬盘，如果想手动操作文件数据流，可以访问 FileUpload.file：\n@app.route('/upload', method='POST')def do_upload():    upload = bottle.request.files.get('upload')    return upload.file.read()\nroot@ubuntu:~# curl http://127.0.0.1:8080/upload -F &quot;upload=@/etc/issue&quot;\nUbuntu 16.04.5 LTS \\n \\l\n这里使用了最危险的读取文件的方法，如果文件非常大，可能系统内存会耗尽，所以最好不要这样做。\nJSON 内容如果客户端将 Content-Type: application/json 的内容发送到服务器，BaseRequest.json 属性会包含已解析的数据（数据结构正常的情况下）。\n@app.route('/json', method='POST')def test_json():    return bottle.request.json\nroot@ubuntu:~# curl http://127.0.0.1:8080/json -X POST -H &apos;content-type: application/json&apos; -d &apos;{&quot;msg&quot;:&quot;hello world&quot;}&apos;\n{&quot;msg&quot;: &quot;hello world&quot;}\n原始请求体你可以通过原始数据作为类文件对象访问 BaseRequest.body。这是 BytesIO 缓冲区或临时文件，具体取决于内容长度和 BaseRequest.MEMFILE_MAX 的设置（默认1M大小）。可以通过 bottle.request[&#39;wsgi.input&#39;] 来访问它。\n上传的内容非常大的情况下（比如上传一个巨大的JSON内容），可以在程序开始提供给 bottle.BaseRequest.MEMFILE_MAX 一个合适的值。否则将抛出 413 Request Entity Too Large。\nWSGI 环境每个 BaseRequest 实例都包含一个 WSGI 环境字典，如果想直接访问它，可以通过 BaseRequest.environ 来直接访问：\n@app.route('/getip')def getip():    return bottle.request.environ.get('REMOTE_ADDR')\nroot@ubuntu:~# curl http://127.0.0.1:8080/getip\n127.0.0.1\n模板引擎Bottle 附带了一个快速而强大的内置模板引擎，名为 Simple Template Engine，要渲染模板，可以使用 template() 函数或者 view() 装饰器。需要做的就是将模板名称和关键字参数传递给模板：\n@app.route('/hello')@app.route('/hello/&lt;name&gt;')def test_template(name='World'):    return bottle.template('hello', name=name)\n这里传递的模板名为 hello，Bottle 会在脚本所在目录和所在目录中的 views 目录下寻找模板文件，可以通过将路径添加到 bottle.TEMPLATE_PATH列表中来增加 Bottle 的搜索路径。模板文件的拓展名为 tpl，接着在脚本目录下创建 views 目录，然后在这个目录下新建 hello.tpl 文件，写入如下内容：\n%if name == &apos;World&apos;:    &lt;h1&gt;Hello &#123;&#123;name&#125;&#125;!&lt;/h1&gt;    &lt;p&gt;This is a test.&lt;/p&gt;%else:    &lt;h1&gt;Hello &#123;&#123;name.title()&#125;&#125;!&lt;/h1&gt;    &lt;p&gt;How are you?&lt;/p&gt;%end\n测试访问，可以看到模板中根据 name 的值进行了逻辑处理\nroot@ubuntu:~# curl http://127.0.0.1:8080/hello\n    &lt;h1&gt;Hello World!&lt;/h1&gt;\n    &lt;p&gt;This is a test.&lt;/p&gt;\nroot@ubuntu:~# curl http://127.0.0.1:8080/hello/abc\n    &lt;h1&gt;Hello Abc!&lt;/h1&gt;\n    &lt;p&gt;How are you?&lt;/p&gt;\n也可以直接将模板字符串传递给 template() 函数，但是并不推荐这样做 例如：\n@app.route('/hello')@app.route('/hello/&lt;name&gt;')def test_template(name='World'):    hello = \"\"\"%if name == 'World':    &lt;h1&gt;Hello &#123;&#123;name&#125;&#125;!&lt;/h1&gt;    &lt;p&gt;This is a test.&lt;/p&gt;%else:    &lt;h1&gt;Hello &#123;&#123;name.title()&#125;&#125;!&lt;/h1&gt;    &lt;p&gt;How are you?&lt;/p&gt;%end\"\"\"    return bottle.template(hello, name=name)\n模板使用 % 开始编写 Python 的代码，使用 %end 结束代码块，更详细的语法规则 下面会讲到。模板在编译后，将缓存在内存中，在清楚缓存之前，对模板的任何改动都不会立即生效，可以通过调用 bottle.TEMPLATES.clear() 来清理缓存，如果在调试模式下将禁用缓存。\n插件Bottle 的核心功能涵盖了最常见的用例，但作为一个微框架，它有其局限性，插件为框架添加缺少的功能，这就是插件发挥作用的地方。\n体验插件这里看看 SQLitePlugin 插件的简单用法，首先通过pip安装这个插件：pip install bottle-sqlite，然后看下面示例：\nimport bottlefrom bottle_sqlite import SQLitePluginapp = bottle.Bottle()sqlite_plugin = SQLitePlugin(dbfile='/tmp/test.db')app.install(sqlite_plugin)@app.route('/createdb')def create(db):    db.execute('create table data (key varchar, value varchar)')    db.commit()    return 'True\\n'@app.route('/set')def db_set(db):    key = bottle.request.params.get('k')    value = bottle.request.params.get('v')    db.execute('insert into data values (?,?)', (key, value))    db.commit()    return 'True\\n'@app.route('/get')def db_get(db):    key = bottle.request.params.get('k')    c = db.execute('select value from data where key=?', (key,))    row = c.fetchone()    print(row)    return row[0] + '\\n'if __name__ == '__main__':    app.run(host='localhost', port=8080, debug=True, reloader=True)\n对接口进行测试：\nroot@ubuntu:~# curl http://127.0.0.1:8080/createdb\nTrue\nroot@ubuntu:~# curl &quot;http://127.0.0.1:8080/set?k=a&amp;v=qwe&quot;\nTrue\nroot@ubuntu:~# curl &quot;http://127.0.0.1:8080/get?k=a&quot;\nqwe\n对 app 对象安装 SQLitePlugin 插件，接着在需要使用数据库的地方，给回调函数添加 db 关键字即可，关键字的位置无所谓。插件检测到添加了 db 的关键字后，会将一个打开的 sqlite3.Connection 对象传递给 db 关键字，这样就可以在回掉函数中操作数据库了。\n卸载插件卸载插件非常简单，调用 app.uninstall() 函数即可：\napp.uninstall(sqlite_plugin)    # 卸载指定的插件app.uninstall(SQLitePlugin)     # 卸载这个类型的所有插件app.uninstall('sqlite')         # 卸载以这个名称开头的所有插件app.uninstall(True)             # 一次性卸载所有插件\n将插件安装到指定的路由有时候并不想全局安装某个插件，可以单独将这个插件安装到某个路由上：\nsqlite_plugin = SQLitePlugin(dbfile='/tmp/test.db')@app.route('/create', apply=[sqlite_plugin])def create(db):    pass\n将需要应用到这个路由的插件添加到 apply 参数的列表中就可以了。\n黑名单插件有时候不想让某个函数应用某个插件，可以使用 skip 来跳过这些插件：\nsqlite_plugin = SQLitePlugin(dbfile='/tmp/test.db')app.install(sqlite_plugin)@app.route('/create', skip=[sqlite_plugin])def create():    pass\n如果设置 skip=True 将跳过所有插件。\n插件与子程序将一个 Bottle 程序挂挂载到另一个 Bottle 程序上，相当于在主程序上创建一个代理路由，访问该代理路由的请求都转发到相应的子程序。此类代理路由是禁用插件的，安装在主程序上的插件并不会影响到子程序 例如：\nimport bottlefrom bottle_sqlite import SQLitePluginapp = bottle.Bottle()blog = bottle.Bottle()sqlite_plugin = SQLitePlugin(dbfile='/tmp/test.db')app.install(sqlite_plugin)@blog.route('/db')def blog_db(db='Not sqlite db\\n'):    return str(db)@app.route('/db')def app_db(db='Not sqlite db\\n'):    return str(db)app.mount('/blog', blog)if __name__ == '__main__':    app.run(host='localhost', port=8080, debug=True, reloader=True)\n访问这几个路由：\nroot@ubuntu:~# curl http://127.0.0.1:8080/db\n&lt;sqlite3.Connection object at 0x7fad044429d0&gt;\nroot@ubuntu:~# curl http://127.0.0.1:8080/blog/db\nNot sqlite db\n使用 app.mount() 函数将 blog 的所有路由挂载到 app 的 /blog 路由下。\n实际开发现在已经可以使用Bottle开发简单的应用了，下面这些知识可以帮助你提高工作效率。\n默认应用Bottle 维护一个全局堆栈的 Bottle 实例，并使用堆栈顶部作为某些模块级函数和装饰器的默认值，例如 bottle.route() 装饰器，是调用默认应用程序的快捷方式：\nfrom bottle import route@route('/')def hello():    return 'hello world'\n对于小型应用程序会非常方便，但是只要导入模块，就会将路由安装到全局应用程序中。为了避免这种导入，Bottle 提供了更明确的方法：\nfrom bottle import Bottleapp = Bottle()@app.route('/')def hello():    return 'hello world'\n分离应用程序对象可以大大提高可重用性，其他开发人员也可以安全的从你的模块中导入对象并使用 Bottle.mount() 将应用程序合并在一起。另外还可以使用应用程序堆栈来隔离路由：\nfrom bottle import route, default_appdefault_app.push()@route('/')def hello():    return 'Hello World'app = default_app.pop()\n调试模式在开发早期，调试模式非常有用，可以在有错误发生时显示更详细的错误信息，并且模板不会缓存，插件也会立即应用。\n可以通过调用 bottle.debug(True) 或者在 app.run() 中设置 debug 参数为 True。\n自动加载运行在开发过程中，修改了代码必须手动重启服务才可以测试更改，自动重新加载器可以帮你完成这些工作：\nimport bottleapp = bottle.Bottle()app.run(reloader=True)\n命令行界面从版本 0.10 开始，就可以使用 Bottle 作为命令行工具：\nroot@ubuntu:~# python -m bottle\nUsage: bottle.py [options] package.module:app\n\nOptions:\n-h, --help            show this help message and exit\n--version             show version number.\n-b ADDRESS, --bind=ADDRESS\n                        bind socket to ADDRESS.\n-s SERVER, --server=SERVER\n                        use SERVER as backend.\n-p PLUGIN, --plugin=PLUGIN\n                        install additional plugin/s.\n--debug               start server in debug mode.\n--reload              auto-reload on file changes.\n\nError: No application specified.\n只用指定应用模块启动即可：\nimport bottleapp = bottle.Bottle()@app.route('/')def hello():    return 'Hello World'\n将代码保存为 hello.py，然后通过命令行启动：python -m bottle --debug --reload hello:app，hello 是模块名，app 是应用对象。\n配置Bottle 应用程序的配置存储在 Bottle.config 这个类似于字典的对象里，可以用与通过配置告诉插件需要做什么，也可以存储自己的配置。\n基础配置Bottle.config 的行为看起来很想普通字典，所有常见的字典方法都能按照预期工作，让我们看看一些例子：\nimport bottleapp = bottle.Bottle()app.config['autojson']    = False      # 关闭JSON自动转换的特性app.config['sqlite.db']   = ':memory:' # 告诉SQLite插件使用哪个数据库app.config['myapp.param'] = 'value'    # 自定义配置值# 一次性配置多个值app.config.update(&#123;    'autojson': False,    'sqlite.db': ':memory:',    'myapp.param': 'value'&#125;)# 添加默认值app.config.setdefault('myapp.param2', 'some default')# 获取值param  = app.config['myapp.param']param2 = app.config.get('myapp.param2', 'fallback value')# 在路由中从配置获取数据的例子@app.route('/about', view='about.rst')def about():    email = app.config.get('my.email', 'nomail@example.com')    return &#123;'email': email&#125;\napp 对象并不是总是可用的，但是你可以在请求上下文中，使用 request 对象获取当前应用程序对象和它的配置\nfrom bottle import requestdef is_admin(user):    return user == request.app.config['myapp.admin_user']\n命名约定为了更好的开发，插件和应用程序应遵守一些简单的命名规则：\n\n所有的键名都应该是小写字符串，不能有特殊字符，但下划线除外。\n命名空间由 “.” 分隔，比如 namespace.field。\nBottle 使用根命名空间进行自己的配置，插件应将所有变量存储在自己的命名空间中，例如 sqlite.db。\n自定义的配置也应该有单独的命名空间，比如 myapp.*\n\n从文件加载配置如果想使非程序员也能够配置程序，或想给程序带来高的可配置性，那么配置文件很有用。这里提供了配置文件的一种非常常见的语法：\n[bottle]debug = True[sqlite]db = /tmp/test.dbcommit = auto[myapp]admin_user = defnull\n现在可以通过 load_config() 方法加载这些配置文件：\napp.config.load_config('/etc/myapp.conf')\n从嵌套的字典加载配置另一个常用的方法使 load_dict()。这个方法将嵌套的字典转换为具有命名空间键和值的平面字典。\n# 从字典中加载配置app.config.load_dict(&#123;    'autojson': False,    'sqlite': &#123; 'db': ':memory:' &#125;,    'myapp': &#123;        'param': 'value',        'param2': 'value2'    &#125;&#125;)assert app.config['myapp.param'] == 'value'# 从json文件中加载配置with open('/etc/myapp.json') as fp:    app.config.load_dict(json.load(fp))\n监听配置更改每次更改 Bottle 中的值时，都将触发应用程序对象上的 config 钩子。此钩子可用于在运行时对配置更改做出反应，例如重新连接到新数据库、更改后端服务上的调试设置 或者调整工作线程池的大小。钩子的回调函数接收两个参数(键, 新值)，并在字典中实际值更改之前调用，如果回调函数引发异常将取消更改，并保留原值。\n@app.hook('config')def on_config_change(key, value):    if key == 'debug':        switch_own_debug_mode_to(value)\n钩子的回调函数不能改变要存储到字典中的值，只能有过滤器的用处。\n过滤器和其他元数据ConfigDict 允许你存储元数据和配置键，目前定义了两个源字段：\n\nhelp: 帮助或说明字符串，可由调试、内省或管理工具去帮助站点管理员配置应用程序。\nfilter: 接收和返回单个值的可调用对象，如果你为键定义了过滤器，那么存储到该键的所有值都先通过过滤器。过滤器可以对值进行检查和修改，或者抛出异常。下面看个例子：\n\nclass SomePlugin(object):    def setup(app):        app.config.meta_set('some.int', 'filter', int)        app.config.meta_set('some.list', 'filter',            lambda val: str(val).split(';'))        app.config.meta_set('some.list', 'help',            'A semicolon separated list.')    def apply(self, callback, route):        ...import bottleapp = bottle.default_app()app.install(SomePlugin())app.config['some.list'] = 'a;b;c'     # 自动转为列表app.config['some.int'] = 'not an int' # 抛出异常\n简单模板引擎Bottle 附带一个快速、功能强大且易学的内置模板引擎，简称 SimpleTemplate。 view() 和 template() 函数帮助用户使用这个引擎。这里解释模板语法，并提供几个常用的示例。\n基本 API 使用\nfrom bottle import SimpleTemplatetpl = SimpleTemplate('Hello &#123;&#123;name&#125;&#125;!')tpl.render(name='World')# 结果：u'Hello World!'\n使用 template() 函数可以简化这个过程\nfrom bottle import templatetemplate('Hello &#123;&#123;name&#125;&#125;!', name='World')\nSimpleTemplate 语法Python 是一种非常强大的语言，但它严格的缩进使它很难用于模板语言。SimpleTemplate 取消了这些限制，允许你编写干净，可读和可维护的模板，同时保留 Python 语言的功能。\n内联表达式上面已经学习了两个大括号这样的语法，实际上可以在大括号中使用任何 Python 表达式：\n&gt;&gt;&gt; template(&apos;Hello {{name}}!&apos;, name=&apos;World&apos;)\n&apos;Hello World!&apos;\n&gt;&gt;&gt; template(&apos;Hello {{name.title() if name else \"stranger\"}}!&apos;, name=None)\n&apos;Hello stranger!&apos;\n&gt;&gt;&gt; template(&apos;Hello {{name.title() if name else \"stranger\"}}!&apos;, name=&apos;mArC&apos;)\n&apos;Hello Marc!&apos;\n如果传入的字符串包含 HTML 字符，则会自动转义来防止 XSS 攻击，但是你可以使用 ! 来表示禁止转义：\n&gt;&gt;&gt; template(&apos;Hello {{name}}&apos;, name=&apos;&lt;b&gt;World&lt;/b&gt;&apos;)\n&apos;Hello &amp;lt;b&amp;gt;World&amp;lt;/b&amp;gt;&apos;\n&gt;&gt;&gt; template(&apos;Hello {{!name}}&apos;, name=&apos;&lt;b&gt;World&lt;/b&gt;&apos;)\n&apos;Hello &lt;b&gt;World&lt;/b&gt;&apos;\n嵌入 Python 代码模板引擎允许你在模板中嵌入 Python 代码行或块。代码行以 % 开头，代码快由 &lt;% 和 %&gt; 包围：\n% name = \"Bob\"  # 行级别的 Python 代码&lt;p&gt;Some plain text in between&lt;/p&gt;&lt;%  # 块级别的 Python 代码  name = name.title().strip()%&gt;&lt;p&gt;More plain text&lt;/p&gt;\n嵌入的 Python 代码遵循常规 Python 语法，但有两个额外的语法规则：\n\n缩进被忽略，你可以根据需要在语句前尽可能多的放置空格，这样可以与周围的代码对其，提高可读性。\n缩进的块现在必须用 %end 显式关闭，比如：\n\n&lt;ul&gt;  % for item in basket:    &lt;li&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt;  % end&lt;/ul&gt;\n空白符控制代码块和代码行在模板中总是跨行的，在模板被渲染后，代码段会被删除，但是模板中并不会出现悬空的空白行，例如：\n&lt;div&gt; % if True:  &lt;span&gt;content&lt;/span&gt; % end&lt;/div&gt;\n被渲染后成为：\n&lt;div&gt;  &lt;span&gt;content&lt;/span&gt;&lt;/div&gt;\n如果想跳过代码段前面的换行符，可以使用双反斜杠结束文本：\n&lt;div&gt;\\\\ %if True:&lt;span&gt;content&lt;/span&gt;\\\\ %end&lt;/div&gt;\n渲染后的效果是：\n&lt;div&gt;&lt;span&gt;content&lt;/span&gt;&lt;/div&gt;\n模板功能每个模板都预置了一些函数，可以帮助处理一些常见的功能。这些函数直接可用，无需安装或导入。\n注意：在 0.12 版本之前，include() 和 rebase() 是语法关键字，而不是函数。\nincludeinclude(sub_template, variables)**\n使用指定的变量渲染子模版，并将生成的文本插入到当前模板。该函数返回包含在子模板中传递或定义的局部变量的字典:\n% include('header.tpl', title='Page Title')Page Content% include('footer.tpl')\nrebaserebase(name, variables)**\n将当前模板标记为稍后包含在不同的模板中，呈现当前模板后，其将生成的文本存储在一个名为 base 的变量中，并传递给基本模板，然后呈现该模板：\n% rebase('base.tpl', title='Page Title')&lt;p&gt;Page Content ...&lt;/p&gt;\n以下是 base.tpl 的内容：\n&lt;html&gt;&lt;head&gt;  &lt;title&gt;&#123;&#123;title or 'No title'&#125;&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt;  &#123;&#123;!base&#125;&#125;&lt;/body&gt;&lt;/html&gt;\n渲染的最终结果：\n&gt;&gt;&gt; from bottle import template\n&gt;&gt;&gt; t = &apos;&apos;&apos;% rebase(&apos;base.tpl&apos;, title=&apos;Page Title&apos;)\n... &lt;p&gt;Page Content ...&lt;/p&gt;&apos;&apos;&apos;\n&gt;&gt;&gt; print(template(t))\n&lt;html&gt;\n&lt;head&gt;\n&lt;title&gt;Page Title&lt;/title&gt;\n&lt;/head&gt;\n&lt;body&gt;\n&lt;p&gt;Page Content ...&lt;/p&gt;\n&lt;/body&gt;\n&lt;/html&gt;\ndefineddefined(name)\n测试一个变量名是否定义：\n&gt;&gt;&gt; t = &apos;&apos;&apos;% if defined(&quot;title&quot;):\n... &lt;p&gt;defined title&lt;/&gt;\n... % else:\n... &lt;p&gt;not defined title&lt;/p&gt;\n... % end&apos;&apos;&apos;\n&gt;&gt;&gt; template(t)\n&apos;&lt;p&gt;not defined title&lt;/p&gt;\\n&apos;\n&gt;&gt;&gt; template(t, title=&apos;test&apos;)\n&apos;&lt;p&gt;defined title&lt;/&gt;\\n&apos;\ngetget(name, default=None)\n和字典的 get 方法相似：\n&gt;&gt;&gt; t = &apos;&apos;&apos;% print(get(&apos;title&apos;))&apos;&apos;&apos;\n&gt;&gt;&gt; template(t)\nNone\n&apos;&apos;\n&gt;&gt;&gt; template(t, title=&apos;abc&apos;)\nabc\n&apos;&apos;\nsetdefaultsetdefault(name, default)\n如果变量没有定义，创建它并提供一个默认值，否则返回它的值：\n&gt;&gt;&gt; t = &apos;&apos;&apos;% setdefault(&quot;title&quot;, &quot;abc&quot;)\n... {{title}}&apos;&apos;&apos;\n&gt;&gt;&gt; template(t)\n&apos;abc&apos;\n&gt;&gt;&gt; template(t, title=&apos;title&apos;)\n&apos;title&apos;\n部署目前我最喜欢的部署方式是使用 gunicorn，如果想通过协程的方式提高程序的并发，还会搭配 gevent。它们都可以很方便的通过 pip 安装\ngunicorn安装pip install gunicorn\n配置文件gunicorn 最好通过配置文件的方式启动，配置文件可以是普通的键值对的文本，也可以是一个可执行的 Python 文件，采用 Python 文件的方式更灵活，所以我更喜欢这个。下面看一个配置文件的例子：\nimport osimport sysimport multiprocessingDEBUG = os.environ.get('DEBUG','FALSE').upper() in ['TRUE','1']# gunicorn configpath_of_current_file = os.path.abspath(__file__)path_of_current_dir = os.path.dirname(path_of_current_file)sys.path.insert(0, path_of_current_dir)worker_class = 'gevent'workers = multiprocessing.cpu_count()chdir = path_of_current_dirworker_connections = 1000timeout = 30max_requests = 2000loglevel = 'info'bind = \"0.0.0.0:8000\"pidfile = '%s/run/gunicorn.pid' % path_of_current_dirif DEBUG:    reload = True    debug = True    errorlog = \"-\"    accesslog = \"-\"else:    reload = False    debug = False    errorlog = '%s/logs/error.log' % path_of_current_dir    accesslog = '%s/logs/access.log' % path_of_current_dir\n配置文件的代码很简单，会自动根据当前系统CPU核数来配置生成多少个工作进程，还可以采用多进程配合多线程的方式，但这里选择了使用协程用以更好的支持并发。\n并且配置文件编写了通过环境变量获取是否进入DEBUG模式的代码，让程序的配置更灵活。更多 gunicron 的配置说明可以查看官方文档：点此打开\n配合Gevent使用 Gevent 可以在几乎不修改任何代码的情况下让 Web 性能获取飙升，安装也非常简单 pip install gevent。在上面的配置文件中，worker_class 已经指定了要使用 gevent\n启动程序gunicorn 的启动方式也非常简单，直接使用命令行将应用程序对象和配置文件传递给 gunicorn:\nhello.py\nimport bottleapp = bottle.Bottle()@app.route('/')def hello():    return 'Hello World'\n启动:\nroot@ubuntu: # gunicorn hello:app -c config.py \n[2018-10-16 11:42:45 +0000] [46823] [INFO] Starting gunicorn 19.6.0\n[2018-10-16 11:42:45 +0000] [46823] [INFO] Listening at: http://0.0.0.0:8000 (46823)\n[2018-10-16 11:42:45 +0000] [46823] [INFO] Using worker: gevent\n[2018-10-16 11:42:45 +0000] [46827] [INFO] Booting worker with pid: 46827\n[2018-10-16 11:42:45 +0000] [46828] [INFO] Booting worker with pid: 46828\n[2018-10-16 11:42:45 +0000] [46829] [INFO] Booting worker with pid: 46829\n[2018-10-16 11:42:45 +0000] [46830] [INFO] Booting worker with pid: 46830\n但是默认是前台启动的，如果想启动后就放入后台执行，可以将 daemon=True 写入配置文件，或者直接在命令行添加 -D 参数。\n使用 Nginx 做静态资源服务器gunicorn 是 WSGI 服务器，并不擅长处理静态资源，可以将静态文件交给 Nginx 处理。使用 Nginx 配置动静分离，将动态的请求转发到 gunicorn ，将静态资源直接返回给客户端，这样又可以提升不少的性能。\n附录可用插件列表官网列出的 Bottle 现在可用的插件：点击打开\n","categories":["Python"],"tags":["bottle","python"]},{"title":"MongoDB分片集群","url":"/2018/03/02/2018/MongoDB%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4/","content":"简介\n当面对海量数据的时候，单台MongoDB的承受能力显然达不到数据要求。分片(Sharding)是MongoDB将大型的集合分割到不同服务器上的方法。分片起源于关系型数据库的分区，但是和关系型数据库的分区相比，MongoDB已经帮用户做了所有能自动完成的事情。MongoDB会自动将需要分片的集合均衡的分布到不同的服务器上，配合副本集保障了数据的可用性和安全性，而这一切对用户都是透明的。\n\n\n概念分片的目的高数据量和吞吐量的数据库应用会对单机的性能造成较大压力。随着数据的增大，单台MongoDB的QPS会严重下降。较大的查询甚至会将单机的CPU和内存资源耗尽。为了解决MongoDB的性能问题，一般有两种解决方法：垂直扩展和水平扩展。\n垂直扩展 就是升级服务器的硬件，增加更多的CPU，增加更大的内存。但是这种方法很容易就达到硬件提升的瓶颈，而且可能需要付出更高的代价。水平扩展 就是一台服务器不行就多台，将数据分布到多个服务器上，需要查询数据的时候根据相应的算法知道数据存放在哪台服务器上就可以了。\n分片的设计一个MongoDB分片集群有三种角色\n\n分片服务器(Shard Server) mongod实例，用于存储实际的数据块。分片服务器可以是一个副本集集群共同来提供服务 防止单点故障。\n配置服务器(Config Server) mongod实例，存储整个集群和分片的元数据，就像是一本书的目录，保存的只是数据的分布表。\n路由服务器(Route Server) mongos实例，客户端由此接入，本身不存放数据，仅供程序连接，起到一个路由的作用。\n\n路由服务器对整个MongoDB分片集群进行了抽象，用户访问mongos提供的监听就像访问一个mongod一样。而分片服务器使用副本集来保障了数据的可用性和安全性。分片集群还提供了良好的扩展能力，随着数据量增大可以方便的增加分片服务器来扩展整个集群的容量。\n用户对分片集群一次完整的读取数据过程如下：\n数据分发在MongoDB分片集群中，将集合的数据拆分成块(chunk)，然后将块分不到不同的分片服务器上。MongoDB的块大小默认是64M，大于64M的块将自动分裂为两个较小的块。MongoDB内置均衡器(balancer)就是用于拆分块和分发块的。\n块的分发主要有两种方式：基于块的数量的分发 和 基于片键范围的定向分发\n基于块的数量的分发MongoDB内置均衡器按照集合的索引字段来进行数据分发，该字段叫做片键(sharded key)片键一般有三种类型：升序片键，随机片键和基于分组的片键。\n升序片键升序片键类似自增长的ID。假如集合foo有10个文档，1-4的文档所在块在分片服务器A上，5-8的文档所在块在分片服务器B上，9-10的文档所在块在分片服务器C上。当有新的文档需要写入时会插入到C服务器上所在的块，当块的大小超过限制后会分裂为两个块，分裂后的旧数据所在块可能会移动到其他服务器，继续新增的数据还会插入到拥有最大ID的块，导致所有的写请求都被路由到了C分片服务器上，数据写入不均匀。\n但是如果按照片键进行范围读取时，数据可能都在同一个块上，读取的性能就比较高了。\n随机片键随机片键是指片键的值不是固定增长，而是一些没有规律的键值。由于写入数据是随机分发的，各分片增长的速度大致相同，减少了chunk 迁移的次数。使用随机分片的弊端是：写入的位置是随机的，如果使用Hash Index来产生随机值，那么范围查询的速度会很慢。\n基于分组的片键基于分组的片键是两字段的复合片键，第一个字段用于分组，第二个字段用于自增，所以第二个字段最好是自增字段。这种片键策略是最好的，能够实现多热点数据的读写。\n选择合适的片键需要对项目是写为主还是读为主的权衡。\n基于片键范围的定向分发如果希望特定范围的块被分发到特定的分片服务器中，可以为分片添加标签，然后为标签指定相应的片键范围，这样，如果一个文档属于某个标签的片键范围，就会被定向到特定的分片服务器中了。\n环境使用三台测试机来搭建环境 使用不同的端口号来启动不同的MongoDB实例。\n系统环境\n\n\n主机名\n系统\nIP\n\n\n\n\nmongo-A\nCentOS 6.8\n10.0.0.3\n\n\nmongo-B\nCentOS 6.8\n10.0.0.4\n\n\nmongo-C\nCentOS 6.8\n10.0.0.5\n\n\n\n拓扑结构\n\n\nmongo-A\nmongo-B\nmongo-C\n\n\n\n\nMongos\nMongos\nMongos\n\n\nConfig Server\nConfig Server\nConfig Server\n\n\nShard Server 1 主\nShard Server 1 备\nShard Server 1 仲裁\n\n\nShard Server 2 主\nShard Server 2 备\nShard Server 2 仲裁\n\n\nShard Server 3 主\nShard Server 3 备\nShard Server 3 仲裁\n\n\n\n服务信息\n\n\n角色\n数据目录\n端口\n副本集名称\n\n\n\n\nMongos\nNone\n27017\nNone\n\n\nConfig Server\n/data/cs\n20000\ncs\n\n\nShard Server 1\n/data/ss1\n21001\nss1\n\n\nShard Server 2\n/data/ss2\n21002\nss2\n\n\nShard Server 3\n/data/ss3\n21003\nss3\n\n\n\n步骤安装MongoDB这里使用Linux平台当前最新版 3.6.3 点此下载\n所有节点全部执行tar xf mongodb-linux-x86_64-3.6.3.tgz -C /usr/local/ln -s /usr/local/mongodb-linux-x86_64-3.6.3/ /usr/local/mongodbmkdir -p /data/&#123;cs,ss1,ss2,ss3&#125;echo &apos;export PATH=/usr/local/mongodb/bin/:$PATH&apos; &gt; /etc/profile.d/mongodb.shsource /etc/profile.d/mongodb.sh\n配置分片集群启动服务所有节点执行mongod --configsvr --dbpath /data/cs --fork --logpath /var/log/mongodcs.log --bind_ip 0.0.0.0 --port 20000 --replSet cs mongod --shardsvr --dbpath /data/ss1 --fork --logpath /var/log/mongodss1.log --bind_ip 0.0.0.0 --port 21001 --replSet ss1mongod --shardsvr --dbpath /data/ss2 --fork --logpath /var/log/mongodss2.log --bind_ip 0.0.0.0 --port 21002 --replSet ss2mongod --shardsvr --dbpath /data/ss3 --fork --logpath /var/log/mongodss3.log --bind_ip 0.0.0.0 --port 21003 --replSet ss3\n配置Config Server随便连接到一个服务器的20000端口mongo 127.0.0.1:20000\n初始化Config Server，在mongo中执行以下代码\nvar cfg = &#123;_id:\"cs\", configsvr:true, members:[         &#123;_id:0,host:'10.0.0.3:20000'&#125;,         &#123;_id:1,host:'10.0.0.4:20000'&#125;,           &#123;_id:2,host:'10.0.0.5:20000'&#125;    ]&#125;;rs.initiate(cfg)\n结果输出：\n&gt; rs.initiate(cfg)\n{\n    &quot;ok&quot; : 1,\n    &quot;operationTime&quot; : Timestamp(1519896701, 1),\n    &quot;$gleStats&quot; : {\n        &quot;lastOpTime&quot; : Timestamp(1519896701, 1),\n        &quot;electionId&quot; : ObjectId(&quot;000000000000000000000000&quot;)\n    },\n    &quot;$clusterTime&quot; : {\n        &quot;clusterTime&quot; : Timestamp(1519896701, 1),\n        &quot;signature&quot; : {\n            &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;),\n            &quot;keyId&quot; : NumberLong(0)\n        }\n    }\n}\n配置Shard Server 1连接mongo-A的21001端口mongo 10.0.0.3:21001\n初始化Shard Server 1var cfg = &#123;_id:\"ss1\",members:[         &#123;_id:0,host:'10.0.0.3:21001',priority:2&#125;,         &#123;_id:1,host:'10.0.0.4:21001',priority:1&#125;,           &#123;_id:2,host:'10.0.0.5:21001',arbiterOnly:true&#125;]     &#125;;rs.initiate(cfg)\n配置Shard Server 2接着连接mongo-A的21002端口mongo 10.0.0.3:21002\n初始化Shard Server 2var cfg = &#123;_id:\"ss2\",members:[         &#123;_id:0,host:'10.0.0.3:21002',priority:2&#125;,         &#123;_id:1,host:'10.0.0.4:21002',priority:1&#125;,           &#123;_id:2,host:'10.0.0.5:21002',arbiterOnly:true&#125;]     &#125;;rs.initiate(cfg)\n配置Shard Server 3连接mongo-A的21003端口mongo 10.0.0.3:21003\n初始化Shard Server 3var cfg = &#123;_id:\"ss3\",members:[         &#123;_id:0,host:'10.0.0.3:21003',priority:2&#125;,         &#123;_id:1,host:'10.0.0.4:21003',priority:1&#125;,           &#123;_id:2,host:'10.0.0.5:21003',arbiterOnly:true&#125;]     &#125;;rs.initiate(cfg)\n配置mongos路由服务选择一台服务器当作mongos路由服务，这里使用mongo-A\n在mongo-A上执行mongos --configdb cs/10.0.0.3:20000,10.0.0.4:20000,10.0.0.5:20000 --fork --logpath /var/log/mongos.log --bind_ip 0.0.0.0\nmongos默认监听27017端口 也是mongod默认监听的端口\n添加分片服务器到集群登陆路由服务mongo 10.0.0.3:27017\n添加分片服务器到集群sh.addShard(\"ss1/10.0.0.3:21001,10.0.0.4:21001,10.0.0.5:21001\")sh.addShard(\"ss2/10.0.0.3:21002,10.0.0.4:21002,10.0.0.5:21002\")sh.addShard(\"ss3/10.0.0.3:21003,10.0.0.4:21003,10.0.0.5:21003\")\n使用sh.status()查看集群状态\nmongos&gt; sh.status()\n--- Sharding Status --- \nsharding version: {\n    &quot;_id&quot; : 1,\n    &quot;minCompatibleVersion&quot; : 5,\n    &quot;currentVersion&quot; : 6,\n    &quot;clusterId&quot; : ObjectId(&quot;5a97c88a1b0ab73e5d64fc6c&quot;)\n}\nshards:\n        {  &quot;_id&quot; : &quot;ss1&quot;,  &quot;host&quot; : &quot;ss1/10.0.0.3:21001,10.0.0.4:21001&quot;,  &quot;state&quot; : 1 }\n        {  &quot;_id&quot; : &quot;ss2&quot;,  &quot;host&quot; : &quot;ss2/10.0.0.3:21002,10.0.0.4:21002&quot;,  &quot;state&quot; : 1 }\n        {  &quot;_id&quot; : &quot;ss3&quot;,  &quot;host&quot; : &quot;ss3/10.0.0.3:21003,10.0.0.4:21003&quot;,  &quot;state&quot; : 1 }\nactive mongoses:\n        &quot;3.6.3&quot; : 1\nautosplit:\n        Currently enabled: yes\nbalancer:\n        Currently enabled:  yes\n        Currently running:  no\n        Failed balancer rounds in last 5 attempts:  0\n        Migration Results for the last 24 hours: \n                No recent migrations\ndatabases:\n        {  &quot;_id&quot; : &quot;config&quot;,  &quot;primary&quot; : &quot;config&quot;,  &quot;partitioned&quot; : true }\n\nmongos&gt;\n至此MongoDB分片集群就搭建完了。\n数据库的分片配置激活数据库的分片功能激活mydb的分片功能\nsh.enableSharding(&quot;mydb&quot;)\nmongos&gt; sh.enableSharding(&quot;mydb&quot;)\n{\n    &quot;ok&quot; : 1,\n    &quot;$clusterTime&quot; : {\n        &quot;clusterTime&quot; : Timestamp(1519954632, 6),\n        &quot;signature&quot; : {\n            &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;),\n            &quot;keyId&quot; : NumberLong(0)\n        }\n    },\n    &quot;operationTime&quot; : Timestamp(1519954632, 6)\n}\nmongos&gt;\n测试升序片键对mydb库的test集合进行分片，然后插入100000条数据\nuse mydbsh.shardCollection(\"mydb.test\",&#123;id:1&#125;)for (var i = 1; i &lt;= 100000; i++)&#123;    db.test.insert(&#123;\"id\":i,\"name\":\"xiaoming\",\"age\":22,\"data\":new Date()&#125;)&#125;\n可以看到test集合的数据都集中在ss3副本集上。\nmongos&gt; db.test.stats()\n{\n    &quot;sharded&quot; : true,\n    &quot;capped&quot; : false,\n    &quot;ns&quot; : &quot;mydb.test&quot;,\n    &quot;count&quot; : 100000,\n    &quot;size&quot; : 8000000,\n    &quot;storageSize&quot; : 2519040,\n    &quot;totalIndexSize&quot; : 2592768,\n    &quot;indexSizes&quot; : {\n        &quot;_id_&quot; : 942080,\n        &quot;id_1&quot; : 1650688\n    },\n    &quot;avgObjSize&quot; : 80,\n    &quot;nindexes&quot; : 2,\n    &quot;nchunks&quot; : 1,\n    &quot;shards&quot; : {\n        &quot;ss3&quot; : {\n            &quot;ns&quot; : &quot;mydb.test&quot;,\n            &quot;size&quot; : 8000000,\n            &quot;count&quot; : 100000,\n            &quot;avgObjSize&quot; : 80,\n            &quot;storageSize&quot; : 2519040,\n            &quot;capped&quot; : false,\n            &quot;wiredTiger&quot; : {\n                &quot;metadata&quot; : {\n                    &quot;formatVersion&quot; : 1\n                },\n测试哈希片键使用哈希片键的方式重新插入100000条数据\nuse mydbdb.test.drop()sh.shardCollection(\"mydb.test\",&#123;id:\"hashed\"&#125;)for (var i = 1; i &lt;= 100000; i++)&#123;    db.test.insert(&#123;\"id\":i,\"name\":\"xiaoming\",\"age\":22,\"data\":new Date()&#125;)&#125;\n再次使用db.test.stats()可以看到文档已经分散到三个副本集了。\nmongos&gt; db.test.stats()\n{\n    &quot;sharded&quot; : true,\n    &quot;capped&quot; : false,\n    &quot;ns&quot; : &quot;mydb.test&quot;,\n    &quot;count&quot; : 100000,\n    &quot;size&quot; : 8000000,\n    &quot;storageSize&quot; : 2572288,\n    &quot;totalIndexSize&quot; : 4280320,\n    &quot;indexSizes&quot; : {\n        &quot;_id_&quot; : 1040384,\n        &quot;id_hashed&quot; : 3239936\n    },\n    &quot;avgObjSize&quot; : 80,\n    &quot;nindexes&quot; : 2,\n    &quot;nchunks&quot; : 6,\n    &quot;shards&quot; : {\n        &quot;ss1&quot; : {\n            &quot;ns&quot; : &quot;mydb.test&quot;,\n            &quot;size&quot; : 2700400,\n            &quot;count&quot; : 33755,\n            &quot;avgObjSize&quot; : 80,\n            &quot;storageSize&quot; : 868352,\n            &quot;capped&quot; : false,\n            &quot;wiredTiger&quot; : {\n                &quot;metadata&quot; : {\n                    &quot;formatVersion&quot; : 1\n                },\n        ...\n        &quot;ss2&quot; : {\n            &quot;ns&quot; : &quot;mydb.test&quot;,\n            &quot;size&quot; : 2651440,\n            &quot;count&quot; : 33143,\n            &quot;avgObjSize&quot; : 80,\n            &quot;storageSize&quot; : 851968,\n            &quot;capped&quot; : false,\n            &quot;wiredTiger&quot; : {\n                &quot;metadata&quot; : {\n                    &quot;formatVersion&quot; : 1\n                },\n        ...\n        &quot;ss3&quot; : {\n            &quot;ns&quot; : &quot;mydb.test&quot;,\n            &quot;size&quot; : 2648160,\n            &quot;count&quot; : 33102,\n            &quot;avgObjSize&quot; : 80,\n            &quot;storageSize&quot; : 851968,\n            &quot;capped&quot; : false,\n            &quot;wiredTiger&quot; : {\n                &quot;metadata&quot; : {\n                    &quot;formatVersion&quot; : 1\n                },\n分片集群的管理集群添加分片服务器sh.addShard(\"ss1/10.0.0.3:21001,10.0.0.4:21001,10.0.0.5:21001\")\n从集群中移除分片服务器use admindb.runCommand(&#123;removeshard:\"ss1\"&#125;)\n需要注意的是，如果要移除的分片服务器是某个集合的主键，需要先将数据移到其他节点。\n查看集群状态sh.status()\n附录","categories":["MongoDB"],"tags":["MongoDB","NoSQL"]},{"title":"OpenVPN 穿越NAT网络","url":"/2018/05/03/2018/OpenVPN%20%E7%A9%BF%E8%B6%8ANAT%E7%BD%91%E7%BB%9C/","content":"简介\n想和朋友联机打局域网游戏，在家需要连接到公司办公，如果是机密信息还要保证数据的加密传输，而且还要简单稳定好用，那么OpenVPN绝对是不二之选，OpenVPN是一个基于OpenSSL库的应用层VPN实现，完全开源免费，而且支持的平台众多，Linux平台，Windows平台，Android和IOS平台也都支持。\n\n\n环境想要连通两个NAT后的网络，比如家里的局域网和公司的局域网就必须存在一个公网IP来做数据中转。这里使用阿里云的一台主机来做数据中转。\n系统使用的是 Ubuntu 16.04.03 64位OpenVPN 使用最新的稳定版 2.3.18 点此下载\n如果下载不了，可能需要自备梯子或者从其他地方下载。如果使用的 CentOS 系列安装可能需要先关闭 SElinux。\n安装也可以选择直接从官方仓库中下载安装使用。\n解决依赖apt-get install make gcc g++ libssl-dev liblzo2-dev libpam-dev unzip\n这里只适用于 Ubuntu 系统\n编译安装tar xf openvpn-2.3.18.tar.xzcd openvpn-2.3.18./configure --prefix=/usr/local/openvpnmake -j4 &amp;&amp; make installmkdir /etc/openvpncp -rf sample/ /etc/openvpn/    # 拷贝配置文件模块cp /etc/openvpn/sample/sample-config-files/server.conf /etc/openvpn/\n由于系统环境的复杂，配置过程中可能会缺少某些库的头文件，只需要找到这些头文件所在的包然后安装下就好了。\n配置证书服务端证书配置easy-rsacd /etc/openvpngit clone -b release/2.x https://github.com/OpenVPN/easy-rsa.gitcd /etc/openvpn/easy-rsa/easy-rsa/2.0\n然后编辑 vars 文件，修改下列内容的值为随意内容。需要注意的是，值不可以是空的。\nexport KEY_COUNTRY=&quot;US&quot;\nexport KEY_PROVINCE=&quot;California&quot;\nexport KEY_CITY=&quot;SanFrancisco&quot;\nexport KEY_ORG=&quot;Fort-Funston&quot;\nexport KEY_EMAIL=&quot;me@myhost.mydomain&quot;\nexport KEY_OU=&quot;MyOrganizationalUnit&quot;\n我这里修改为了如下内容\nexport KEY_COUNTRY=&quot;CN&quot;\nexport KEY_PROVINCE=&quot;BeiJing&quot;\nexport KEY_CITY=&quot;BeiJing&quot;\nexport KEY_ORG=&quot;wu&quot;\nexport KEY_EMAIL=&quot;admin@localhost.com&quot;\nexport KEY_OU=&quot;openvpn&quot;\n接着修改 export KEY_NAME=&quot;EasyRSA&quot; 这句话，将 EasyRSA 改为自己喜欢的名字，这里就简单的使用 server，修改后就可以保存退出了。\n创建根证书source vars./clean-all./build-ca\n这一步一路的回车就好，因为已经在 vars 文件中配置过了。\nroot@ubuntu:/etc/openvpn/easy-rsa/easy-rsa/2.0# ./build-ca \nGenerating a 2048 bit RSA private key\n............................................................+++\n..........................+++\nwriting new private key to &apos;ca.key&apos;\n-----\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter &apos;.&apos;, the field will be left blank.\n-----\nCountry Name (2 letter code) [CN]:\nState or Province Name (full name) [BeiJing]:\nLocality Name (eg, city) [BeiJing]:\nOrganization Name (eg, company) [wu]:\nOrganizational Unit Name (eg, section) [openvpn]:\nCommon Name (eg, your name or your server&apos;s hostname) [wu CA]:\nName [server]:\nEmail Address [admin@localhost.com]:\n颁发服务端证书./build-key-server server\n这个 server 就是刚才 export KEY_NAME=&quot;EasyRSA&quot; 中指定的名字。之后就是一路的回车，当遇到两个问答的时候都回答 y 就可以了。\nroot@ubuntu:/etc/openvpn/easy-rsa/easy-rsa/2.0# ./build-key-server server\nGenerating a 2048 bit RSA private key\n.......................+++\n..............+++\nwriting new private key to &apos;server.key&apos;\n-----\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter &apos;.&apos;, the field will be left blank.\n-----\nCountry Name (2 letter code) [CN]:\nState or Province Name (full name) [BeiJing]:\nLocality Name (eg, city) [BeiJing]:\nOrganization Name (eg, company) [wu]:\nOrganizational Unit Name (eg, section) [openvpn]:\nCommon Name (eg, your name or your server&apos;s hostname) [server]:\nName [server]:\nEmail Address [admin@localhost.com]:\n\nPlease enter the following &apos;extra&apos; attributes\nto be sent with your certificate request\nA challenge password []:\nAn optional company name []:\nUsing configuration from /etc/openvpn/easy-rsa/easy-rsa/2.0/openssl-1.0.0.cnf\nCheck that the request matches the signature\nSignature ok\nThe Subject&apos;s Distinguished Name is as follows\ncountryName           :PRINTABLE:&apos;CN&apos;\nstateOrProvinceName   :PRINTABLE:&apos;BeiJing&apos;\nlocalityName          :PRINTABLE:&apos;BeiJing&apos;\norganizationName      :PRINTABLE:&apos;wu&apos;\norganizationalUnitName:PRINTABLE:&apos;openvpn&apos;\ncommonName            :PRINTABLE:&apos;server&apos;\nname                  :PRINTABLE:&apos;server&apos;\nemailAddress          :IA5STRING:&apos;admin@localhost.com&apos;\nCertificate is to be certified until Apr 30 07:50:21 2028 GMT (3650 days)\nSign the certificate? [y/n]:y\n\n\n1 out of 1 certificate requests certified, commit? [y/n]y\nWrite out database with 1 new entries\nData Base Updated\n生成Diffie-Hellman文件\nDiffie-Hellman是一种确保共享KEY安全穿越不安全网络的方法\n\n./build-dh/usr/local/openvpn/sbin/openvpn --genkey --secret keys/ta.key\n这一步需要的时间会长一些。\n客户端证书颁发客户端证书使用 build-key 命令可以颁发一个不带密码的证书，如果需要带密码保护的证书，可以使用 build-key-pass 命令。这里使用不带密码的凭证，证书名为 client1\n./build-key client1\n同理 一路回车后最后两个问答输入 y\nroot@ubuntu:/etc/openvpn/easy-rsa/easy-rsa/2.0# ./build-key client1\nGenerating a 2048 bit RSA private key\n....................+++\n..............................+++\nwriting new private key to &apos;client1.key&apos;\n-----\nYou are about to be asked to enter information that will be incorporated\ninto your certificate request.\nWhat you are about to enter is what is called a Distinguished Name or a DN.\nThere are quite a few fields but you can leave some blank\nFor some fields there will be a default value,\nIf you enter &apos;.&apos;, the field will be left blank.\n-----\nCountry Name (2 letter code) [CN]:\nState or Province Name (full name) [BeiJing]:\nLocality Name (eg, city) [BeiJing]:\nOrganization Name (eg, company) [wu]:\nOrganizational Unit Name (eg, section) [openvpn]:\nCommon Name (eg, your name or your server&apos;s hostname) [client1]:\nName [server]:\nEmail Address [admin@localhost.com]:\n\nPlease enter the following &apos;extra&apos; attributes\nto be sent with your certificate request\nA challenge password []:\nAn optional company name []:\nUsing configuration from /etc/openvpn/easy-rsa/easy-rsa/2.0/openssl-1.0.0.cnf\nCheck that the request matches the signature\nSignature ok\nThe Subject&apos;s Distinguished Name is as follows\ncountryName           :PRINTABLE:&apos;CN&apos;\nstateOrProvinceName   :PRINTABLE:&apos;BeiJing&apos;\nlocalityName          :PRINTABLE:&apos;BeiJing&apos;\norganizationName      :PRINTABLE:&apos;wu&apos;\norganizationalUnitName:PRINTABLE:&apos;openvpn&apos;\ncommonName            :PRINTABLE:&apos;client1&apos;\nname                  :PRINTABLE:&apos;server&apos;\nemailAddress          :IA5STRING:&apos;admin@localhost.com&apos;\nCertificate is to be certified until Apr 30 07:58:09 2028 GMT (3650 days)\nSign the certificate? [y/n]:y\n\n\n1 out of 1 certificate requests certified, commit? [y/n]y\nWrite out database with 1 new entries\nData Base Updated\n安置证书现在所有的证书都在 keys 目录中，为了方便使用，将 keys 目录直接软链到 /etc/openvpn/ 下 \nln -s /etc/openvpn/easy-rsa/easy-rsa/2.0/keys/ /etc/openvpn/keys\n到这里，安装的部分就结束了。\n使用服务端配置配置文件编辑服务端配置文件：/etc/openvpn/server.conf 修改内容如下：\nport 2001\nproto udp\ndev tun\nca keys/ca.crt\ncert keys/server.crt\nkey keys/server.key  \ndh keys/dh2048.pem\nserver 10.0.0.0 255.255.255.0\nifconfig-pool-persist ipp.txt\npush &quot;route 10.0.0.0 255.255.255.0&quot;\nclient-to-client\nkeepalive 10 120\ntls-auth keys/ta.key 0 \ncipher AES-256-CBC\nauth SHA256\nkey-direction 0\nuser nobody\ngroup nogroup\npersist-key\npersist-tun\nstatus openvpn-status.log\nverb 3\n需要注意的是，这里使用 udp 的 2001 端口，在阿里云等环境，还需要配置相应的安全组策略来开放这个端口的流量。\nLinux配置开启 Linux 的内核转发功能，编辑 /etc/sysctl.conf 文件，取消掉 #net.ipv4.ip_forward=1 之前的注释。然后执行 sysctl -p 命令。\nroot@ubuntu:/etc/openvpn# sysctl -p\nnet.ipv4.ip_forward = 1\nvm.swappiness = 0\nnet.ipv4.neigh.default.gc_stale_time = 120\nnet.ipv4.conf.all.rp_filter = 0\nnet.ipv4.conf.default.rp_filter = 0\nnet.ipv4.conf.default.arp_announce = 2\nnet.ipv4.conf.lo.arp_announce = 2\nnet.ipv4.conf.all.arp_announce = 2\nnet.ipv4.tcp_max_tw_buckets = 5000\nnet.ipv4.tcp_syncookies = 1\nnet.ipv4.tcp_max_syn_backlog = 1024\nnet.ipv4.tcp_synack_retries = 2\nnet.ipv6.conf.all.disable_ipv6 = 1\nnet.ipv6.conf.default.disable_ipv6 = 1\nnet.ipv6.conf.lo.disable_ipv6 = 1\n还需要确保 iptable 的 FORWARD 链允许数据转发\niptables -P FORWARD ACCEPT\n启动OpenVPN/usr/local/openvpn/sbin/openvpn --cd /etc/openvpn/ --config /etc/openvpn/server.conf\n以调试模式启动 OpenVPN，如果启动过程中有什么错误的话会显示在输出里，确定没有问题了，可以添加 --daemon 参数在后台运行 OpenVPN\nroot@ubuntu:/etc/openvpn# /usr/local/openvpn/sbin/openvpn --cd /etc/openvpn/ --config /etc/openvpn/server.conf \nThu May  3 16:32:55 2018 OpenVPN 2.3.18 x86_64-unknown-linux-gnu [SSL (OpenSSL)] [LZO] [EPOLL] [MH] [IPv6] built on May  3 2018\nThu May  3 16:32:55 2018 library versions: OpenSSL 1.0.2g  1 Mar 2016, LZO 2.08\nThu May  3 16:32:55 2018 Diffie-Hellman initialized with 2048 bit key\nThu May  3 16:32:55 2018 Control Channel Authentication: using &apos;keys/ta.key&apos; as a OpenVPN static key file\nThu May  3 16:32:55 2018 Outgoing Control Channel Authentication: Using 160 bit message hash &apos;SHA1&apos; for HMAC authentication\nThu May  3 16:32:55 2018 Incoming Control Channel Authentication: Using 160 bit message hash &apos;SHA1&apos; for HMAC authentication\nThu May  3 16:32:55 2018 Socket Buffers: R=[212992-&gt;212992] S=[212992-&gt;212992]\nThu May  3 16:32:55 2018 ROUTE_GATEWAY 172.31.143.253/255.255.240.0 IFACE=eth0 HWADDR=00:16:3e:08:fb:5f\nThu May  3 16:32:55 2018 TUN/TAP device tun0 opened\nThu May  3 16:32:55 2018 TUN/TAP TX queue length set to 100\nThu May  3 16:32:55 2018 do_ifconfig, tt-&gt;ipv6=0, tt-&gt;did_ifconfig_ipv6_setup=0\nThu May  3 16:32:55 2018 /sbin/ifconfig tun0 10.0.0.1 pointopoint 10.0.0.2 mtu 1500\nThu May  3 16:32:55 2018 /sbin/route add -net 10.0.0.0 netmask 255.255.255.0 gw 10.0.0.2\nThu May  3 16:32:55 2018 GID set to nogroup\nThu May  3 16:32:55 2018 UID set to nobody\nThu May  3 16:32:55 2018 UDPv4 link local (bound): [undef]\nThu May  3 16:32:55 2018 UDPv4 link remote: [undef]\nThu May  3 16:32:55 2018 MULTI: multi_init called, r=256 v=256\nThu May  3 16:32:55 2018 IFCONFIG POOL: base=10.0.0.4 size=62, ipv6=0\nThu May  3 16:32:55 2018 IFCONFIG POOL LIST\nThu May  3 16:32:55 2018 Initialization Sequence Completed\n使用 ifconfig 命令，应该可以看到多出来了一块 tun0 的网卡。\n制作客户端ovpn文件为了方便客户端的连接，可以在服务端制作好客户端的配置文件，只需将文件下发给客户端，就可以直接使用了。这个文件的拓展名是 ovpn \ncd /etc/openvpn/mkdir make_clientscp sample/sample-config-files/client.conf make_clients/cd make_clients\n然后编辑 client.conf 为以下内容，其中连接服务器的 IP 需要修改为自己的。\nclient\ndev tun\nproto udp\nremote 47.xxx.xxx.155 2001\nresolv-retry infinite\nnobind\nuser nobody\ngroup nogroup\npersist-key\npersist-tun\nremote-cert-tls server\ncipher AES-256-CBC\nauth SHA256\nkey-direction 1\nverb 3\nexplicit-exit-notify 1\n还记得刚才颁发的客户端证书 client1 吧，先为这个证书生成一份配置文件。使用一个自动化脚本来完成配置文件的创建。新建 make_config.sh 脚本，然后写入如下内容\n#!/bin/bash# First argument: Client identifierKEY_DIR=/etc/openvpn/keysOUTPUT_DIR=./filesBASE_CONFIG=./client.confcat $&#123;BASE_CONFIG&#125; \\    &lt;(echo -e '&lt;ca&gt;') \\    $&#123;KEY_DIR&#125;/ca.crt \\    &lt;(echo -e '&lt;/ca&gt;\\n&lt;cert&gt;') \\    $&#123;KEY_DIR&#125;/$&#123;1&#125;.crt \\    &lt;(echo -e '&lt;/cert&gt;\\n&lt;key&gt;') \\    $&#123;KEY_DIR&#125;/$&#123;1&#125;.key \\    &lt;(echo -e '&lt;/key&gt;\\n&lt;tls-auth&gt;') \\    $&#123;KEY_DIR&#125;/ta.key \\    &lt;(echo -e '&lt;/tls-auth&gt;') \\    &gt; $&#123;OUTPUT_DIR&#125;/$&#123;1&#125;.ovpn\n开始创建\nchmod +x make_config.shmkdir files./make_config.sh client1\n这个 client1 就是用户证书的名字，也只有存在才可以创建成功。脚本正常执行后可以在 files 目录中看到 client1.ovpn 文件，这个文件中已经包含了客户端所需要的密钥以及连接信息，所以只需要将这个文件发给用户，然后在客户端上导入就可以直接连接了。不过要注意，基于密钥的认证方式，每个密钥只允许同时一台机器连接使用。\n客户端连接首先需要将生成的 ovpn 文件发送给用户的机器上，然后还需要安装适合当前平台的客户端。\n在 Linux 上登陆 OpenVPNLinux上编译出的 openvpn 程序既可以是服务端，也可以是客户端，所以只需要再下载下来源码包编译一次就可以了。连接也非常方便，直接使用 openvpn --config client1.ovpn 即可。如果想后台运行，也只需要添加 --daemon 参数。\n当连接成功后，可以看到多出来一块 tun0 的网卡\ntun0: flags=4305&lt;UP,POINTOPOINT,RUNNING,NOARP,MULTICAST&gt;  mtu 1500\n        inet 10.0.0.6  netmask 255.255.255.255  destination 10.0.0.5\n        inet6 fe80::bf9f:2316:1d8c:83d1  prefixlen 64  scopeid 0x20&lt;link&gt;\n        unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  txqueuelen 100  (UNSPEC)\n        RX packets 1  bytes 84 (84.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 5  bytes 276 (276.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n服务端IP为 10.0.0.1，可以看看能不能PING通\nroot@raspberrypi:~# ping 10.0.0.1 -c 4\nPING 10.0.0.1 (10.0.0.1) 56(84) bytes of data.\n64 bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=62.2 ms\n64 bytes from 10.0.0.1: icmp_seq=2 ttl=64 time=61.7 ms\n64 bytes from 10.0.0.1: icmp_seq=3 ttl=64 time=68.1 ms\n64 bytes from 10.0.0.1: icmp_seq=4 ttl=64 time=68.1 ms\n\n--- 10.0.0.1 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3005ms\nrtt min/avg/max/mdev = 61.782/65.097/68.185/3.103 ms\n在 Windows 上登陆 OpenVPNWindows 客户端需要在官方下载，下载时可能需要自备梯子，下载地址：点此打开\n下载安装成功后，第一次打开会弹出一个窗口，说没有可以读取的配置文件，这时候只需右击系统状态栏里OpenVPN的小图标，然后选择 Import file... 打开刚才生成的 client1.ovpn 就可以了。然后再次右击小图标，点击 Connect，等弹出的窗口自动退出口，系统也会通知 OpenVPN 是否连接成功。\n在 Windows 上也是可以PING通服务器的\nC:\\Users\\yunfwe\\Desktop&gt;ping 10.0.0.1\n\n正在 Ping 10.0.0.1 具有 32 字节的数据:\n来自 10.0.0.1 的回复: 字节=32 时间=68ms TTL=64\n来自 10.0.0.1 的回复: 字节=32 时间=71ms TTL=64\n来自 10.0.0.1 的回复: 字节=32 时间=62ms TTL=64\n来自 10.0.0.1 的回复: 字节=32 时间=60ms TTL=64\n\n10.0.0.1 的 Ping 统计信息:\n    数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)，\n往返行程的估计时间(以毫秒为单位):\n    最短 = 60ms，最长 = 71ms，平均 = 65ms\n在 Android 上登陆 OpenVPN在谷歌应用商店里可以找到一款名为 openvpn-connect 的apk，使用这个软件也可以通过导入ovpn文件的方式连接到服务器。\n附录","categories":["OpenVPN"],"tags":["openvpn"]},{"title":"MongoDB初探","url":"/2018/02/27/2018/MongoDB%E5%88%9D%E6%8E%A2/","content":"简介\n  MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。\n\n\n环境\n在 CentOS6.8 上使用MongoDB的二进制包 只要不是太古老的Linux系统都可以直接运行。也可以选择在Windows上使用MongoDB。\n\n各版本MongoDB下载地址\n\n\n\n系统类型\n下载地址\n\n\n\n\nLinux\n点击打开\n\n\nWindows\n点击打开\n\n\n\n下载合适的版本 这里使用Linux平台当前最新版 3.6.3 点此下载\n入门篇安装与启动由于使用的是二进制版的MongoDB，直接解压就可以使用了。\ntar xf mongodb-linux-x86_64-3.6.3.tgz -C /usr/local/ln -s /usr/local/mongodb-linux-x86_64-3.6.3/ /usr/local/mongodbmkdir /usr/local/mongodb/data/usr/local/mongodb/bin/mongod --dbpath /usr/local/mongodb/\n当显示waiting for connections on port 27017时MongoDB就成功启动了。使用Ctrl+C停止MongoDB。\n后台运行\n如果想让MongoDB在后台运行 可以使用--fork\n\n/usr/local/mongodb/bin/mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log\n使用--fork必须配合--logpath指定日志输出位置。\n使用--bind_ip 0.0.0.0可以将服务监听到所有网络 --port配置监听端口。\n注意：3.6以前的版本默认是监听在0.0.0.0的，而3.6之后默认监听在127.0.0.1了。\n配置环境变量echo &apos;export PATH=/usr/local/mongodb/bin/:$PATH&apos; &gt; /etc/profile.d/mongodb.shsource /etc/profile.d/mongodb.sh\n这样就可以不用绝对路径来使用mongo相关的命令了。\n使用mongo命令 进入MongoDB交互环境，使用show dbs列出当前默认数据库。\n&gt; show dbs\nadmin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\n&gt; \n到了这一步MongoDB就安装启动成功了，接下来就看看MongoDB如何使用的吧。\n开发篇\nMongoDB使用JavaScript做shell，自MongoDB 2.4以后的版本采用V8引擎执行所有JavaScript代码，对于熟悉JavaScript的开发者MongoDB可以说是非常亲切了。\n\n基本概念MongoDB是一种非关系型数据库(NoSQL)，非关系型数据库以键值对(key-value)存储。键可以理解为关系型数据库的字段名，值为字段值。但是它的结构是不固定的，关系型数据库的每一条记录的字段都是相同的，而NoSQL可以有不同的键，并且NoSQL值的类型都可以是不同的。\n数据库的概念 MongoDB中和关系型数据库相同，使用show dbs看到的就是已经存在的数据库。而表的概念在MongoDB中叫做集合，表中的一行数据 在MongoDB中叫文档。表字段在MongoDB中叫键(key)，表字段值在MongoDB中叫值(value)\n关系型数据库和非关系型数据库对比\n\n\n\n对比项\nMongoDB\nMySQL\n\n\n\n\n数据库\n数据库\n数据库\n\n\n表格\n集合\n二维表\n\n\n表记录\n文档\n一条记录\n\n\n字段名\n键\n字段名\n\n\n字段值\n值\n字段值\n\n\n\n题外话：MongoDB的数据库有点像Python中命令空间的概念，集合就是个列表，而文档就是一个字典了。字典里的键和值也对应着MongoDB的键和值。\n默认的数据库\n\nadmin 类似于MySQL的默认mysql库 用于存放用户账户信息和权限。\nlocal  这个库用于存放主从复制相关的数据\nconfig 当MongoDB用于分片设置时 config数据库在内部使用，用于保存分片的相关信息\n\n基本操作切换数据库使用db命令查看当前使用的数据库，使用use &lt;DB&gt;切换数据库\n&gt; show dbs\nadmin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\n&gt; db\ntest\n&gt; \nMongoDB默认使用的是test库，可是show dbs为什么没有看到test库呢？是因为MongoDB不需要什么创建数据库的语句，也不需要创建表的语句，在需要的时候 也就是你向库中写入数据的时候，如果不存在则才会自动创建。\n接下来切换到mydb中\nuse mydb\n集合中插入文档MongoDB中也不需要显性的创建一个集合，直接向某个集合中插入文档就可以了，如果集合不存在 则会自动创建。\ninsert方法比如我在一个名为person的集合插入一条文档数据\n&gt; db.person.insert({&quot;name&quot;:&quot;xiaoming&quot;,&quot;age&quot;:21})\nWriteResult({ &quot;nInserted&quot; : 1 })\n&gt;\n现在看看库和集合是不是自动创建了呢\n&gt; show dbs;\nadmin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\nmydb    0.000GB\n&gt; show tables;\nperson\n&gt; \n查询集合中的文档find方法再向集合中插入一个文档\n&gt; db.person.insert({&quot;name&quot;:&quot;xiaohong&quot;,&quot;age&quot;:20})\nWriteResult({ &quot;nInserted&quot; : 1 })\n&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 21 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n&gt; \n使用find方法可以查看person集合中的所有文档，面向对象的操作方法 是不是感觉非常简单呢。mongo会给每条文档自动生成_id键，这个可以理解为关系型数据库的主键。\nfind方法使用查询条件来过滤输出，相当于关系型数据库的where\n普通条件查询查询name为xiaoming的文档\n&gt; db.person.find({&quot;name&quot;:&quot;xiaoming&quot;})\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 21 }\n&gt; \n查询age小于21的文档\n&gt; db.person.find({&quot;age&quot;:{$lt:21}})\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n&gt; \n小于等于使用$lte，大于使用$gt，大于等于使用$gte，不等于使用$ne\nAND条件查询查询name为xiaoming 并且age为21的文档\n&gt; db.person.find({&quot;name&quot;:&quot;xiaoming&quot;,&quot;age&quot;:21})\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 21 }\n&gt;\nOR条件查询查询name为xiaoming 或者age为20的文档，可以看到所有匹配的记录都被查到了。\n&gt; db.person.find({$or:[{&quot;name&quot;:&quot;xiaoming&quot;},{&quot;age&quot;:20}]})\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 21 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n&gt; \nAND和OR联合使用类似于 WHERE name=&quot;xiaohong&quot; AND (name=&quot;xiaoming&quot; OR age=20)\n&gt; db.person.find({&quot;name&quot;:&quot;xiaohong&quot;,$or:[{&quot;name&quot;:&quot;xiaoming&quot;},{&quot;age&quot;:20}]})\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n&gt;\nlimit方法使用limit方法可以只输出指定的文档条数\n&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952a2606b5ba9661fa06f1&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad106b5ba9661fa06f2&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n&gt; db.person.find().limit(2)\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n&gt; \nskip方法skip方法输出跳过多少条文档\n&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952a2606b5ba9661fa06f1&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad106b5ba9661fa06f2&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n&gt; db.person.find().skip(2)\n{ &quot;_id&quot; : ObjectId(&quot;5a952a2606b5ba9661fa06f1&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad106b5ba9661fa06f2&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n&gt; \nsort方法sort方法对数据进行排序。sort方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而 -1 是用于降序排列。\n&gt; db.person.find().sort({&quot;age&quot;:1})\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }\n&gt; db.person.find().sort({&quot;age&quot;:-1})\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n&gt; \n题外话：可以使用db.person.find().pretty()来美化数据输出格式。\n更新文档数据\nMongoDB中可以使用update和save方法来更新文档数据，两个方法的应用还是有些区别的。\n\nupdate方法\nupdate方法 第一个参数是查询条件，第二个参数是要修改的键值\n\n将name为xiaoming的记录 age值修改为22\n\n&gt; db.person.update({&quot;name&quot;:&quot;xiaoming&quot;},{$set:{&quot;age&quot;:22}})\nWriteResult({ &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 })\n&gt; db.person.find({&quot;name&quot;:&quot;xiaoming&quot;})\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 22 }\n&gt; \n需要注意的是 update默认只更新匹配到的第一条文档，如果想要更改所有匹配的 使用{multi:true}\ndb.person.update({&quot;name&quot;:&quot;xiaoming&quot;}, {$set:{&quot;age&quot;:20}}, {multi:true})\n从3.2版本开始，MongoDB提供了updateOne()来更新单个文档，updateMany()来更新多个文档。\nsave方法\nsave方法直接传入一个新的文档保存到集合中，如果文档的_id存在 则会替换掉旧文档。\n\n使用save方法\n&gt; db.person.save({\n    &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), \n    &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 \n})\nWriteResult({ &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 })\n&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n&gt; \n删除文档\n删除文档前 先使用find方法验证匹配条件是否正确是一个好习惯\n\nremove方法\nremove方法默认会删除所有匹配的文档，第二个参数传入{justOne: true}则只会删除匹配的一个。\n\n使用remove方法\n&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952a2606b5ba9661fa06f1&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad106b5ba9661fa06f2&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n{ &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 }\n&gt; db.person.remove({&quot;name&quot;:&quot;xiaoming&quot;})\nWriteResult({ &quot;nRemoved&quot; : 3 })\n&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }\n{ &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 }\n&gt; \n想要删除集合中的所有文档 可以使用remove({})。MongoDB官方推荐使用deleteOne和deleteMany来删除文档。\n删除集合drop方法&gt; db.person.drop()\ntrue\n&gt; db.person.find()\n&gt;\n删除数据库dropDatabase方法&gt; db.dropDatabase()\n{ &quot;dropped&quot; : &quot;mydb&quot;, &quot;ok&quot; : 1 }\n&gt; show dbs\nadmin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\n&gt; \n运维篇权限控制\n默认MongoDB是没有启用权限控制的，这样无疑非常不安全。\n\n添加管理员账号&gt; use admin\nswitched to db admin\n&gt; db.createUser({user:&quot;root&quot;,pwd:&quot;123456&quot;,roles:[{&quot;role&quot;:&quot;root&quot;,&quot;db&quot;:&quot;admin&quot;}]})\nSuccessfully added user: {\n    &quot;user&quot; : &quot;root&quot;,\n    &quot;roles&quot; : [\n        {\n            &quot;role&quot; : &quot;root&quot;,\n            &quot;db&quot; : &quot;admin&quot;\n        }\n    ]\n}\n&gt; \n修改启动参数关闭MongoDB后重新启动mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log --bind_ip 0.0.0.0 --auth\n添加--auth参数则可以启用MongoDB的认证功能。\n接下来重新连接MongoDB，看看操作是不是需要认证了。\n&gt; use admin\nswitched to db admin\n&gt; show tables\n2018-02-28T07:57:45.759+0000 E QUERY    [thread1] Error: listCollections failed: {\n    &quot;ok&quot; : 0,\n    &quot;errmsg&quot; : &quot;not authorized on admin to execute command { listCollections: 1.0, filter: {}, $db: \\&quot;admin\\&quot; }&quot;,\n    &quot;code&quot; : 13,\n    &quot;codeName&quot; : &quot;Unauthorized&quot;\n} \n用户认证使用db.auth(user,password)来进行登陆数据库。\n&gt; use admin\nswitched to db admin\n&gt; db.auth(&quot;root&quot;,&quot;123456&quot;)\n1\n&gt; show tables;\nsystem.users\nsystem.version\n&gt; \n可以看到可以操作admin库了\n为其他库配置认证\n需要注意的是 添加认证的库必须存在。\n\n还是需要先切换到admin库中才能为其他库创建认证。\n&gt; use admin\nswitched to db admin\n&gt; db.auth(&quot;root&quot;,&quot;123456&quot;)\n1\n&gt; db.createUser({user:&quot;op&quot;,pwd:&quot;123456&quot;,roles:[{&quot;role&quot;:&quot;readWrite&quot;,&quot;db&quot;:&quot;mydb&quot;}]})\nSuccessfully added user: {\n    &quot;user&quot; : &quot;op&quot;,\n    &quot;roles&quot; : [\n        {\n            &quot;role&quot; : &quot;readWrite&quot;,\n            &quot;db&quot; : &quot;mydb&quot;\n        }\n    ]\n}\n&gt; \n退出后重新登陆MongoDB\n&gt; use mydb\nswitched to db mydb\n&gt; show tables;\n2018-02-28T08:05:19.021+0000 E QUERY    [thread1] Error: listCollections failed: {\n    &quot;ok&quot; : 0,\n    &quot;errmsg&quot; : &quot;not authorized on mydb to execute command { listCollections: 1.0, filter: {}, $db: \\&quot;mydb\\&quot; }&quot;,\n    &quot;code&quot; : 13,\n    &quot;codeName&quot; : &quot;Unauthorized&quot;\n}\n&gt; db.auth(&quot;op&quot;,&quot;123456&quot;)\n1\n&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a96637de474606ab43c8e33&quot;) }\n{ &quot;_id&quot; : ObjectId(&quot;5a966385e474606ab43c8e34&quot;), &quot;a&quot; : 1 }\n&gt; \n数据备份恢复\n数据备份恢复对于数据库系统来说是个非常重要的话题。\n\n数据备份(mongodump)命令用法如下:mongodump -h &lt;HOST&gt; -d &lt;DB&gt; -o &lt;PATH&gt;\n-h 指定连接的主机 格式是IP或者IP:PORT-d 指定备份的库名-o 指定备份的输出路径 默认是当前路径下的dump目录中\n如果库需要认证的话 还需要使用-u和-p参数指定用户名和密码如果不指定库名 则备份所有库。\n比如:mongodump -h 127.0.0.1:27017 -d mydb -o /tmp/dump\n备份目标目录不存在会自动创建。\n数据恢复(mongorestore)命令用法如下:mongorestore -h &lt;HOST&gt; -d &lt;DB&gt; &lt;PATH&gt;\n-h 指定连接的主机 格式是IP或者IP:PORT-d 指定备份的库名&lt;PATH&gt; 最后直接给出从哪恢复数据的目录\n比如将刚才备份的mydb恢复到newdb中mongorestore -h 127.0.0.1:27017 -d newdb /tmp/dump/mydb/\n如果想恢复备份的所有库 可以不指定库名 然后指定所有库所在的父目录即可mongorestore -h 127.0.0.1:27017  /tmp/dump/\n这样子就会按照库名进行恢复了。\n其他备份恢复方式MongoDB还提供了mongoexport和mongoimport工具对数据进行备份，可以将数据备份为csv, json的格式。\n或者还可以停掉MongoDB的服务 直接对MongoDB的数据目录进行备份，注意备份后的目录还存在mongod.lock文件的话需要删除才能在新的库上启动，不过如果存在mongod.lock文件 倒是需要担心备份的数据是否完整了。\nMongoDB集群MongoDB主从复制\n主从复制提供了数据的冗余备份，提高了数据的可用性，并可以保证数据的安全性。官方已经不推荐使用主从复制方式，搭建MongoDB集群还有更好的方式。\n\n主从复制的好处\n\n提高数据安全性，多台服务器同时硬盘损坏的概率是小于单台的\n数据的高可用性，多台服务器同时宕机的概率是小于单台的\n灾难恢复能力，当发生硬盘损坏，数据还有副本以便恢复\n热备份能力，无需关闭或者降级服务就可以对数据进行备份、压缩等。\n分布式读取数据，读取请求可以分发到多台服务器，降低单实例的读写压力。\n\n主从复制原理MongoDB的主从复制至少需要两个节点，一个Master节点，其他的都是Slave节点。\n还记得MongoDB启动后默认的local这个库吗，当Master进行写操作时，Master将写操作记录在local库的oplog集合里。Slave节点就通过读取Master节点的oplog将数据复制到自身一份，并且还会将复制信息写入到自己的oplog中，这样即使是Slave节点 也可以将自己作为同步源给其他Slave节点了。\n需要注意的是，oplog是有固定大小的，到达最大大小后，新的记录会覆盖掉旧的记录。\n主从复制配置\n需要先关闭已经运行的MongoDB进程\n\nMaster节点执行mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log --bind_ip 0.0.0.0 --master\n可以看到只需要在主节点是添加--master 表示这一个Master节点就可以了。\nSlave节点执行mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log --bind_ip 0.0.0.0 --slave --source 192.168.8.253:27017\nSlave节点添加--slave 并指明Master节点的地址--source 192.168.8.253:27017\n验证数据是否同步Master节点执行\n&gt; use mydb\nswitched to db mydb\n&gt; db.test.insert({&quot;a&quot;:1})\nWriteResult({ &quot;nInserted&quot; : 1 })\n&gt; \nSlave节点执行\n&gt; rs.slaveOk()\n&gt; use mydb\nswitched to db mydb\n&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a9619088cd96bc4a16514a9&quot;), &quot;a&quot; : 1 }\n&gt; \n由于Slave节点默认是不允许读写的，所以需要执行rs.slaveOk()来允许读取。\nMongoDB副本集\nReplica Sets方式，也是MongoDB官方推荐的方式。副本集方式比传统的主从复制改进的地方就是可以进行故障自动转移。如果主节点挂了，会自动选举一个从节点作为主，这个过程对用户是透明的。\n\n副本集原理一个副本集即为服务于同一数据集的多个 MongoDB 实例，其中一个为主节点，其余的都为从节点。主节点上能够完成读写操作，从节点仅能用于读操作。主节点需要记录所有改变数据库状态的操作，这些记录 保存在local数据库的oplog中，各个从节点通过此 oplog来复制数据并应用于本地。\n集群中的各节点还会通过传递心跳信息来检测各自的健康状况。当主节点故障时。多个从节点会触发一次新的选举操作，并选举其中的一个成为新的主节点(通常谁的优先级更高，谁就是新的主节点)。心跳信息默认每2秒传递一次。副本集中的副本节点在主节点挂掉后通过心跳机制检测到后，就会在集群内发起主节点的选举机制，自动选举出一位新的主服务器。\n副本集可以包括三种节点：主节点、从节点、仲裁节点。\n\n主节点负责处理客户端请求，读、写数据, 记录在其上所有操作的oplog;\n\n从节点定期轮询主节点的oplog进行同步数据。默认情况下从节点不支持客户端读取数据，但可以设置(rs.slaveOk())；副本集的机制在于主节点出现故障的时候，余下的节点会选举出一个新的主节点，从而保证系统可以正常运行。\n\n仲裁节点不复制数据，仅参与投票。由于它没有访问的压力，比较空闲，因此不容易出故障。由于副本集出现故障的时候，存活的节点必须大于副本集节点总数的一半，否则无法选举主节点，或者主节点会自动降级为从节点，整个副本集变为只读。因此，增加一个不容易出故障的仲裁节点，可以增加有效选票，降低整个副本集不可用的风险。仲裁节点可多于一个。也就是说只参与投票，不接收复制的数据，也不能成为活跃节点。仲裁节点并非必须存在。\n\n\nMongoDB 3.0之后官方推荐MongoDB副本集节点最少为3台，最多50台，仲裁节点最大为7个。为了避免脑裂发生 副本集成员最好为奇数。太多的副本集成员会增加复制成本，反而拖累整个集群。\n副本集配置\n注意：--dbpath的路径如果已经存在数据 最好先清除。\n\n所有节点执行mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log --bind_ip 0.0.0.0 --replSet rstest\n只需要在启动参数上增加--replSet rstest，rstest是副本集的名称。 \n登陆某个节点执行\n&gt; var cfg = {_id:&quot;rstest&quot;,members:[ \n    {_id:0,host:&apos;10.0.0.3:27017&apos;,priority:2}, \n    {_id:1,host:&apos;10.0.0.4:27017&apos;,priority:1},   \n    {_id:2,host:&apos;10.0.0.5:27017&apos;,arbiterOnly:true}] \n};\n&gt; rs.initiate(cfg)\n{\n    &quot;ok&quot; : 1,\n    &quot;operationTime&quot; : Timestamp(1519793379, 1),\n    &quot;$clusterTime&quot; : {\n        &quot;clusterTime&quot; : Timestamp(1519793379, 1),\n        &quot;signature&quot; : {\n            &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;),\n            &quot;keyId&quot; : NumberLong(0)\n        }\n    }\n}\nrstest:SECONDARY&gt; \n将10.0.0.3的优先级配置为2，10.0.0.5配置为仲裁节点。稍等一下，然后执行rs.status()方法看看10.0.0.3是否被选举为了PRIMARY\n&quot;members&quot; : [\n        {\n            &quot;_id&quot; : 0,\n            &quot;name&quot; : &quot;10.0.0.3:27017&quot;,\n            &quot;health&quot; : 1,\n            &quot;state&quot; : 1,\n            &quot;stateStr&quot; : &quot;PRIMARY&quot;,\n            &quot;uptime&quot; : 228,\n            &quot;optime&quot; : {\n                &quot;ts&quot; : Timestamp(1519794123, 1),\n                &quot;t&quot; : NumberLong(2)\n            },\n            &quot;optimeDate&quot; : ISODate(&quot;2018-02-28T05:02:03Z&quot;),\n            &quot;electionTime&quot; : Timestamp(1519793982, 1),\n            &quot;electionDate&quot; : ISODate(&quot;2018-02-28T04:59:42Z&quot;),\n            &quot;configVersion&quot; : 1,\n            &quot;self&quot; : true\n        },\nrs.status()方法可以详细的看到集群中每个节点的状态。\n验证副本集数据同步主节点插入数据\nrstest:PRIMARY&gt; use mydb\nswitched to db mydb\nrstest:PRIMARY&gt; db.person.insert({&quot;a&quot;:1})\nWriteResult({ &quot;nInserted&quot; : 1 })\nrstest:PRIMARY&gt;\n从节点验证数据\nrstest:SECONDARY&gt; rs.slaveOk()\nrstest:SECONDARY&gt; show dbs;\nadmin   0.000GB\nconfig  0.000GB\nlocal   0.000GB\nmydb    0.000GB\nrstest:SECONDARY&gt; use mydb\nswitched to db mydb\nrstest:SECONDARY&gt; db.person.find()\n{ &quot;_id&quot; : ObjectId(&quot;5a96386fe6101b17e4e221f0&quot;), &quot;a&quot; : 1 }\nrstest:SECONDARY&gt;\n验证副本集故障转移关闭主节点服务\nrstest:PRIMARY&gt; use admin\nswitched to db admin\nrstest:PRIMARY&gt; db.shutdownServer()\n登陆其他节点查看主节点是否更变\n&gt; rs.status()\n    {\n            &quot;_id&quot; : 1,\n            &quot;name&quot; : &quot;10.0.0.4:27017&quot;,\n            &quot;health&quot; : 1,\n            &quot;state&quot; : 1,\n            &quot;stateStr&quot; : &quot;PRIMARY&quot;,\n            &quot;uptime&quot; : 812,\n            &quot;optime&quot; : {\n                &quot;ts&quot; : Timestamp(1519794720, 1),\n                &quot;t&quot; : NumberLong(3)\n            },\n            &quot;optimeDate&quot; : ISODate(&quot;2018-02-28T05:12:00Z&quot;),\n            &quot;electionTime&quot; : Timestamp(1519794589, 1),\n            &quot;electionDate&quot; : ISODate(&quot;2018-02-28T05:09:49Z&quot;),\n            &quot;configVersion&quot; : 1,\n            &quot;self&quot; : true\n        },\n当原本的主节点上线后，会根据优先级重新选举，所以主节点就恢复到10.0.0.3上了。\n副本集的常用操作查看集群配置信息local库的system.replset集合存放着集群所有节点的信息，也可以使用rs.conf()来查看\n&gt; use local\n&gt; db.system.replset.find().pretty()\n&gt; rs.conf()\n重新配置副本集\n注意：重新配置副本集必须在主节点上进行\n\n更改主从节点的优先级，使用rs.reconf()方法重新加载配置\nrstest:PRIMARY&gt; var cfg = {_id:&quot;rstest&quot;,members:[ \n    {_id:0,host:&apos;10.0.0.3:27017&apos;,priority:1}, \n    {_id:1,host:&apos;10.0.0.4:27017&apos;,priority:2},\n    {_id:2,host:&apos;10.0.0.5:27017&apos;,arbiterOnly:true}] \n};\nrstest:PRIMARY&gt; rs.reconfig(cfg)\n{\n    &quot;ok&quot; : 1,\n    &quot;operationTime&quot; : Timestamp(1519795465, 1),\n    &quot;$clusterTime&quot; : {\n        &quot;clusterTime&quot; : Timestamp(1519795465, 1),\n        &quot;signature&quot; : {\n            &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;),\n            &quot;keyId&quot; : NumberLong(0)\n        }\n    }\n}\nrstest:PRIMARY&gt;\n动态添加和删除节点添加从节点\nrstest:PRIMARY&gt; rs.add(&quot;10.0.0.6:27017&quot;)\n{\n    &quot;ok&quot; : 1,\n    &quot;operationTime&quot; : Timestamp(1519796327, 1),\n    &quot;$clusterTime&quot; : {\n        &quot;clusterTime&quot; : Timestamp(1519796327, 1),\n        &quot;signature&quot; : {\n            &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;),\n            &quot;keyId&quot; : NumberLong(0)\n        }\n    }\n}\nrstest:PRIMARY&gt;\n添加仲裁节点\nrstest:PRIMARY&gt; rs.addArb(&quot;10.0.0.7:27017&quot;)\n{\n    &quot;ok&quot; : 1,\n    &quot;operationTime&quot; : Timestamp(1519796416, 1),\n    &quot;$clusterTime&quot; : {\n        &quot;clusterTime&quot; : Timestamp(1519796416, 1),\n        &quot;signature&quot; : {\n            &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;),\n            &quot;keyId&quot; : NumberLong(0)\n        }\n    }\n}\n删除节点\nrstest:PRIMARY&gt; rs.remove(&quot;10.0.0.7:27017&quot;)\n{\n    &quot;ok&quot; : 1,\n    &quot;operationTime&quot; : Timestamp(1519796468, 1),\n    &quot;$clusterTime&quot; : {\n        &quot;clusterTime&quot; : Timestamp(1519796468, 1),\n        &quot;signature&quot; : {\n            &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;),\n            &quot;keyId&quot; : NumberLong(0)\n        }\n    }\n}\nMongodb分片集群\nSharding cluster是一种可以水平扩展的模式，在数据量很大时特给力。\n\n分片集群原理在数据量非常大的情况下，单台MongoDB数据库的性能会严重下降，而将数据分片可以很好的解决单台服务器磁盘空间、内存、CPU等硬件资源的限制问题。\n把数据水平拆分出去，降低单节点的访问压力。每个分片都是一个独立的数据库，所有的分片组合起来构成一个逻辑上的完整的数据库。因此，分片机制降低了每个分片的数据操作量及需要存储的数据量，达到多台服务器来应对不断增加的负载和数据的效果。\n一个分片集群需要三种角色\n\n分片服务器(Shard Server) mongod实例，用于存储实际的数据块。分片服务器可以是一个副本集集群共同来提供服务 防止单点故障。\n配置服务器(Config Server) mongod实例，存储整个集群和分片的元数据，就像是一本书的目录，保存的只是数据的分布表。\n路由服务器(Route Server) mongos实例，客户端由此接入，本身不存放数据，仅供程序连接，起到一个路由的作用。\n\n分片集群在数据量非常大的情况下才能展现能力，这里只做简单讲解。\n附录MongoDB配置文件实验中启动MongoDB都是通过命令行参数的方式启动的，这样显然并不是很友好。可以将参数写入到配置文件中，然后启动的时候通过--config或者-f启动。\n比如 可以将参数写入以下配置文件\ndbpath = /usr/local/mongodb/data/\nfork = true\nlogpath = /var/log/mongod.log\nbind_ip = 0.0.0.0\nauth = true\n像--fork和--auth 启用就填true，禁用就填false\n重新启动MongoDB\nkillall mongodmongod -f mongod.conf\n也可以登陆到MongoDB中，使用admin库的shutdownServer方法关闭服务。\n&gt; use admin\nswitched to db admin\n&gt; db.shutdownServer()\nserver should be down...\n2018-02-28T08:24:49.077+0000 I NETWORK  [thread1] trying reconnect to 127.0.0.1:27017 (127.0.0.1) failed\n","categories":["MongoDB"],"tags":["nosql","mongodb"]},{"title":"Pyenv Python版本管理器","url":"/2018/10/08/2018/Pyenv%20Python%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8/","content":"\n简介\nNode.js 有一个非常好用的版本管理器叫 nvm，可以很方便的安装和管理多种 node.js 的版本，于是开始寻找 Python 是否也存在类似的工具，这样可以方便的切换 Python2 和 Python3 的环境，以及 Python 发布新版本后可以迅速的体验一番，而且还不会对当前系统环境照成影响。所幸 遇到了 pyenv 这个工具。项目主页：https://github.com/pyenv/pyenv\n\n安装这里在 ubuntu 16.04 上安装 pyenv，其他发行版上安装方法也都大同小异。\n安装 pyenvpyenv 默认会安装在 ~/.pyenv，可以通过设置环境变量 PYENV_ROOT 来改变这个目录。如果是普通用户，就最好将 pyenv 安装到自己家目录了。\n安装依赖apt-get updateapt-get install curl git\n使用自动化脚本安装pyenvexport PYENV_ROOT=\"/usr/local/pyenv\"curl -L https://github.com/pyenv/pyenv-installer/raw/master/bin/pyenv-installer | bash\n修改 .bashrc 使其自动加载 pyenv\necho 'export PYENV_ROOT=\"/usr/local/pyenv\"' &gt;&gt; ~/.bashrcecho 'export PATH=\"/usr/local/pyenv/bin:$PATH\"' &gt;&gt; ~/.bashrcecho 'eval \"$(pyenv init -)\"' &gt;&gt; ~/.bashrcecho 'eval \"$(pyenv virtualenv-init -)\"' &gt;&gt; ~/.bashrcexec bash\n这时可以检查 pyenv 命令是否可用了。\nroot@localhost:~# pyenv\npyenv 1.2.7\nUsage: pyenv &lt;command&gt; [&lt;args&gt;]\n\nSome useful pyenv commands are:\n    commands    List all available pyenv commands\n    local       Set or show the local application-specific Python version\n    global      Set or show the global Python version\n    shell       Set or show the shell-specific Python version\n    install     Install a Python version using python-build\n    uninstall   Uninstall a specific Python version\n    rehash      Rehash pyenv shims (run this after installing executables)\n    version     Show the current Python version and its origin\n    versions    List all Python versions available to pyenv\n    which       Display the full path to an executable\n    whence      List all Python versions that contain the given executable\n\nSee `pyenv help &lt;command&gt;&apos; for information on a specific command.\nFor full documentation, see: https://github.com/pyenv/pyenv#readme\n使用查看可以安装的 Python 环境命令： pyenv install --list\n这条命令会列出当前可用的所有Python环境，可以看到可选的环境官方的加上第三方的是非常多的\n安装目标 Python 环境命令： pyenv install ${version}\n只需要将 ${version} 写成上面列出的所有可选的 Python 环境即可，Python 的源码包会存放到 ${PYENV_ROOT} 目录下的 cache 目录下(如果没有需要手动创建)，默认从官方镜像站下载，如果速度比较慢，可以选择手动从国内镜像站下载，手动将源码包放入这个目录，然后再执行安装命令。\n# 首先安装编译Python需要的开发包和开发工具apt-get install zlib1g-dev libbz2-dev libssl-dev libncurses5-dev  \\libsqlite3-dev libreadline-dev tk-dev libgdbm-dev libdb-dev \\libpcap-dev xz-utils libexpat-dev gcc make# 手动放置源码包的方式# mkdir $&#123;PYENV_ROOT&#125;/cache# cd $&#123;PYENV_ROOT&#125;/cache# wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tar.xz# 执行编译安装pyenv install 3.6.6\n如果需要将 Python 编译为动态共享库的方式，则需要将编译参数通过环境变量传给 pyenv\nenv PYTHON_CONFIGURE_OPTS=\"--enable-shared\" pyenv install 3.6.6\n安装完成\nroot@localhost:~# env PYTHON_CONFIGURE_OPTS=&quot;--enable-shared&quot; pyenv install 3.6.6\nInstalling Python-3.6.6...\nInstalled Python-3.6.6 to /usr/local/pyenv/versions/3.6.6\n列出当前版本命令： pyenv version 查看当前版本\nroot@localhost:~# pyenv version\nsystem (set by /usr/local/pyenv/version)\n命令： pyenv versions 查看当前可用版本\nroot@localhost:~# pyenv versions\n* system (set by /usr/local/pyenv/version)\n  3.6.6\n切换当前 shell 会话的 Python 版本命令： pyenv shell 3.6.6\nroot@localhost:~# python -V\nPython 2.7.12\nroot@localhost:~# pyenv shell 3.6.6\nroot@localhost:~# python -V\nPython 3.6.6\n这个命令并不会影响其他会话里的 Python 版本，而且在关闭这个 shell 会话后，设置就消失了，所以只是临时的。\n指定全局的 Python 版本命令： pyenv global 3.6.6\n这时全局的 Python 版本都变成了指定的 3.6.6，如果想设置回系统默认的版本可以使用 pyenv global system\n设置某个目录使用的 Python 版本命令： pyenv local 3.6.6\n这个目录就比较有意思了，当进入某个目录后，然后在这个目录下执行这个命令，那么以后只要切换到这个目录，那么使用的 Python 版本就是指定的这个版本了。\n如果想取消这个设置，可以删除这个目录下的 .python-version 文件\n卸载已安装的 Python 版本命令： pyenv uninstall 3.6.6\n辛辛苦苦安装上，我就不测试执行了。\n附录再配合上 Python 的虚拟环境，简直强无敌啊，更重要的是，非 root 用户也可以随意的安装配置不同的 Python 版本了。\n","categories":["Python"],"tags":["python"]},{"title":"一步步搭建PXE网络装机","url":"/2018/06/03/2018/%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%90%AD%E5%BB%BAPXE%E7%BD%91%E7%BB%9C%E8%A3%85%E6%9C%BA/","content":"简介\nPXE (preboot execute environment，预启动执行环境) 是由 Intel 公司设计的协议，它可以使计算机通过网络启动。当计算机引导时，BIOS 把 PXE client 调入内存执行，并显示出命令菜单，经用户选择后，PXE client将放置在远端的操作系统通过网络下载到本地运行。除了可以通过网络直接运行操作系统外，也可以用于通过网络来将系统安装到本地。在运维中工作中，通过 PXE 来为机房服务器批量部署系统是非常方便的。\n\n\n环境PXE 对运行环境没有什么需求，只需能提供 tftp, dhcp, http 等服务的系统即可。这里使用 Linux 环境来搭建PXE服务。使用 dnsmasq 这个小巧玲珑的软件提供 tftp 和 dhcp 服务，使用 Nginx 来提供 http 服务。\n步骤PXE 的启动原理是 PXE client 在网卡的 ROM 中，可以在计算机开机的时候选择通过硬盘引导还是 PXE 等引导方式，比如 DELL 的服务器在出现开机 LOGO 画面后通过键入 F12 来进入 PXE 引导，Vmware 新创建的虚拟机在第一次启动的时候如果没有装载光驱或者ISO镜像，则会尝试通过网络引导。如果是笔记本或者台式机可以在开机的时候进入引导菜单，然后选择通过网卡设备启动。\n当进入 PXE 引导界面后，PXE client 会向网络中的 dhcp 服务器请求IP地址，dhcp 服务器发现是个 PXE client 的请求会将分配好的IP和引导程序的访问地址返回给 PXE client。这个引导程序一般是名为 pxelinux.0 的文件，这个文件是通过 tftp 协议发送给 PXE client 的。当客户端成功获取到引导文件和引导文件的相关配置文件后就成功加载出引导菜单。这个菜单则是我们通过更改 pxelinux.0 的配置文件来的。下面是通过Vmware引导的效果：\n如果在30秒内没做任何选择则默认从本地磁盘启动，这样就避免了某些将PXE启动作为第一启动项的服务器重启后误重装系统。当选择了某个项目的时候，比如 Install CentOS6.8 for vmware 则向服务器获取根据配置文件中指定的 CentOS 内核文件和启动参数。当需要的数据都准备好后，系统则开始启动 Linux 内核，接下来的操作就跟普通的安装系统没两样了，只不过需要的数据都是通过网络获取的。比如安装 CentOS 过程中需要的所有 rpm 包都是通过 http 服务提供的 CentOS 镜像站提供的了。\n但是如何通过 PXE 来同时安装成百上千台服务器呢？在安装系统的过程中，总会遇到各种需要交互的地方，比如给硬盘分区，选择语言，创建用户等地方，幸好大部分的系统安装镜像都支持通过 Kickstart 自动应答在安装过程中免人工干预的进行系统安装。就像是你的所有问题的回答我先写成一个文件，然后你需要问的时候先从文件中找答案一样。自动应答文件通常是 ks.cfg 文件，此文件的位置大多通过在启动 Linux 内核的时候通过启动参数的方式告诉内核。\n接下来就看看 PXE 启动该如何配置。\n服务配置安装 dnsmasq可以首先从Linux发行版的官方仓库中找找有没有 dnsmasq 的软件包，如果没有可以下载编译。\n编译方法：cd /usr/local/src/wget http://www.thekelleys.org.uk/dnsmasq/dnsmasq-2.79.tar.xztar xf dnsmasq-2.79.tar.xzcd dnsmasq-2.79 &amp;&amp; makecp src/dnsmasq /usr/local/bin/\n只需要将 dnsmasq 的二进制文件放到系统环境变量就可以了，接下来给它提供一个配置文件来告诉它要启动哪些服务。源码目录下有一个官方提供的配置文件模板，不过我们并不需要这么多的配置。\nmkdir -p /data/pxeboot          # PXE启动所需要的文件就都放到这里了cd /data/pxebootvim dnsmasq.conf\n然后写入以下内容：\n# enable dhcp\ndhcp-range=192.168.4.10,192.168.4.200,12h\ndhcp-option=3,192.168.4.254\ndhcp-option=option:dns-server,114.114.114.114,119.29.29.29\n#dhcp-boot=pxelinux.0\ndhcp-boot=undionly.kpxe\n\n# disable dns\nport=0\n\n# enable tftp\nenable-tftp\ntftp-root=/data/pxeboot\n一定要注意，dhcp-range 给客户端分配的IP地址池一定要是自己网段的。根据前面讲解的 PXE 启动的原理，可能大家会比较好奇，为什么这里 dhcp 推送的是 undionly.kpxe 这个文件呢？这个会在下面讲到，接下来就可以先启动 dnsmasq 了。\ndnsmasq -C dnsmasq.conf -d      # 如果不加 -d 参数，dnsmasq 则进入后台运行\n[root@localhost pxeboot]# dnsmasq -C dnsmasq.conf -d\ndnsmasq: started, version 2.79 DNS disabled\ndnsmasq: compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN ......\ndnsmasq-dhcp: DHCP, IP range 192.168.4.10 -- 192.168.4.200, lease time 12h\ndnsmasq-tftp: TFTP root is /data/pxeboot \n现在基础的 dhcp 和 tftp 服务已经搭建完成了，dhcp 监听在 udp 67 端口，tftp 监听在 udp 69，使用前最好关闭服务器的 selinux 和 iptables。\n安装 Nginx也不一定非要使用 Nginx，只要是能提供通过 HTTP 协议对文件进行访问服务的程序都可以，只不过感觉 Nginx 用起来更得心应手一些。同样，如果可以从发行版的官方仓库安装就非常省事了，或者手动编译也可以。\n编译方法：\ncd /usr/local/src/wget http://nginx.org/download/nginx-1.14.0.tar.gztar xf nginx-1.14.0.tar.gzcd nginx-1.14.0./configure --prefix=/usr/local/nginx --without-http_rewrite_modulemake -j4 &amp;&amp; make install\n因为用不到 Nginx 的 rewrite 规则，而且这个模块依赖 pcre 库，所以就去掉了，接下来简单的配置下 Nginx。\nmkdir -p /data/wwwroot/pxefiles         # /data/wwwroot 作为HTTP根目录vim /usr/local/nginx/conf/nginx.conf\n然后写入以下内容：\nworker_processes  4;\nevents {\n    worker_connections  1024;\n}\nhttp {\n    include       mime.types;\n    default_type  application/octet-stream;\n    sendfile        on;\n    autoindex       on;\n    keepalive_timeout  65;\n    server {\n        listen       80;\n        server_name  localhost;\n        location / {\n            root   /data/wwwroot;\n            index  index.html index.htm;\n        }\n        error_page   500 502 503 504  /50x.html;\n        location = /50x.html {\n            root   html;\n        }\n    }\n}\n/usr/local/nginx/sbin/nginx     # 启动Nginx服务\n安装 ipxe 引导文件为什么这里又出现了 ipxe 引导文件呢？理论上来说，只是用 pxelinux.0 确实也可以引导各种系统，但是 pxelinux.0  只支持使用 tftp 协议来加载需要的文件。 tftp 在使用 UDP 传输数据，为了保证文件的完整性，tftp 自己实现了一套数据校验机制，但是却大大降低了文件传输效率。而且某些未知情况下 tftp 在局域网内居然只有 KB 级别的传输速率。于是，一些支持 http 、ftp、nfs 等文件传输协议的引导程序诞生了，ipxe 就是其中一种。\nipxe 提供的引导文件针对不同使用场合又分好几种，比如 .pxe，.kpxe，.kkpxe 格式的引导文件。比较常见的是 .pxe，.kpxe，其中的区别可以看这里：点此打开，这里使用 undionly.kpxe 引导文件，采用链式加载的方法加载 pxelinux.0。这样就可以实现既使用 ipxe 提供的网络协议支持，还可以使用 pxelinux.0 提供的引导界面了。\n编译 undionly.kpxe：\ncd /usr/local/src/git clone git://git.ipxe.org/ipxe.gitcd ipxe/srcvim embed.ipxe\n写入如下内容：\n#!ipxe\ndhcp\nchain tftp://${next-server}/menu.ipxe\n其中 ${next-server} 会自动解析为 dhcp 服务器的地址，tftp 也搭建在这个地址上。当通过 dhcp 获取到IP地址后，通过 tftp 协议请求 menu.ipxe 文件，然后 ipxe 会解析和执行文件里的内容，这个文件可以说就是 ipxe 的配置文件了。接着编译出 undionly.kpxe，这样 undionly.kpxe 才会默认就加载同目录下的 menu.ipxe 文件了。\nmake bin/undionly.kpxe EMBED=embed.ipxecp bin/undionly.kpxe /data/pxeboot/\n其中编译步骤需要 lzma.h 这个头文件，需要安装你的发行版上提供这个头文件的软件包。编译好的 undionly.kpxe 可以保存下来下次搭建环境的时候直接用，如果服务是搭建在 Windows 系统上也可以使用这个编译好的文件。\n然后编辑 menu.ipxe 文件，配置接下来的文件都通过 http 协议来访问，并且链接到 pxelinux.0。\nvim /data/pxeboot/menu.ipxe\n写入如下内容：\n#!ipxe\nset 210:string http://192.168.4.6/pxefiles/\nset 209:string pxelinux.cfg/default\nchain ${210:string}pxelinux.0\n其中 set 210:string 定义了请求的文件的主目录，因为之前创建的 /data/wwwroot/ 为 http 的根目录，/data/wwwroot/pxefiles/ 目录中存放 pxelinux.0 相关的数据文件。其中的服务器IP地址需要替换为你实际的服务器IP。set 209:string 则定义了 pxelinux.0 直接加载 pxelinux.cfg/default 这个配置文件，否则 pxelinux.0 会阶梯性的查找配置文件，如果都没找到最后默认才加载 pxelinux.cfg/default。\n安装 pxelinux.0 引导文件接下来的操作就是在 /data/wwwroot/pxefiles/ 目录下进行了，因为 ipxe 启动后剩下的文件都是通过 http 协议访问的。\npxelinux.0 可以通过发行版的 syslinux 包来获取，或者自己从官方下载也可，这里采用从官方下载的方式。\ncd /usr/local/src/wget https://mirrors.edge.kernel.org/pub/linux/utils/boot/syslinux/Testing/3.86/syslinux-3.86-pre4.tar.xztar xf syslinux-3.86-pre4.tar.xzcd syslinux-3.86-pre4cp com32/menu/vesamenu.c32 /data/wwwroot/pxefiles/cp core/pxelinux.0 /data/wwwroot/pxefiles/cp memdisk/memdisk /data/wwwroot/pxefiles/\nsyslinux 最新版是16年发布的 6.04，但是使用中发现无法引导 ESXI，而且 pxelinux.0 引导后还要加载好几个 .c32 文件，所以采用老一点的 3.86 版本。 接着给 pxelinux.0 提供配置文件\ncd /data/wwwroot/pxefiles/mkdir pxelinux.cfgvim pxelinux.cfg/default\n写入以下内容：\ndefault vesamenu.c32\ntimeout 300\n\nmenu title Welcome to PXE server!\nmenu background splash.jpg\nmenu color border 0 #ffffffff #00000000\nmenu color sel 7 #ffffffff #ff000000\nmenu color title 0 #ffffffff #00000000\nmenu color tabmsg 0 #ffffffff #00000000\nmenu color unsel 0 #ffffffff #00000000\nmenu color hotsel 0 #ff000000 #ffffffff\nmenu color hotkey 7 #ffffffff #ff000000\nmenu color scrollbar 0 #ffffffff #00000000\n\nlabel local\n    menu label Boot from local drive\n    menu default\n    localboot 0xffff\n这里为了界面美观使用了一张背景图片: splash.jpg，图片需要是一张 640*480 像素的 jpg 图片，并根据图片的主题颜色调整下页面边框、文字等颜色，如果不需要使用背景图片的话可以将 menu background 和 menu color 的配置项都删掉或者注释掉。\n其中 timeout 300 会在引导界面30秒无操作就就启动下面 label 中定义为 menu default 的条目。到这一步已经可以尝试将虚拟机或者主机通过 PXE 启动，看看是否可以加载出引导界面了。\n接下来，试试通过 PXE 实际启动或安装一些系统吧！\n网络启动\n即使是通过网络安装，也是需要系统的镜像包的。最好先将需要安装的系统的镜像下载到本地，当然如果对自己网速很自信的话是可以直接通过公网来安装系统的（方法见附录）。\n\n安装 CentOS下载系统镜像下载最新的CentOS镜像可以去官网或者国内的镜像站找，旧版本的可以在官网里找到。或者一个简单的方法，http://mirror.nsc.liu.se/centos-store/6.8/isos/x86_64/  把其中的6.8改为相应的版本号就可以了。\n这里使用和机房服务器系统版本一致的 CentOS 6.8 镜像，如果只是想安装一个最小化的 CentOS 系统的话，选择 minimal.iso，而如果想安装带桌面的甚至想搭建一个本地的yum源，就使用 bin-DVD1.iso 和 bin-DVD2.iso 这两个镜像。其中 bin-DVD2.iso 不可用于系统安装，因为里面只是额外的RPM包，搭建 yum源的话可以将两个镜像的内容合并到一个目录中。还有个是 LiveCD.iso 或者 LiveDVD.iso 的镜像，这种镜像可以直接刻录到光盘并从光盘启动系统。\n这里直接使用 bin-DVD 的镜像。\n配置安装源首先将 bin-DVD1.iso 和 bin-DVD2.iso 的内容合并到一个目录中mkdir -p /data/wwwroot/yum/CentOS6.8/ mount -o loop CentOS-6.8-x86_64-bin-DVD1.iso /mnt/cp -rf /mnt/* /data/wwwroot/yum/CentOS6.8/umount /mnt/mount -o loop CentOS-6.8-x86_64-bin-DVD2.iso /mnt/cp -rf /mnt/* /data/wwwroot/yum/CentOS6.8/      # 所有同名文件都覆盖掉umount /mnt/ln -s /data/wwwroot/yum/ /data/wwwroot/pxefiles/yum\n这里创建了一个软链接的原因是 menu.ipxe 中定义为pxe主目录在 /data/wwwroot/pxefiles/ 中。\n准备自动应答文件每次安装完 CentOS 的系统后不知道大家是否有留意root用户家目录下的三个文本文件 anaconda-ks.cfg，install.log，install.log.syslog。其中 anaconda-ks.cfg 就是系统安装过程中的所有问答产生的 ks.cfg 自动应答文件，这个是可以直接拿来用的。\n如果这个文件被删除了，那么也可以通过软件包 system-config-kickstart 来定制，此工具需要在图形化界面下或者配置好了X11转移的环境中使用。使用 yum -y install system-config-kickstart 安装后使用 system-config-kickstart 运行程序。\n配置好后使用 Ctrl+S 保存并退出，将制作好的 ks.cfg 文件或者 anaconda-ks.cfg 复制到刚才创建的yum源中。因为不同的主机类型可能对应着不同的自动应答文件，所以可以保存为针对不同安装类型或平台的自动应答文件。\ncp /root/anaconda-ks.cfg /data/wwwroot/yum/CentOS6.8/ks-minimal-vmware.cfg\nks-minimal-vmware.cfg 文件内容为：\ninstall\nreboot\ntext\nurl --url=http://192.168.4.6/yum/CentOS6.8\nlang zh_CN.UTF-8\nkeyboard us\nnetwork --onboot yes --device eth0 --mtu=1500 --bootproto dhcp --noipv6\n# root passwd : 123456\nrootpw  --iscrypted $6$5dCFp4Me$YkPWb8h0M/wRUPH3puKXcmbhsErJxfFPCXTtIzfglpfHriMBJsRtqjS5Ewh6Vj/h3mnRdXfsAGcadD3TpRAlk1\nfirewall --service=ssh\nauthconfig --enableshadow --passalgo=sha512\nselinux --disabled\ntimezone --utc Asia/Shanghai\nbootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb rhgb quiet quiet&quot;\nzerombr\nclearpart --all --drives=sda\npart /boot --fstype=ext4 --size=500\npart swap --size=2048\npart / --fstype=ext4 --grow --size=1\nrepo --name=&quot;CentOS&quot;  --baseurl=http://192.168.4.6/yum/CentOS6.8 --cost=100\n%packages\n@Base\n@Core\n%post\ncd /etc/yum.repos.d/\nmkdir bak\nmv * bak\ncat &gt;&gt; CentOS-Base.repo &lt;&lt;END\n[base]\nname=CentOS-$releasever Base\nbaseurl=http://192.168.4.6/yum/CentOS6.8\nenabled=1\ngpgcheck=0\nEND\nyum update\nyum -y install lrzsz\n其中配置了 root 密码为 123456，只安装了最基础的软件包。在安装完之后自动配置系统的yum源到本地服务器上，并且安装 lrzsz 工具包。这里密码是通过加密后的，也可以直接使用 rootpw 123456 这种方式。其中 reboot 会在安装完成后自动重启。\n添加PXE启动项该为 pxelinux.0 添加 CentOS6.8 的启动项了，编辑 pxelinux.cfg/default，在 label local 前添加如下配置块：\nlabel centos6.8\n    menu label Install CentOS6.8 for vmware (minimal install)\n    kernel /yum/CentOS6.8/images/pxeboot/vmlinuz\n    append initrd=/yum/CentOS6.8/images/pxeboot/initrd.img ks=http://192.168.4.6/yum/CentOS6.8/ks-minimal-vmware.cfg ksdevice=eth0\nkernel 和 initrd 可以使用文件对于URL的相对路径，加载的内核也是 CentOS 镜像中提供的支持PXE启动的内核文件。ks 是传给内核的参数，制定了自动应答文件的位置。内核启动后就不是由PXE控制网卡了，就无法使用相对路径的方式获取文件，所以自动应答文件要使用全路径。ksdevice 在单网卡的情况下可以不指定，如果是多网卡的服务器不指定 ksdevice 的话，安装过程则会停在让你手动选择要使用的网卡界面。\n开始安装再次进入PXE引导界面，可以看到刚才新加的启动项生效了，接着选择它并回车。\n可以看到剩下的过程根本没有人工干预就安装完成了。\n安装完成后会自动重启。\n安装 Ubuntu下载系统镜像镜像可以从Ubuntu官网下载，也可以在中科大或其他的国内开源镜像站中下载。点此打开\n这里使用 ubuntu-16.04.4-server-amd64.iso 这个镜像，最新的 ubuntu-18.04 并没有经过测试，不知道是否还能用此方法进行安装。\n配置安装源同理将镜像解压到web目录。\nmkdir -p /data/wwwroot/apt/ubuntu16.04mount -o loop ubuntu-16.04.4-server-amd64.iso /mnt/cp -rf /mnt/* /data/wwwroot/apt/ubuntu16.04umount /mnt/ln -s /data/wwwroot/apt/ /data/wwwroot/pxefiles/apt\n准备自动应答文件也可以在 ubuntu 上使用 system-config-kickstart 工具来制作自动应答文件，使用前先安装：apt install system-config-kickstart。ubuntu 的自动应答文件不可以和 CentOS 的通用。\nvim /data/wwwroot/apt/ubuntu16.04/ks-server-vmware.cfg\n文件内容如下：\nlang en_US\nlangsupport en_US\nkeyboard us\nmouse\ntimezone Asia/Shanghai\nrootpw --disabled\n# ubuntu password: 123456\nuser ubuntu --fullname &quot;ubuntu&quot; --iscrypted --password $1$4C9x9TxO$PfPaSIUWQwN80J0MtEyQ3.\nreboot\ntext\ninstall\nurl --url http://192.168.4.6/apt/ubuntu16.04/\nbootloader --location=mbr \nzerombr yes\nclearpart --all --initlabel \npart / --fstype ext4 --size 1 --grow \npart swap --size 2048 \nauth  --useshadow  --enablemd5 \nnetwork --bootproto=dhcp --device=eth0\nfirewall --disabled \nskipx\n%packages\n@^minimal\n@core\nopenssh-server\n其中新建了一个叫 ubuntu 的用户，用户密码是 123456。默认没有配置root用户的密码，可以使用普通用户登陆后使用 sudo 来切换到 root 用户。ubuntu 默认是不允许 root 用户登陆的，需要修改 /etc/ssh/sshd_config 中的 PermitRootLogin 为 yes。\n添加PXE启动项编辑 pxelinux.cfg/default 添加如下 label 块：\nlabel ubuntu server 16.04\n    menu label Install Ubuntu server 16.04.4 (minimal install)\n    kernel /apt/ubuntu16.04/install/netboot/ubuntu-installer/amd64/linux\n    append initrd=apt/ubuntu16.04/install/netboot/ubuntu-installer/amd64/initrd.gz ks=http://192.168.4.6/apt/ubuntu16.04/ks-server-vmware.cfg  --- live-installer/net-image=http://192.168.4.6/apt/ubuntu16.04/install/filesystem.squashfs\n开始安装\n\n安装完成后会自动重启。\n安装 ESXI下载系统镜像在官网下载需要登陆，官方下载地址。如果是用于服务器安装，那最好找找有没有服务器官方提供的针对服务器硬件的 ESXI 版本，比如戴尔官方提供的定制版 ESXI 戴尔官方下载地址\n这里使用戴尔官方提供的 VMware ESXi 5.5 Update 3 点此下载\n配置安装源ESXI 的镜像比较特殊，需要做些调整才可以通过 PXE 安装。mkdir -p /data/wwwroot/esxi/5.5mount -o loop VMware-VMvisor-Installer-5.5.0.update03-3029944.x86_64-Dell_Customized-A00.iso /mntcp -rf /mnt/* /data/wwwroot/esxi/5.5/umount /mntln -s /data/wwwroot/esxi/ /data/wwwroot/pxefiles/esxi\n修改 exsi/5.5 目录中的 boot.cfg\nsed -i '1a\\prefix=/esxi/5.5/' /data/wwwroot/esxi/5.5/boot.cfgsed -i '6s/\\///g' /data/wwwroot/esxi/5.5/boot.cfgsed -i 's/^kernel=.*$/kernel=tboot.b00/g' /data/wwwroot/esxi/5.5/boot.cfg\n准备自动应答文件编辑 /data/wwwroot/esxi/5.5/ks.cfg，写入如下内容：\naccepteula\nrootpw 12345678\nclearpart --firstdisk=local --overwritevmfs\ninstall --firstdisk=local  --overwritevmfs\nnetwork --bootproto=dhcp --device=vmnic0\nreboot\nroot 用户的密码是 12345678\n添加PXE启动项编辑 pxelinux.cfg/default 添加如下 label 块：\nlabel Install ESXI 5.5 for dell\n    menu label Install ESXI 5.5 for dell\n    kernel /esxi/5.5/mboot.c32\n    append -c /esxi/5.5/boot.cfg ks=http://192.168.4.6/esxi/5.5/ks.cfg \n开始安装虽然下载的是针对服务器的，但是为了方便截图依然使用虚拟机测试。需要注意的是，虚拟机安装 ESXI 需要将操作系统设置为 VMware EXS(X)\n然后正常进入PXE引导菜单\n\n安装完成后会自动重启。\n安装 WindowsWindows 系统的安装就比较特殊了，因为不像 Linux 可以通过内核引导启动，虽然也可以实现无人应答安装，但是研究的成本高于工作中的实际成本，所以这里只实现了可以通过网络手动安装 Windows 系统。\nWindows 系统的安装需要一个 WinPE 的安装环境，先通过网络引导启动 WinPE，然后在 WinPE 环境中安装 Windows 镜像。\n下载系统镜像除了可以在微软官方下载镜像，也可以在国内好心人制作的 MSDN I Tell You 里下载。\n这里使用 windows_server_2008_R2_standard_enterprise_and_datacenter_x64_dvd_x15-59777.iso 这个镜像。\n配置镜像站首先需要一个带网络功能的 WinPE，如果不嫌麻烦的话可以百度如何制作 WinPE 镜像，如果采用第三方提供做好的 WinPE 就需要保证镜像是否是干净安全的，而且还需要集成了网卡驱动，如果是用于服务器安装，可能还需要集成 Raid 卡的驱动。\n这里使用无垠PE制作的 Win8PE64网络版.iso 点此打开网盘分享 密码：sees。其中有一个 win8pe_x64_raid_network.iso 的镜像据说是集成了 Raid 卡驱动适用于服务器的 WinPE，实际还并未测试过。\nPXE环境对中文的支持能力几乎没有，所以下载后需要将文件名中的中文去掉，然后放到相应目录。然后将 Windows 系统安装镜像解压。\nmkdir -p /data/wwwroot/windows/windows_server_2008_x64mv Win8PE64网络版.iso /data/wwwroot/windows/win8pe.isoln -s /data/wwwroot/windows/ /data/wwwroot/pxefiles/windowsmount -o loop windows_server_2008_R2_standard_enterprise_and_datacenter_x64_dvd_x15-59777.iso /mntcp -rf /mnt/* /data/wwwroot/windows/windows_server_2008_x64/umount /mnt\n接下来就是另一个比较麻烦的地方了，因为在 WinPE 中通过网络安装 Windows 系统最简单方便的方法就是在 Linux 上创建 Samba 共享，然后 WinPE 中挂载使用。Samba 软件也可以从发行版的官方仓库中获得，或者手动编译安装。\n编译安装 Samba：\nwget https://download.samba.org/pub/samba/stable/samba-4.8.2.tar.gztar xf samba-4.8.2.tar.gzcd samba-4.8.2./configure --prefix=/usr/local/sambamake -j4 &amp;&amp; make install\n配置过程中如果出现了什么错误，就根据提示自行解决依赖。接着配置 Samba 共享目录并启动服务。\nvim /usr/local/samba/etc/smb.conf\n写入如下内容：\n[global]\nworkgroup = MYGROUP\nserver string = Samba Server\nserver role = standalone server\nlog file = /dev/stdout\nmax log size = 50\ndns proxy = no \npam password change = yes\nmap to guest = bad user\nusershare allow guests = yes\ncreate mask = 0664\nforce create mode = 0664\ndirectory mask = 0775\nforce directory mode = 0775\nforce user = root\nforce group = root\nfollow symlinks = yes\nload printers = no\nprinting = bsd\nprintcap name = /dev/null\ndisable spoolss = yes\nsocket options = TCP_NODELAY\nstrict locking = no\nvfs objects = recycle\nrecycle:keeptree = yes\nrecycle:versions = yes\nmin protocol = SMB2\n\n[public]\npath = /data/wwwroot/windows/\nbrowsable = yes\nread only = yes\nguest ok = yes\nveto files = /._*/.apdisk/.AppleDouble/.DS_Store/.TemporaryItems/.Trashes/desktop.ini/ehthumbs.db/Network Trash Folder/Temporary Items/Thumbs.db/\ndelete veto files = yes\n启动 Samba 服务后可以在 Windows 上连接试试\n/usr/local/samba/sbin/smbd -D\n在 Windows 资源管理器中输入 \\\\192.168.4.6 就可以打开共享的目录了。\n添加PXE启动项还记得之前和 pxelinux.0 同一目录的 memdisk 文件吧，这通过这个文件可以将 iso 镜像加载到内存中启动，就利用这个方式来启动 WinPE 镜像。\n编辑 pxelinux.cfg/default 添加如下 label 块：\nlabel Install windows for vmware (WinPE)\n    menu label Install Windows for vmware (WinPE)\n    kernel memdisk\n    append initrd=/windows/win8pe.iso ksdevice=bootif raw iso\n开始安装选择启动 WinPE\n进入 WinPE 桌面环境后连接到服务端的 Samba 共享目录，然后执行 Windows 系统安装镜像中的 setup.exe\n剩下的步骤就是 Windows 系统的普遍安装方式了。\nUbuntu LiveCDLiveCD 是个比较有意思的模式，用于直接通过光盘或者镜像启动 Linux，相当于直接将光盘作为根文件系统，在不安装到硬盘的情况下就可以体验到当前发行版了。而且稍加修改就可以通过网络来启动，由于不依赖硬盘启动，个人认为还可以将 LiveCD 模式当作救援模式使用，因为 LiveCD 模式下相当于正常启动了 Linux 系统，因此也可以正常使用包管理器来安装软件，以及挂载和卸载硬盘。\nLiveCD 需要通过 NFS 来加载镜像内容，因此还需要搭建一个 NFS 目录共享。\n下载系统镜像由于 Ubuntu Server 的镜像不支持 LiveCD 模式，所以这里使用桌面版的 Ubuntu-16.04 镜像。镜像名为：ubuntu-16.04.3-desktop-amd64.iso\n配置 NFS 共享各发行版的 NFS 使用的软件包名称都不太一样，可以借助搜索引擎获取你所使用的发行版是如何安装 NFS 共享软件包的，这里就使用 CentOS 6.8 的 NFS 共享为例。\nmkdir /data/wwwroot/apt/ubuntu16.04-desktop/mount -o loop ubuntu-16.04.3-desktop-amd64.iso /mnt/cp -rf /mnt/* /data/wwwroot/apt/ubuntu16.04-desktop/umount /mntyum install -y rpcbind nfs-utilsvim /etc/exports\n写入如下内容：\n/data/wwwroot/apt/ubuntu16.04-desktop/    *    (ro,sync,no_root_squash)\n启动 NFS 服务\nservice rpcbind restartservice nfs restart\n共享成功后可以在其他主机上看到自己的共享：\n[root@localhost ~]# showmount -e 192.168.4.6\nExport list for 192.168.4.6:\n/data/wwwroot/apt/ubuntu16.04-desktop *\n[root@localhost ~]#\n添加PXE启动项编辑 pxelinux.cfg/default 添加如下 label 块：\nlabel Ubuntu 16.04 amd64\n    menu label Ubuntu 16.04 amd64 LiveCD\n    kernel /apt/ubuntu16.04-desktop/casper/vmlinuz.efi\n    append initrd=/apt/ubuntu16.04-desktop/casper/initrd.lz boot=casper netboot=nfs nfsroot=192.168.4.133:/data/wwwroot/apt/ubuntu16.04-desktop/  splash locale=zh_CN url=http://192.168.4.133/apt/ubuntu16.04-desktop/preseed/ubuntu.seed\n进入 LiveCD 模式\n加载过程可能会比较慢，但最后还是成功进入了 Ubuntu 桌面。\n附录附件：点击下载压缩包里包含了所有的配置文件和dnsmasq, pxelinux.0, undionly.kpxe 这些就可以免去编译安装了。\n再介绍一个好玩的，通过中科大网络启动服务来安装系统 点此访问\n如果觉得手动配置PXE启动的每一个环节非常麻烦，可以试试自动化装机神器 Cobbler。\n","categories":["PXE"],"tags":["pxe"]},{"title":"WebSocket 协议分析","url":"/2018/06/22/2018/WebSocket%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90/","content":"简介\nWebSocket协议是基于TCP的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。它弥补了 HTTP 协议只能只能由客户端，而无法实现服务器主动推送消息。在此之前，浏览器想了解服务端有没有更新数据只能每隔一段时间就发送一个HTTP请求去询问，这样的效率是非常低下的。而通过 WebSocket，服务器和客户端可以建立一条稳定的连接，并且可以双向通信。\n\n\n协议分析WebSocket 协议的规范可以翻阅 RFC 6455\nWebSocket协议有两部分：握手和数据传输。由客户端主动发送连接请求，握手信息是标准的HTTP协议，并通过 Upgrade 字段来表示升级为 WebSocket 协议，因此 WebSocket 的请求也很容易的可以穿过HTTP代理等服务。\n握手阶段客户端发起的握手请求：\nGET /chat HTTP/1.1\nHost: server.example.com\nUpgrade: WebSocket\nConnection: Upgrade\nSec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ==\nOrigin: http://example.com\nSec-WebSocket-Protocol: chat, superchat\nSec-WebSocket-Version: 13\n来自服务端的响应：\nHTTP/1.1 101 Switching Protocols\nUpgrade: WebSocket\nConnection: Upgrade\nSec-WebSocket-Accept:s3pPLMBiTxaQ9kYGzzhZRbK+xOo=\nSec-WebSocket-Protocol: chat\n接下来看各字段具体作用\n\nUpgrade: WebSocket：这是一个特殊的HTTP请求，目的是将客户端和服务端的通信协议从HTTP协议升级到 WebSocket 协议。\nSec-WebSocket-Key：这是一段Base64加密的密钥。\nSec-WebSocket-Accept：服务端收到客户端发来的密钥后追加一段魔法字符串，并将结果进行SHA-1散列签名后再经过Base64加密返回客户端。\nSec-WebSocket-Protocol：表示客户端提供的可供选择的自协议，及服务端选中的支持的子协议。\nOrigin：服务器端用于区分未授权的 websocket 浏览器。\nHTTP/1.1 101 Switching Protocols：其中101为服务器返回的状态码，所有非101的状态码都表示握手并未完成。\n\n在对 Sec-WebSocket-Accept 的解释中，有一个魔法字符串，这个魔法字符串是 WebSocket 标准中规定的一个常量：258EAFA5-E914-47DA-95CA-C5AB0DC85B11。这个常量只是定制标准时随机生成的一个标识符而已。\n传输阶段Websocket协议通过序列化的数据帧传输数据。数据封包协议中定义了opcode、payload length、Payload data等字段。其中要求：客户端向服务器传输的数据帧必须进行掩码处理，服务器若接收到未经过掩码处理的数据帧，则必须主动关闭连接。服务器向客户端传输的数据帧一定不能进行掩码处理，客户端若接收到经过掩码处理的数据帧，则必须主动关闭连接。\n具体数据帧格式如下所示：\n0                   1                   2                   3\n0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1\n+-+-+-+-+-------+-+-------------+-------------------------------+\n|F|R|R|R| opcode|M| Payload len |    Extended payload length    |\n|I|S|S|S|  (4)  |A|     (7)     |             (16/64)           |\n|N|V|V|V|       |S|             |   (if payload len==126/127)   |\n| |1|2|3|       |K|             |                               |\n+-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - +\n|     Extended payload length continued, if payload len == 127  |\n+ - - - - - - - - - - - - - - - +-------------------------------+\n|                               |Masking-key, if MASK set to 1  |\n+-------------------------------+-------------------------------+\n| Masking-key (continued)       |          Payload Data         |\n+-------------------------------- - - - - - - - - - - - - - - - +\n:                     Payload Data continued ...                :\n+ - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - +\n|                     Payload Data continued ...                |\n+---------------------------------------------------------------+\n00010001\nFIN：标识是否为此消息的最后一个数据包，占 1 bitRSV1, RSV2, RSV3： 用于扩展协议，一般为0，各占1bitOpcode：数据包类型（frame type），占4bits\n\n0x0：标识一个中间数据包\n0x1：标识一个text类型数据包\n0x2：标识一个binary类型数据包\n0x3-7：保留\n0x8：标识一个断开连接类型数据包\n0x9：标识一个ping类型数据包\n0xA：表示一个pong类型数据包\n0xB-F：保留\n\nMASK：占1bits 用于标识PayloadData是否经过掩码处理。如果是1，Masking-key域的数据即是掩码密钥，用于解码PayloadData。客户端发出的数据帧需要进行掩码处理，所以此位是1。Payload length：Payload data的长度，占7bits，7+16bits，7+64bits。如果其值在0-125，则是payload的真实长度。如果值是126，则后面2个字节形成的16bits无符号整型数的值是payload的真实长度。如果值是127，则后面8个字节形成的64bits无符号整型数的值是payload的真实长度。Masking-key：如果是客户端发送的数据，长度信息之后的4个字节是掩码，Payload data：应用层数据，客户端发往服务端需要将数据的每一位和掩码的第 N%4 位进行异或运算。\n而服务端返回的数据则不需要掩码和加密数据。\n实现服务端接下来使用 Python3 来实现一个简单的 WebSocket 回声服务器，并每个比特的分析 WebSocket 协议的头部。\n编写代码import structimport socketimport base64import hashlibHOST = '0.0.0.0'PORT = 2000MAGIC_STRING = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11'HTTP_RESPONSE = (    'HTTP/1.1 101 Switching Protocols\\r\\n'    \"Upgrade: websocket\\r\\n\"    \"Connection: Upgrade\\r\\n\"    \"Sec-WebSocket-Accept: &#123;KEY&#125;\\r\\n\"    \"WebSocket-Location: ws://&#123;HOST&#125;/echo\\r\\n\\r\\n\")\n这里定义监听在 TCP 2000 端口，还有 WebSocket 标准定义的魔法字符串，以及通过 HTTP 协议建立 WebSocket 连接的响应模板字符串。\ndef handshake(conn):    headers = &#123;&#125;    raw_headers = conn.recv(4096)    if not len(raw_headers): return False    header, data = raw_headers.split(b'\\r\\n\\r\\n', 1)    for line in header.split(b'\\r\\n')[1:]:        key, val = line.split(b': ', 1)        headers[key] = val    try:        sec_key = headers[b'Sec-WebSocket-Key']    except: return False    res_key = base64.b64encode(hashlib.sha1(sec_key + MAGIC_STRING.encode()).digest())    http_response = HTTP_RESPONSE.format(KEY=res_key.decode(), HOST=HOST)    conn.send(http_response.encode())    return True\n解析客户端发来的 WebSocket 握手请求，请求头中的 Sec-WebSocket-Key 和魔法字符串拼接后的SHA1的值经过Base64编码返回客户端，这一步握手就成功了，接下来的数据传输就是通过 WebSocket 协议进行了。\ndef parseData(package):    fin = package[0] &gt;&gt; 7              # 第一个字节(8 bit)右移7位获得FIN的比特位。    opcode = package[0] &amp; 0b1111       # 与运算获取最后四个比特位(opcode)的值    mask_flag = package[1] &gt;&gt; 7        # 客户端必须将MASK设置为1（必须将数据进行掩码处理）    data_length = package[1] &amp; 0b1111111   # 计算数据长度    if data_length == 126:             # 如果数据长度126，则之后的2个字节也是长度信息        masks = package[4:8]           # 所以掩码值就在第 4,5,6,7 这四个字节        raw_data = package[8:]         # 实际的数据所在字节    elif data_length == 127:           # 如果数据长度127，则之后的8个字节也是长度信息        masks = package[10:14]         # 所以掩码值就在第 10,11,12,13 这四个字节        raw_data = package[14:]    else:        masks = package[2:6]           # 如果长度在0-125，则 2,3,4,5 就是掩码的值        raw_data = package[6:]    data = b\"\"    i = 0    for B in raw_data:        tmp = B ^ masks[i % 4]         # 将数据的每个字节与掩码进行异或运算        data += struct.pack('B', tmp)  # 然后将值打包为二进制        i += 1    return data\n解析接收到的 WebSocket 数据帧，并返回解密后的数据部分。\ndef packData(data):    finAndOpcode = struct.pack('B', 0b10000001)    maskAndLength = struct.pack('B', len(data))    return finAndOpcode+maskAndLength+data\n构建服务端返回客户端的数据帧，因为不需要对数据按字节异或加密，所以代码比较简单。\ndef startServer():    sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM)    sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1)    sock.bind((HOST, PORT))    sock.listen(5)    print('Server listen on %s:%s ...' % (HOST,PORT))    while True:        conn, addr = sock.accept()        if not handshake(conn):             print(\"Client %s:%s handshake failed!\" % addr)        print(\"Client %s:%s handshake success!\" % addr)        data = conn.recv(4096)        print('Raw data: ', data, sep='')        print('Fact data: '+parseData(data).decode())        conn.send(packData(parseData(data)))        conn.close()if __name__ == '__main__':    try:        startServer()    except KeyboardInterrupt:        print(\"Server exit...\")\n创建套接字监听，并启动服务，当有客户端握手成功后，将客户端发来的数据原样返回并关闭连接。运行脚本，然后看看效果吧！\n浏览器测试这里在 Chrome 浏览器中做演示，F12 进入开发者模式，然后点击 Console，现在就打开 JavaScript 的交互界面了。然后输入如下代码：\nvar ws = new WebSocket(\"ws://127.0.0.1:2000/echo\")ws.onmessage = data =&gt; &#123;console.log(\"Recv: \"+data.data)&#125;ws.send(\"Hi! 喵喵喵\")\n可以看到，发送给服务端的字符串又被原样返回了。\n\n服务端也可以看到终端上的输出：\nyunfwe@zhzz:/mnt/c/Users/yunfwe/Desktop$ python3 server.py\nServer listen on 0.0.0.0:2000 ...\nClient 127.0.0.1:53117 handshake success!\nRaw data: b&apos;\\x81\\x8d7\\x91\\xc6\\x8b\\x7f\\xf8\\xe7\\xab\\xd2\\x07sn\\xa1$#\\x1d\\x82&apos;\nFact data: Hi! 喵喵喵\n附录客户端一般都是浏览器等程序，如果感兴趣的话也可以试试用 Python 实现一个简单的 WebSocket 客户端。\n","categories":["WebSocket"],"tags":["websocket"]},{"title":"一起动手写一个VPN","url":"/2018/05/24/2018/%E4%B8%80%E8%B5%B7%E5%8A%A8%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AAVPN/","content":"简介\n了解了OpenVPN之后，发现通过一个UDP隧道来打通NAT网络非常有意思，于是就萌发出使用Python来实现一个类似于OpenVPN的隧道，OpenVPN不仅支持UDP协议还支持TCP协议，但是这里并不会像OpenVPN设计的这么复杂完善，只使用简单的UDP协议和密码认证。也通过这个小程序来更深入的学习下Linux网络相关的知识。\n\n\n环境VPN隧道的实现依赖于Linux内核提供的 tun/tap 虚拟网络接口，只要不是太古董级别的Linux系统，或者其他类Unix系统就都可以支持。可以查看是否存在设备文件 /dev/net/tun，如果存在则表示支持 tun/tap 功能，对于早些的Linux内核，设备文件还可能是 /dev/tun。\n其中 tun 是模拟的三层网络设备，只支持三层以上的协议，只能做到点对点隧道，而 tap 则可以模拟二层网络设备，arp 协议等二层协议也是支持的，可以实现多机组成的虚拟局域网。tun 也可以通过数据转发的方式实现互通。\n服务端代码为了更高的性能和不依赖第三方库使用Python3完成，客户端就尽量兼容更多版本的Python。网络使用常用的 tun 虚拟网卡。\n编程先来理解一下使用 tun 的VPN是如何实现的呢？简单来说 就是 /dev/net/tun 设备实现了应用层直接处理网络数据包的能力。当使用 /dev/net/tun 创建了虚拟网卡设备后，发到这个网卡的数据包会被 /dev/net/tun 拦截并返回给打开它上上层程序，上层程序可以通过 udp、tcp 甚至 icmp 协议将原始的数据包发送到目标主机。当目标主机通过网络接受到数据包后再写入到 /dev/net/tun 设备中，/dev/net/tun 再将数据包注入到内核的网络协议栈按照正常到达的数据包来处理。VPN大部分采用的是通过 udp 协议发送到对端的，如果是通过 tcp 协议传输，tcp 包内部包裹着另一个 tcp 包，如果发生了丢包重传现象，内部的 tcp 包和外部的 tcp 包可能发生混乱。\n服务端程序\n服务端程序使用 Python3 开发，只使用了标准库\n\n导入需要的模块import osimport sysimport timeimport structimport socketfrom fcntl import ioctlfrom select import selectfrom threading import Threadfrom ipaddress import ip_network\n可能大多数人都熟悉 os, sys, time 这些模块，而对其他的就不太了解了。其中 struct 是一个将Python的数据类型转换为C语言中的数据类型的字节流的模块。fnctl.ioctl 用来对设备的一些特性进行控制，比如这里来设定要启用的虚拟网卡的类型和网卡名称。select 是 I/O多路复用 的一个实现，用来在单线程中高效的利用网络I/O。ipaddress 模块是Python3新增的模块，用来解析IP地址的。\n定义一些常量DEBUG = TruePASSWORD = b'4fb88ca224e'BIND_ADDRESS = '0.0.0.0',2003NETWORK = '10.0.0.0/24'BUFFER_SIZE = 4096MTU = 1400IPRANGE = list(map(str,ip_network(NETWORK)))[1:]LOCAL_IP = IPRANGE.pop(0)TUNSETIFF = 0x400454caIFF_TUN   = 0x0001IFF_TAP   = 0x0002\n在这里定义了一些常量，比如认证的密码，服务监听的地址，以及整个网络段。其中不太好理解的可能是 TUNSETIFF, IFF_TUN 和 IFF_TAP 这三个常量。这三个常量实际上是定义在 linux/if_tun.h 这个头文件中，因为用Python来实现 tun 隧道 所以也需要使用这三个常量。TUNSETIFF 这个常量是告诉 ioctl 要完成虚拟网卡的注册，而IFF_TUN 和 IFF_TAP 则表示是要使用 tun 类型还是 tap 类型的虚拟网卡。\n创建和启动虚拟网卡def createTunnel(tunName='tun%d',tunMode=IFF_TUN):    tunfd = os.open(\"/dev/net/tun\", os.O_RDWR)    ifn = ioctl(tunfd, TUNSETIFF, struct.pack(b\"16sH\", tunName.encode(), tunMode))    tunName = ifn[:16].decode().strip(\"\\x00\")    return tunfd,tunName    def startTunnel(tunName,peerIP):    os.popen('ifconfig %s %s dstaddr %s mtu %s up' %                 (tunName, LOCAL_IP, peerIP, MTU)).read()    now = lambda :time.strftime('[%Y/%m/%d %H:%M:%S] ')\n先看 createTunnel 函数，默认是使用 tun 类型的虚拟网卡，os.open 是更底层的文件读写方式，事实上，常用的 open(&#39;filename&#39;) 方法就是对 os.open 的高级封装，os.O_RDWR 标志以读写模式打开 tun 的设备文件。然后使用 ioctl 来创建一个虚拟网卡，并返回创建成功后的网卡名称，默认是按照 tun0，tun1 依次增加的。\nstartTunnel 就是用 ifconfig 命令为这个虚拟网卡配置IP地址。MTU 之所以设置为 1400 因为Linux默认网卡的 MTU 是 1500，但是隧道来的数据包还要包裹一层 udp 封装发往对端，如果隧道的 MTU 也设置为 1500 的话，那最终通过 udp 封装后肯定会超出物理网卡的界限，最终会被拆分为两个数据包发送二照成不必要的浪费。 now 是一个 lambda 表达式，给下面的打印调试信息使用。\nVPN的核心实现class Server():    def __init__(self):        self.sessions = []        self.readables = []        self.udp = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)        self.udp.bind(BIND_ADDRESS)        self.readables.append(self.udp)        self.tunInfo = &#123;            'tunName':None, 'tunfd':None,             'addr':None, 'tunAddr':None, 'lastTime':None            &#125;        print('Server listen on %s:%s...' % BIND_ADDRESS)    def getTunByAddr(self, addr):        for i in self.sessions:            if i['addr'] == addr: return i['tunfd']        return -1        def getAddrByTun(self,tunfd):        for i in self.sessions:            if i['tunfd'] == tunfd: return i['addr']        return -1    def createSession(self, addr):        tunfd,tunName = createTunnel()        tunAddr = IPRANGE.pop(0)        startTunnel(tunName,tunAddr)        self.sessions.append(            &#123;                'tunName':tunName, 'tunfd':tunfd, 'addr':addr,                 'tunAddr':tunAddr, 'lastTime':time.time()            &#125;        )        self.readables.append(tunfd)        reply = '%s;%s' % (tunAddr,LOCAL_IP)        self.udp.sendto(reply.encode(), addr)    def delSessionByTun(self, tunfd):        if tunfd == -1: return False        for i in self.sessions:            if i['tunfd'] == tunfd:                self.sessions.remove(i)                IPRANGE.append(i['tunAddr'])        self.readables.remove(tunfd)        os.close(tunfd)        return True    def updateLastTime(self, tunfd):        for i in self.sessions:            if i['tunfd'] == tunfd:                i['lastTime'] = time.time()    def cleanExpireTun(self):        while True:            for i in self.sessions:                if (time.time() - i['lastTime']) &gt; 60:                    self.delSessionByTun(i['tunfd'])                    if DEBUG: print('Session: %s:%s expired!' % i['addr'])            time.sleep(1)    def auth(self,addr,data,tunfd):        if data == b'\\x00':            if tunfd == -1:                self.udp.sendto(b'r', addr)            else:                self.updateLastTime(tunfd)            return False        if data == b'e':            if self.delSessionByTun(tunfd):                if DEBUG: print(\"Client %s:%s is disconnect\" % addr)            return False        if data == PASSWORD:            return True        else:            if DEBUG: print('Clinet %s:%s connect failed' % addr)            return False    def run_forever(self):        cleanThread = Thread(target=self.cleanExpireTun)        cleanThread.setDaemon(True)        cleanThread.start()        while True:            readab = select(self.readables, [], [], 1)[0]            for r in readab:                if r == self.udp:                    data, addr = self.udp.recvfrom(BUFFER_SIZE)                    if DEBUG: print(now()+'from    (%s:%s)' % addr, data[:10])                    try:                        tunfd = self.getTunByAddr(addr)                        try:                            os.write(tunfd,data)                        except OSError:                            if not self.auth(addr,data,tunfd):continue                            self.createSession(addr)                            if DEBUG: print('Clinet %s:%s connect successful' % addr)                    except OSError: continue                else:                    try:                        addr = self.getAddrByTun(r)                        data = os.read(r, BUFFER_SIZE)                        self.udp.sendto(data,addr)                        if DEBUG: print(now()+'to      (%s:%s)' % addr, data[:10])                    except Exception:                        continue\n一步一步的来看，首先定义了一个 Server 的类。在初始化方法 __init__ 中，self.sessions = [] 用来保存连接的用户会话，self.readables = [] 用来保存为每个会话创建的隧道的文件描述符，接着创建了一个 udp 的网络套接字，并将这个套接字加入到 self.readables 中。self.tunInfo 定义了每个会话保存的隧道信息。\n接下来的 getTunByAddr 是通过接受到的 udp 数据包的来源信息找到需要注入到哪条隧道中，getAddrByTun 正好相反，根据从隧道来的数据找到是要通过 udp 发往哪个主机。\ncreateSession 则是客户端连接成功后为它创建一个会话和相应的虚拟网卡，并且将客户端的网卡配置信息通过 udp 发送过去。 delSessionByTun 是用来清理用户会话和虚拟网卡。\nupdateLastTime 用来在客户端发送来心跳包后更新用户最后一次发送心跳包的时间戳，cleanExpireTun 用来清理已经超过一分钟没有发来心跳包的客户端，认为这个客户端已经失去了连接，但是可能因为网络故障等原因没有正常关闭隧道。\nauth 则是对客户端发来的数据进行处理，如何客户端发来 b&#39;\\x00&#39; 则表明这是一个心跳包，但是如果并不存在这个心跳包源主机的会话，可能因为网络原因服务端清理了这个客户端的会话，就发送 b&#39;r&#39; 告诉客户端重新认证。否则就更新这个会话的最后心跳包的时间戳。客户端在退出的时候会发送 b&#39;e&#39; 到服务端，然后服务端会主动清理这个客户端的会话。最后会匹配数据包是否是认证密码，如果认证成功了就返回 True 程序会继续处理。\nrun_forever 是整个服务运转的核心了，首先使用一个新线程启动会话清理方法，然后进入事件循环，使用 select 监听 udp 网络套接字和隧道套接字的可读事件，一旦某个套接字有数据过来了 select 则会返回这个套接字对象，然后判断这个套接字是网络套接字还是隧道套接字，如果是网络套接字则首先尝试将数据写入到客户端所在的隧道中，如果数据内容不是一个正确的网络数据包格式或者没有找到这个客户端地址相关联的隧道，就进入异常处理模式，因为新客户端的连接和心跳包导致进入异常处理的频率是比较小的 所以并不会对整体性能照成很大的影响，如果在一开始就进行数据内容判断的话 就非常影响程序的性能了，因为毕竟接收到的大多都是合法的能写入到隧道的数据包。\n接着如果可读对象是一个隧道文件描述符的话，就找到客户端的网络地址，通过 udp 将读取到的数据包发送给客户端，并且如果出现了任何异常的话 就跳过。\n程序执行入口if __name__ == '__main__':    try:        Server().run_forever()    except KeyboardInterrupt:        print('Closing vpn server ...')\n创建一个匿名对象并且启动 run_forever 方法。\n客户端程序\n客户端就比较简单了，只需要将网络来的数据写入隧道，隧道来的数据通过网络发送出去\n\n导入需要的模块from __future__ import print_functionfrom __future__ import unicode_literalsimport osimport sysimport timeimport structimport socketfrom fcntl import ioctlfrom select import selectfrom threading import Thread\n因为需要尽可能的支持更多的Python版本，所以需要使用一些兼容性相关的小技巧。\n定义一些常量PASSWORD = b'4fb88ca224e'MTU = 1400BUFFER_SIZE = 4096KEEPALIVE = 10TUNSETIFF = 0x400454caIFF_TUN   = 0x0001IFF_TAP   = 0x0002\n同服务端，客户端也需要配置隧道，客户端多了一个 KEEPALIVE 的常量，用来定义多久向服务端发送心跳包。\n创建和启动虚拟网卡def createTunnel(tunName='tun%d',tunMode=IFF_TUN):    tunfd = os.open(\"/dev/net/tun\", os.O_RDWR)    ifn = ioctl(tunfd, TUNSETIFF, struct.pack(b\"16sH\", tunName.encode(), tunMode))    tunName = ifn[:16].decode().strip(\"\\x00\")    return tunfd,tunName    def startTunnel(tunName, localIP, peerIP):    os.popen('ifconfig %s %s dstaddr %s mtu %s up' %             (tunName, localIP, peerIP, MTU)).read()\nstartTunnel 有个不同的地方是还需要知道对端（服务端）的隧道IP。\nVPN的核心实现class Client():    def __init__(self):        self.udp = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)        self.udp.settimeout(5)        self.to = SERVER_ADDRESS    def keepalive(self):        def _keepalive(udp, to):            while True:                time.sleep(KEEPALIVE)                udp.sendto(b'\\x00', to)        k = Thread(target=_keepalive, args=(self.udp, self.to), name='keepalive')        k.setDaemon(True)        k.start()    def login(self):        self.udp.sendto(PASSWORD,self.to)        try:            data,addr = self.udp.recvfrom(BUFFER_SIZE)            tunfd,tunName = createTunnel()            localIP,peerIP = data.decode().split(';')            print('Local ip: %s\\tPeer ip: %s' % (localIP,peerIP))            startTunnel(tunName,localIP,peerIP)            return tunfd        except socket.timeout:            return False    def run_forever(self):        print('Start connect to server...')        tunfd = self.login()        if not tunfd:            print(\"Connect failed!\")            sys.exit(0)        print('Connect to server successful')        self.keepalive()        readables = [self.udp, tunfd]        while True:            try:                readab = select(readables, [], [], 10)[0]            except KeyboardInterrupt:                self.udp.sendto(b'e', self.to)                raise KeyboardInterrupt            for r in readab:                if r == self.udp:                    data, addr = self.udp.recvfrom(BUFFER_SIZE)                    try:                        os.write(tunfd, data)                    except OSError:                        if data == b'r':                            os.close(tunfd)                            readables.remove(tunfd)                            print('Reconnecting...')                            tunfd = self.login()                            readables.append(tunfd)                        continue                else:                    data = os.read(tunfd, BUFFER_SIZE)                    self.udp.sendto(data, self.to)\n和服务端的比较类似，不同的是客户端需要处理的是登陆、从服务端接收到隧道配置信息然后创建和启动隧道和处理服务端发来的 b&#39;r&#39; 重连命令。还会启动一个定期发送心跳包的线程，这个主要是因为在传统的 NAT 模型中，UDP会话可能在短短的几分钟甚至几十秒钟就会被网关设备清理掉，导致VPN隧道断开。而不断地发送心跳包则可以保持网关设备上客户端和服务端的UDP会话。\n程序执行入口if __name__ == '__main__':    try:        SERVER_ADDRESS = (sys.argv[1], int(sys.argv[2]))        Client().run_forever()    except IndexError:        print('Usage: %s [remote_ip] [remote_port]' % sys.argv[0])    except KeyboardInterrupt:        print('Closing vpn client ...')\n这里通过命令行获取客户端要连接的服务端IP和端口，如果参数出错并给出相应的提示信息。\n运行结果在服务端使用Python3运行服务端程序：\nroot@ubuntu:~# python3 vpnserver.py \nServer listen on 0.0.0.0:2003...\n服务正常监听，然后客户端启动客户端程序：\n[root@localhost ~]# python vpnclient.py 192.168.4.233 2003\nStart connect to server...\nLocal ip: 10.0.0.2    Peer ip: 10.0.0.1\nConnect to server successful\n\n[root@localhost ~]# ifconfig tun0\ntun0      Link encap:UNSPEC  HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  \n        inet addr:10.0.0.2  P-t-P:10.0.0.1  Mask:255.255.255.255\n        UP POINTOPOINT RUNNING NOARP MULTICAST  MTU:1400  Metric:1\n        RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:500 \n        RX bytes:0 (0.0 b)  TX bytes:0 (0.0 b)\n客户端连接成功后打印出连接信息，并且可以看到多出来一块 tun0 的虚拟网卡。\nroot@ubuntu:~# python3 vpnserver.py \nServer listen on 0.0.0.0:2003...\n[2018/05/26 13:47:13] from    (192.168.4.6:58502) b&apos;4fb88ca224&apos;\nClinet 192.168.4.6:58502 connect successful\n[2018/05/26 13:47:23] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n[2018/05/26 13:47:33] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n[2018/05/26 13:47:43] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n[2018/05/26 13:47:53] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n[2018/05/26 13:48:03] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n[2018/05/26 13:48:13] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n[2018/05/26 13:48:23] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n[2018/05/26 13:48:33] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n[2018/05/26 13:48:43] from    (192.168.4.6:58502) b&apos;\\x00&apos;\n\nroot@ubuntu:~# ifconfig tun0\ntun0      Link encap:UNSPEC  HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00  \n        inet addr:10.0.0.1  P-t-P:10.0.0.2  Mask:255.255.255.255\n        UP POINTOPOINT RUNNING NOARP MULTICAST  MTU:1400  Metric:1\n        RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:500 \n        RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n可以看到服务端也打印出客户端连接成功的消息，以及打印出每次从客户端发来的数据包信息。同样也有一条到客户端的虚拟网卡。接着尝试服务端是否可以直接PING通客户端了。\nroot@ubuntu:~# ping 10.0.0.2 -c 2 \nPING 10.0.0.2 (10.0.0.2) 56(84) bytes of data.\n64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.814 ms\n64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.569 ms\n\n--- 10.0.0.2 ping statistics ---\n2 packets transmitted, 2 received, 0% packet loss, time 999ms\nrtt min/avg/max/mdev = 0.569/0.691/0.814/0.125 ms\n\n[2018/05/26 13:51:40] to      (192.168.4.6:58502) b&apos;\\x00\\x00\\x08\\x00E\\x00\\x00T\\x19\\xdd&apos;\n[2018/05/26 13:51:40] from    (192.168.4.6:58502) b&apos;\\x00\\x00\\x08\\x00E\\x00\\x00T\\x99V&apos;\n[2018/05/26 13:51:41] to      (192.168.4.6:58502) b&apos;\\x00\\x00\\x08\\x00E\\x00\\x00T\\x19\\xe4&apos;\n[2018/05/26 13:51:41] from    (192.168.4.6:58502) b&apos;\\x00\\x00\\x08\\x00E\\x00\\x00T\\x99W&apos;\n可以看到隧道是正常的，并且服务端打印出了去的两个ICMP包和回来的两个ICMP包，接着关闭客户端程序。\n[2018/05/26 13:54:45] from    (192.168.4.6:58502) b&apos;e&apos;\nClient 192.168.4.6:58502 is disconnect\n服务端接收到了 b&#39;e&#39; 后打印客户端断开连接的消息，接着发现 tun0 这块虚拟网卡也消失了。\n附录服务端程序就完成了，但是还是存在非常多的问题，比如用户认证的安全性，select 的性能和支持的最大客户端数量可以使用更好的 epoll 方式，但是 select 的平台兼容性比较强，如果考虑把程序移植到 Windows 的话可以继续使用（不考虑移植到Windows，但是Windows的tap驱动软件是否提供了这种可能？）。客户端断开后重连IP就会改变，如果能给客户端固定IP就好了，以及没法监控每个客户端的流量和控制客户端的速率。服务端应该采用配置文件的方式来更改运行的参数，并且应该能够使用守护进程的方式运行并处理 kill 命令发送的信号，这样这个程序就比较完善了。\n注意：程序中多次出现的 b&#39;e&#39;, b&#39;r&#39; 这样的字符，这只是表示Python中 Byte 类型的数据。\n","categories":["Python"],"tags":["python","vpn","udp"]},{"title":"打造自己的ubuntu开发环境","url":"/2018/02/10/2018/%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84ubuntu%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","content":"简介\n对于经常在Linux做开发的开发者 打造一款让自己用的舒服 赏心悦目的系统开发环境是非常重要的。看着精美的主题和系统 心情也会变得更好，心情好了，代码的质量也就更高了。linux好的桌面发行版有Archlinux啊 Ubuntu啊 还有国产良心Deepin啊之类的，Archlinux太需要折腾了，Deepin呢 已经帮用户做的太多了，安装完毕后总觉得很多自己用不到的软件，桌面自己可以折腾的地方也不多，于是就选择了Ubuntu。鉴于下一个Ubuntu的LTS版18.04还有两个多月才发布 遂使用Ubuntu 16.04来折腾。\n\n\n环境\n由于Windows系统的便利性还是比Ubuntu高的 还有很多Ubuntu无法代替的地方 所以就只好吧Ubuntu安装到虚拟机里了\n\n\n\n\n主机\n内存\nCPU\n硬盘\n\n\n\n\nWindows 10 64位\n8G DDR4\ni7 6代\n256G SSD\n\n\n\n\n\n\n虚拟机\n内存\nCPU\n硬盘\n\n\n\n\nUbuntu 16.04 64位\n4G DDR4\ni7 6代\n40G SSD\n\n\n\n步骤获取Ubuntu\n可以在ubuntu的官网获取 但是速度可能会比较慢。可以在国内的镜像站上免费下载ubuntu系统镜像\n\n在阿里云镜像站获取最新版ubuntu 16.04的镜像\nubuntu-16.04.3-desktop-amd64.iso 点此下载\n安装Ubuntu可以选择在虚拟机或者物理机上安装Ubuntu\n在终端中更新升级软件\n\n由于Ubuntu的官方镜像站有中国的服务器，中文版的也默认使用中国的服务器 所以就不更改镜像站了\n\n执行以下命令sudo apt-get updatesudo apt-get upgrade\n接下来就是开始美化主题了\n安装漂亮的主题\n这里使用我比较喜欢的Numix主题\n\ndeb离线安装\n\n由于安装Numix主题需要添加Numix的ppa源 官方源有时候并不稳定 因为也可以直接安装Numix的deb包。在ubuntu内用火狐浏览器打开此页面后下载，或者Windows上下载好后想办法传入到ubuntu中。如果想使用官方ppa源安装可以跳过这一段。\n\n\n\n\n包名\n下载地址\n\n\n\n\nnumix-gtk-theme\n点此下载\n\n\nnumix-icon-theme-circle\n点此下载\n\n\n\n然后安装这两个包，如果没报错的话应该就安装成功了dpkg -i numix-gtk-theme.debdpkg -i numix-icon-theme-circle.deb\n注意：直接安装deb包只在当前ubuntu版本上测试通过，其他版本不保证可以使用，最好还是使用官方ppa源的安装方式。\n使用Numix官方源安装\n\n如果使用deb离线安装成功的话 这一步就不用继续了哦\n\nsudo add-apt-repository ppa:numix/ppasudo apt-get updatesudo apt-get install numix-gtk-theme numix-icon-theme-circle\n还需要一款主题管理工具来更改主题sudo apt-get install unity-tweak-tool\n打开tweak工具 然后将主题、桌面壁纸等换成自己喜欢的吧\n是不是瞬间感觉用户体验上升了一个档次呢 逼格也更高了\n安装常用软件搜狗输入法Ubuntu内用火狐浏览器打开：https://pinyin.sogou.com/linux/ 点击立即下载64位。下载好后打开文件所在目录，然后在此目录打开终端 输入以下命令开始安装。sudo apt-get install -f ./sogoupinyin_2.2.0.0102_amd64.deb\n安装完后需要注销下重新登陆 然后打开浏览器 点击左上角小键盘的图标 切换到搜狗输入法。试试看，是不是可以很舒服的输入中文了。使用Shift键切换中英输入哦。\nChrome浏览器\n由于Windows下一直使用Chrome浏览器，所以对Chrome比较情有独钟。下载需要自备梯子哦。\n\nChrome浏览器下载地址：https://www.google.cn/chrome/\n如果用Ubuntu中的火狐浏览器打开Chrome浏览器的主页，可以直接点击下载Chrome的图标。Windows下的话 需要点击下载适用于其他平台的Chrome，下载后传到Ubuntu中。\n接下来安装deb包sudo apt-get install -f ./google-chrome-stable_current_amd64.deb\n其他软件的安装方式都大同小异 可以在Ubuntu应用商店找到的就在应用商店安装，找不到的就去官方找有没有ppa源或者deb包。\n附录漂亮的锁屏界面\n","categories":["Ubuntu"],"tags":["Ubuntu"]},{"title":"Peewee 轻量级ORM框架","url":"/2018/03/20/2018/Peewee%20%E8%BD%BB%E9%87%8F%E7%BA%A7ORM%E6%A1%86%E6%9E%B6/","content":"\n简介\nPeewee 是Python的一款轻量级ORM框架。ORM 是对象-关系映射（Object-Relational Mapping），是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。简单的说，ORM是通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系数据库中。ORM 屏蔽了底层数据库操作的细节，使代码几乎不用修改即可支持不同的底层数据库存储。支持Python2.7和3.4以上的版本，内置对SQLite, MySQL和Postgresql的支持。本文通过阅读官方文档翻译而来。\n\n环境这里使用 Windows 版的 Python 3.6 和当前最新版的 peewee 3.1.3。\nGithub地址：https://github.com/coleifer/peewee\n使用安装这里使用 pip 命令安装\npip install peewee\n也可以将代码 git 下来 使用 setup 安装\ngit clone https://github.com/coleifer/peewee.git cd peewee python setup.py install\n如果底层想要使用 MySQL 数据库需要安装 MySQL 的连接驱动：pip install pymysql，并且配置好一个可用的 MySQL 数据库。Postgres 同理，Postgres 的连接驱动：pip install psycopg2。\n SQLite 是 Python 标准库的模块，不需要额外安装和配置，也更简单方便，所以这里就以 SQLite 为例。\n快速体验先来体验一下 peewee 对数据交互带来的方便吧。\n创建数据模型先理解下什么 ORM ，ORM 是将编程语言中的对象映射为数据库中的数据，比如说 可以将编程语言中的一个类，映射为数据库的一个表，这个类被称为模型类（Model class）。模型类的字段实例（Field instance），映射为数据库中表的字段。模型实例（Model instance）映射为数据库中表的每一行数据。\n建议在命令行中执行下面的代码，这样就更直观的知道每一步都发生了什么。\n在项目中使用 peewee 时，刚开始最好创建一个模型类，peewee 会自动根据这个模型类在数据库中创建好表。下面看看模型类如何定义的：\nfrom peewee import *db = SqliteDatabase('people.db')class Person(Model):    name = CharField()    birthday = DateField()    is_relative = BooleanField()    class Meta:        database = db # This model uses the \"people.db\" database.\n当我们使用外键建立模型之间的关系时，peewee 可以很容易的做到这一点。\nclass Pet(Model):    owner = ForeignKeyField(Person, backref='pets')    name = CharField()    animal_type = CharField()    class Meta:        database = db # this model uses the \"people.db\" database\n现在创建好了模型，让我们连接到数据库。虽然在执行第一条查询的时候会自动连接数据库，但是手动连接可以立即显示数据库连接的任何错误，在使用完后手动关闭数据库连接也是个很好的习惯。\ndb.connect()\n首先在数据库中创建存储数据的表。这将创建具有适当列，索引，序列和外键约束的表：\ndb.create_tables([Person, Pet])\n可以看到 当前目录 已经出现了一个 people.db 的 SQLite 数据库文件。\n存储数据现在开始存储一些数据，我们将使用 save() 和 create() 方法添加和修改表中的记录\nfrom datetime import dateuncle_bob = Person(name='Bob', birthday=date(1960, 1, 15), is_relative=True)uncle_bob.save() # bob is now stored in the database. Returns: 1\n调用 save() 将返回修改的行数。也可使用 create() 方法来添加一个人：\ngrandma = Person.create(name='Grandma', birthday=date(1935, 3, 1), is_relative=True)herb = Person.create(name='Herb', birthday=date(1950, 5, 5), is_relative=False)\n如果想更改某行，修改模型实例的属性，然后调用 save() 方法就会同步到数据库了。\ngrandma.name = 'Grandma L.'grandma.save()\n现在已经在数据库中存储了三个人，让我们给他们一些宠物。奶奶不喜欢宠物，但Herb是宠物的爱好者。\nbob_kitty = Pet.create(owner=uncle_bob, name='Kitty', animal_type='cat')herb_fido = Pet.create(owner=herb, name='Fido', animal_type='dog')herb_mittens = Pet.create(owner=herb, name='Mittens', animal_type='cat')herb_mittens_jr = Pet.create(owner=herb, name='Mittens Jr', animal_type='cat')\n经过漫长的时间后，Mittens 生病死亡了，现在从数据库中删的它。\nherb_mittens.delete_instance()\ndelete_instance() 方法也会返回删除的行数。\n叔叔 Bob 觉得在 Herb 的房间死了太多动物，所以收养了他的狗 Fido。\nherb_fido.owner = uncle_bobherb_fido.save()bob_fido = herb_fido # rename our variable for clarity\n检索数据数据库的优势在于可以通过SQL语句来检索数据，现在看看 peewee 中是如何检索数据的。\n查询一条记录让我们从数据库中获取奶奶的记录，从数据库获取单条记录使用 select.get()\ngrandma = Person.select().where(Person.name == 'Grandma L.').get()\n我们也可以使用等效的缩写 Model.get()\ngrandma = Person.get(Person.name == 'Grandma L.')\n列出记录让我们列出所有人的记录\nfor person in Person.select():    print(person.name, person.is_relative)\n输出：\nBob True\nGrandma L. True\nHerb False\n让我们列出所有的猫和它们主人的名字\nquery = Pet.select().where(Pet.animal_type == 'cat')for pet in query:    print(pet.name, pet.owner.name)\n输出：\nKitty Bob\nMittens Jr Herb\n但是这样的查询有一个很大的问题，因为我们想要知道宠物主人的名字，但是 Pet 表中并没有这一个字段，所以当访问 pet.owner.name 的时候，peewee 不得不执行额外的查询来检索宠物的所有者，这样的情况通常应该是避免的。\n我们应当使用 join 进行关联查询来避免额外的开销\nquery = (Pet         .select(Pet, Person)         .join(Person)         .where(Pet.animal_type == 'cat'))for pet in query:    print(pet.name, pet.owner.name)\n输出：\nKitty Bob\nMittens Jr Herb\n让我们看看 Bob 有哪些宠物\nfor pet in Pet.select().join(Person).where(Person.name == 'Bob'):    print(pet.name)\n输出：\nKitty\nFido\n我们还有一个很酷的方法获取 Bob 的宠物，因为我们已经有一个表示 Bob 的对象，所以我们可以这样做\nfor pet in Pet.select().where(Pet.owner == uncle_bob):    print(pet.name)\n排序让我们添加一个 order_by() 方法来让它们按照字母顺序排序\nfor pet in Pet.select().where(Pet.owner == uncle_bob).order_by(Pet.name):    print(pet.name)\n输出：\nFido\nKitty\n让我们按照年纪 从年轻到年老列出人们\nfor person in Person.select().order_by(Person.birthday.desc()):    print(person.name, person.birthday)\n输出：\nBob 1960-01-15\nHerb 1950-05-05\nGrandma L. 1935-03-01\n结合过滤器表达式Peewee 支持任意嵌套的表达式。让我们得到所有生日不一的人\n1940之前的人（Grandma）1959年之后的人（Bob）\nd1940 = date(1940, 1, 1)d1960 = date(1960, 1, 1)query = (Person         .select()         .where((Person.birthday &lt; d1940) | (Person.birthday &gt; d1960)))for person in query:    print(person.name, person.birthday)\n输出：\nBob 1960-01-15\nGrandma L. 1935-03-01\n现在看看生日在1940年至1960年之间的人\nquery = (Person         .select()         .where(Person.birthday.between(d1940, d1960)))for person in query:    print(person.name, person.birthday)\n输出：\nHerb 1950-05-05\n聚合和预获取现在让我们列出所有的人和他们有多少宠物\nfor person in Person.select():    print(person.name, person.pets.count(), 'pets')\n输出：\nBob 2 pets\nGrandma L. 0 pets\nHerb 1 pets\n在这种情况下，我们又为返回的每个人执行了附加查询！我们可以通过执行join并使用sql函数来聚合结果来避免这种情况。\nquery = (Person         .select(Person, fn.COUNT(Pet.id).alias('pet_count'))         .join(Pet, JOIN.LEFT_OUTER)  # include people without pets.         .group_by(Person)         .order_by(Person.name))for person in query:    # \"pet_count\" becomes an attribute on the returned model instances.    print(person.name, person.pet_count, 'pets')\n输出：\nBob 2 pets\nGrandma L. 0 pets\nHerb 1 pets\n一只宠物只能有一个主人，所以当进行从 Pet 到 Person 的 join 操作时，它们通常都会进行一次匹配。当我们从 Person 到 Pet 的 join 时，情况会不同，因为一个人可能没有宠物，或者他们可能有几只宠物。因为我们使用关系数据库，当我们从 Person 到 Pet 的 join 时，那么每个宠物都会重复每个拥有多个宠物的人。\n它看起来像这样：query = (Person         .select(Person, Pet)         .join(Pet, JOIN.LEFT_OUTER)         .order_by(Person.name, Pet.name))for person in query:    # We need to check if they have a pet instance attached, since not all    # people have pets.    if hasattr(person, 'pet'):        print(person.name, person.pet.name)    else:        print(person.name, 'no pets')\n输出：\nBob Fido\nBob Kitty\nGrandma L. no pets\nHerb Mittens Jr\n通常这种类型的重复是不可取的，我们可以使用一种 prefetch() 的特殊方法\nquery = Person.select().order_by(Person.name).prefetch(Pet)for person in query:    print(person.name)    for pet in person.pets:        print('  *', pet.name)\nSQL 函数这将使用一个 SQL 方法来查找名字以大写或者小写 g 开头的人\nexpression = fn.Lower(fn.Substr(Person.name, 1, 1)) == 'g'for person in Person.select().where(expression):    print(person.name)\n输出：\nGrandma L.\n这只是 peewee 的基础，你还可以使查询更复杂，其他的 SQL 子句也可以使用，比如 group_by(), having(), limit(), offset()\n关闭数据库当使用完数据库，我们应该关闭它\ndb.close()\n从数据库导出模型如果已经存在的数据库，可以使用模型生成器 pwiz 自动生成 peewee 模型\n比如将刚才 people.db 的数据再导出模型\npython -m pwiz -e sqlite people.db\n如果想导出 MySQL 库的数据 可以这样做：python -m pwiz -e mysql -H localhost -p3306 -uuser -Ppassword  dbname &gt; db.py\n数据库连接数据库Peewee 的 Database 对象表示到数据库的连接。Database 类将实例化打开的数据库连接所需的所有信息，这些信息可用于：\n\n打开和关闭连接\n执行查询请求\n事务管理\n内省表，列，索引和约束\n模型整合\n\npeewee支持 SQLite, MySQL 和 Postgres。每个数据库类都提供了一些基本的数据库特定的配置选项\nfrom peewee import *# SQLite database using WAL journal mode and 64MB cache.sqlite_db = SqliteDatabase('/path/to/app.db', pragmas=(    ('journal_mode', 'wal'),    ('cache_size', -1024 * 64)))# Connect to a MySQL database on network.mysql_db = MySQLDatabase('dbname', user='root', password='db_password',                         host='10.1.0.8', port=3306)# Connect to a Postgres database.pg_db = PostgresqlDatabase('my_app', user='postgres', password='secret',                           host='10.1.0.9', port=5432)\nPeewee 通过特定的扩展模块提供了对 SQLite 和 Postgres 的高级支持。要使用扩展功能，需要导入特殊数据库模块的 Database 类\nfrom playhouse.sqlite_ext import SqliteExtDatabase# Use SQLite (will register a REGEXP function and set busy timeout to 3s).db = SqliteExtDatabase('/path/to/app.db', regexp_function=True, timeout=3,                       pragmas=(('journal_mode', 'wal'),))from playhouse.postgres_ext import PostgresqlExtDatabase# Use Postgres (and register hstore extension).db = PostgresqlExtDatabase('dbname', user='postgres', register_hstore=True)\nDatabase 类的初始化方法第一个参数是期望的数据库名称，剩下的参数将传给建立连接的底层数据库驱动程序\n使用URL连接数据库playhouse 模块提供了一个 connect() 函数，它接受数据库URL 并返回一个数据库实例\n示例：import osfrom peewee import *from playhouse.db_url import connect# Connect to the database URL defined in the environment, falling# back to a local Sqlite database if no database URL is specified.db = connect(os.environ.get('DATABASE') or 'sqlite:///default.db')class BaseModel(Model):    class Meta:        database = db\n数据库URL示例：\n\nsqlite:///my_database.db 将为 my_database.db 在当前目录创建 SqliteDatabase 实例。\nsqlite:///:memory 将要创建在内存中的 SqliteDatabase 实例。\npostgresql://postgres:my_password@localhost:5432/my_database 将创建一个 PostgresqlDatabase 实例。并提供用户名和密码以及连接的主机和端口\nmysql://user:passwd@ip:port/my_db 将为本地 MySQL 数据库创建 MySQLDatabase 的实例。\n\n数据库运行时配置有时候直到运行时数据库配置才会直到，这些值可以从配置文件或者环境变量获取。在这种情况下可以通过将 None 指定为数据库名来推迟数据库的初始化。\ndatabase = SqliteDatabase(None)  # Un-initialized database.class SomeModel(Model):    class Meta:        database = database\n这时候尝试连接数据库时会抛出一个异常\ndatabase.connect()Exception: Error, database not properly initialized before opening connection\n可以手动调用 init() 方法来初始化数据库\ndatabase_name = raw_input('What is the name of the db? ')database.init(database_name, host='localhost', user='postgres')\n动态定义数据库为了更好地控制数据库的定义/初始化方式，可以使用 Proxy() 方法，Proxy() 方法充当占位符，然后在运行时您可以将其交换出一个不同的对象。\ndatabase_proxy = Proxy()  # Create a proxy for our db.class BaseModel(Model):    class Meta:        database = database_proxy  # Use proxy for our DB.class User(BaseModel):    username = CharField()# Based on configuration, use a different database.if app.config['DEBUG']:    database = SqliteDatabase('local.db')elif app.config['TESTING']:    database = SqliteDatabase(':memory:')else:    database = PostgresqlDatabase('mega_production_db')# Configure our proxy to use the db we specified in config.database_proxy.initialize(database)\n连接管理打开一个数据库连接，使用 Database.connect() 方法\ndb = SqliteDatabase(':memory:') db.connect()\n如果尝试再次调用 connect() 将会得到一个 OperationalError\ndb.connect()Traceback (most recent call last):  File \"&lt;stdin&gt;\", line 1, in &lt;module&gt;  File \"/home/charles/pypath/peewee.py\", line 2390, in connect    raise OperationalError('Connection already opened.')peewee.OperationalError: Connection already opened.\n为了阻止这个异常，可以添加参数 reuse_if_open = True\ndb.connect()db.connect(reuse_if_open = True)\n\n注意：如果数据库连接已打开，则返回 False\n\n调用 close() 将关闭已打开的数据库连接，再次调用 close() 则只会返回 False\n\n小提示：虽然在使用之前没必要显式连接到数据库，但时最好明确连接。这样如果连接失败，在打开的时候就可以捕获该异常，而不是执行数据库操作的时候。如果在使用数据库连接池。则需要调用 connect() 和 close() 以确保连接正确回收。\n\nPeewee 使用线程本地存储跟踪连接状态，使得 Peewee 数据库对象可以安全的用于多个线程，每个线程都拥有自己的连接。\n数据库对象本身可以使用 with 上下文管理器，在上下文管理器中打开一个连接，在连接关闭之前提交，如果错误发生，这种情况下事务将回滚。\ndb.is_closed()  # Truewith db:    print(db.is_closed())  # Falsedb.is_closed()  # True\nconnection_context() 方法也可用于装饰器\n@db.connection_context()def prepare_database():    # DB connection will be managed by the decorator, which opens    # a connection, calls function, and closes upon returning.    db.create_tables(MODELS)  # Create schema.    load_fixture_data(db)\n使用 Database.connection() 方法可以获取底层数据库驱动的原始对象。\ndb.connection()# &lt;sqlite3.Connection object at 0x0574DF20&gt;\n连接池连接池由 Playhouse 扩展库中包含的池模块提供\n\n超时后的连接收回\n最大连接数上限\n\nfrom playhouse.pool import PooledMySQLDatabasedb = PooledMySQLDatabase(    'my_database',    max_connections=8,    stale_timeout=300,    time_out=60,    user='root',     password='db_password',    host='10.1.0.8')class BaseModel(Model):    class Meta:        database = db\n以下数据库连接池类可用：\n\nPooledPostgresqlDatabase\nPooledPostgresqlExtDatabase\nPooledMySQLDatabase\nPooledSqliteDatabase\nPooledSqliteExtDatabase\n\n执行查询如果想直接执行 SQL 语句，可以使用 Database.execute_sql() 方法。\ndb = SqliteDatabase('my_app.db')db.connect()# Example of executing a simple query and ignoring the results.db.execute_sql(\"ATTACH DATABASE ':memory:' AS cache;\")# Example of iterating over the results of a query using the cursor.cursor = db.execute_sql('SELECT * FROM users WHERE status = ?', (ACTIVE,))for row in cursor.fetchall():    # Do something with row, which is a tuple containing column data.    pass\n事务管理Peewee 提供了几个用于处理事务的接口，最常用的是 Database.atomic() 方法，它也支持嵌套事务。如果包装块中发生异常，则当前事务将回滚，否则将提交。\n而在 atomic() 上下文管理器包装的代码块内部时，可以通过调用 Transaction.rollback() 或者 Transaction.commit() 显性的回滚或提交事务。\nwith db.atomic() as transaction:  # Opens new transaction.    try:        save_some_objects()    except ErrorSavingData:        # Because this block of code is wrapped with \"atomic\", a        # new transaction will begin automatically after the call        # to rollback().        transaction.rollback()        error_saving = True    create_report(error_saving=error_saving)    # Note: no need to call commit. Since this marks the end of the    # wrapped block of code, the `atomic` context manager will    # automatically call commit for us.\natomic() 不仅可以用作上下文管理器，还可用做装饰器\n用作装饰器：db = SqliteDatabase(':memory:')with db.atomic() as txn:    # This is the outer-most level, so this block corresponds to    # a transaction.    User.create(username='charlie')    with db.atomic() as nested_txn:        # This block corresponds to a savepoint.        User.create(username='huey')        # This will roll back the above create() query.        nested_txn.rollback()    User.create(username='mickey')# When the block ends, the transaction is committed (assuming no error# occurs). At that point there will be two users, \"charlie\" and \"mickey\".\n还可使用 atomic() 方法来获取或创建数据：try:    with db.atomic():        user = User.create(username=username)    return 'Success'except peewee.IntegrityError:    return 'Failure: %s is already in use.' % username\n用作装饰器：@db.atomic()def create_user(username):    # This statement will run in a transaction. If the caller is already    # running in an `atomic` block, then a savepoint will be used instead.    return User.create(username=username)create_user('charlie')\n保存点：\n可以像显式创建事务一样，也可以使用 savepoint() 方法显式创建保存点。保存点必须发生在一个事务中，但可以任意嵌套。\nwith db.transaction() as txn:    with db.savepoint() as sp:        User.create(username='mickey')    with db.savepoint() as sp2:        User.create(username='zaizee')        sp2.rollback()  # \"zaizee\" will not be saved, but \"mickey\" will be.\n如果手动提交或回滚保存点，则不会自动创建新的保存点。这与事务的行为不同，它会在手动提交/回滚之后自动打开新的事务。\n日志记录所有查询都使用标准库 logging 模块记录到 peewee 命名空间。查询使用 DEBUG 级别。如果你对查询有兴趣，你可以简单地注册一个处理程序。\n# Print all queries to stderr.import logginglogger = logging.getLogger('peewee')logger.setLevel(logging.DEBUG)logger.addHandler(logging.StreamHandler())\n模型和字段模型类、字段实例和模型实例都映射到了数据库\n\n\n\n项\n对应于\n\n\n\n\n模型类\n数据库\n\n\n字段实例\n表中的列\n\n\n模型实例\n表中的行\n\n\n\n下面的例子演示了定义数据库连接和模型类的方法\nfrom peewee import *# 创建一个数据库的实例db = SqliteDatabase('my_app.db')# 创建一个指定数据库的基础模型类class BaseModel(Model):    class Meta:        database = db# 定义模型类class User(BaseModel):    username = CharField(unique=True)# 定义模型类class Tweet(BaseModel):    user = ForeignKeyField(User, backref='tweets')    message = TextField()    created_date = DateTimeField(default=datetime.datetime.now)    is_published = BooleanField(default=True)\n字段字段类用于描述模型属性到数据库字段的映射，每一个字段类型都有一个相应的 SQL 存储类型，如 varchar, int。并且python的数据类型和 SQL 存储类型之间的转换是透明的。\n在创建模型类时，字段被定义为类属性。有一种特殊类型的字段 ForeignKeyField，可以以更直观的方式表示模型之间的外键关系。\nclass Message(Model):    user = ForeignKeyField(User, backref='messages')    body = TextField()    send_date = DateTimeField()\n这允许你编写如下的代码：\nprint(some_message.user.username)for message in some_user.messages:    print(message.body)\n字段类型表\n\n\n字段类型\nSqlite\nPostgresql\nMySQL\n\n\n\n\nIntegerField\ninteger\ninteger\ninteger\n\n\nBigIntegerField\ninteger\nbigint\nbigint\n\n\nSmallIntegerField\ninteger\nsmallint\nsmallint\n\n\nAutoField\ninteger\nserial\ninteger\n\n\nFloatField\nreal\nreal\nreal\n\n\nDoubleField\nreal\ndouble precision\ndouble precision\n\n\nDecimalField\ndecimal\nnumeric\nnumeric\n\n\nCharField\nvarchar\nvarchar\nvarchar\n\n\nFixedCharField\nchar\nchar\nchar\n\n\nTextField\ntext\ntext\nlongtext\n\n\nBlobField\nblob\nbytea\nblob\n\n\nBitField\ninteger\nbigint\nbigint\n\n\nBigBitField\nblob\nbytea\nblob\n\n\nUUIDField\ntext\nuuid\nvarchar(40)\n\n\nDateTimeField\ndatetime\ntimestamp\ndatetime\n\n\nDateField\ndate\ndate\ndate\n\n\nTimeField\ntime\ntime\ntime\n\n\nTimestampField\ninteger\ninteger\ninteger\n\n\nIPField\ninteger\nbigint\nbigint\n\n\nBooleanField\ninteger\nboolean\nbool\n\n\nBareField\nuntyped\n不支持\n不支持\n\n\nForeignKeyField\ninteger\ninteger\ninteger\n\n\n\n字段初始参数所有字段类型接受的参数与默认值\n\nnull = False – 布尔值，表示是否允许存储空值\nindex = False – 布尔值，表示是否在此列上创建索引\nunique = False – 布尔值，表示是否在此列上创建唯一索引\ncolumn_name = None – 如果和属性名不同，底层的数据库字段使用这个值\ndefault = None – 字段默认值，可以是一个函数，将使用函数返回的值\nprimary_key = False – 布尔值，此字段是否是主键\nconstraints = None - 一个或多个约束的列表 例如：[Check(&#39;price &gt; 0&#39;)]\nsequence = None – 序列填充字段（如果后端数据库支持）\ncollation = None – 用于排序字段/索引的排序规则\nunindexed = False – 表示虚拟表上的字段应该是未索引的（仅用于sqlite）\nchoices = None – 一个可选的迭代器，包含两元数组（value, display）\nhelp_text = None – 表示字段的帮助文本\nverbose_name = None – 表示用户友好的字段名\n\n一些字段的特殊参数\n\n\n\n字段类型\n特殊参数\n\n\n\n\nCharField\nmax_length\n\n\nFixedCharField\nmax_length\n\n\nDateTimeField\nformats\n\n\nDateField\nformats\n\n\nTimeField\nformats\n\n\nTimestampField\nresolution, utc\n\n\nDecimalField\nmax_digits, decimal_places, auto_round, rounding\n\n\nForeignKeyField\nmodel, field, backref, on_delete, on_update, extra\n\n\nBareField\ncoerce\n\n\n\n字段默认值创建对象时，peewee 可以为字段提供默认值，例如将字段的默认值null设置为0class Message(Model):    context = TextField()    read_count = IntegerField(default=0)\n如果想提供一个动态值，比如当前时间，可以传入一个函数\nclass Message(Model):    context = TextField()    timestamp = DateTimeField(default=datetime.datetime.now)\n数据库还可以提供字段的默认值。虽然 peewee 没有明确提供设置服务器端默认值的 API，但您可以使用 constraints 参数来指定服务器默认值：\nclass Message(Model):    context = TextField()    timestamp = DateTimeField(constraints=[SQL('DEFAULT CURRENT_TIMESTAMP')])\n外键字段foreignkeyfield 是一种特殊的字段类型，允许一个模型引用另一个模型。通常外键将包含与其相关的模型的主键（但您可以通过指定一个字段来指定特定的列）。\n可以通过追加 _id 的外键字段名称来访问原始外键值\ntweets = Tweet.select()for tweet in tweets:    # Instead of \"tweet.user\", we will just get the raw ID value stored    # in the column.    print(tweet.user_id, tweet.message)\nForeignKeyField 允许将反向引用属性绑定到目标模型。隐含地，这个属性将被命名为 classname_set，其中 classname 是类的小写名称，但可以通过参数覆盖 backref：\nclass Message(Model):    from_user = ForeignKeyField(User)    to_user = ForeignKeyField(User, backref='received_messages')    text = TextField()for message in some_user.message_set:    # We are iterating over all Messages whose from_user is some_user.    print(message)for message in some_user.received_messages:    # We are iterating over all Messages whose to_user is some_user    print(message)\n日期字段DateField TimeField 和 DateTimeField 字段\nDateField 包含 year month dayTimeField 包含 hour minute secondDateTimeField 包含以上所有\n创建模型表为了开始使用模型，它需要打开一个到数据库的连接并创建表。Peewee 将运行必要的 CREATE TABLE 查询，另外创建约束和索引。\n# Connect to our database.db.connect()# Create the tables.db.create_tables([User, Tweet])\n默认情况下，Peewee 将确定表是否已经存在，并有条件地创建它们。如果你想禁用它，指定 safe=False。\n模型选项和表格元数据为了不污染模型空间，模型的配置被放置在名为 Meta 的特殊类中\nfrom peewee import *contacts_db = SqliteDatabase('contacts.db')class Person(Model):    name = CharField()    class Meta:        database = contacts_db\n模型一旦定义，访问元数据应该访问 ModelClass._meta\nPerson._meta.fieldsPerson._meta.primary_keyPerson._meta.database\n有几个选项可以指定为Meta属性。虽然大多数选项都是可继承的，但有些选项是特定于表的，不会被子类继承。\n\n\n\n选项\n含义\n是否可继承\n\n\n\n\ndatabase\n模型的数据库\n是\n\n\ntable_name\n用于存储数据的表的名称\n否\n\n\ntable_function\n函数动态生成表名\n是\n\n\nindexes\n要索引的字段列表\n是\n\n\nprimary_key\n一个 CompositeKey 实例\n是\n\n\nconstraints\n表约束列表\n是\n\n\nschema\n模型的数据库概要\n是\n\n\nonly_save_dirty\n当调用 model.save() 时，只保存脏字段\n是\n\n\noptions\n用于创建表扩展选项的字典\n是\n\n\ntable_alias\n用于查询中的表的别名\n否\n\n\ndepends_on\n此表依赖于另一个表的创建\n否\n\n\nwithout_rowid\n指示表不应该有rowid（仅限SQLite）\n否\n\n\n\n不可被继承的例子\n&gt;&gt;&gt; db = SqliteDatabase(&apos;:memory:&apos;)\n&gt;&gt;&gt; class ModelOne(Model):\n...     class Meta:\n...         database = db\n...         table_name = &apos;model_one_tbl&apos;\n...\n&gt;&gt;&gt; class ModelTwo(ModelOne):\n...     pass\n...\n&gt;&gt;&gt; ModelOne._meta.database is ModelTwo._meta.database\nTrue\n&gt;&gt;&gt; ModelOne._meta.table_name == ModelTwo._meta.table_name\nFalse\n自定义主键或者没有主键可以用 CompositeKey 或者将主键设置为 False\nclass BlogToTag(Model):    \"\"\"A simple \"through\" table for many-to-many relationship.\"\"\"    blog = ForeignKeyField(Blog)    tag = ForeignKeyField(Tag)    class Meta:        primary_key = CompositeKey('blog', 'tag')class NoPrimaryKey(Model):    data = IntegerField()    class Meta:        primary_key = False\n索引和约束Peewee 可以在单列或多列上创建索引，可以包含 UNIQUE 约束。Peewee 还在模型和字段上支持用户定义的约束。\n单列索引和约束单列索引是使用字段初始化参数定义的。以下示例在用户名字段上添加唯一索引，并在电子邮件字段上添加常规索引：\nclass  User （Model ）：    username  =  CharField （unique = True ）    email  =  CharField （index = True ）\n要在列上添加用户定义的约束，可以使用constraints参数传递它 。您可能希望将默认值指定为架构的一部分，或者添加一个 CHECK 约束，例如：\nclass Product(Model):    name = CharField(unique=True)    price = DecimalField(constraints=[Check('price &lt; 10000')])    created = DateTimeField(        constraints=[SQL(\"DEFAULT (datetime('now'))\")])\n多列索引多列索引可以使用嵌套元组定义为元属性。每个数据库索引都是一个两个元素的元组，第一部分是字段名称的元组，第二部分是布尔值，指示索引是否应该是唯一的。\nclass Transaction(Model):    from_acct = CharField()    to_acct = CharField()    amount = DecimalField()    date = DateTimeField()    class Meta:        indexes = (            # create a unique on from/to/date            (('from_acct', 'to_acct', 'date'), True),            # create a non-unique on from/to            (('from_acct', 'to_acct'), False),        )\n创建高级索引Peewee 支持更结构化的 API，以便使用该 Model.add_index() 方法在模型上声明索引，或直接使用 ModelIndexhelper 类。\nclass Article(Model):    name = TextField()    timestamp = TimestampField()    status = IntegerField()    flags = IntegerField()# Add an index on \"name\" and \"timestamp\" columns.Article.add_index(Article.name, Article.timestamp)# Add a partial index on name and timestamp where status = 1.Article.add_index(Article.name, Article.timestamp,                  where=(Article.status == 1))# Create a unique index on timestamp desc, status &amp; 4.idx = Article.index(    Article.timestamp.desc(),    Article.flags.bin_and(4),    unique=True)Article.add_index(idx)\n表约束Peewee允许您为您添加任意约束Model，这将在创建模式时成为表定义的一部分。\n例如，假设您有一个具有两列组合主键的人员表格，即人员的姓名。您希望将另一个表与人员表相关联，为此，您需要定义一个外键约束：\nclass Person(Model):    first = CharField()    last = CharField()    class Meta:        primary_key = CompositeKey('first', 'last')class Pet(Model):    owner_first = CharField()    owner_last = CharField()    pet_name = CharField()    class Meta:        constraints = [SQL('FOREIGN KEY(owner_first, owner_last) '                           'REFERENCES person(first, last)')]\n也可以使用 CHECK 在表级别实施约束：\nclass Product(Model):    name = CharField(unique=True)    price = DecimalField()    class Meta:        constraints = [Check('price &lt; 10000')]\n其他主键非整数主键如果想使用非整数主键，可以在创建字段时指定 primary_key=True。当希望使用非自动增量主键为模型创建新实例时，您需要确保 save() 指定 force_insert=True。\nfrom peewee import *class UUIDModel(Model):    id = UUIDField(primary_key=True)\n自动递增ID在新行插入数据库时​​会自动生成，当调用 save() 时 peewee 会根据主键值的存在性来确定是否执行 insert 和 update。由于在上一个例子中，数据库驱动程序不会生成新的ID，所以需要手动指定它。在第一次调用 save() 时，传入：force_insert = True\nimport uuid# This works because .create() will specify `force_insert=True`.obj1 = UUIDModel.create(id=uuid.uuid4())# This will not work, however. Peewee will attempt to do an update:obj2 = UUIDModel(id=uuid.uuid4())obj2.save() # WRONGobj2.save(force_insert=True) # CORRECT# Once the object has been created, you can call save() normally.obj2.save()\n复合主键Peewee 对复合键有基本的支持。为了使用组合键，必须将 primary_key 模型选项的属性设置为一个 CompositeKey 实例：\nclass BlogToTag(Model):    \"\"\"A simple \"through\" table for many-to-many relationship.\"\"\"    blog = ForeignKeyField(Blog)    tag = ForeignKeyField(Tag)    class Meta:        primary_key = CompositeKey('blog', 'tag')\n手动指定主键有时不希望数据库自动为主键生成值，例如在批量加载关系数据时。要一次性处理这个问题，您可以简单地告诉 peewee auto_increment 在导入期间关闭：\ndata = load_user_csv() # load up a bunch of dataUser._meta.auto_increment = False # turn off auto incrementing IDswith db.transaction():    for row in data:        u = User(id=row[0], username=row[1])        u.save(force_insert=True) # &lt;-- force peewee to insert rowUser._meta.auto_increment = True\n如果想要始终控制主键，则不要使用 PrimaryKeyField 字段类型，而要使用正常 IntegerField（或其他列类型）：\nclass User(BaseModel):\n    id = IntegerField(primary_key=True)\n    username = CharField()\n\n&gt;&gt;&gt; u = User.create(id=999, username=&apos;somebody&apos;)\n&gt;&gt;&gt; u.id\n999\n&gt;&gt;&gt; User.get(User.username == &apos;somebody&apos;).id\n999\n没有主键的模型如果你想创建一个没有主键的模型，你可以在内部类 Meta 中指定 ：primary_key = False\nclass MyData(BaseModel):    timestamp = DateTimeField()    value = IntegerField()    class Meta:        primary_key = False\n更改和查询本章将介绍在关系型数据库上执行 CRUD 操作\n\nModel.create()，用于执行 INSERT 请求。\nModel.save() 和 Model.update() 执行 UPDATE 请求。\nModel.delete_instance() 和 Model.delete() 执行 DELETE 请求。\nModel.select()，用于执行 SELECT 请求。\n\n创建一条新记录可以使用 Model.create() 创建一个新的模型实例。此方法接受关键字参数，其中键与模型字段的名称相对应。返回一个新实例并将一行添加到表中。\nUser.create(username='Charlie')\n这将插入一行新数据到数据库中，主键将自动检索并存储在模型实例中。或者还可以先创建模型实例，然后调用 save()\n&gt;&gt;&gt; user = User(username=&apos;Charlie&apos;)\n&gt;&gt;&gt; user.save()  # save() returns the number of rows modified.\n1\n&gt;&gt;&gt; user.id\n1\n&gt;&gt;&gt; huey = User()\n&gt;&gt;&gt; huey.username = &apos;Huey&apos;\n&gt;&gt;&gt; huey.save()\n1\n&gt;&gt;&gt; huey.id\n2\n当模型有外键时，可以在创建新记录时直接将模型实例分配给外键字段。\n&gt;&gt;&gt; tweet = Tweet.create(user=huey, message=&apos;Hello!&apos;)\n也可以使用相关对象主键的值：\n&gt;&gt;&gt; tweet = Tweet.create(user=2, message=&apos;Hello again!&apos;)\n如果只是想插入数据而不需要创建模型实例，则可以使用 Model.insert()：\n&gt;&gt;&gt; User.insert(username=&apos;Mickey&apos;).execute()\n3\n批量插入可以通过调用 insert_many() 高效率的插入大量数据\ndata_source = [    &#123;'field1': 'val1-1', 'field2': 'val1-2'&#125;,    &#123;'field1': 'val2-1', 'field2': 'val2-2'&#125;,    # ...]# 最快的方法MyModel.insert_many(data_source).execute()# 也可以使用元组 并指定插入的字段fields = [MyModel.field1, MyModel.field2]data = [('val1-1', 'val1-2'),        ('val2-1', 'val2-2'),        ('val3-1', 'val3-2')]MyModel.insert_many(data, fields=fields)# 也可以包含在一个事务中with db.atomic():    MyModel.insert_many(data, fields=fields)\n如果要批量加载的数据存储在另一个表中，则还可以创建其源为 SELECT 请求的 INSERT 请求。使用 方法：Model.insert_from()\nquery = (TweetArchive         .insert_from(             Tweet.select(Tweet.user, Tweet.message),             fields=[Tweet.user, Tweet.message])         .execute())\n更新数据一旦模型具有主键，后续的任何 save() 都将导致 UPDATE 而不是 INSERT，该模型的主键不会改变。\n&gt;&gt;&gt; user.save()\n1\n&gt;&gt;&gt; user.id\n2\n&gt;&gt;&gt; user.username = &apos;Tom&apos;\n&gt;&gt;&gt; user.save()\n1\n&gt;&gt;&gt; user.id\n2\n如果想更新多条记录，使用 Model.update()\n&gt;&gt;&gt; today = datetime.today()\n&gt;&gt;&gt; query = Tweet.update(is_published=True).where(Tweet.creation_date &lt; today)\n&gt;&gt;&gt; query.execute()  # Returns the number of rows that were updated.\n4\n原子更新peewee 允许执行原子更新。假设需要更新计数器，天真的方法是这样写的：\n&gt;&gt;&gt; for stat in Stat.select().where(Stat.url == request.url):\n...     stat.counter += 1\n...     stat.save()\n这样速度不仅特别慢，如果多进程同时更新计数器，还会受到竞争条件的影响。可以使用 update() 自动更新计数器。\nquery = Stat.update(counter=Stat.counter + 1).where(Stat.url == request.url)query.execute()\n还可以使这些更新语句更复杂些。让我们给所有员工一个奖金，等于他们以前的奖金加上他们工资的10％：\nquery = Employee.update(bonus=(Employee.bonus + (Employee.salary * .1)))query.execute()\n还可以使用子查询来更新值：\nsubquery = Tweet.select(fn.COUNT(Tweet.id)).where(Tweet.user == User.id)update = User.update(num_tweets=subquery)update.execute()\n删除记录要删除单个模型实例，可以使用 Model.delete_instance()，delete_instance() 方法将删除给定的模型实例，并可以递归删除任何依赖对象（指定 recursive=True）\nuser = User.get(User.id == 1)user.delete_instance()\n要删除多行，可以使用删除命令：\nquery = Tweet.delete().where(Tweet.creation_date &lt; one_year_ago)query.execute()\n查询一条记录可以使用 Model.get() 方法来检索查询匹配到的单个实例。对于主键查找，还可以使用快捷方式 Model.get_by_id()。如果没有查询到结果，将返回一个异常\n&gt;&gt;&gt; User.get(User.id == 1)\n&lt;__main__.User object at 0x25294d0&gt;\n\n&gt;&gt;&gt; User.get_by_id(1)  # Same as above.\n&lt;__main__.User object at 0x252df10&gt;\n\n&gt;&gt;&gt; User[1]  # Also same as above.\n&lt;__main__.User object at 0x252dd10&gt;\n\n&gt;&gt;&gt; User.get(User.id == 1).username\nu&apos;Charlie&apos;\n\n&gt;&gt;&gt; User.get(User.username == &apos;Charlie&apos;)\n&lt;__main__.User object at 0x2529410&gt;\n\n&gt;&gt;&gt; User.get(User.username == &apos;nobody&apos;)\nUserDoesNotExist: instance matching query does not exist:\nSQL: SELECT t1.&quot;id&quot;, t1.&quot;username&quot; FROM &quot;user&quot; AS t1 WHERE t1.&quot;username&quot; = ?\nPARAMS: [&apos;nobody&apos;]\n对于更高级的查询，可以使用 SelectBase.get()。\n&gt;&gt;&gt; (Tweet\n...  .select()\n...  .join(User)\n...  .where(User.username == &apos;charlie&apos;)\n...  .order_by(Tweet.created_date.desc())\n...  .get())\n&lt;__main__.Tweet object at 0x2623410&gt;\n获取或创建Peewee 有一个用于执行获取或者创建类型操作的方法 Model.get_or_create()，它首先尝试检索匹配的行，否则将创建一个新行\nuser, created = User.get_or_create(username=username)\n选择多行可以使用 Model.select() 从表中检索多行，peewee 允许迭代以及检索和切片这些行\n&gt;&gt;&gt; query = User.select()\n&gt;&gt;&gt; [user.username for user in query]\n[&apos;Charlie&apos;, &apos;Huey&apos;, &apos;Peewee&apos;]\n\n&gt;&gt;&gt; query[1]\n&lt;__main__.User at 0x7f83e80f5550&gt;\n\n&gt;&gt;&gt; query[1].username\n&apos;Huey&apos;\n\n&gt;&gt;&gt; query[:2]\n[&lt;__main__.User at 0x7f83e80f53a8&gt;, &lt;__main__.User at 0x7f83e80f5550&gt;]\n除了返回模型实例之外，选择查询还可以返回字典，元组和命名集。\n&gt;&gt;&gt; query = User.select().dicts()\n&gt;&gt;&gt; for row in query:\n...     print(row)\n\n{&apos;id&apos;: 1, &apos;username&apos;: &apos;Charlie&apos;}\n{&apos;id&apos;: 2, &apos;username&apos;: &apos;Huey&apos;}\n{&apos;id&apos;: 3, &apos;username&apos;: &apos;Peewee&apos;}\n过滤可以使用普通的Python操作符来过滤特定的记录。 Peewee 支持多种查询操作符。\n&gt;&gt;&gt; user = User.get(User.username == &apos;Charlie&apos;)\n&gt;&gt;&gt; for tweet in Tweet.select().where(Tweet.user == user, Tweet.is_published == True):\n...     print(tweet.user.username, &apos;-&gt;&apos;, tweet.message)\n...\nCharlie -&gt; hello world\nCharlie -&gt; this is fun\n\n&gt;&gt;&gt; for tweet in Tweet.select().where(Tweet.created_date &lt; datetime.datetime(2011, 1, 1)):\n...     print(tweet.message, tweet.created_date)\n...\nReally old tweet 2010-01-01 00:00:00\n还可以使用 join 后过滤\n&gt;&gt;&gt; for tweet in Tweet.select().join(User).where(User.username == &apos;Charlie&apos;):\n...     print(tweet.message)\nhello world\nthis is fun\nlook at this picture of my food\n如果想表达复杂的逻辑，还可以使用 | 或者 &amp; 操作符\n&gt;&gt;&gt; Tweet.select().join(User).where(\n...     (User.username == &apos;Charlie&apos;) |\n...     (User.username == &apos;Peewee Herman&apos;))\n排序要按顺序返回行，要使用 order_by() 方法\n&gt;&gt;&gt; for t in Tweet.select().order_by(Tweet.created_date):\n...     print(t.pub_date)\n...\n2010-01-01 00:00:00\n2011-06-07 14:08:48\n2011-06-07 14:12:57\n\n&gt;&gt;&gt; for t in Tweet.select().order_by(Tweet.created_date.desc()):\n...     print(t.pub_date)\n...\n2011-06-07 14:12:57\n2011-06-07 14:08:48\n2010-01-01 00:00:00\n还可以使用 + 和 - 前缀来指示排序：\n# The following queries are equivalent:Tweet.select().order_by(Tweet.created_date.desc())Tweet.select().order_by(-Tweet.created_date)  # Note the \"-\" prefix.# Similarly you can use \"+\" to indicate ascending order, though ascending# is the default when no ordering is otherwise specified.User.select().order_by(+User.username)\n还可以使用 join 连接后排序\nquery = (Tweet         .select()         .join(User)         .order_by(User.username, Tweet.created_date.desc()))\n当对计算值进行排序时，可以包含必需的 sql 表达式，或者分配给该值别名。\n# Let's start with our base query. We want to get all usernames and the number of# tweets they've made. We wish to sort this list from users with most tweets to# users with fewest tweets.query = (User         .select(User.username, fn.COUNT(Tweet.id).alias('num_tweets'))         .join(Tweet, JOIN.LEFT_OUTER)         .group_by(User.username))\n还可以在 select 中使用 COUNT 表达式来排序\nquery = (User         .select(User.username, fn.COUNT(Tweet.id).alias('num_tweets'))         .join(Tweet, JOIN.LEFT_OUTER)         .group_by(User.username)         .order_by(fn.COUNT(Tweet.id).desc()))\n获取随机记录偶尔可能想从数据库中提取一条随机记录，可以通过 random 或 rand（取决于你的数据库）来完成这个任务：\n# Postgresql and Sqlite use the Random function# Pick 5 lucky winners:LotteryNumber.select().order_by(fn.Random()).limit(5)# MySQL uses Rand:# Pick 5 lucky winners:LotterNumber.select().order_by(fn.Rand()).limit(5)\n分页paginate() 方法可以轻松对记录进行分页，paginate() 方法需要两个参数，page_number, 和 items_per_page。\n&gt;&gt;&gt; for tweet in Tweet.select().order_by(Tweet.id).paginate(2, 10):\n...     print(tweet.message)\n...\ntweet 10\ntweet 11\ntweet 12\ntweet 13\ntweet 14\ntweet 15\ntweet 16\ntweet 17\ntweet 18\ntweet 19\n计数可以计算任何查询中选择的行数\n&gt;&gt;&gt; Tweet.select().count()100&gt;&gt;&gt; Tweet.select().where(Tweet.id &gt; 50).count()50\n汇总假设你有一些用户，并希望得到他们的列表以及每个人的推文数量。\nquery = (User         .select(User, fn.Count(Tweet.id).alias('count'))         .join(Tweet, JOIN.LEFT_OUTER)         .group_by(User))\n返回标量值可以通过调用 Query.scalar() 来返回标量值：\n&gt;&gt;&gt; PageView.select(fn.Count(fn.Distinct(PageView.url))).scalar()\n100\n您可以通过传递 as_tuple=true 来返回多个标量值：\n&gt;&gt;&gt; Employee.select(\n...     fn.Min(Employee.salary), fn.Max(Employee.salary)\n... ).scalar(as_tuple=True)\n(30000, 50000)\nSQL函数，子查询和原始表达式要使用特殊的 SQL 函数，需要使用 fn 的对象来构造请求假设要获取所有以字母 a 开头的用户列表：\n# Select the user's id, username and the first letter of their username, lower-casedfirst_letter = fn.LOWER(fn.SUBSTR(User.username, 1, 1))query = User.select(User, first_letter.alias('first_letter'))# Alternatively we could select only users whose username begins with 'a'a_users = User.select().where(first_letter == 'a')for user in a_users:    print(user.username)\n有时候想传入一些任意的 SQL ，可以使用特殊的 SQL 类来做到这点\n# We'll query the user table and annotate it with a count of tweets for# the given userquery = (User         .select(User, fn.Count(Tweet.id).alias('ct'))         .join(Tweet)         .group_by(User))# Now we will order by the count, which was aliased to \"ct\"query = query.order_by(SQL('ct'))# You could, of course, also write this as:query = query.order_by(fn.COUNT(Tweet.id))\n有两种方法可以用 peewee 执行手动编写的 SQL 语句：\n\nDatabase.execute_sql() 用户执行任意类型的查询\n用于执行 SELECT 查询和返回模型实例的 RawQuery\n\n安全和SQL注入默认情况下，peewee会参数化查询，所以用户传入的参数将被转义。这条规则唯一的例外是，如果你正在编写一个原始的 sql 查询或传入一个可能包含不可信数据的 sql 对象。为了减轻这一点，请确保任何用户定义的数据都作为查询参数传入，而不是实际的 sql 查询的一部分：\n# Bad! DO NOT DO THIS!query = MyModel.raw('SELECT * FROM my_table WHERE data = %s' % (user_data,))# Good. `user_data` will be treated as a parameter to the query.query = MyModel.raw('SELECT * FROM my_table WHERE data = %s', user_data)# Bad! DO NOT DO THIS!query = MyModel.select().where(SQL('Some SQL expression %s' % user_data))# Good. `user_data` will be treated as a parameter.query = MyModel.select().where(SQL('Some SQL expression %s', user_data))\n返回元组/字典/名称元组有时候不需要创建模型实例的开销，只需要数据即可，可以使用：\n\ndicts()\nnamedtuples()\ntuples()\nobjects() – 接受用行元组调用的任意构造函数。\n\nstats = (Stat         .select(Stat.url, fn.Count(Stat.url))         .group_by(Stat.url)         .tuples())# iterate over a list of 2-tuples containing the url and countfor stat_url, stat_count in stats:    print(stat_url, stat_count)\n同样也可以使用 dicts() 将数据作为字典返回\nstats = (Stat         .select(Stat.url, fn.Count(Stat.url).alias('ct'))         .group_by(Stat.url)         .dicts())# iterate over a list of 2-tuples containing the url and countfor stat in stats:    print(stat['url'], stat['ct'])\n查询操作符Peewee 支持以下类型的比较：\n\n\n\n对照\n含义\n\n\n\n\n==\nx 等于 y\n\n\n&lt;\nx 小于 y\n\n\n&lt;=\nx 小于或等于 y\n\n\n>\nx 大于 y\n\n\n>=\nx 大于或等于 y\n\n\n!=\nx 不等于 y\n\n\n&lt;&lt;\nx IN y, y 是一个列表或查询\n\n\n>&gt;\nx IS y, 当 y 是 None 或者 NULL\n\n\n%\nx LIKE y, 当 y 可能包含通配符\n\n\n**\nx ILIKE y, 当 y 可能包含通配符\n\n\n^\nx XOR y\n\n\n~\n非 (例如：NOT x)\n\n\n\n还有一些查询可以用方法：\n方法含义.contains(substr)通配符搜索子字符串.startswith(prefix)搜索以prefix为前缀的值.endswith(suffix)搜索以suffix为后缀的值.between(low,high)搜索low和 high之间的值.regexp(exp)正则表达式匹配.bin_and(value)二进制 AND.bin_or(value)二进制 OR.in_(value)值是否属于.not_in(value)值是否不属于.is_null(is_null)是 NULL 或者不是 NULL .concat(other)连接两个字符串.distinct()标记不同的选择列\n\n要使用逻辑运算符来组合子句，使用：\n操作符意思示例&amp;AND(User.is_active==True)&amp;(User.is_admin==True)|OR(User.is_admin)|(User.is_superuser)~NOT~(User.username&lt;&lt;[‘foo’,‘bar’,‘baz’])\n\n如何使用查询操作符的示例：\n# Find the user whose username is \"charlie\".User.select().where(User.username == 'charlie')# Find the users whose username is in [charlie, huey, mickey]User.select().where(User.username &lt;&lt; ['charlie', 'huey', 'mickey'])Employee.select().where(Employee.salary.between(50000, 60000))Employee.select().where(Employee.name.startswith('C'))Blog.select().where(Blog.title.contains(search_string))\n这里是如何组合表达式的示例：\n# Find any users who are active administrations.User.select().where(  (User.is_admin == True) &amp;  (User.is_active == True))# Find any users who are either administrators or super-users.User.select().where(  (User.is_admin == True) |  (User.is_superuser == True))# Find any Tweets by users who are not admins (NOT IN).admins = User.select().where(User.is_admin == True)non_admin_tweets = Tweet.select().where(~(Tweet.user &lt;&lt; admins))# Find any users who are not my friends (strangers).friends = User.select().where(User.username.in_(['charlie', 'huey', 'mickey']))strangers = User.select().where(User.id.not_in(friends))\n请记住：\n\n使用 .in_() 和 .not_in() 替换 in 和 not in\n使用 &amp; 替换 and\n使用 | 替换 or\n使用 ~ 替换 not\n使用 .is_null() 替换 is None 或者 == None\n在使用逻辑运算符时，不要忘记使用圆括号包含比较结果\n\n用户自定义操作符如果发现自己需要的操作符不在上表中，可以非常容易的自定义操作符，比如取模运算\n这里是如何在 SQLite 中添加取模运算的支持：\nfrom peewee import *from peewee import Expression # the building block for expressionsdef mod(lhs, rhs):    return Expression(lhs, '%', rhs)\n现在可以将自定义运算符来构建更丰富的查询\n# Users with even ids.User.select().where(mod(User.id, 2) == 0)\n附录Peewee 的详细使用说明请翻阅 Peewee官方文档\n","categories":["Python"],"tags":["python","peewee"]},{"title":"愉快的用 Vim 写代码","url":"/2018/05/11/2018/%E6%84%89%E5%BF%AB%E7%9A%84%E7%94%A8Vim%E5%86%99%E4%BB%A3%E7%A0%81/","content":"简介\nVim 是一款高可定制的文本编辑器软件，而大多数人使用 vim 应该是从 Linux 的教科书里得知的吧。vim 来自于 vi 编辑器，而 vi 在1976年就发布了，经过如此多年的进化，可以说是非常成熟和强大了。但是 vim 的学习曲线比较陡，但是对 vim 学习的越深入，使用 vim 提升的效率就越高。这里是这几天对 vim 的学习，打造出的一款比较得心应手的编程工具。\n\n\n环境在 Ubuntu 16.04 和 Ubuntu 18.04 上测试成功，理论上比较高的 Vim 版本都可以。Mac 没测试环境 ╮(╯▽╰)╭ ，Windows 就用 IDE 了，不想用 IDE 还可以使用 Notepad++ 或者 VScode。Vim 胜在是安装在服务器上的，这样需要远程连接服务器来写代码调试的话就非常方便了。先秀几张效果截图。\n代码补全\n文件分屏\n文件操作\n安装自己写的配置已经开源在了 Github 上 点击浏览\n因为安装过程中需要联网安装插件，所以务必保证网络正常，并且已经安装 git 命令行工具。\n输入以下命令安装：source &lt;(curl -s https://raw.githubusercontent.com/yunfwe/vimconf/master/install.sh)\nVim 的配置被安装到了家目录下的 .vimrc 文件和 .vim 目录，如果安装之前存在着两个目录，脚本将自动备份。如果想卸载也非常简单，手动删除家目录下的 .vimrc 和 .vim 即可，或者执行提供好的卸载脚本也可以：source &lt;(curl -s https://raw.githubusercontent.com/yunfwe/vimconf/master/uninstall.sh)\n配置Vim 的配置文件非常强大，是一种专门的 Vim Script 的语言编写，大部分的 Vim 插件也都是用这个语言写的\n这里看看配置文件的内容，以及各内容的说明\n&quot; curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim\n&quot; vim -c &quot;PlugInstall&quot; -c &quot;q&quot; -c &quot;q&quot;\n\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 使用plug\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\ncall plug#begin(&apos;~/.vim/plugged&apos;)\nPlug &apos;scrooloose/nerdtree&apos;      &quot; 目录树插件\nPlug &apos;vim-airline/vim-airline&apos;  &quot; 状态栏插件\nPlug &apos;vim-airline/vim-airline-themes&apos; &quot; 状态栏主题插件\nPlug &apos;joshdick/onedark.vim&apos;     &quot; 状态栏主题使用的颜色\nPlug &apos;jiangmiao/auto-pairs&apos;     &quot; 自动补全引号括号\nPlug &apos;vim-scripts/SuperTab&apos;     &quot; 提高Tab键能力的插件\n&quot;Plug &apos;vim-scripts/c.vim&apos;        &quot; 官方C语言插件\nPlug &apos;rkulla/pydiction&apos;         &quot; 轻量级的Python补全插件\nPlug &apos;luochen1990/rainbow&apos;      &quot; 为不同的括号添加颜色的插件\ncall plug#end()\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nVim 的配置文件中，用双引号开头表示注释，是被 Vim 忽略的，Vim 安装插件最简单的方法就是使用插件管理器，但是插件管理器也是 Vim 的一个插件，所以这个插件就需要手动安装了，因此安装脚本的开头就是从 Github 上获取这个插件管理器，然后放到相应的目录中后 先用一个简单的只包含需要安装其他插件指令的配置文件启动 Vim 并安装其他插件。\n插件大多数人都选择直接从 github 上获取，所以插件名就可以不用写 github 的全路径，只需要用户名和仓库名就可以了，Vim 的插件管理器还有非常多的种类，但是 vim-plug 可以并发下载安装插件，比其他种类的更轻，更快。\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 实用设置\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot;当打开vim且没有文件时自动打开NERDTree\nautocmd vimenter * if !argc() | NERDTree | endif\n&quot; 只剩 NERDTree时自动关闭\nautocmd bufenter * if (winnr(&quot;$&quot;) == 1 &amp;&amp; exists(&quot;b:NERDTreeType&quot;) &amp;&amp; b:NERDTreeType == &quot;primary&quot;) | q | endif\nset autoread        &quot; 设置当文件被改动时自动载入\nif has(&quot;autocmd&quot;)\n    au BufReadPost * if line(&quot;&apos;\\&quot;&quot;) &gt; 1 &amp;&amp; line(&quot;&apos;\\&quot;&quot;) &lt;= line(&quot;$&quot;) | exe &quot;normal! g&apos;\\&quot;&quot; | endif\nendif\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 编码设置\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nset langmenu=zh_CN.UTF-8\nset helplang=cn\nset termencoding=utf-8\nset encoding=utf8\nset fileencodings=utf8,ucs-bom,gbk,cp936,gb2312,gb18030\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 通用设置\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nlet mapleader = &quot;,&quot;      &quot; 定义&lt;leader&gt;键\nset nocompatible         &quot; 设置不兼容原始vi模式\nfiletype on              &quot; 设置开启文件类型侦测\nfiletype plugin on       &quot; 设置加载对应文件类型的插件\nset noeb                 &quot; 关闭错误的提示\nsyntax enable            &quot; 开启语法高亮功能\nsyntax on                &quot; 自动语法高亮\nset t_Co=256             &quot; 开启256色支持\nset cmdheight=1          &quot; 设置命令行的高度\nset showcmd              &quot; select模式下显示选中的行数\nset scrolloff=3          &quot; 光标移动到buffer的顶部和底部时保持3行距离 \nset ruler                &quot; 总是显示光标位置\nset laststatus=2         &quot; 总是显示状态栏\nset number               &quot; 开启行号显示\nset cursorline           &quot; 高亮显示当前行\nset whichwrap+=&lt;,&gt;,h,l   &quot; 设置光标键跨行\nset virtualedit=block,onemore   &quot; 允许光标出现在最后一个字符的后面\nset incsearch            &quot; 实时搜索\nset mouse-=a             &quot; 不允许使用鼠标操作\nset noeb vb t_vb=        &quot; 关闭终端响铃\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 代码缩进和排版\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nset autoindent           &quot; 设置自动缩进\nset cindent              &quot; 设置使用C/C++语言的自动缩进方式\nset cinoptions=g0,:0,N-s,(0    &quot; 设置C/C++语言的具体缩进方式\nset smartindent          &quot; 智能的选择对其方式\nfiletype indent on       &quot; 自适应不同语言的智能缩进\nset expandtab            &quot; 将制表符扩展为空格\nset tabstop=4            &quot; 设置编辑时制表符占用空格数\nset shiftwidth=4         &quot; 设置格式化时制表符占用空格数\nset softtabstop=4        &quot; 设置4个空格为制表符\nset smarttab             &quot; 在行和段开始处使用制表符\n&quot;set nowrap               &quot; 禁止折行\nset wrap                 &quot; 自动折行\nset iskeyword+=_,$,@,%,#,-  &quot; 带有如下符号的单词不要被换行分割\nset backspace=2          &quot; 使用回车键正常处理indent,eol,start等\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 代码补全\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nset wildmenu             &quot; vim自身命名行模式智能补全\nset completeopt-=preview &quot; 补全时不显示窗口，只显示补全列表\nset matchtime=1          &quot; 匹配括号高亮的时间（单位是十分之一秒）\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 代码折叠\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nset foldmethod=syntax   &quot; 设置基于语法进行代码折叠\nset nofoldenable        &quot; 关闭折叠代码\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 缓存设置\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nset nobackup            &quot; 设置不备份\nset noswapfile          &quot; 禁止生成临时文件\nset autoread            &quot; 文件在vim之外修改过，自动重新读入\nset autowrite           &quot; 设置自动保存\nset confirm             &quot; 在处理未保存或只读文件的时候，弹出确认\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n正如每个配置项的注释所言，这个是对 Vim 编辑器的一些配置。\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 新文件标题\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot;新建.c,.h,.sh,.java文件，自动插入文件头 \nautocmd BufNewFile *.cpp,*.[ch],*.sh,*.rb,*.java,*.py exec &quot;:call SetTitle()&quot; \n&quot;&quot;定义函数SetTitle，自动插入文件头 \nfunc SetTitle() \n    &quot;如果文件类型为.sh文件 \n    if &amp;filetype == &apos;sh&apos; \n        call setline(1,&quot;\\#!/bin/bash&quot;) \n        call append(line(&quot;.&quot;), &quot;&quot;) \n    elseif &amp;filetype == &apos;python&apos;\n        call setline(1,&quot;#!/usr/bin/env python&quot;)\n        call append(line(&quot;.&quot;),&quot;# -*- coding:utf-8 -*-&quot;)\n        call append(line(&quot;.&quot;)+1,&quot;# Author: root  date: &quot;.strftime(&quot;%Y-%m-%d&quot;))\n        call append(line(&quot;.&quot;)+2, &quot;&quot;) \n        call append(line(&quot;.&quot;)+3, &quot;&quot;) \n\n    elseif &amp;filetype == &apos;ruby&apos;\n        call setline(1,&quot;#!/usr/bin/env ruby&quot;)\n        call append(line(&quot;.&quot;),&quot;# encoding: utf-8&quot;)\n        call append(line(&quot;.&quot;)+1, &quot;&quot;)\n        call append(line(&quot;.&quot;)+2, &quot;&quot;)\n\n        &quot;    elseif &amp;filetype == &apos;mkd&apos;\n        &quot;        call setline(1,&quot;&lt;head&gt;&lt;meta charset=\\&quot;UTF-8\\&quot;&gt;&lt;/head&gt;&quot;)\n    else \n        call setline(1, &quot;/*************************************************************************&quot;) \n        call append(line(&quot;.&quot;), &quot;    &gt; File Name: &quot;.expand(&quot;%&quot;)) \n        call append(line(&quot;.&quot;)+1, &quot;    &gt; Author: root&quot;) \n        call append(line(&quot;.&quot;)+2, &quot;    &gt; Mail: root@localhost.com&quot;) \n        call append(line(&quot;.&quot;)+3, &quot;    &gt; Created Time: &quot;.strftime(&quot;%Y-%m-%d&quot;)) \n        call append(line(&quot;.&quot;)+4, &quot; ************************************************************************/&quot;) \n        call append(line(&quot;.&quot;)+5, &quot;&quot;)\n    endif\n    if expand(&quot;%:e&quot;) == &apos;cpp&apos;\n        call append(line(&quot;.&quot;)+6, &quot;#include &lt;iostream&gt;&quot;)\n        call append(line(&quot;.&quot;)+7, &quot;using namespace std;&quot;)\n        call append(line(&quot;.&quot;)+8, &quot;&quot;)\n        call append(line(&quot;.&quot;)+9, &quot;&quot;)\n    endif\n    if &amp;filetype == &apos;c&apos;\n        call append(line(&quot;.&quot;)+6, &quot;#include &lt;stdio.h&gt;&quot;)\n        call append(line(&quot;.&quot;)+7, &quot;&quot;)\n        call append(line(&quot;.&quot;)+8, &quot;&quot;)\n    endif\n    if expand(&quot;%:e&quot;) == &apos;h&apos;\n        call append(line(&quot;.&quot;)+6, &quot;#ifndef _&quot;.toupper(expand(&quot;%:r&quot;)).&quot;_H&quot;)\n        call append(line(&quot;.&quot;)+7, &quot;#define _&quot;.toupper(expand(&quot;%:r&quot;)).&quot;_H&quot;)\n        call append(line(&quot;.&quot;)+8, &quot;#endif&quot;)\n        call append(line(&quot;.&quot;)+9, &quot;&quot;)\n    endif\n    if &amp;filetype == &apos;java&apos;\n        call append(line(&quot;.&quot;)+6,&quot;public class &quot;.expand(&quot;%:r&quot;))\n        call append(line(&quot;.&quot;)+7,&quot;&quot;)\n    endif\n    &quot;新建文件后，自动定位到文件末尾\nendfunc \nautocmd BufNewFile * normal G\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n这段配置就用到了定义函数，逻辑判断等语法，作用是在 Vim 编辑新文件的时候，根据文件名来自动生成不同的文件头部信息，为了方便，可以把代码中的 Author 和 Mail 配置为自己的信息，这样就不用每次创建了文件之后再修改了。\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 键盘命令\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nnnoremap &lt;C-N&gt; :bn&lt;CR&gt;\nnnoremap &lt;C-P&gt; :bp&lt;CR&gt;\nnmap &lt;Esc&gt;&lt;Esc&gt;&lt;Esc&gt; :qa!&lt;CR&gt; &quot; 连续三个Esc不保存退出全部\n&quot; 切换NERDTree \nmap &lt;F3&gt; :NERDTreeToggle&lt;CR&gt;\n:autocmd BufRead,BufNewFile *.dot map &lt;F5&gt; :w&lt;CR&gt;:!dot -Tjpg -o %&lt;.jpg % &amp;&amp; eog %&lt;.jpg  &lt;CR&gt;&lt;CR&gt; &amp;&amp; exec &quot;redr!&quot;\n&quot;C，C++ 按F5编译运行\nmap &lt;F5&gt; :call CompileRunGcc()&lt;CR&gt;\nfunc! CompileRunGcc()\n    exec &quot;w&quot;\n    if &amp;filetype == &apos;c&apos;\n        &quot;exec &quot;!g++ % -o %&lt;&quot;\n        &quot;exec &quot;!time ./%&lt;&quot;\n        exec &quot;!g++ % -o %&lt; &amp;&amp; time ./%&lt;&quot;\n    elseif &amp;filetype == &apos;cpp&apos;\n        &quot;exec &quot;!g++ % -std=c++11 -o %&lt;&quot;\n        &quot;exec &quot;!time ./%&lt;&quot;\n        exec &quot;!g++ % -std=c++11 -o %&lt; &amp;&amp; time ./%&lt;&quot;\n    elseif &amp;filetype == &apos;java&apos; \n        &quot;exec &quot;!javac %&quot; \n        &quot;exec &quot;!time java %&lt;&quot;\n        exec &quot;!javac % &amp;&amp; time java %&lt;&quot;\n    elseif &amp;filetype == &apos;sh&apos;\n        :!time bash %\n    elseif &amp;filetype == &apos;python&apos;\n        exec &quot;!time python %&quot;\n    elseif &amp;filetype == &apos;html&apos;\n        exec &quot;!firefox % &amp;&quot;\n    elseif &amp;filetype == &apos;go&apos;\n        &quot;        exec &quot;!go build %&lt;&quot;\n        exec &quot;!time go run %&quot;\n    elseif &amp;filetype == &apos;mkd&apos;\n        exec &quot;!~/.vim/markdown.pl % &gt; %.html &amp;&quot;\n        exec &quot;!firefox %.html &amp;&quot;\n    endif\nendfunc\n&quot;代码调试\nmap &lt;F8&gt; :call Rungdb()&lt;CR&gt;\nfunc! Rungdb()\n    exec &quot;w&quot;\n    if &amp;filetype == &apos;cpp&apos;\n        &quot;exec &quot;!g++ % -std=c++11 -g -o %&lt;&quot;\n        &quot;exec &quot;!gdb ./%&lt;&quot;\n        exec &quot;!g++ % -std=c++11 -g -o %&lt; &amp;&amp; gdb ./%&lt;&quot;\n    elseif &amp;filetype == &apos;c&apos;\n        &quot;exec &quot;!gcc % -g -o %&lt;&quot;\n        &quot;exec &quot;!gdb ./%&lt;&quot;\n        exec &quot;!gcc % -g -o %&lt; &amp;&amp; gdb ./%&lt;&quot;\n    elseif &amp;filetype == &apos;python&apos;\n        exec &quot;!python -m pdb %&quot;\n    elseif &amp;filetype == &apos;go&apos;\n        &quot;exec &quot;!go build -o %&lt; %&quot;\n        &quot;exec &quot;!gdb ./%&lt;&quot;\n        exec &quot;!go build -o %&lt; % &amp;&amp; gdb ./%&lt;&quot;\n    endif\nendfunc\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n定义了一些快捷键，比如在同时编辑多个文件时 Ctrl + p 和 Ctrl + n 可以切换到上一个或下一个，连击三次 Esc 会不保存退出全部文件， F3 会切换是否显示文件目录树，F5 编译运行和 F8 调试。还有就是插件自己的快捷键，比如使用 Ctrl + w + w 可以切换窗口，使用 s 或者 i 可以分割窗口。使用 m 可以显示文件操作菜单，这些都是 NERDTree 目录树插件的快捷键，还可以自己按照 Vim 的规则定义一些方便的快捷键。\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 主题\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\nset background=dark\nlet g:onedark_termcolors=256\ncolorscheme onedark\n这里就是应用了下载的第一个插件的那个主题，感觉非常养眼，不 是没那么毁眼。其中有几个特殊的字符需要特殊的几种字体才能看到，我喜欢用的 Consolas 字体是没问题的。\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; 插件配置\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n&quot; airline\nlet g:airline_theme=&quot;onedark&quot;\nlet g:airline_powerline_fonts = 1\nlet g:airline#extensions#tabline#enabled = 1\nif !exists(&apos;g:airline_symbols&apos;)\n    let g:airline_symbols = {}\nendif\nlet g:airline_left_sep = &apos;&apos;\nlet g:airline_left_alt_sep = &apos;&apos;\nlet g:airline_right_sep = &apos;&apos;\nlet g:airline_right_alt_sep = &apos;&apos;\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n\n&quot; nerdtree\n&quot;let g:NERDTreeFileExtensionHighlightFullName = 1\n&quot;let g:NERDTreeExactMatchHighlightFullName = 1\n&quot;let g:NERDTreePatternMatchHighlightFullName = 1\n&quot;let g:NERDTreeHighlightFolders = 1          \n&quot;let g:NERDTreeHighlightFoldersFullName = 1  \n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n\n&quot; pydiction \nlet g:pydiction_location = &apos;~/.vim/plugged/pydiction/complete-dict&apos;\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n\n&quot; rainbow\nlet g:rainbow_active = 1 &quot;0 if you want to enable it later via :RainbowToggle\n&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;\n顾名思义，就是针对安装的插件的配置了，不同的插件会读取其中不同的值来产生不同的行为。\n附录如果体验了和平常不同的 Vim 后对它产生了浓厚的兴趣，那么对 Vim 的使用进行一次深入的学习那就最好不过了。\n\n官方中文文档在线\n官方中文文档下载\n\n","categories":["Vim"],"tags":["vim","linux"]},{"title":"回调地狱的终结：Pormise & Async","url":"/2018/12/31/2018/%E5%9B%9E%E8%B0%83%E5%9C%B0%E7%8B%B1%E7%9A%84%E7%BB%88%E7%BB%93%EF%BC%9APormise%20&%20Async/","content":"简介\n由于 JavaScript 是一门单线程，事件驱动的语言，因此异步编程方式是它一个非常重要的特性。无论是客户端的 JavaScript 还是服务端的 JavaScript 在处理 HTTP请求响应、事件监听、文件读取等操作时都避不开回调，如果异步的事件需要嵌套执行，那么回调给代码结构和可读性简直带来了灾难，这个被后人称之为：回调地狱。\n\n\n环境\n由于大多数浏览器环境不支持 async/await 这些 ES8 提案才支持的语法，因此 JavaScript 执行环境选择 Node.js。浏览器不支持包含 ES7/ES8 的语法特性的代码，可以通过 Babel 等工具转为低版本 JavaScript 语法运行。\n\n\n\n\n软件\n版本\n\n\n\n\n操作系统\nWindows 10\n\n\nNode.js\nv10.13.0\n\n\n\n教程经典回调问题JavaScript 中对异步事件处理是通过给异步事件传递处理函数的方式，也就是回调（callback）来完成，下面看一个例子：\nconst fs = require(\"fs\")/*     以 utf-8 编码打开当前目录下 aaa.txt 文件。    如果回调函数执行失败，则打印失败原因，否则打印文件内容。*/fs.readFile(\"aaa.txt\", \"utf-8\", function(err, data)&#123;    if (err) &#123;        console.log(err.message)    &#125; else &#123;        console.log(data)    &#125;&#125;)\n这是一个经典的 JavaScript 处理异步事件的方法，我们将对数据的后续处理写成函数传递给 fs.readFile 方法，文件读取成功后 fs.readFile 会自动调用我们传递给它的函数。\n现在我们需要进行秩序的读取三个甚至更多的文件，只有在 aaa.txt 读取完成后再继续读取 bbb.txt，接着再读取 ccc.txt。传统的解决方案应该会写出下面的代码：\nconst fs = require(\"fs\")/*     以 utf-8 编码打开当前目录下 aaa.txt 文件。    如果回调函数执行失败，则打印失败原因，否则打印文件内容。*/fs.readFile(\"aaa.txt\", \"utf-8\", function(err, data)&#123;    if (err) &#123;        console.log(err.message)    &#125; else &#123;        console.log(data)    &#125;    // 继续读取 bbb.txt    fs.readFile(\"bbb.txt\", \"utf-8\", function(err, data)&#123;        if (err) &#123;            console.log(err.message)        &#125; else &#123;            console.log(data)        &#125;        // 继续读取 ccc.txt        fs.readFile(\"ccc.txt\", \"utf-8\", function(err, data)&#123;            if (err) &#123;                console.log(err.message)            &#125; else &#123;                console.log(data)            &#125;        &#125;)    &#125;)&#125;)\n如果还要继续读取更多的文件，并对文件内容进行操作，那之后的代码也都要写在回调函数中，会造成嵌套越来越多。这样对代码的可读性和日后的维护都带来了很大挑战。\n随着 JavaScript 能干的事情越来越多，人们已经不满足只用它来处理一些简单的事情了，当随着代码越来越多，项目工程越来越大，JavaScript 的不断发展中，势必会寻找一些解决方案来应对这些问题。\n之前最流行的是 2009 年 12 月发布的 ES5 标准，终于在 2015 年的 6 月 ES6 发布了，这是个历经 6 年沉淀出的版本，给 JavaScript 带来了大量的新特性并保持了向下的兼容，其中对异步回调地狱的解决方案：Promise 就是这个版本带来的特性之一。\nJavaScript 设计时的缺陷，历史包袱等原因，后面新的版本带来新特性的同时，又要对之前代码保持兼容，现在 JavaScript 各种功能重复又不相同的 API 也让人一言难尽。。。\n当代的 PromisePromise：承诺的意思，你可以通过 Promise 封装一个异步事件，并且在事件创建后再将回调函数传递给 Promise，而 Promise 则向你承诺异步事件有结果的时候，会调用之后传给 Promise 的处理函数。而传统的回调，是在事件创建之初就一并将回调函数传递过去的。\nPromise 基本概念在浏览器环境或者 Node.js 环境中，Promise 是一个全局的构造函数。Promise 构造函数接受一个函数作为参数，我们需要封装的异步事件，就是写在这个函数中的。这个函数的主要作用只是为了封装异步事件为一个 Promise 对象，那么异步事件的正常结果和异次结果又该如何处理呢？\n答案是这个函数会接收两个函数作为参数，一个用来处理正常结果的，一个用来处理异次结果。大致样子如下：\nlet promise = new Promise(function(resolve, reject)&#123;    if (/* 异步操作成功 */) &#123;        resolve(data)    &#125; else &#123;        reject(err)    &#125;&#125;)\nresolve 和 reject 这里都只是形参，当一个 Promise 对象创建的时候，传递的函数就立即执行了。函数的执行会产生三种状态：pending、fulfilled、rejected。\n\npending：异步事件初始化，还没有结果的时候。\nfulfilled：在函数中调用 resolve 方法后将触发 Promise 对象的状态更改为 fulfilled，表示异步事件正常结束。\nrejected：当异步事件抛出异常时，我们调用这个函数将触发 Promise 对象的状态更改为 rejected，表示异步事件异常结束。\n\n之后我们就可以给 Promise 绑定 fulfilled 和 rejected 状态的回调函数了，我们通过 Promise.prototype.then() 函数来将 fulfilled 和 rejected 状态的处理函数传递进去：\npromise.then(function(data)&#123;    // 当 Promise 的状态变为 fulfilled 的时候执行的回调    console.log(data)&#125;, function(err)&#123;    // 当 Promise 的状态变为 rejected 的时候执行的回调    console.log(err)&#125;)\n在封装 Promise 对象中通过 resolve(data) 可以将异步事件返回的数据传递出去，然后由 .then() 的第一个回调函数来接收，因此我们就可以将对异步事件结果的处理过程写在 .then() 的第一个回调函数中了。同理，对异常结果的处理在 .then() 的第二个回调函数中处理。\n如果不需要对异常情况进行处理，对异常处理的回调函数在 .then() 中是可以省略的，也就是说，可以只给 .then() 传递一个正常结果处理的回调即可。\nPromise 初体验说了这么多，现在就看看怎么把之前出现的读取文件的例子用 Promise 改造一下，看看和传统的回调嵌套有什么本质上的不同。\nconst fs = require(\"fs\")let promise = new Promise(function(resolve, reject)&#123;    fs.readFile(\"aaa.txt\", \"utf-8\", (err, data)=&gt;&#123;        /*             由于作用域的原因，如果给 readFile 的回调使用 function()，            那么将无法访问 resolve 和 reject 方法了。        */        if (err) &#123;            reject(err)        &#125; else &#123;            resolve(data)        &#125;    &#125;)&#125;)promise.then(function(data)&#123;    // 处理成功读取到文件内容的回调函数    console.log('文件内容：' + data)&#125;,function(err)&#123;    // 处理读取文件异常的回调函数    console.log('失败原因：' + err.message)&#125;)\n当文件正常读取后的执行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\n文件内容：Hello! this is aaa.txt\n当文件不存在的执行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\n失败原因：ENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\aaa.txt&apos;\n结果与我们预料的相同，接下来读取多个文件，我们总不能为每个文件都单独写一串封装为 Promise 对象的代码吧，最好的做法是用一个构造函数，传给这个函数不同的文件名称，然后自动为我们返回一个封装好的 Promise 对象：\nfunction readFile(fileName) &#123;    return new Promise(function(resolve, reject)&#123;        fs.readFile(fileName, \"utf-8\", (err, data)=&gt;&#123;            /*                 由于作用域的原因，如果给 readFile 的回调使用 function()，                那么将无法访问 resolve 和 reject 方法了。            */            if (err) &#123;                reject(err)            &#125; else &#123;                resolve(data)            &#125;        &#125;)    &#125;)&#125;\n我们创建了一个新的 readFile 函数，这个函数会根据不同的文件名，自动返回一个封装好的 Promise 对象。如果我们想并发的读取多个文件，大可以这样来写：\nreadFile(\"aaa.txt\").then(function(data)&#123;...&#125;)readFile(\"bbb.txt\").then(function(data)&#123;...&#125;)readFile(\"ccc.txt\").then(function(data)&#123;...&#125;)\n但是这并不能满足我们读完 aaa.txt 再继续往下读取的意愿，那么我们可以让第一个文件的处理结束后，返回第二个文件的 Promise 对象，然后通过 .then() 进行链式调用的方法依次读取：\n 点击显示/隐藏代码\nconst fs = require(\"fs\")function readFile(fileName) &#123;    return new Promise(function(resolve, reject)&#123;        fs.readFile(fileName, \"utf-8\", (err, data)=&gt;&#123;            /*                 由于作用域的原因，如果给 readFile 的回调使用 function()，                那么将无法访问 resolve 和 reject 方法了。            */            if (err) &#123;                reject(err)            &#125; else &#123;                resolve(data)            &#125;        &#125;)    &#125;)&#125;readFile(\"aaa.txt\").then(function (data)&#123;    // 处理 aaa.txt    console.log('文件内容：' + data)    return readFile(\"bbb.txt\")&#125;, function (err)&#123;    console.log('失败原因：' + err.message)&#125;).then(function (data)&#123;    // 处理 bbb.txt    console.log('文件内容：' + data)    return readFile(\"ccc.txt\")&#125;, function (err)&#123;    console.log('失败原因：' + err.message)&#125;).then(function (data)&#123;    // 处理 ccc.txt    console.log('文件内容：' + data)&#125;, function (err)&#123;    console.log('失败原因：' + err.message)&#125;)\n\n\n当文件都正常读取的情况下：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\n文件内容：Hello! this is aaa.txt\n文件内容：Hello! this is bbb.txt\n文件内容：Hello! this is ccc.txt\n这中写法，即使我们要读取再多的文件，也只需要依次往下排列代码就行了，并不需要对代码进行嵌套，也更不存在回调地狱的问题了。但是如果遇到一个文件读取失败呢？可达鸭眉头一皱发现事情并不简单\nbbb.txt 读取失败的情况：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\n文件内容：Hello! this is aaa.txt\n失败原因：ENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\bbb.txt&apos;\n文件内容：undefined\n因为 bbb.txt 不存在，所以 Promise 里触发了 fulfilled 状态，那么执行的就是错误处理的方法，然而在错误处理的方法中，我们并没有返回读取下一个文件的 Promise 对象。解决方法也很简单，就是在每一个 Promise 的异常处理函数中也返回下一个 Promise。。。\nreadFile(\"aaa.txt\").then(function (data)&#123;    // 处理 aaa.txt    console.log('文件内容：' + data)    return readFile(\"bbb.txt\")&#125;, function (err)&#123;    console.log('失败原因：' + err.message)    return readFile(\"bbb.txt\")&#125;).then(function (data)&#123;    // 处理 bbb.txt    console.log('文件内容：' + data)    return readFile(\"ccc.txt\")&#125;, function (err)&#123;    console.log('失败原因：' + err.message)    return readFile(\"ccc.txt\")&#125;).then(function (data)&#123;    // 处理 ccc.txt    console.log('文件内容：' + data)&#125;, function (err)&#123;    console.log('失败原因：' + err.message)&#125;)\n结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\n文件内容：Hello! this is aaa.txt\n失败原因：ENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\bbb.txt&apos;\n文件内容：Hello! this is ccc.txt\nPromise 异常处理正常情况下，一把都是有关联的异步操作才会使用 Promise 来链起来执行，因为下一个异步操作可能会依赖于上一个异步操作的结果，如果其中一个异步操作失败，那么剩下的就没继续执行下去的意义了。如果我们为每个 Promise 对象都指定了异常处理回调，链中的某一个 Promise 即使触发了异常，整个链依然会继续执行下去的，虽然结果并不是我们想要的。\n我们更希望的是，当某一个 Promise 发生异常的时候，就立即终止整个 Promise 链的执行，我们可以统一使用 Promise.prototype.catch() 来捕获异常并终止整个链。\nreadFile(\"aaa.txt\").then(function (data)&#123;    // 处理 aaa.txt    console.log('文件内容：' + data)    return readFile(\"bbb.txt\")&#125;).then(function (data)&#123;    // 处理 bbb.txt    console.log('文件内容：' + data)    return readFile(\"ccc.txt\")&#125;).then(function (data)&#123;    // 处理 ccc.txt    console.log('文件内容：' + data)&#125;).catch(function(err)&#123;    console.log(err.message)&#125;)\n执行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\n文件内容：Hello! this is aaa.txt\nENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\bbb.txt&apos;\nbbb.txt 文件不存在，.catch() 捕获了这个异常并终止了接下来的执行。如果在 .then() 中产生的异常也会被 .catch() 捕获。\nreadFile(\"aaa.txt\").then(function (data)&#123;    // 处理 aaa.txt    console.log('文件内容：' + data)    throw new Error(\"手动触发的异常\")    return readFile(\"bbb.txt\")&#125;).then(function (data)&#123;    // 处理 bbb.txt    console.log('文件内容：' + data)    return readFile(\"ccc.txt\")&#125;).then(function (data)&#123;    // 处理 ccc.txt    console.log('文件内容：' + data)&#125;).catch(function(err)&#123;    console.log(err.message)&#125;)\n运行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\n文件内容：Hello! this is aaa.txt\n手动触发的异常\n因此一般总是建议在 Promise 的后面跟上一个 .catch() 来处理已知的或者意料之外的异常。当然，你依然可以在 .catch() 中也返回一个 Promise 对象，然后继续用 .then() 进行其他的逻辑处理。Promise 最直接的好处就是链式调用。\nPromise 的其他用法这里举例说明 Pormise 的几个其他常用的方法，其他更详细的 Pormise 用法可以查阅 MDN web docs：Pormise\nPormise.all()Pormise.all() 接收一个由多个 Promise 对象组成的数组，只有这个数据里所有的 Promise 对象都完成的时候才会去调用 .then() 方法，否则有一个失败，那么整体就是 rejected：\nconst fs = require(\"fs\")function readFile(fileName) &#123;    return new Promise(function(resolve, reject)&#123;        fs.readFile(fileName, \"utf-8\", (err, data)=&gt;&#123;            if (err) &#123;                reject(err)            &#125; else &#123;                resolve(data)            &#125;        &#125;)    &#125;)&#125;Promise.all([readFile(\"aaa.txt\"), readFile(\"bbb.txt\"), readFile(\"ccc.txt\")]).then(function(data)&#123;    console.log(data)&#125;).catch(function(err)&#123;    console.log(err.message)&#125;)\n正常情况下返回的是个包含结果集的数组：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\n[ &apos;Hello! this is aaa.txt&apos;,\n  &apos;Hello! this is bbb.txt&apos;,\n  &apos;Hello! this is ccc.txt&apos; ]\n如果有一个异常，则会触发 .catch()：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\bbb.txt&apos;\nPormise.race()与 Pormise.all() 用法相似，但是结果不同，Pormise.race() 中只要有一个 Pormise 对象率先改变状态（不管完成还是失败），那 Pormise.race() 之后 .then() 就都是对这一个改变状态了的 Pormise 的处理。\nPromise.race([readFile(\"aaa.txt\"), readFile(\"bbb.txt\"), readFile(\"ccc.txt\")]).then(function(data)&#123;    console.log(data)&#125;).catch(function(err)&#123;    console.log(err.message)&#125;)\naaa.txt 先完成读取，所以只返回了 aaa.txt 的数据：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nHello! this is aaa.txt\n判断一个文件是否存在比读取文件内容快得多，所以 bbb.txt 不存在的情况下率先改变成了 rejected 状态：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\bbb.txt&apos;\n基于 Pormise.race() 的性质，我们可以给浏览器的 Ajax 请求添加超时的功能：\nPormise.race([$ajax.get(\"/api\"), new Promise(function()(resolve, reject)&#123;        setTimeout(() =&gt; reject(new Error('request timeout')), 5000)    &#125;)])\n这样如果 $ajax 没有在 5 秒之内完成的话，setTimeout 就会将状态率先改为 rejected 了。\n未来的 Async之所以说 async 是未来的，是因为 ES8 的标准才引入了 async 关键字，async 是 Generator 的语法糖，而 Generator 是 ES6 提供的一种异步编程解决方案。以后使用 async 越来越多一定是个趋势。\nasync 配合 await 可以让异步的代码看起来和同步的一样，并且可以使用 try 和 catch 来捕捉异步事件产生的异常。想了解这两个需要先熟悉什么是 Generator。\nGenerator基本用法Generator（生成器）是用于将一个函数变成 Generator 函数，这种函数的执行过程和普通函数不太一样，普通函数使用 return 返回值，而 Generator 函数中还可以使用 yield 返回值，并且 yield 还可以在函数内使用多次。return 返回值后整个函数就完成执行了，而 yield 只表示这个函数暂停了，下一次继续驱动 Generator 函数运行的时候，就会从上次暂停的地方继续运行。下面看一个简单的例子：\nfunction* gen()&#123;    yield \"hello\"    yield \"world\"&#125;\n注意申明一个 Generator 函数和普通函数的不同，Generator 函数需要在 function 和函数名中间加上一个 *，加在哪里并不重要，function *gen() 和 function*gen() 都可以，但是推荐使用 function* gen() 这种方式。接着使用两个 yield 返回了两个字符串，下面看看如何运行这种函数：\nC:\\Users\\yunfwe\\Desktop&gt;node\n&gt; function* gen(){\n...     yield &quot;hello&quot;\n...     yield &quot;world&quot;\n... }\nundefined\n&gt; let f = gen()\nundefined\n&gt; f\nObject [Generator] {}\n&gt; f.next()\n{ value: &apos;hello&apos;, done: false }\n&gt; f.next()\n{ value: &apos;world&apos;, done: false }\n&gt; f.next()\n{ value: undefined, done: true }\n我们运行 gen() 后，返回的是一个 Generator 类型的对象，然后调用这个对象的 next 方法，返回了一个普通对象，这个对象的 value 属性是第一个 yield 返回的值，第二个属性 done 表示这个 Generator 函数是否运行结束。当第三次执行 f.next() 的时候，因为已经没有 yield 可以执行了所以 done 的值变成了 true。\n创建一个整数列表接下来使用一个小例子来更深入的了解下 Generator 函数的运行原理。我们编写一个 range 函数，传给它一个整数，然后返回从 0 到 传递的整数之间所有的整数，先看普通函数版本：\nfunction range(len)&#123;    let l = []    for (let i = 0; i &lt; len; i++)&#123;        l.push(i)    &#125;    return l&#125;\n运行结果：\n&gt; range(5)\n[ 0, 1, 2, 3, 4 ]\n&gt; range(10)\n[ 0, 1, 2, 3, 4, 5, 6, 7, 8, 9 ]\n的确达到了我们的目的，但是这个函数有一个致命的缺陷，就是如果要生成的范围非常巨大，比如 range(99999999999999)\n&gt; range(99999999999999)\n\n==== JS stack trace =========================================\n\n    0: ExitFrame [pc: 000003D44F75C5C1]\nSecurity context: 0x02931fb858a1 &lt;JSObject&gt;\n    1: range [000002931FBA36F9] [repl:~1] [pc=000003D44F7622DB](this=0x01e40aa9ad49 &lt;JSGlobal Object&gt;,len=0x02931fbbdf59 &lt;Number 1e+14&gt;)\n    2: /* anonymous */ [000002931FBBE1F9] [repl:1] [bytecode=000002931FBBDF81 offset=10](this=0x01e40aa9ad49 &lt;JSGlobal Object&gt;)\n    3: InternalFrame [pc: 000003D44F70F0B6]\n    4: EntryFrame [pc: 000003D44F709455]\n    5: E...\n\nFATAL ERROR: CALL_AND_RETRY_LAST Allocation failed - JavaScript heap out of memory\nnode 进程直接挂掉了，因为所有生成的数都在一个数组里保存，这个数组很容易就超过了堆内存的限制。而如果使用 Generator 函数，每一个值只会在调用的时候生成并返回，并且没有在函数内部保存这个值，那自然不会发生堆内存超出了：\nfunction* range(len)&#123;    for (let i = 0; i &lt; len; i++)&#123;        yield i    &#125;&#125;\n可以看到，因为缺少了对产生的值的保存，代码反而更精简了。那么怎么打印它所产生的值呢？总不能挨个执行 next 吧，ES6 新添了 for ... of 的语法，所有只要实现了 Iterator 接口的对象都可以使用这个语法来遍历，比如：\nlet l = [3,2,1,'a','b','c']// 使用 for ... of 遍历for (let i of l)&#123;    console.log(i)&#125;// 输出：3 2 1 a b c// 使用 for ... in 遍历for (let i in l)&#123;    console.log(i)&#125;// 输出：0 1 2 3 4 5\nfor ... of 和 for ... in 最大的区别就是 for ... of 会直接将数组的值传递给了 let i，而 for ... in 将数组的索引传递给了 let i。我们的 Generator 函数也实现了 Iterator 接口所以也可以使用 for ... of 的方法来取值：\nfunction* range(len)&#123;    for (let i = 0; i &lt; len; i++)&#123;        yield i    &#125;&#125;for (let i of range(99999999999999))&#123;    console.log(i)&#125;\n这时候屏幕开始疯狂输出了。。。\n给 Generator 对象传值在 Generator 对象运行期间，我们还可以在外部通过 next 方法传递一些值给生成器内部，在生成器对象内部对传递进来的值进行处理，看下面例子：\nfunction* gen()&#123;    let w = yield \"hello\"    console.log(w)    yield w&#125;\n在 yield 返回 hello 字符串后，我们用 let w 再保存 yield 接收到的值：\n&gt; function* gen(){\n...     let w = yield &quot;hello&quot;\n...     console.log(w)\n...     yield w\n... }\nundefined\n&gt; let g = gen()\nundefined\n&gt; g.next()\n{ value: &apos;hello&apos;, done: false }\n&gt; g.next(&quot;world&quot;)\nworld\n{ value: &apos;world&apos;, done: false }\n&gt; g.next(&quot;world&quot;)\n{ value: undefined, done: true }\n运行到 let g = gen() 的时候，创建了一个生成器对象 g，第一次 g.next() 的时候为什么我们没有传值进去呢？因为它运行到 yield &quot;hello&quot; 的时候就暂停函数了，如果这个时候传值进去，它也没办法处理。当第二次执行 g.next(&quot;world&quot;) 的时候，从上次暂停的地方继续运行，也就相当于开始运行 let w = (yield) 了，这时候通过 next 传递进去的值就由 yield 返回给内部的 let w，接着生成器继续运行到下一个 yield w 的时候，将 w 的值返回给外部调用者。再继续执行 g.next(&quot;world&quot;) 可内部已经没有 yield 语句进行接收传进去的值了，所以没法处理，生成器结束运行。\nGenerator 与 Pormise利用生成器对象可以将值返回外部调用者并暂停，然后从外部接收值并继续运行到下一个 yield 的机制，配合 Promise 又能碰撞出什么样的火花呢？\n回到之前需要顺序读取三个文件的问题，我们理想状态下，想要写出这样的代码：\nconst fs = require(\"fs\")function readFile(fileName) &#123;    return new Promise(function(resolve, reject)&#123;        fs.readFile(fileName, \"utf-8\", (err, data)=&gt;&#123;            if (err) &#123;                reject(err)            &#125; else &#123;                resolve(data)            &#125;        &#125;)    &#125;)&#125;function* gen()&#123;    let aaa = yield readFile(\"aaa.txt\")    console.log(aaa)    let bbb = yield readFile(\"bbb.txt\")    console.log(bbb)    let ccc = yield readFile(\"ccc.txt\")    console.log(ccc)&#125;\n通过 yield 将程序的控制权交给外部，让外部处理 readFile() 返回的 Promise 对象，然后外部处理完成后将数据传递给 yield，生成器内部就可以直接获取到处理好的数据了，接着再处理其他文件的读取。\n接下来我们该实现如何在外部启动并处理这个生成器，然后将生成器返回的 Promise 对象处理好后再传递给生成器：\nlet g = gen()g.next().value.then(function(data)&#123;    g.next(data).value.then(function(data)&#123;        g.next(data).value.then(function(data)&#123;            g.next(data)        &#125;)    &#125;)&#125;)\n通过 g.next().value 获取到了生成器返回来的 Promise 对象，接着使用 .then() 方法处理读取文件完成后的数据通过 g.next(data) 传递回去并继续处理它返回的下一个 Promise 对象，于是就写出了这样的代码。先看看是否达到我们预期的效果了吧：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nHello! this is aaa.txt\nHello! this is bbb.txt\nHello! this is ccc.txt\n没问题，虽然外部处理生成器返回的 Promise 还是一团糟，但是生成器函数写的就像是同步代码那样了。接下来就是对外部处理生成器对象的方法进行优化了。我们可以发现，外部对 g.next() 的执行基于生成器用 yield 返回了多少次，我们可以用生成器返回对象的 done 属性来判断这个生成器是否结束，然后用递归的方法不断进行 g.next(data) 处理：\nfunction run(gen)&#123;    let g = gen()    function next(data)&#123;        let result = g.next(data)        if (result.done) return result.value        result.value.then(function(data)&#123;            next(data)        &#125;)    &#125;    next()&#125;\n我们定义了一个 run 函数作为生成器函数的辅助函数，run 函数内部首先初始化了生成器对象，然后定义了一个 next 的函数，这个函数通过递归来控制生成器返回值和传递值，通过判断生成器是否已经完成来结束递归。接着我们通过 run 函数来启动 gen 生成器函数：\n完整代码： 点击显示/隐藏代码\nconst fs = require(\"fs\")function readFile(fileName) &#123;    return new Promise(function(resolve, reject)&#123;        fs.readFile(fileName, \"utf-8\", (err, data)=&gt;&#123;            if (err) &#123;                reject(err)            &#125; else &#123;                resolve(data)            &#125;        &#125;)    &#125;)&#125;function run(gen)&#123;    let g = gen()    function next(data)&#123;        let result = g.next(data)        if (result.done) return result.value        result.value.then(function(data)&#123;            next(data)        &#125;)    &#125;    next()&#125;function* gen()&#123;    let aaa = yield readFile(\"aaa.txt\")    console.log(aaa)    let bbb = yield readFile(\"bbb.txt\")    console.log(bbb)    let ccc = yield readFile(\"ccc.txt\")    console.log(ccc)&#125;run(gen)\n\n\n执行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nHello! this is aaa.txt\nHello! this is bbb.txt\nHello! this is ccc.txt\n我们还可以在 run 函数中通过 catch 来处理异常的情况，我们可以将异常传递进去，或者直接终止生成器：\nfunction run(gen)&#123;    let g = gen()    function next(data)&#123;        let result = g.next(data)        if (result.done) return result.value        result.value.then(function(data)&#123;            next(data)        &#125;).catch(function(err)&#123;            next(err)  // 如果将err传递进去，则生成器继续运行        &#125;)    &#125;    next()&#125;\n运行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nHello! this is aaa.txt\n{ [Error: ENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\bbb.txt&apos;]\nerrno: -4058,\ncode: &apos;ENOENT&apos;,\nsyscall: &apos;open&apos;,\npath: &apos;C:\\\\Users\\\\yunfwe\\\\Desktop\\\\bbb.txt&apos; }\nHello! this is ccc.txt\nGenerator 已经有点好用了，那么还有没有更好用的方法呢？\nasync/await 闪亮登场前面也有说到，async 是 Generator 的语法糖，async 就相当于将 Generator 函数，以及之前我们写的 run 这个辅助执行器融合到了一起。await 关键字只能用在 async 申明的函数中，意为等待一个异步操作完成。\n基本用法上一节处理依次读取三个文件的 gen 和 run 方法，我们先用 async 和 await 改造一下，先体现一下它的用法：\nasync function genAsync()&#123;    let aaa = await readFile(\"aaa.txt\")    console.log(aaa)    let bbb = await readFile(\"bbb.txt\")    console.log(bbb)    let ccc = await readFile(\"ccc.txt\")    console.log(ccc)&#125;\n我们只是把申明 Generator 函数的 * 换成了在函数前面用 async，然后在需要等待异步操作完成的地方使用 await 代替了 yield，然后其他的什么辅助方法都不需要了，完整代码如下：\nconst fs = require(\"fs\")function readFile(fileName) &#123;    return new Promise(function(resolve, reject)&#123;        fs.readFile(fileName, \"utf-8\", (err, data)=&gt;&#123;            if (err) &#123;                reject(err)            &#125; else &#123;                resolve(data)            &#125;        &#125;)    &#125;)&#125;async function genAsync()&#123;    let aaa = await readFile(\"aaa.txt\")    console.log(aaa)    let bbb = await readFile(\"bbb.txt\")    console.log(bbb)    let ccc = await readFile(\"ccc.txt\")    console.log(ccc)&#125;genAsync()\n运行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nHello! this is aaa.txt\nHello! this is bbb.txt\nHello! this is ccc.txt\n有没有觉得很棒！甚至我们都可以像写同步代码一样，通过 try...catch 来捕捉 await 产生的异常！\nasync function genAsync()&#123;    let aaa = await readFile(\"aaa.txt\")    console.log(aaa)    try &#123;        let bbb = await readFile(\"bbb.txt\")        console.log(bbb)    &#125;     catch (err) &#123;        console.log(err.message)    &#125;        let ccc = await readFile(\"ccc.txt\")    console.log(ccc)&#125;\n我们在可能出现异常的地方使用 try...catch 来捕捉，运行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nHello! this is aaa.txt\nENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\bbb.txt&apos;\nHello! this is ccc.txt\n异步代码写起来比以前舒服太多了，接下来就探究下 async 都帮我们做了什么吧！\nasync 函数使用 async 申明的函数返回的是一个 Promise 对象，如果通过 return 返回值，相当于将 Promise 的状态变为了 fulfilled 状态，可以通过 .then() 来处理返回的数据。如果在 async 函数中抛出异常，相当于将 Promise 的状态变成了 rejected，可以通过 .catch() 来捕捉。\nasync function f()&#123;    return \"hello world\"&#125;f().then(function(data)&#123;    console.log(data)&#125;)async function f1()&#123;    throw new Error(\"Error!\")&#125;f1().catch(function(err)&#123;    console.log(err.message)&#125;)\n执行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node async.js\nhello world\nError!\nawait 命令只有 async 函数内部才可以使用 await 命令。await 命令后面可以跟上一个 Promise 对象（或者定义了 then 方法的对象）或者其他类型的数据，如果是其他类型数据，await 会直接返回这个数据。\n如果是 Promise 对象，当 await 后面的 Promise 对象的状态变成 fulfilled，await 将返回它的值。如果 await 后面的 Promise 对象的状态变成 rejected，await 会立即抛出一个异常，并结束 async 函数的运行，可以通过 async 函数的 .catch() 在外部来捕捉这个异常，或者直接用 try...catch 在内部捕捉 await 抛出的异常。\nawait 后面 Promise 状态为 fulfilled 的情况：\nasync function f()&#123;    let d = await Promise.resolve(\"Done\")    console.log(d)&#125;f()\n运行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node async.js\nDone\nawait 后面 Promise 状态为 rejected 的情况：\nasync function f()&#123;    try &#123;        let d = await Promise.reject(\"Error!\")        console.log(d)    &#125;     catch (err) &#123;        console.log(\"Catch: \" + err)    &#125;&#125;f()\n运行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node async.js\nCatch: Error!\n如果 async 内部没有捕捉到 await 抛出的异常，那么可以在 async 函数外部通过 .catch() 方法捕捉：\nasync function f()&#123;    try &#123;        let d = await Promise.reject(\"Error!\")        console.log(d)    &#125;     catch (err) &#123;        console.log(\"Catch: \" + err)    &#125;    await Promise.reject(\"New Error!\")&#125;f().catch(function(err)&#123;    console.log(err)&#125;)\n运行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node async.js\nCatch: Error!\nNew Error!\n如果 async 内部多个 await 等待异步结果，只要有一个 await 抛出了异常没被捕捉，那么整个 async 函数就立即停止运行了，我们继续改造之前读取文件的例子：\nasync function genAsync()&#123;    let aaa = await readFile(\"aaa.txt\")    console.log(aaa)    let bbb = await readFile(\"bbb.txt\")    console.log(bbb)    let ccc = await readFile(\"ccc.txt\")    console.log(ccc)&#125;genAsync().catch(function(err)&#123;    console.log(err.message)&#125;)\n可以看到，bbb.txt 不存在的情况下，如果没有捕捉这个异常，genAsync 就 rejected 了。运行结果：\nC:\\Users\\yunfwe\\Desktop&gt;node app.js\nHello! this is aaa.txt\nENOENT: no such file or directory, open &apos;C:\\Users\\yunfwe\\Desktop\\bbb.txt&apos;\n附录这是 2018 年最后一篇博客，特此纪念一下 (￣▽￣)”\n参考文档\nPromise\nGenerator\nAsync\n\n","categories":["JavaScript"],"tags":["javascript"]},{"title":"玩转树莓派","url":"/2018/04/24/2018/%E7%8E%A9%E8%BD%AC%E6%A0%91%E8%8E%93%E6%B4%BE/","content":"简介\nRaspberry Pi 中文名为树莓派，原本是为学习计算机编程教育而设计的只有卡片大小的微型电脑，上面可以运行 Linux 甚至 Windows 10 loT 系统。树莓派虽小，却五脏俱全，而且拥有丰富的拓展接口，是学习Linux、嵌入式、物联网的利器。\n\n\n开始使用准备工具\n树莓派，当前最新版本是 这里使用的是树莓派3B\n读卡器，给树莓派烧录系统用，因为树莓派的系统安装在内存卡。\n最好 8G 或以上的 Micro SD 卡，但是也不用太大，否则可能不稳定甚至不支持。\n最好 5V 2.5A 电源（普通安卓充电器也可以），如果需要为树莓派扩展硬件的话，电源需要比较给力。\n鼠标、键盘、HDMI转VGA线还有显示器，不过这些并不是必须的，看情况使用。\n\n安装系统下载镜像包镜像包可以选择官方的镜像，或者第三方的镜像\n官方下载：https://www.raspberrypi.org/downloads/Ubuntu：https://wiki.ubuntu.com/ARM/RaspberryPi\n这里下载官方系统的Lite版，点此下载。\n解压和烧录可以在Linux下和Windows下进行烧录，Windows下需要下载 Win32 Disk IMager 工具进行烧录，linux下可以直接使用dd命令。\nLinux下烧录将内存卡插入到读卡器，然后读卡器插入电脑，读卡器设备被系统映射为了 /dev/sdc。\n注意：Linux需要看看读卡器被系统映射为了哪个设备文件，如果指定错了设备文件，后果可能不堪设想。\n# 先卸载一下 确保系统没有主动挂载这个设备，如果存在多个分区，需要卸载多个umount /dev/sdc1\tunzip 2018-04-18-raspbian-stretch-lite.zipsudo dd if=2018-04-18-raspbian-stretch-lite.img of=/dev/sdc bs=4M\nWindows下烧录先将下载的xz镜像解压为img文件，然后使用 Win32 Disk IMager 工具烧录到内存卡。\n需要注意的是，选择SD卡的设备，然后选择好解压后的img镜像后点击 write 开始写入。\n启动树莓派正常来说，插入内存卡，插入网线就可以开机了，树莓派默认会DHCP获取IP地址，但是如果局域网不存在DHCP服务，那启动后会在获取DHCP地址过程中等待五六分钟，而且这种情况没有显示器就没法操作树莓派了。\n配置静态IP但是对于不存在DHCP服务的局域网，可以在启动树莓派之前就配置好树莓派的IP地址，这样启动后就会自动应用配置的IP，连显示器和键盘也不需要了。\n以下操作在 Linux 上进行。\nmount /dev/sdc2 /mnt\t\t# 烧录后树莓派的rootfs在sdc的第二个分区上vim /mnt/etc/network/interfaces # 编辑这个文件为下面内容，将IP信息替换为合适的信息\n# This file describes the network interfaces available on your system\n# and how to activate them. For more information, see interfaces(5).\n\n# The loopback network interface\nauto lo\niface lo inet loopback\n\n# Source interfaces\n# Please check /etc/network/interfaces.d before changing this file\n# as interfaces may have been defined in /etc/network/interfaces.d\n# See LP: #1262951\n# source /etc/network/interfaces.d/*.cfg\nauto eth0\niface eth0 inet static\n    address 192.168.2.220\n    netmask 255.255.255.0\n    network 192.168.2.0\n    broadcast 192.168.2.255\n    gateway 192.168.2.254\n    # dns-* options are implemented by the resolvconf package, if installed\n    dns-nameservers 119.29.29.29\n    dns-nameservers 223.5.5.5\n自动启动SSH服务系统默认启动是不启动SSH服务的，所以还要修改下 rc.local 文件，将 SSH服务 在系统启动后也跟着起来。\n编辑 /mnt/etc/rc.local 添加内容：systemctl start ssh.servic\n开机启动插入内存卡，连接网线，连接电源的那一刻树莓派就自动启动了。默认用户名：pi 默认密码：raspberry，ssh连接下试试吧。\n系统定制\n定制只能在 Linux 环境下进行，这里使用 ubuntu 16.04 64位系统。\n\n对原始的img镜像文件进行修改定制，这样如果以后需要频繁重装系统，或者用于商业目的时，可能就有这种需求了。\n安装需要的包apt-get updateapt-get install qemu qemu-user qemu-user-static kpartx\n将镜像挂在到系统目录需要先将系统镜像映射到loop设备文件，才能正常挂载镜像文件中的分区\nlosetup /dev/loop0 2018-04-18-raspbian-stretch-lite.imgkpartx -av /dev/loop0mount /dev/mapper/loop0p2 /mnt/\n这样就将镜像的 rootfs 挂载到了 /mnt 下，系统镜像有两个分区，分别被映射为了 /dev/mapper/loop0p1 和 loop0p2， 其中loop0p1是内核存放分区，暂时是不需要的。\n修改镜像中的数据qemu 提供了一个非常有意思的功能，可以 chroot 到异构CPU的二进制组成的根文件系统中，这样就可以在 x86 上对 ARM 的根文件系统的程序做调式了。\nmodprobe binfmt_miscecho &apos;:arm:M::\\x7fELF\\x01\\x01\\x01\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x00\\x02\\x00\\x28\\x00:\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\x00\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xff\\xfe\\xff\\xff\\xff:/usr/bin/qemu-static-arm-binfmt:P&apos; &gt; /proc/sys/fs/binfmt_misc/registercp /usr/bin/qemu-arm-static /mnt/usr/bin/\t# 将此文件拷贝到ARM的根中chroot /mnt/ bash\n执行了 chroot 之后，如果没有报错就切换到树莓派的根文件系统了，可以看看当前根的二进制文件是不是 ARM 架构的了 file /bin/bash，或者执行 uname -a 可以看到 内核也被模拟成了 ARM 架构的。\n接下来就可以进行一些安装配置和修改文件等操作了，比如修改网卡的配置文件配置一个静态的IP地址，这样启动树莓派后就可以直接连接了。接下来修改 apt 源为阿里云源，加快软件下载速度。\n修改：/etc/apt/sources.list\ndeb http://mirrors.aliyun.com/raspbian/raspbian stretch main contrib non-free rpi\n之后可以 apt-get update 然后安装需要的软件了。这时候就可以执行 systemctl enable ssh.service 命令，将SSH服务加入开机自启了。\n修改完后退出了 chroot 环境，然后对 /mnt 目录进行卸载。\nexit \t\t\t# 执行exit命令或者 Ctrl + d 就可以退出了umount /mnt\t\t# 如果卸载不掉，使用 fuser -ka /mnt 强制卸载kpartx -d /dev/loop0\t# 卸载loop0中的分区映射losetup -d /dev/loop0\t# 卸载img文件和loop0的映射\n刷入内存卡进行开机验证一些不当的修改可能导致无法开机，而且一些特殊的软件包会对内核进行更改，这种情况下就无法使用这种方式定制了。建议每次修改完系统镜像后都进行一次归档保存，并且记录每次归档的修改信息，这样如果某次修改出现了问题导致无法开机，就可以回退到上一次归档的镜像而不是重头再来了。\n功能和拓展连接WiFi树莓派3B默认是包含了WiFi和蓝牙模块的，配置连接WiFi路由器也很简单。\n首先安装连接WiFi使用的程序apt install wpasupplicant\n连接WPA加密的WiFi创建配置文件: /etc/wpa_supplicant/wpa_supplicant.conf\nnetwork={\n        ssid=&quot;SSID&quot;\n        key_mgmt=WPA-PSK\n        psk=&quot;PASSWORD&quot;\n}\n将 SSID 和 PASSWORD 替换成要连接的用户名和密码就可以了。\n然后执行 wpa_supplicant 命令手动连接到WiFi\nwpa_supplicant -i wlan0 -c /etc/wpa_supplicant/wpa_supplicant.conf\n这种方式连接WiFi 如果有错误会打印错误信息，适合手动调试WiFi，等连接无误后，ifconfig 命令可以看到 wlan0 这块网卡。这个时候还是没有IP地址的，需要手动配置一个IP地址或者使用 dhclient wlan0 命令来自动获取IP地址。\n还可以让系统 networking 服务来开机自动连接，修改网卡配置文件：/etc/network/interfaces 添加以下内容\nauto wlan0\niface wlan0 inet dhcp\n　　wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf\n或者配置为静态IP地址\nauto wlan0\niface wlan0 inet static\n    address 192.168.0.2\n    netmask 255.255.255.0\n    gateway 192.168.0.1\n    dns-nameservers 119.29.29.29\n    dns-nameservers 114.114.114.114\n　　wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf\n注意: 使用 systemctl restart networking.service 时，如果长时间没有反应，千万不要强行停止，否则可能会各种问题\n连接隐藏的WiFi修改配置文件：/etc/wpa_supplicant/wpa_supplicant.conf 为以下内容\nnetwork={\n    ssid=&quot;SSID&quot;\n    scan_ssid=1\n    psk=&quot;PASSWORD&quot;\n}\n同理，将 SSID 和 PASSWORD 替换为自己实际的，其他步骤和上面的一致。\n连接没密码的WiFi修改配置文件：/etc/wpa_supplicant/wpa_supplicant.conf 为以下内容\nnetwork={\n        ssid=&quot;SSID&quot;\n        key_mgmt=NONE\n}\n添加多个WiFi可以在配置文件中添加多个 network 配置块来添加多个WiFi配置，wpa_supplicant 将会自动连接可以连接的WiFi，也可以手动配置优先级来偏重连接某个WiFi。\nnetwork={\n    ssid=&quot;SSID1&quot;\n    psk=&quot;PASSWORD1&quot;\n    priority=1\n    id_str=&quot;homeOne&quot;\n}\n\nnetwork={\n    ssid=&quot;SSID2&quot;\n    psk=&quot;PASSWORD2&quot;\n    priority=2\n    id_str=&quot;homeTwo&quot;\n}\n使用4G上网由于树莓派3B并没有自带4G模块，所以想使用SIM卡拨号上网就需要另外买一个4G模块。树莓派3B也没有适用于4G模块的 Mini PCI-e 接口，所以还需要买一个 Mini PCI-e 转 USB 的4G模块专用开发板。\n这里4G模块使用 华为ME909s-821，SIM卡使用联通实名制的4G卡，需要先保证4G卡可以正常上网。\n安装4G拨号软件apt install wvdial\n修改配置文件：/etc/wvdial.conf 添加如下内容\n[Dialer wcdma]\nInit1 = ATZ\nInit2 = ATQ0 V1 E1 S0=0\nInit3 = AT+CGDCONT=1,&quot;IP&quot;,&quot;3gnet&quot;\nModem Type = Analog Modem\nBaud = 9600\nNew PPPD = yes\nModem = /dev/ttyUSB0\nISDN = 0\nPhone = *99#\nPassword = guest\nUsername = guest\n需要注意的地方是 Modem = /dev/ttyUSB0 ，需要找到4G模块的设备文件，如果不确定4G模块的设备文件是啥，可以先记录下 /dev/ 目录下的所有文件名，然后插上后看看多出来了哪些，4G模块会多出来5个设备文件，一般第一个 ttyUSB* 设备文件是 Modem 的设备文件，也就是 /dev/ttyUSB0，但是如果已经存在了其它的 ttyUSB* 文件，则4G模块的设备文件会依次往后排。\n将4G模块插入 Mini PCI-e 接口将SIM卡插入到卡槽，天线最好接上，否则信号可能太差导致拨号失败。\n使用 wvdial wcdma 命令开始拨号，当出现如下信息时，则拨号成功了\n--&gt; local  IP address 10.90.80.32\n--&gt; pppd: XE[01]\n--&gt; remote IP address 10.64.64.64\n--&gt; pppd: XE[01]\n--&gt; primary   DNS address 123.123.123.123\n--&gt; pppd: XE[01]\n--&gt; secondary DNS address 123.123.123.124\n--&gt; pppd: XE[01]\n这时候使用 ifconfig 可以看到 ppp0 接口已经连接\nppp0      Link encap:Point-to-Point Protocol  \n        inet addr:10.90.80.32  P-t-P:10.64.64.64  Mask:255.255.255.255\n        UP POINTOPOINT RUNNING NOARP MULTICAST  MTU:1500  Metric:1\n        RX packets:6 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:7 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:3 \n        RX bytes:66 (66.0 B)  TX bytes:129 (129.0 B)\n然后替换默认路由到点对点拨号的对端IP就可以使用4G上网了\nip ro replace default via 10.64.64.6ping www.baidu.com -c 4\nroot@raspberrypi:~# ip ro replace default via 10.64.64.64 \nroot@raspberrypi:~# ping www.baidu.com -c 4\nPING www.a.shifen.com (61.135.169.121) 56(84) bytes of data.\n64 bytes from 61.135.169.121: icmp_seq=1 ttl=54 time=36.2 ms\n64 bytes from 61.135.169.121: icmp_seq=2 ttl=54 time=25.9 ms\n64 bytes from 61.135.169.121: icmp_seq=3 ttl=54 time=21.9 ms\n64 bytes from 61.135.169.121: icmp_seq=4 ttl=54 time=19.8 ms\n\n--- www.a.shifen.com ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3003ms\nrtt min/avg/max/mdev = 19.859/25.984/36.220/6.300 ms\nroot@raspberrypi:~# \n还有一些需要注意的地方，如果使用物联网卡，需要确保物联网卡是否支持4G，是否支持数据业务，以及4G模块支持的网络和运营商。\n将 wvdial 程序 Ctrl + c 后4G就自动断开了。\n使用GPS模块如果想用树莓派做行车记录仪之类的东西，GPS模块就必不可少了，这里使用 NEO-7N-0-002 GPS模块。这款GPS模块支持通过USB连接到树莓派，也支持和树莓派直接进行串口连接。\nUSB连接直接使用普通的数据线连接，自带陶瓷天线，但是最好外接天线。使用自带的陶瓷天线定位时最好将GPS模块放到靠窗的位置，户外效果最佳，否则将无法定位。\n连接如下，通过USB连接后设备被映射为 /dev/ttyACM0\n当橘红色的灯按频率闪灭，而不是常亮时就定位成功了，使用 cat /dev/ttyACM0 命令查看GPS模块的输出只需要关心 $GPGGA 的内容就可以，定位成功的信息是这样子的\nroot@raspberrypi:~# cat /dev/ttyACM0 |grep GPGGA\n$GPGGA,025456.00,?955.49947,N,?1619.28218,E,2,08,1.52,98.4,M,-8.7,M,,0000*74\n$GPGGA,025457.00,?955.49948,N,?1619.28211,E,2,08,1.52,98.5,M,-8.7,M,,0000*72\n$GPGGA,025458.00,?955.49960,N,?1619.28209,E,2,08,1.52,98.4,M,-8.7,M,,0000*7F\n$GPGGA,025459.00,?955.49967,N,?1619.28204,E,2,08,1.52,98.3,M,-8.7,M,,0000*73\n其中 ?955.49947,N,?1619.28218,E N前面的浮点数表示北纬，E前面的浮点数表示东经，为了防止位置信息泄露，所以其中有一位数字用 ? 代替了，想了解 $GPGGA 的更多详细信息，可以翻阅 GPGGA 卫星数据格式。\n串口连接由于树莓派3B自带的串口被用于蓝牙了，所以最省事的方法就是使用USB转TTL线，将TTL线的 +5V 接到GPS模块的 VCC 引脚， GND 接到GPS模块的 GND，TXD 接到GPS模块的 RXD，RXD 接到GPS模块的 TXD，也就是说TTL线的输入输出要和GPS模块的输入输出交叉接。\n但是不知道是不是这款GPS模块板子上印刷错了，导致TTL线的 RXD 必须和 GPS模块上印刷的 RXD 引脚相接才能正常接收数据，由于只需要从GPS模块上接收数据，所以TTL线的 TXD 也可以不和GPS模块相接。\n接线图如下\n使用 minicom -D /dev/ttyUSB0 -b 9600 命令就可以获取GPS数据了。如果要处理GPS数据，可以用程序直连串口获取。摁下 Ctrl + a 松开后摁 x 然后敲下回车就退出 minicom 了。\n设备和设备文件绑定前面的4G模块使用的是 /dev/ttyUSB0 设备文件，TTL线使用的也是 /dev/ttyUSB0，如果同时使用这两个模块，重启后谁也无法确定当前的 /dev/ttyUSB0 是哪个模块，这种情况可以使用 udev 规则来绑定设备和设备文件。\n使用 udevadm info --attribute-walk --name=/dev/ttyUSB0 可以查看当前 /dev/ttyUSB0 设备的详细信息，然后通过这些信息匹配来为设备文件建立一个软连接，这样每次可以通过软连接来访问设备了。\n添加文件：/etc/udev/rules.d/mydevice.rules\nKERNEL==&quot;ttyUSB*&quot;, ATTRS{idVendor}==&quot;1a86&quot;, ATTRS{idProduct}==&quot;7523&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;,  SYMLINK+=&quot;ttl0&quot;\nKERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;02&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;,  SYMLINK+=&quot;hw4g0&quot;\nKERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;03&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;,  SYMLINK+=&quot;hw4g1&quot;\nKERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;04&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;,  SYMLINK+=&quot;hw4g2&quot;\nKERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;05&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;,  SYMLINK+=&quot;hw4g3&quot;\nKERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;06&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;,  SYMLINK+=&quot;hw4g4&quot;\n这样同时使用GPS和4G模块就可以通过访问 /dev/ttl0 和 /dev/hw4g0 来实现了。udev 规则的编写可以执行 man udev 获取。\n附录资料参考：\n\n树莓派命令行配置WiFi网络\n树莓派调试华为4G模块\n华为LTE模块AT拨号上网\n树莓派调试GPS模块\nudev绑定USB串口的方式\n\n","categories":["IoT"],"tags":["ubuntu","raspberry"]},{"title":"从零开始搭建Vue开发环境","url":"/2018/12/21/2018/%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BAVue%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83/","content":"简介\nVue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与现代化的工具链以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。本篇文章记录不使用 vue-cli 的自动化功能，手动搭建一个 Vue 的开发环境。\n\n\n环境\n\n\n软件\n版本\n\n\n\n\n操作系统\nWindows 10\n\n\nNode.js\nv10.13.0\n\n\nChrome浏览器\n70\n\n\n\n步骤初始化项目目录创建一个空的目录作为项目目录，并在目录内执行 npm init --yes\nD:\\Workspace\\webapp&gt;npm init --yes\nWrote to D:\\Workspace\\webapp\\package.json:\n\n{\n&quot;name&quot;: &quot;webapp&quot;,\n&quot;version&quot;: &quot;1.0.0&quot;,\n&quot;description&quot;: &quot;&quot;,\n&quot;main&quot;: &quot;index.js&quot;,\n&quot;scripts&quot;: {\n    &quot;test&quot;: &quot;echo \\&quot;Error: no test specified\\&quot; &amp;&amp; exit 1&quot;\n},\n&quot;keywords&quot;: [],\n&quot;author&quot;: &quot;&quot;,\n&quot;license&quot;: &quot;ISC&quot;\n}\n并创建新目录 src 作为代码的存放目录。在 src 目录中创建 index.html 写入以下内容：\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=\"app\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n加速 npm 包下载默认的 npm 非常连接官方的 npm 源，下载速度非常慢，可以使用 cnpm 来加速下载。\n首先全局安装 cnpmnpm install -g cnpm --registry=https://registry.npm.taobao.org\n之后就可以使用 cnpm 来开心的下载 npm 包了，但是 cnpm 下载某些包会出现依赖无法完全解决的问题，导致包无法正常使用，这种情况就只好配合 npm 来使用了。\n还有一种加速 npm 包下载的方法，就是让默认的 npm 命令使用国内的 npm 镜像站。可以注意到，上一条安装 cnpm 的命令中，就使用了 --registry=https://registry.npm.taobao.org 临时将下载源切换到 taobao 提供的 npm 镜像站。这里使用 nrm 工具来切换镜像站，nrm 工具也需要先使用 npm 来安装。\nnpm install -g nrm --registry=https://registry.npm.taobao.org\nnrm ls 命令可以看到当前默认使用的是 npm 的官方源\nD:\\Workspace\\webapp&gt;nrm ls\n\n* npm ---- https://registry.npmjs.org/\ncnpm --- http://r.cnpmjs.org/\ntaobao - https://registry.npm.taobao.org/\nnj ----- https://registry.nodejitsu.com/\nrednpm - http://registry.mirror.cqupt.edu.cn/\nnpmMirror  https://skimdb.npmjs.com/registry/\nedunpm - http://registry.enpmjs.org/\n使用 nrm use taobao 将默认源切换到 taobao 提供的镜像站\nD:\\Workspace\\webapp&gt;nrm use taobao\n\nRegistry has been set to: https://registry.npm.taobao.org/\n\nD:\\Workspace\\webapp&gt;nrm ls\n\nnpm ---- https://registry.npmjs.org/\ncnpm --- http://r.cnpmjs.org/\n* taobao - https://registry.npm.taobao.org/\nnj ----- https://registry.nodejitsu.com/\nrednpm - http://registry.mirror.cqupt.edu.cn/\nnpmMirror  https://skimdb.npmjs.com/registry/\nedunpm - http://registry.enpmjs.org/\n搭建 webpack 开发环境安装 webpackVue 官方推荐的开发方式是配合 webpack 打包工具，那么首先把 webpack 环境搭建起来。\ncnpm install webpack webpack-cli --save-dev\nwebpack3 中，webpack和它的命令行工具都包含在一个包中，但在 webpack4 中，官方将两者分开了，所以必须两个包都安装才可以使用 webpack 命令。官方推荐局部安装 webpack ，直接输入 webpack 命令是没法找到的，高版本的 node.js 可以使用 npx 命令来执行 webpack，或者直接使用相对路径执行 webpack。\nD:\\Workspace\\webapp&gt;webpack -v\n&apos;webpack&apos; 不是内部或外部命令，也不是可运行的程序\n或批处理文件。\n\nD:\\Workspace\\webapp&gt;npx webpack -v\n4.28.0\n\nD:\\Workspace\\webapp&gt;node_modules\\.bin\\webpack -v\n4.28.0\n使用 webpack 打包接下来在 src 目录下编写一个 main.js，文件内容如下：\nlet app = document.getElementById(\"app\")app.innerHTML = \"&lt;h1&gt;Hello webpack!&lt;h1&gt;\"\n将 main.js 打包为 bundle.js，我们一般将打包后的文件单独放到 dist 目录下：\nnpx webpack src\\main.js -o dist\\bundle.js --mode development\nD:\\Workspace\\webapp&gt;npx webpack src\\main.js -o dist\\bundle.js --mode development\nHash: 8a16b3a0c76c2b1d9f8a\nVersion: webpack 4.28.0\nTime: 94ms\nBuilt at: 2018-12-20 22:58:15\n    Asset      Size  Chunks             Chunk Names\nbundle.js  3.85 KiB    main  [emitted]  main\nEntrypoint main = bundle.js\n[./src/main.js] 82 bytes {main} [built]\n如果不加上 --mode development，webpack 则默认使用 production 级别去打包，如果代码里有 console.log 等无关程序运行逻辑的代码都会被清理掉，这样不方便项目的调试。这时可以看到项目目录下多出来一个 dist 目录，目录中有一个打包好的 bundle.js。这个例子中并没有在 main.js 里引入第三方的文件，如果引入了，webpack 也会一并打包为一个 bundle.js。\n在 index.html 里引入打包好的 bundle.js：&lt;body&gt;    &lt;div id=\"app\"&gt;&lt;/div&gt;    &lt;script src=\"../dist/bundle.js\"&gt;&lt;/script&gt;&lt;/body&gt;\n浏览器查看效果：\n\nwebpack 配置文件用命令行的方式是非常不方便，如果关闭了终端，下次使用 webpack 编译代码就还需要输入长长的一串代码，我们可以将代码写入到 webpack 的配置文件中，并配合 package.json 提供的自定义脚本命令功能来实现方便的编译。\n与 package.json 同级的目录下创建 webpack.config.js 文件，当前项目目录下为：\n\nwebpack.config.js 里写入如下内容：\nconst path = require('path')module.exports = &#123;    entry: path.join(__dirname, './src/main.js'),    output: &#123;        path: path.join(__dirname, \"./dist\"),        filename: \"bundle.js\"    &#125;,    mode: \"development\"&#125;\n代码语法使用 node.js 的语法，并使用 module.exports 将配置暴露出去，其中 entry 表示入口文件，也就是我们的 main.js 所在的目录。output 提供一个输出的目录和打包后的文件名。mode 则是配置使用哪种模式进行打包。之后我们对 webpack 的配置也都是围绕这个文件进行。\n这是在命令行只输入 npx webpack 命令，可以看到也编译成功了。\n接着修改 package.json，在 scripts 项中添加 &quot;build&quot;: &quot;webpack&quot;，这里就不需要借助 npx 工具来执行 webpack 了，npm 会在合适的位置运行 webpack 命令。\n当前 package.json 内容如下：\n&#123;  \"name\": \"webapp\",  \"version\": \"1.0.0\",  \"description\": \"\",  \"main\": \"index.js\",  \"scripts\": &#123;    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\",    \"build\": \"webpack\"  &#125;,  \"keywords\": [],  \"author\": \"\",  \"license\": \"ISC\",  \"devDependencies\": &#123;    \"webpack\": \"^4.28.0\",    \"webpack-cli\": \"^3.1.2\"  &#125;,&#125;\n控制台运行 npm run build\nD:\\Workspace\\webapp&gt;npm run build\n\n&gt; webapp@1.0.0 build D:\\Workspace\\webapp\n&gt; webpack\n\nHash: 8a16b3a0c76c2b1d9f8a\nVersion: webpack 4.28.0\nTime: 95ms\nBuilt at: 2018-12-20 23:25:53\n    Asset      Size  Chunks             Chunk Names\nbundle.js  3.85 KiB    main  [emitted]  main\nEntrypoint main = bundle.js\n[./src/main.js] 82 bytes {main} [built]\n预设的命令执行成功了。\nwebpack-dev-server 配置每次更改了代码，每次都需要重新编译，并刷新浏览器页面，这样是非常浪费时间的。而且通过文件的方式在浏览器预览效果，后期可能会出现各种问题。webpack-dev-server 则提供了一个支持时时编译，并自动刷新浏览器的功能。\n我们首先安装它：\ncnpm install webpack-dev-server --save-dev\nwebpack-dev-server 也支持直接通过命令行参数启动，但是既然已经使用了 webpack.config.js 来管理配置，那么就不提倡命令行参数启动了。修改 webpack.config.js 内容如下：\nconst path = require('path')const webpack = require(\"webpack\")module.exports = &#123;    entry: path.join(__dirname, './src/main.js'),    output: &#123;        path: path.join(__dirname, \"./dist\"),        filename: \"bundle.js\"    &#125;,    mode: \"development\",    devServer: &#123;        open: true,        port: 3000,        hot: true    &#125;,    plugins: [        new webpack.HotModuleReplacementPlugin(),    ]&#125;\n我们添加了 devServer 和 plugins 配置项，并导入了一个新的包 webpack。devServer 里配置的三个属性，open 表示自动帮我们打开浏览器，port 表示服务监听在 3000 端口，hot 表示开启热加载功能。热加载功能一个需要注意的地方就是需要在 plugins 里添加这个插件，否则热加载功能是关闭的，所以才有了 new webpack.HotModuleReplacementPlugin() 这段代码。\n还有一个需要注意的地方是，使用 webpack-dev-server 时一定要将 mode 设置为 development，否则每次热更新都非常慢，因为编译为 production 是非常耗时且消耗 CPU 资源的，但是可以给打包后的代码带来更小的体积。\n接着在 package.json 中添加命令，并修改 build 命令构建 production 级别的代码：\n\"scripts\": &#123;  \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\",  \"build\": \"webpack --mode production\",  \"dev\": \"webpack-dev-server\"&#125;\n控制台输入 npm run dev 命令，可以看到 webpack-dev-server 开始执行了，片刻，浏览器也自动打开了项目的根目录的页面：\n\nindex.html 在 src 目录下，点击 src 目录则打开了先前的页面。修改 main.js 里的内容为如下：\nlet app = document.getElementById(\"app\")app.innerHTML = \"&lt;h1&gt;Hello Vue!&lt;h1&gt;\"\n可以看到每次对代码 Ctrl + S 保存一次，控制台就多输出一些内容，如果内容有 Compiled successfully. 则表示自动编译成功了，当我们兴高采烈的刷新浏览器时发现，怎么一点变化都没！这是因为 webpack-dev-server 并不是直接将编译后的代码保存在磁盘上，而且放在了内存中。而我们刚才的 index.html 引入的还是之前编译好的 bundle.js 文件。\n修改 index.html 将引入 bundle.js 的代码改为 &lt;script src=&quot;/bundle.js&quot;&gt;&lt;/script&gt;，接着重启服务或者刷新浏览器试试：\n\n而且每次修改了 main.js 后都会自动帮我们编译并刷新浏览器。还有个小问题，webpack-dev-server 每次打开浏览器能不能直接定位到 index.html 而不是我们手动进入 src 目录呢？答案是肯定的，修改 devServer 的属性如下：\ndevServer: &#123;    open: true,    port: 3000,    hot: true,    contentBase: \"src\",&#125;,\ncontentBase 会告诉 webpack-dev-server 以哪个目录作为根目录，然后重启 webpack-dev-server 可以看到浏览器自动打开的就是我们希望看到的页面了。\n但是。。。当我们自动修改了 main.js 的时候，webpack-dev-server 会自动编译并把它放入内存，而 index.html 依然在物理磁盘上，那么我们能不能把这个文件也放入内存？这时还需要借助一个 html-webpack-plugin 的插件，接下来安装并使用它：\ncnpm install html-webpack-plugin --save-dev\n修改 webpack.config.js 为如下内容：\nconst path = require('path')const webpack = require(\"webpack\")const htmlWebpackPlugin = require(\"html-webpack-plugin\")module.exports = &#123;    entry: path.join(__dirname, './src/main.js'),    output: &#123;        path: path.join(__dirname, \"./dist\"),        filename: \"bundle.js\"    &#125;,    mode: \"development\",    devServer: &#123;        open: true,        port: 3000,        hot: true,        // contentBase: \"src\",    &#125;,    plugins: [        new webpack.HotModuleReplacementPlugin(),        new htmlWebpackPlugin(&#123;            template: path.join(__dirname, \"./src/index.html\"),            filename: \"index.html\"        &#125;)    ]&#125;\n这里我们做了三处更改，首先引入了 html-webpack-plugin 这个插件，然后注释掉了 contentBase: &quot;src&quot;，接着初始化了 htmlWebpackPlugin 的对象，并将 index.html 的路径和文件名提供给插件。\n还需要修改 index.html 将引入 bundle.js 的代码去掉：\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=\"app\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n然后重启 webpack-dev-server 可以看到，又打开了熟悉的页面。为什么我们没有引入 bundle.js 还可以正常显示页面呢？打开控制台可以看到，html-webpack-plugin 已经帮我们自动加入这句代码了。\n\n其实这个插件最重要的一点是，我们执行 npm run build 编译项目的时候，html-webpack-plugin 还会帮我们把处理好的 index.html 文件放入 dist 目录中。\n\nwebpack 处理 csswebpack 会自动处理 main.js 中通过 import 引入的其他 JavaScript 代码，同样也可以处理通过 import 引入的 css 样式文件，不过需要使用专门的 css-loader 来进行处理。我们需要先安装打包处理 css 文件的两个包：style-loader 和 css-loader\ncnpm install style-loader css-loader --save-dev\n现在 webpack 还不认识 css 文件，还需要修改 webpack.config.js 增加处理 css 文件的规则，修改后配置文件内容如下：\nconst path = require('path')const webpack = require(\"webpack\")const htmlWebpackPlugin = require(\"html-webpack-plugin\")module.exports = &#123;    entry: path.join(__dirname, './src/main.js'),    output: &#123;        path: path.join(__dirname, \"./dist\"),        filename: \"bundle.js\"    &#125;,    mode: \"development\",    devServer: &#123;        open: true,        port: 3000,        hot: true,        // contentBase: \"src\",    &#125;,    plugins: [        new webpack.HotModuleReplacementPlugin(),        new htmlWebpackPlugin(&#123;            template: path.join(__dirname, \"./src/index.html\"),            filename: \"index.html\"        &#125;)    ],    module: &#123;        rules: [            &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;        ]    &#125;&#125;\n其中新添了 module 配置项，并在其中添加了 rules。每一条规则都是一个对象格式，其中 test 是正则表达式，用于匹配以 .css 结尾的文件，use 配置了使用哪些加载器来处理匹配到的文件，加载器是从后往前处理的，css 文件先通过 css-loader 处理，然后才经过 style-loader 处理。 \n接着在 src 目录下新建 css 文件夹用于存放公共的 css 样式文件。css 目录中创建 base.css 文件来编写一些基础样式，文件内容如下：\n* &#123;    margin: 0;    padding: 0;&#125;div &#123;    text-align: center;&#125;\n接着在 main.js 里引入这个样式文件：\nimport './css/base.css'let app = document.getElementById(\"app\")app.innerHTML = \"&lt;h1&gt;Hello Vue!&lt;h1&gt;\"\n由于更改了 webpack 的配置文件，所以需要重启 webpack-dev-server，然后浏览器查看效果：\n\n样式成功引入了。\nwebpack 中使用 less对于习惯用 less 的语法来写 css 的开发者，webpack 也提供了相应的加载器可以很方便的处理 less 代码。我们首先需要安装 less 的编译器以及 less 的加载器：\ncnpm install less less-loader --save-dev\n然后 rules 规则中添加对 less 文件的处理：\nmodule: &#123;    rules: [        &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,        &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;    ]&#125;\ncss 目录中编写 base.less 文件：@baseColor: blue;div &#123;    h1 &#123;        color: @baseColor;    &#125;&#125;\n然后 main.js 中引入这个文件：import './css/base.css'import './css/base.less'let app = document.getElementById(\"app\")app.innerHTML = \"&lt;h1&gt;Hello Vue!&lt;h1&gt;\"\n重启 webpack-dev-server，浏览器查看效果：\n\nwebpack 中使用 sasswebpack 处理 sass 语法编写的文件和 less 原理相同，不过由于 sass 是通过 ruby 写的编译器，通过 npm 安装会非常麻烦，而通过 cnpm 就非常容易了。同样先安装 sass 的编译器和加载器：\ncnpm install node-sass sass-loader --save-dev\nwebpack 配置文件中添加处理 .scss 文件的规则：\nmodule: &#123;    rules: [        &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,        &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;,        &#123;test: /\\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;    ]&#125;\ncss 目录中编写 base.scss 文件：\n$baseColor: pink;div &#123;    h1 &#123;        background-color: $baseColor;    &#125;&#125;\nmain.js 引入这个文件：\nimport './css/base.css'import './css/base.less'import './css/base.scss'let app = document.getElementById(\"app\")app.innerHTML = \"&lt;h1&gt;Hello Vue!&lt;h1&gt;\"\n重启 webpack-dev-server，浏览器查看效果：\n\nwebpack 处理其他资源css 中经常会引入一些背景图片、字体图标等文件，如果 webpack 不对这些文件也进行处理，那网页还是会出问题的。用 webpack 打包小图片和小图标还可以完美的解决客户端和浏览器因为传输小图片造成的 HTTP 资源浪费问题。之前我们解决这种问题通常是采用精灵图的方式。\n处理这些资源我们需要安装 url-loader，它又依赖于 file-loader：\ncnpm install url-loader file-loader --save-dev\n处理背景图片同处理 css 文件的过程，我们也需要在 webpack 配置文件中增加处理图片文件的规则：\nmodule: &#123;    rules: [        &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,        &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;,        &#123;test: /\\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;,        &#123;test: /\\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader']&#125;    ]&#125;\n在 src 目录下创建 images 目录\n现在我们给网页增加一个背景图： \n将背景图保存为 bg.png，并放入 src/images 目录中，然后修改 base.css 中引入这个图片作为背景：\n* &#123;    margin: 0;    padding: 0;&#125;html &#123;    background: url(../images/bg.png);    background-repeat: repeat;&#125;div &#123;    text-align: center;&#125;\n重启 webpack-dev-server 后，页面背景图被成功加载了。\n\n这些图片 webpack 是如何处理的呢？我们不妨 F12 开发者模式查看下：\n\nwebpack 将图片以 Base64 的编码格式直接写入了 css 样式中，这样浏览器就不需要再次发起一次对图片的 HTTP 请求了。Base64 编码也有个不足的地方是，编码后的文件比源文件要增大三分之一，如果是小文件，Base64 的优势还是非常明显的，但是如果图片尺寸非常大，那带来的额外网络资源消耗就非常不划算了。我们可以通过给 url-loader 插件进行传参，来手动控制将多大尺寸的图片进行 Base64 编码。\n修改 webpack 配置文件，我们用 get 请求传参的方式给 url-loader 传递参数：\nmodule: &#123;    rules: [        &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,        &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;,        &#123;test: /\\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;,        &#123;test: /\\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader?limit=8192']&#125;    ]&#125;\n这表示只有小于 8192 字节的图片，我们才需要进行 Base64 编码。图片的大小是 13.4K 明显超过了限制。重启 webpack-dev-server 查看效果：\n\n现在文件名是一个32位的哈希值来表示，这样做的好处是可以避免如果项目中有内容完全相同的文件，就不需要处理两次了。当然这个名字的结构我们也是可以自定义的：\nmodule: &#123;    rules: [        &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,        &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;,        &#123;test: /\\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;,        &#123;   test: /\\.(jpg|png|gif|bmg|jpeg)$/,             use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]']        &#125;    ]&#125;\n我们将文件的原名称放在第一位，后面紧跟8位的哈希值，后面带上原来的扩展名，修改 webpack 配置文件后并重启 webpack-dev-server：\n\n处理字体图标文件一些 css 样式库自带了图标以及字体文件，比如 Bootstrap，如果我们不对这些资源进行处理的话，页面也是无法正常显示的，下面就使用 Bootstrap 试试图标字体该如何处理。\n首先安装 bootstrap：\ncnpm install bootstrap@3 --save\n由于我们只使用 Bootstrap 提供的样式，所以就不引入 jquery 等依赖了。\n修改 webpack 配置文件，添加处理图标字体的规则：\nmodule: &#123;    rules: [        &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,        &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;,        &#123;test: /\\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;,        &#123;   test: /\\.(jpg|png|gif|bmg|jpeg)$/,             use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]']        &#125;,        &#123;test: /\\.(ttf|eot|svg|woff|woff2)$/, use: 'url-loader'&#125;    ]&#125;\n在 main.js 中引入 bootstrap.css 并向 div 元素中追加一个图标：import './css/base.css'import './css/base.less'import './css/base.scss'import '../node_modules/bootstrap/dist/css/bootstrap.css'let app = document.getElementById(\"app\")app.innerHTML = \"&lt;h1&gt;Hello Vue!&lt;h1&gt;\"let icon = document.createElement('i')icon.className = \"glyphicon glyphicon-music\"app.appendChild(icon)\n重启 webpack-dev-server：\n\n小小的图标出现了。\nwebpack 中 babel 配置webpack 虽然支持一部分 ES6 语法，但是我们还是无法放开了写 ES6 语法的。这时我们就需要一款工具，来自动帮我们把高版本的 JavaScript 语法转变为较低版本的，这样对于 webpack 和浏览器兼容性都比较好，而且我们也可以享受 ES6 甚至更高版本的语法带来的编程体验。这款工具就叫做 Babel。\n安装 Babel 需要两套包：cnpm install babel-core@6 babel-loader@7 babel-plugin-transform-runtime --save-devcnpm install babel-preset-env babel-preset-stage-0 --save-dev\n接着修改 webpack 配置文件，让 .js 文件先通过 Babel 进行处理：\nmodule: &#123;    rules: [        &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,        &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;,        &#123;test: /\\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;,        &#123;   test: /\\.(jpg|png|gif|bmg|jpeg)$/,             use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]']        &#125;,        &#123;test: /\\.(ttf|eot|svg|woff|woff2)$/, use: 'url-loader'&#125;,        &#123;test: /\\.js$/, use: 'babel-loader', exclude: /node_modules/&#125;    ]&#125;\n这里通过 babel-loader 对 js 文件进行处理，并排除了 node_modules 中的 js 文件。如果不排除 node_modules，Babel 会将其中的所有 js 文件都打包编译，这样可能照成很多无法预料的结果，这显然不是我们希望的。\n到这一步还没有结束，我们还需要给 Babel 提供一个配置文件，告诉 Babel 编译 js 文件的一些配置。配置文件名称是 .babelrc，文件内容格式是 JSON。\n在项目主目录下创建 .babelrc 文件，并写入如下内容：\n&#123;    \"presets\": [      \"env\",      \"stage-0\"    ],    \"plugins\": [      \"transform-runtime\"    ]&#125;\n可以看到配置文件的内容和之前安装的几个包是相关的，其中 plugins 里放的就是之前安装的 babel-plugin-transform-runtime。而 presets 里的东西就更厉害了，如果我们要编译不同语法的 js 代码，比如 React 的 jsx 语法，ES6 甚至 ES7/8 的语法，就需要使用 babel-presets-* 相对应的包了。这些包里包含了不同标准代码的转码规则。\n接下来修改 main.js 添加一些 ES6 才支持的语法：\nimport './css/base.css'import './css/base.less'import './css/base.scss'import '../node_modules/bootstrap/dist/css/bootstrap.css'let app = document.getElementById(\"app\")app.innerHTML = \"&lt;h1&gt;Hello Vue!&lt;h1&gt;\"let icon = document.createElement('i')icon.className = \"glyphicon glyphicon-music\"app.appendChild(icon)class Person&#123;    static info = &#123;name: \"xiaoming\", age: 20&#125;    static show()&#123;        console.log(Person.info.name, Person.info.age)    &#125;&#125;Person.show()\n重启 webpack-dev-server，打开浏览器开发者选项，可以看到我们用 class 定义的类，并调用类里静态方法的代码执行成功了。\n\n文件总结现在的目录树是：\nwebapp\n├── dist\n│   ├── bundle.js\n│   └── index.html\n├── node_modules ...\n├── src\n│   ├── css\n│   │   ├── base.css\n│   │   ├── base.less\n│   │   └── base.scss\n│   ├── images\n│   │   └── bg.png\n│   ├── index.html\n│   └── main.js\n├── .babelrc\n├── package.json\n└── webpack.config.js\n文件内容：\nbase.css:* &#123;    margin: 0;    padding: 0;&#125;html &#123;    background: url(../images/bg.png);    background-repeat: repeat;&#125;div &#123;    text-align: center;&#125;\nbase.less:@baseColor: blue;div &#123;    h1 &#123;        color: @baseColor;    &#125;&#125;\nbase.scss:$baseColor: pink;div &#123;    h1 &#123;        background-color: $baseColor;    &#125;&#125;\nindex.html:&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;    &lt;meta http-equiv=\"X-UA-Compatible\" content=\"ie=edge\"&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=\"app\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\nmain.js:import './css/base.css'import './css/base.less'import './css/base.scss'import '../node_modules/bootstrap/dist/css/bootstrap.css'let app = document.getElementById(\"app\")app.innerHTML = \"&lt;h1&gt;Hello Vue!&lt;h1&gt;\"let icon = document.createElement('i')icon.className = \"glyphicon glyphicon-music\"app.appendChild(icon)class Person&#123;    static info = &#123;name: \"xiaoming\", age: 20&#125;    static show()&#123;        console.log(Person.info.name, Person.info.age)    &#125;&#125;Person.show()\n.babelrc:&#123;    \"presets\": [      \"env\",      \"stage-0\"    ],    \"plugins\": [      \"transform-runtime\"    ]&#125;\npackage.json:&#123;  \"name\": \"webapp\",  \"version\": \"1.0.0\",  \"description\": \"\",  \"main\": \"index.js\",  \"scripts\": &#123;    \"test\": \"echo \\\"Error: no test specified\\\" &amp;&amp; exit 1\",    \"build\": \"webpack --mode production\",    \"dev\": \"webpack-dev-server\"  &#125;,  \"keywords\": [],  \"author\": \"\",  \"license\": \"ISC\",  \"devDependencies\": &#123;    \"babel-core\": \"^6.26.3\",    \"babel-loader\": \"^7.1.5\",    \"babel-plugin-transform-runtime\": \"^6.23.0\",    \"babel-preset-env\": \"^1.7.0\",    \"babel-preset-stage-0\": \"^6.24.1\",    \"css-loader\": \"^2.0.1\",    \"file-loader\": \"^3.0.1\",    \"html-webpack-plugin\": \"^3.2.0\",    \"less\": \"^3.9.0\",    \"less-loader\": \"^4.1.0\",    \"node-sass\": \"^4.11.0\",    \"sass-loader\": \"^7.1.0\",    \"style-loader\": \"^0.23.1\",    \"url-loader\": \"^1.1.2\",    \"webpack\": \"^4.28.0\",    \"webpack-cli\": \"^3.1.2\",    \"webpack-dev-server\": \"^3.1.10\"  &#125;,  \"dependencies\": &#123;    \"bootstrap\": \"^3.4.0\"  &#125;&#125;\nwebpack.config.js:const path = require('path')const webpack = require(\"webpack\")const htmlWebpackPlugin = require(\"html-webpack-plugin\")module.exports = &#123;    entry: path.join(__dirname, './src/main.js'),    output: &#123;        path: path.join(__dirname, \"./dist\"),        filename: \"bundle.js\"    &#125;,    mode: \"development\",    devServer: &#123;        open: true,        port: 3000,        hot: true,        // contentBase: \"src\",    &#125;,    plugins: [        new webpack.HotModuleReplacementPlugin(),        new htmlWebpackPlugin(&#123;            template: path.join(__dirname, \"./src/index.html\"),            filename: \"index.html\"        &#125;)    ],    module: &#123;        rules: [            &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,            &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;,            &#123;test: /\\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;,            &#123;   test: /\\.(jpg|png|gif|bmg|jpeg)$/,                 use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]']            &#125;,            &#123;test: /\\.(ttf|eot|svg|woff|woff2)$/, use: 'url-loader'&#125;,            &#123;test: /\\.js$/, use: 'babel-loader', exclude: /node_modules/&#125;        ]    &#125;&#125;\nwebpack 与 Vue 的结合安装 vue这一步比较简单，直接用 cnpm 安装即可。\ncnpm install vue --save\n编写 Vue 代码删除 main.js 原来的内容，新的内容如下：\nimport Vue from \"vue\"let vm = new Vue(&#123;    el: \"#app\",    data:&#123;        msg:\"Hello Vue\"    &#125;&#125;)\n并修改 index.html：\n&lt;body&gt;    &lt;div id=\"app\"&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;&lt;/body&gt;\n启动 webpack-dev-server 后，预料的 Hello Vue 并没有出现，打开浏览器控制台，这时出现了一个异常：\n\nVue 中的一个坑为什么和我们直接在页面中通过 script 标签引入 vue.js 的结果不同呢？先来看 Vue 的警告是什么。\n[Vue warn]: You are using the runtime-only build of Vue where the template compiler is not available. \nEither pre-compile the templates into render functions, or use the compiler-included build.\n\n(found in &lt;Root&gt;)\n大致意思说，当前使用的是 Runtime Only 版本的 Vue，其中的模板编译器不可用，所以直接在 index.html 里写的模板字符串就没办法被编译了。解决方案也给了两个，要么预先将模板编译成 render 方法，要么使用包含编译器的 Vue.js 文件。\n这是因为我们通过 import Vue from &quot;vue&quot; 导入的 Vue，是个精简版的 Vue…，把模板编译的功能给阉割了，所以模板字符串就没法被正常的替换了。可以查看 node_modules\\vue\\package.json 文件中 &quot;main&quot;: &quot;dist/vue.runtime.common.js&quot;，Vue 默认导出的是 dist/vue.runtime.common.js 这个文件。\n我们可以在 main.js 中手动导入完整版的 vue.js 文件试试：\nimport Vue from \"vue/dist/vue.js\"let vm = new Vue(&#123;    el: \"#app\",    data:&#123;        msg:\"Hello Vue\"    &#125;&#125;)\n问题似乎是解决了：\n\n但这并不是官方推荐的做法，否则 vue 的包不会默认导出不带编译器的 Runtime Only 版本了。在 vue 的包目录中，完整版的 vue.js 304K 的大小，而 vue.runtime.common.js 才 210K 大小。\nVue2 中的 template 模板会先经过模板编译器编译成 render 函数，最终都通过调用 render 函数将页面呈现出来。模板的编译功能可以离线进行，也可以在浏览器上进行。在浏览器上进行编译模板需要消耗更多的内存和CPU资源，所以离线编译模板会让页面的体验更佳。\n如何使用 webpack 离线编译 Vue 模板，之后会讲到，下面先来看看如何使用 render 的方式渲染模板\n使用 render 渲染模板修改 main.js 的内容为如下：import Vue from \"vue/dist/vue.js\"let hello = &#123;    template: \"&lt;h1&gt;&#123;&#123;msg&#125;&#125;&lt;/h1&gt;\",    data()&#123;        return &#123;            msg:\"Hello Render\"        &#125;    &#125;&#125;let vm = new Vue(&#123;    el: \"#app\",    render: function(createElement)&#123;        return createElement(hello)    &#125;&#125;)\n修改 index.html 去掉模板字符串：&lt;body&gt;    &lt;div id=\"app\"&gt;&lt;/div&gt;&lt;/body&gt;\n这里我们定义了一个新的 hello 模板，render 函数会接收一个方法，用这个方法可以将指定的模板渲染成 DOM 结构的对象（虚拟DOM），render 需要返回这个对象，然后这个对象被 Patch 到真实的 DOM 中(el: &quot;#app&quot;)。\n查看浏览器，页面被成功的渲染出来了：\n\n但结果似乎有个不太一样的地方，我们用模板字符串或者使用 components 申明的子组件，都包含在 &lt;div id=&quot;app&quot;&gt;&lt;/div&gt; 容器中，而使用 render 渲染的模板，却直接将 &lt;div id=&quot;app&quot;&gt;&lt;/div&gt; 替换了！\n使用 webpack 处理 vue 文件官方推荐的做法是将 Vue 的所有模板都定义为组件，单独写入以 .vue 结尾的文件，然后使用 vue-loader 和 vue-template-compiler 将 .vue 模板文件都离线编译处理成 JavaScript 代码。这样自然就不需要使用完整版 Vue 自带的模板编译功能了。\n接下来安装这两个包：cnpm install vue-loader vue-template-compiler --save-dev\n修改 webpack 配置文件，引入 vue 插件，以及增加对 .vue 文件的处理规则：\nconst path = require('path')const webpack = require(\"webpack\")const htmlWebpackPlugin = require(\"html-webpack-plugin\")const VueLoaderPlugin = require('vue-loader/lib/plugin')module.exports = &#123;    entry: path.join(__dirname, './src/main.js'),    output: &#123;        path: path.join(__dirname, \"./dist\"),        filename: \"bundle.js\"    &#125;,    mode: \"development\",    devServer: &#123;        open: true,        port: 3000,        hot: true,        // contentBase: \"src\",    &#125;,    plugins: [        new webpack.HotModuleReplacementPlugin(),        new VueLoaderPlugin(),        new htmlWebpackPlugin(&#123;            template: path.join(__dirname, \"./src/index.html\"),            filename: \"index.html\"        &#125;)    ],    module: &#123;        rules: [            &#123;test: /\\.css$/, use: ['style-loader', 'css-loader']&#125;,            &#123;test: /\\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;,            &#123;test: /\\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;,            &#123;   test: /\\.(jpg|png|gif|bmg|jpeg)$/,                 use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]']            &#125;,            &#123;test: /\\.(ttf|eot|svg|woff|woff2)$/, use: 'url-loader'&#125;,            &#123;test: /\\.js$/, use: 'babel-loader', exclude: /node_modules/&#125;,            &#123;test: /\\.vue$/, use: 'vue-loader'&#125;        ]    &#125;&#125;\nsrc 目录下新建 App.vue 文件，然后写入如下内容：\n&lt;template&gt;    &lt;div id=\"app\"&gt;        &#123;&#123;msg&#125;&#125;    &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123;    data()&#123;        return &#123;            msg: \"Hello App!\"        &#125;    &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt;\nmain.js 中引入并渲染这个组件：import Vue from \"vue\"import App from \"./App.vue\"let vm = new Vue(&#123;    el: \"#app\",    render: function(createElement)&#123;        return createElement(App)    &#125;,&#125;)\n重启 webpack-dev-server，Hello App! 成功的在页面显示了出来。\n子组件使用我们接着在 src 目录创建一个 components 目录用来保存子组件。\n在 components 目录中创建 Login.vue 文件，并写入如下内容：\n&lt;template&gt;    &lt;div&gt;        &lt;h3&gt;登陆&lt;/h3&gt;        账号：&lt;input type=\"text\"&gt;&lt;br&gt;        密码：&lt;input type=\"password\"&gt;    &lt;/div&gt;&lt;/template&gt;\n在 App.vue 中引入并使用这个组件：&lt;template&gt;    &lt;div id=\"app\"&gt;        &#123;&#123;msg&#125;&#125;        &lt;login&gt;&lt;/login&gt;    &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import login from './components/Login.vue'export default &#123;    data()&#123;        return &#123;            msg: \"Hello App!\"        &#125;    &#125;,    components:&#123;        'login': login    &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt;\n当前浏览器页面：\n\n路由的使用接下来使用路由来导航到其他组件，需要先安装 Vue 的路由模块：\ncnpm install vue-router --save\n在 components 目录中创建 Register.vue 文件，并写入如下内容：&lt;template&gt;    &lt;div&gt;        &lt;h3&gt;注册&lt;/h3&gt;        账号：&lt;input type=\"text\"&gt;&lt;br&gt;        密码：&lt;input type=\"password\"&gt;&lt;br&gt;        确认密码：&lt;input type=\"password\"&gt;&lt;br&gt;        &lt;input type=\"submit\" value=\"提交\"&gt;    &lt;/div&gt;&lt;/template&gt;\n我们在 App.vue 中通过路由访问这两个组件：\n&lt;template&gt;    &lt;div id=\"app\"&gt;        &#123;&#123;msg&#125;&#125;        &lt;br&gt;        &lt;router-link to=\"/login\"&gt;登陆&lt;/router-link&gt;        &lt;router-link to=\"/register\"&gt;注册&lt;/router-link&gt;        &lt;router-view&gt;&lt;/router-view&gt;    &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import login from './components/Login.vue'import register from './components/Register.vue'export default &#123;    data()&#123;        return &#123;            msg: \"Hello App!\"        &#125;    &#125;,    components:&#123;        'login': login,        'register': register    &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt;\n然后在 src 目录下创建一个单独的 router.js 文件来存放路由配置信息：\nimport Vue from 'vue'import VueRouter from 'vue-router'Vue.use(VueRouter)import login from './components/Login.vue'import register from './components/Register.vue'export default new VueRouter(&#123;    routes:[        &#123;path:\"/login\", component: login&#125;,        &#123;path:\"/register\", component: register&#125;,    ]&#125;)\n在 main.js 中应用这个路由：\nimport Vue from \"vue\"import App from \"./App.vue\"import router from \"./router.js\"let vm = new Vue(&#123;    el: \"#app\",    render: function(createElement)&#123;        return createElement(App)    &#125;,    router: router&#125;)\n浏览器查看效果：\nvue 中使用 lessVue 的样式写在模板文件的 style 标签中，并且可以给 style 标签使用 lang 属性来表明要使用的 css 语法。给 style 标签添加 scoped 属性可以让样式只对当前组件生效。\n编辑 App.vue 的代码，内容如下：\n&lt;template&gt;    &lt;div id=\"app\"&gt;        &#123;&#123;msg&#125;&#125;        &lt;br&gt;        &lt;router-link to=\"/login\"&gt;登陆&lt;/router-link&gt;        &lt;router-link to=\"/register\"&gt;注册&lt;/router-link&gt;        &lt;router-view&gt;&lt;/router-view&gt;    &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import login from './components/Login.vue'import register from './components/Register.vue'export default &#123;    data()&#123;        return &#123;            msg: \"Hello App!\"        &#125;    &#125;,    components:&#123;        'login': login,        'register': register    &#125;&#125;&lt;/script&gt;&lt;style lang=\"less\" scoped&gt;    #app &#123;        @line: 30px;        a &#123;            display: inline-block;            width: 80px;            height: @line;            text-decoration: none;            border: 1px solid skyblue;            text-align: center;            line-height: @line;            border-radius: 5px;            color: #666666;            transition: all 0.3s ease;                    &#125;        a:hover &#123;            background-color: skyblue;            color: white;        &#125;        a:active &#123;            background-color:rgb(0, 255, 157);        &#125;    &#125;&lt;/style&gt;\n之前已经配置了 less 加载器，所以可以在页面上直接看到效果了：\n\nVue 是如何保证加上 scoped 属性的 style 标签只作用于当前的组件而不会影响其他组件呢？可以看到，Vue 自动给当前组件的所有标签都加上了 data-v-7ba5bd90 这个属性，这个属性就相当于每个组件的唯一标识。只要在样式中选择只给带有这个标识的标签应用样式，这样就做到各组件互不影响了。\n\n编译打包 Vue 项目当项目完成后，就可以将项目编译测试部署了，下面运行 npm run build 将项目打包测试，最终我们生成了一个 111KB 的 bundle.js 文件，浏览器里打开 index.html 也测试无误。\n\n\n到这里 “从零开始搭建Vue开发环境” 就完成了。\n当前项目目录树：\nwebapp\n├── dist\n│   ├── bundle.js\n│   └── index.html\n|── node_modules ...\n├── src\n│   ├── App.vue\n│   ├── components\n│   │   ├── Login.vue\n│   │   └── Register.vue\n│   ├── css\n│   │   ├── base.css\n│   │   ├── base.less\n│   │   └── base.scss\n│   ├── images\n│   │   └── bg.png\n│   ├── index.html\n│   ├── main.js\n│   └── router.js\n├── .babelrc\n├── package.json\n└── webpack.config.js\n附录Chrome Vue 拓展使用 Chrome 的 Vue 拓展插件，可以很方便的调试 Vue 项目，安装插件需要访问 Google 商店，安装地址：点击打开\n使用效果：\n\n项目文件打包下载点击下载\n解压后进入 webapp 目录，执行 npm install 或者 cnpm install 安装依赖。\n","categories":["Vue"],"tags":["web","vue","webpack"]},{"title":"Linux IO多路复用","url":"/2019/11/16/2019/Linux%20IO%E5%A4%9A%E8%B7%AF%E5%A4%8D%E7%94%A8/","content":"简介\n在平常的工作中，遇到 IO 密集型任务，比如要频繁调用外部的 API 接口（网络IO），或者频繁读写文件（磁盘IO）通常代码都会在 IO 任务创建后等待 IO 任务结束并将需要的数据返回。这种同步的编程方式是最简单的，但同时也是效率最低的。比如在一个 Web 后端中，如果是单线程单进程的运行模式，一次就只能处理一个客户端的请求，即使引入了多线程/多进程，虽然可以同时服务多个客户端了，但是如果瞬间几千的并发连接，那么后端就必须创建相对多的线程或进程，这时候 CPU 将会花费大量的时间和资源用于线程上下文切换上，而且这么多的线程，如果用到了锁机制来保证一些共享数据的安全，还将进一步的降低 Web 后端的性能。而 IO 多路复用的出现，则给这种局面带来了转机。\n\n\n环境\n\n\n软件\n版本\n\n\n\n\n操作系统\nUbuntu 18.04\n\n\nPython\n3.6\n\n\n\n教程在学习 IO 多路复用前，我们先理解一些基本的概念，渐进式的学习 IO 多路复用。\n同步/异步同步和异步的概念，在不同的角度有不同的回答，这里举几个简单的例子来说明一下。\n\n在楼下食堂买饭，当点完餐后，你就站在台前呆若木鸡的等，直到你点的餐做好了你才端走去吃。因为吃饭和点餐是相互依赖的事情，所以在点餐没有得到结果（食物）之前就什么也不干一直等待，这就是同步。异步就是在点完餐后，你就找个地坐着玩手机，就干点别的 不傻等了。节约了等待过程的时间浪费，但是怎么才能知道自己点的餐好了呢？这时候可以选择每隔五分钟就上吧台问一问，没有好就继续回去玩手机。这种方式也就称之为轮询。还有一种更高效的方式，就是点完餐后服务人员给你一个号，当你的餐准备完毕就广播你的号，你就可以前去领餐了。这种方式就是消息通知。\n\n在一套 Web 系统中，比如我们要导出员工表，当点击导出的按钮后，过一会就开始自动下载员工表。在浏览器内部，浏览器发起 http 请求我们的后端接口，这时候后端保持着 http 连接，当把员工数据从数据库中找到并绘制成表格后就返回给浏览器，这就是同步。而异步就是当浏览器发起请求后，后端直接返回它一个任务 ID，并提供它一个接口用来查询任务进度。这时候想要知道任务是否已经结束就需要不停的刷新页面查看任务状态，这种轮询的方式是非常比较浪费资源切低效的。最高效的方式就是后端可以主动通知浏览器任务已经结束了，关于主动推的技术目前主流的是 WebSocket。\n\n在日常的编程中，我们接触最多的就是同步编程的方式了，比如我们使用 requests 库发起一个 http 请求，在请求发出后，函数将以阻塞的方式等待对方返回数据。在阻塞期间，是没有任何一行代码被执行，整个程序都处于挂起状态，直到对方返回数据后才继续往下走，如果有多个不想关的请求需要被发送，比如爬虫程序，那么同步编程的方式效率简直太低了。JavaScript 在浏览器中，通过 XMLHttpRequest 发送 ajax 请求的时候，默认是直接返回的，但是你需要将事后对数据的处理方法通过回调的形式传递给 XMLHttpRequest 对象，当请求的接口响应后，会主动调用对数据处理的回调函数。这种通过非阻塞加回调的方式，就是一种常见的异步编程方式。\n\n\n由上可以看到，同步就是事物之间串行化的执行过程，异步就是事物之间无需互相等待。同步和异步所关注的就是事件完成后的消息通知机制，是阻塞等待、轮询还是事件通知/回调。\n阻塞/非阻塞阻塞和非阻塞是在调用者的角度来看，例如发起一个 IO 相关的系统调用，或者 wait 另外的线程，sleep 主动挂起自己，都会使程序进行阻塞。而我们大多遇到的阻塞案例，都是进行了 IO 相关的系统调用。\n什么是系统调用？简单来说就是内核提供给用户程序的 API 接口，用于操纵内核才有权限访问的内容。例如我们在 Python 中对文件进行读写，我们并不需要关心文件存储在哪种物理介质上，是机械硬盘是U盘还是固态硬盘，这是因为在驱动、内核、C语言库的层层封装下，我们才得以用非常简单的方式对文件进行读写。对于网络也一样，我们不需要关心网卡的类型和性质，只需要简单的调用 socket 模块就可以完成对网络的操控。这些库本质上都只是调用了C语言提供的标准库，C语言的标准库中又调用了内核提供的这些系统调用完成的。那内核又为什么不允许用户进程直接操控硬件呢？是为了自我保护，如果任何进程都能随意的操控硬件，操控内存中的数据则是非常危险的，内核都可能分分钟被恶意程序干掉。\n现在再来看看因为 IO 相关的系统调用造成阻塞的原因是什么。Linux 上的 strace 命令可以跟踪用户进程的系统调用，下面写一段因为网络 IO 造成的阻塞的例子：\nimport sockets = socket.socket(socket.AF_INET,socket.SOCK_DGRAM)s.bind(('',9090))data, addr = s.recvfrom(4096)s.sendto(data, addr)s.close()\n使用 strace python echo.py 执行脚本，在一片输出后，停在了 recvfrom(3, 这个地方：\n...\nsocket(AF_INET, SOCK_DGRAM, IPPROTO_IP) = 3\nbind(3, {sa_family=AF_INET, sin_port=htons(9090), sin_addr=inet_addr(&quot;0.0.0.0&quot;)}, 16) = 0\nrecvfrom(3, \n我们需要关注的是最后三行，前面打印的都是 Python 虚拟机在启动的时候加载动态链接库、读取脚本内容、分配内存空间等相关的系统调用。当脚本执行到 s = socket.socket(socket.AF_INET,socket.SOCK_DGRAM) 发起了第一个系统调用 socket，就是创建了一个网络套接字文件，返回的文件描述符是 3，在系统的 /proc 下也可以看到该进程打开的所有文件描述符：\nroot@yunfwe:~# ps aux |grep echo.py\nroot     10533  0.0  0.0  18720  1932 pts/0    S+   20:40   0:00 strace python echo.py\nroot     10535  0.0  0.4  35684  9084 pts/0    S+   20:40   0:00 python echo.py\nroot     14654  0.0  0.0  14428  1052 pts/2    S+   20:50   0:00 grep --color=auto echo.py\nroot@yunfwe:~# ls -lh /proc/10535/fd\ntotal 0\nlrwx------ 1 root root 64 2019/11/10 20:50:52 0 -&gt; /dev/pts/0\nlrwx------ 1 root root 64 2019/11/10 20:50:52 1 -&gt; /dev/pts/0\nlrwx------ 1 root root 64 2019/11/10 20:50:52 2 -&gt; /dev/pts/0\nlrwx------ 1 root root 64 2019/11/10 20:50:52 3 -&gt; &apos;socket:[274124191]&apos;\nroot@yunfwe:~#\n程序当前已经打开了 4 个文件描述符，其中 1,2,3 分别对应着 标准输入，标准输出，错误输出，其中都指向了 /dev/pts/0，这个设备文件就是当前 SSH 连接的虚拟终端，所以程序的输出我们才会在终端上看到。最后一个 socket 类型的文件就是打开的网络套接字了。\n接着 s.bind((&#39;&#39;,9090)) 的语句发起了第二个系统调用，就是给刚才创建的网络套接字绑定了监听地址和端口。如果没有异常，bind 系统调用将返回 0。接着执行到 data, addr = s.recvfrom(4096) 语句的时候，发起了第三个系统调用，这个系统调用并长时间的阻塞了 Python 进程，这个过程又发生了什么？\n进程在进行系统调用的时候，用户进程触发软中断，CPU 接收到中断信号后由用户态切换到内核态去运行相应系统调用的内核函数，此时用户进程是被挂起的（进程被放入等待队列中，这时进程的状态为 sleeping），并等待系统调用执行完毕后 CPU 由内核态切换到用户态才被重新唤醒（进程重新被放入执行队列，只有此队列的进程才可能获得 CPU 执行权，此时进程的状态为 running）。所以，前面在进行 socket 和 bind 系统调用的时候，Python 进程并不是没有被阻塞，而是阻塞的时间太短，我们感知不到而已。\n当网卡又数据来到的时候，网卡将产生一个硬中断来通知内核来处理数据，内核发现了有该进程监听的端口的数据的时候，将数据由内核空间的缓冲区拷贝到用户进程空间的缓冲区，并重新将用户进程唤醒（放置到运行队列），这时用户进程就拿到了需要的数据。我们可以使用 nc 命令向此端口发送一些数据，看看用户进程之后的动作。\n新建终端，并通过 nc 命令发送数据：\nroot@yunfwe:~# echo &apos;hello&apos; |nc -4u 127.0.0.1 9090\nhello\nPython 进程退出，strace 命令的跟踪如下：\nrecvfrom(3, &quot;hello\\n&quot;, 4096, 0, {sa_family=AF_INET, sin_port=htons(53114), sin_addr=inet_addr(&quot;127.0.0.1&quot;)}, [16]) = 6\nsendto(3, &quot;hello\\n&quot;, 6, 0, {sa_family=AF_INET, sin_port=htons(53114), sin_addr=inet_addr(&quot;127.0.0.1&quot;)}, 16) = 6\nclose(3)                                = 0\nrt_sigaction(SIGINT, {sa_handler=SIG_DFL, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x7f1fa7148f20}, {sa_handler=0x561f54bcebe0, sa_mask=[], sa_flags=SA_RESTORER, sa_restorer=0x7f1fa7148f20}, 8) = 0\nexit_group(0)                           = ?\n+++ exited with 0 +++\nroot@yunfwe:~# \nrecvfrom 系统调用将接收到的字符串 hello\\n 和客户端地址由内核态返回到用户态，用户态紧接着通过 sendto 系统调用将数据发送给客户端地址，然后 close 系统调用关闭打开的文件描述符，用户进程执行完毕，Python 解释器退出。进程退出也是用户进程生命周期的最后一个系统调用，这时候内核将回收进程所占用的资源（打开的文件、占用的内存等），然后将进程的退出码返回给进程的调用者，这就是该进程的父进程。\n题外话：无论是文件 IO 相关的系统调用，还是网络 IO 相关的系统调用，都会发生由 内核缓冲区 -&gt; 用户空间缓冲区，或者 用户空间缓冲区 -&gt; 内核缓冲区的数据复制，对于 Web 静态资源服务器，比如 Nginx 像客户端发送文件数据，需要先将硬盘上读取的文件由内核缓冲区 -&gt; 用户空间缓冲区，然后再由用户空间缓冲区 -&gt; 内核的网络套接字缓冲区 -&gt; 发送到客户端，这个过程是低效的，因此 Linux 内核提供了 sendfile 这个系统调用，这个系统调用将文件描述符（必须是真实的文件）作为输入，套接字描述符作为输出，达到在两个套接字之间直接传递数据，完全在内核内部完成，而避免了数据在内核和用户进程间的复制，并且避免了多余的系统调用。所以 Nginx 作为号称可以榨干计算机最后一丝性能的服务软件，自然也提供了对 sendfile 的支持，只需要在提供静态资源访问的配置块中添加 sendfile on; 即可。\n说完了程序为什么会发送阻塞，再说说如何避免阻塞，也就是非阻塞。非阻塞 IO 最简单的实现就是多线程，遇到耗时的 IO 操作，就开启一个线程处理，这样就可以做到不阻塞当前线程了。对于 socket 模块，也可以将套接字对象设置为非阻塞模式：socket.setblocking(false)，这样再进行 recv 等系统调用时将抛出一个异常而不是阻塞当前线程。对于文件，Linux 内核提供了 AIO 相关的系统调用，但是市面上也并没有看到太多的应用。当今最常用的非阻塞 IO 的方法就是 IO多路复用，Linux 提供 IO 多路复用相关的几个系统调用就是 select、poll、epoll。Python 协程的完整实现，IO 多路复用也是不可少的一个环节，Nginx 出了名和高效，也就是借助了 IO 多路复用的能力。\nPS：中断其实也就是一种异步的事件通知机制，可见整套计算机系统的设计中穿插着各种的同步和异步。其他原因造成的阻塞，例如锁、wait、sleep 函数等，各位有兴趣可以自己探索一番。\nIO多路复用IO 多路复用是如何在单个线程内并发处理多个网络套接字的一种方式，已经是系统高性能网络服务器的必备技术，Nginx、Redis 等也都用到了 IO 多路复用技术。\nselect最先出来，且兼容性最好的 IO 多路复用技术是 select 系统调用。它的实现思路是，传递给它一个包含所有套接字描述符的数组，如果数组内的套接字有数据到来，select 将返回这些可以操作的套接字，并唤醒进程继续处理，否则将一直阻塞，或直到设置的 timeout 超时。Python 的标准库 select.select 提供了对它的封装，下面一个简单的例子看看如何使用。\nselect.select 函数申明：\nselect(rlist, wlist, xlist[, timeout]) -&gt; (rlist, wlist, xlist)\n\nrlist 对应可读列表，此列表内的套接字有数据来到时会使 select 返回。\nwlist 对应可写列表，此列表内的套接字可写时返回。\nxlist 对应异常列表，此列表内的套接字异常，比如已被关闭时返回。\n可选的 timeout 参数，如果提供，则 select 会在超时后唤醒进程。因此，我们也可以使用 select.select([],[],[],2) 来模拟 time.sleep 函数。\n\nselect 函数返回一个包含三种情况套接字列表的元组，例如返回的 rlist 内的套接字，肯定是已经有数据可读的套接字，因此这时候调用 recv 就不会将进程阻塞了。同时处理多个客户端连接的原因也在这里，当有新的客户端连接，或者客户端有数据发送到服务端时，select 都将唤醒线程去处理，且处理过程中 recv 也不会造成单个套接字的阻塞导致整个线程内所有套接字都无法被处理。\n下面看代码：\nimport selectimport sockets = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)s.setblocking(False)s.bind(('',9090))s.listen(5)print 'Server is listen on 0.0.0.0:9090'rlist = [s, ]while True:    rables , _ , xables = select.select(rlist,[],[])    for sock in rables:        if sock is s:            new_sock, addr = sock.accept()            new_sock.setblocking(False)            print 'New client : %s:%s' % addr            rlist.append(new_sock)        else:            msg = sock.recv(4096)            if msg == '' or 'exit' in msg:                 sock.close()                rlist.remove(sock)                print 'Have a client exit...'            else:                print 'Recv msg: %s' % msg                sock.send('From server: ' + msg)\n将代码运行起来：\nroot@yunfwe:~# python echo.py \nServer is listen on 0.0.0.0:9090\n这时代码被阻塞到了 select 处，接着新开一个终端，通过 nc 命令连接此端口，并发送 hello 字符串：\nroot@yunfwe:~# nc 127.0.0.1 9090\nhello\nFrom server: hello\n这时服务端打印如下：\nroot@yunfwe:~# python echo.py \nServer is listen on 0.0.0.0:9090\nNew client : 127.0.0.1:41700\nRecv msg: hello\n这个过程中，select 已经返回了两次，第一次是 nc 客户端接入的时候，执行了获取客户端套接字以及将客户端套接字也加入 rlist 中，第二次返回因为客户端发送了 hello 字符串。sock.recv(4096) 这一步，并不是指从套接字缓存区读取 4096 个字节，而是创建一个长度为 4096 的用户进程缓冲区，然后接收从内核中套接字缓冲区复制来的数据，所以并不一定 recv 返回的数据就有 4096 的长度。接着再新开一个终端再次用 nc 连接服务端：\nroot@yunfwe:~# nc 127.0.0.1 9090\nhi\nFrom server: hi\n可以看到，第二个客户端也被正常的服务了！\nroot@yunfwe:~# python echo.py \nServer is listen on 0.0.0.0:9090\nNew client : 127.0.0.1:41700\nRecv msg: hello\n\nNew client : 127.0.0.1:41702\nRecv msg: hi\n在单线程中，同时处理多个客户端的连接，而且如果设置了 timeout 关键字，就可以在超时后做一些额外的处理工作，IO 多路复用就提供了这么强大的能力。\n接着两个客户端都向服务器发送 exit 字符串来退出连接：\nroot@yunfwe:~# python echo.py \nServer is listen on 0.0.0.0:9090\nNew client : 127.0.0.1:41700\nRecv msg: hello\n\nNew client : 127.0.0.1:41702\nRecv msg: hi\n\nHave a client exit...\nHave a client exit...\n以上就是 select 的简单示例，可以看到 select 还是非常简单，那么 select 又是如何完成套接字的监听和唤醒进程的呢？\n在上面的例子中，已经有两个客户端连接了，加上服务端监听服务端口的套接字，一共有三个套接字。在进行 select 系统调用时，select 会将调用线程分别放到这三个套接字的等待队列中，这时线程就失去了执行权，当其中任何一个套接字有数据到来，将触发中断处理程序，中断程序会将线程从等待队列移除，然后重新加入执行队列。线程被唤醒后就知道，肯定有至少一个套接字接收了数据，这时只需要遍历 select 返回的列表就可以拿到所有就绪的套接字了。\nselect 的实现非常简单，而且在多个平台都有实现（Windows，Linux，Mac 都可用），但是简单不一定代表高效，如果需要被同时监听的套接字太多，每次 select 都先检查套接字缓冲区是否已经有准备好的数据，如果有就直接返回，没有就需要将线程加入到每个套接字的等待队列，唤醒也需要从每个套接字的等待队列移除。这个过程需要经历至少一次对套接字列表的遍历，套接字列表越大，每次 select 调用的成本也越高，这也是 Linux 限制 select 默认最高 1024 个描述符的原因之一。\nepoll在 select 的基础上，升级发展出了 poll，但是基本的原理还是一样，select 中遇到的问题，poll 也没有解决，只是 poll 没有了 1024 最大文件描述符的限制。再之后，对 select 进行功能分离和引入 eventpoll 对象来作为代理，优化存储套接字的数据结构，使 IO 多路复用的效率大大提高，这就是 epoll。\n在 select 中，每次 select 调用，都会将线程添加到套接字的等待队列，唤醒也需要从所有套接字队列中把线程移除，epoll 添加了一层代理（eventpoll），只需要使用 epoll_create 就可以创建它，然后使用 epoll_ctl 维护要监听的套接字，当添加要监听的套接字的时候，只是将 eventpoll 添加到这些套接字的等待队列，而不是直接将线程添加到等待队列了。当套接字接收到数据，中断处理进程会给 eventpoll 对象的 rdlist （就绪列表）中引用这些准备就绪的套接字。当程序执行到 epoll_wait 时，如果 rdlist 中已经有就绪的套接字就直接返回，否则将线程放到 eventpoll 中的等待队列里完成对线程的阻塞，当套接字再次收到数据，线程才会被再次唤醒。\n正因为 rdlist 的存在，eventpoll 就不需要对所有套接字进行遍历来收集准备就绪的套接字了。而且只需要判断 rdlist 的有无数据就可以完成对线程的阻塞和唤醒，epoll_ctl 也使用红黑树来维护要监视的套接字，所以综上，就是 epoll 更高效和快速的原因。\nPython 的 select.epoll 实现了对 epoll 的封装，刚才的示例使用 epoll 来改造：\nimport selectimport sockets = socket.socket(socket.AF_INET, socket.SOCK_STREAM)s.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEPORT, 1)s.setblocking(False)s.bind(('',9090))s.listen(5)print 'Server is listen on 0.0.0.0:9090'epoll = select.epoll()epoll.register(s.fileno(), select.EPOLLIN)fd_map = &#123;s.fileno(): s&#125;while True:    events = epoll.poll()    for fd, event in events:        sock = fd_map[fd]        if sock is s:            new_sock, addr = sock.accept()            new_sock.setblocking(False)            print 'New client : %s:%s' % addr            epoll.register(new_sock.fileno(), select.EPOLLIN | select.EPOLLET)            fd_map[new_sock.fileno()] = new_sock        elif event == select.EPOLLIN:            msg = sock.recv(4096)            if msg == '' or 'exit' in msg:                 sock.close()                epoll.unregister(fd)                del fd_map[fd]                print 'Have a client exit...'            else:                print 'Recv msg: %s' % msg                sock.send('From server: ' + msg)\n程序的执行效果与 select 版一致，就不再演示了。epoll 与 select 在 Python 上的用法还是有些区别的，select 可以直接传递套接字对象，而 epoll 只能传递套接字的文件描述符（sock.fileno()），所以我们需要手动维护一个文件描述符到套接字的映射。epoll.register(s.fileno(), select.EPOLLIN) 就是在一开始的时候，注册端口监听的套接字，之后每次调用 epoll.poll() 的时候，就不需要重新注册了。select.EPOLLIN 就是监听此套接字的可读事件，对应着 select.EPOLLOUT 为可写事件。在注册客户端套接字的时候多出来 select.EPOLLET 是表示将此套接字的监听模式设置为边缘触发模式，接下来的代码对数据的处理逻辑就与 select 版相同了。\n关于水平触发和边缘触发：水平触发是默认的情况，当有数据来到，通过 recv 函数读取数据时，如果一次性没有读完（例如接收缓冲区太小），则此套接字在下次执行 epoll.poll() 的时候，依然会被返回，直到此套接字缓冲区被读空为止。如果存在大量没有读完的套接字，水平触发模式效率是比较低的。边缘触发则相反，如果数据一次没读完，也只通知一次，直到下次有新的数据到来。所以如果采用边缘触发模式，应该循环读取数据，直到套接字缓存区被读完抛出异常为止。因此，边缘触发的示例中，从套接字缓冲区读取数据的部分应该改为如下形式：\nelif event == select.EPOLLIN:    msg = ''    while True:        try:            msg += sock.recv(4096)        except socket.error:            break\n到这里，希望大家都对这些概念都有了基本的理解。\n附录","categories":["Linux"],"tags":["python","linux"]},{"title":"高性能Web站点优化","url":"/2018/02/17/2018/%E9%AB%98%E6%80%A7%E8%83%BDWeb%E7%AB%99%E7%82%B9%E4%BC%98%E5%8C%96/","content":"简介\n根据《构建高性能Web站点(修订版)》一书 加上自己的一些经验和理解写出了这篇博客，并在附录中留下了自己画的脑图。强烈推荐对Web站点优化有兴趣的开发者、web运维、架构师等阅读这本书。书中几乎涵盖了Web站点性能优化的所有内容，包括数据的网络传输、服务器并发处理能力、动态网页缓存、动态网页静态化、应用层数据缓存、分布式缓存、Web服务器缓存、反向代理缓存、脚本解释速度、页面组件分离、浏览器本地缓存、浏览器并发请求、文件的分发、数据库I/O优化、数据库访问、数据库分布式设计、负载均衡、分布式文件系统、性能监控等。\n\n\n目录\n由前端到后端的方式讲解web架构中可以优化的地方\n\n客户端优化\n客户端指用户的浏览器 html页面最终由浏览器渲染为用户所看到的界面。常用的浏览器有Chrome、Firefox、IE/Edge、Opera等，通常使用更新版本的浏览器可以获得更高的性能和更好的用户体验。浏览器一般都向下兼容，而由于历史遗留问题 依旧有大量用户使用较旧版本的浏览器 比如IE8/IE9 甚至还有IE6的用户，各浏览器的兼容性问题 也成了前端开发者要面临的严峻问题。\n\n页面缓存\n使用HTTP协议的缓存协议 将资源服务器资源缓存到浏览器本地，用户只需和服务器请求需要更新的数据即可，这样大大提升了页面的加载速度 也降低了服务器的带宽使用。下面看看HTTP协议中有关缓存的内容\n\nLast-Modified浏览器向服务器发起资源请求，服务器响应用户资源的同时在响应的HTTP头部中添加Last-Modified字段，字段的值是这个资源的最后修改时间。比如Last-Modified: Thu, 15 Feb 2018 08:04:16 GMT\n当客户端再次向浏览器请求这个资源时 会在HTTP请求头添加If-Mondified-Since字段，字段的值也是这个资源的最后修改时间。这意味着浏览器向服务器问 我请求的这个资源在此之后还有更新吗？这时候浏览器会检查这个资源在此之后有更新，如果没有更新就会返回304 Not Mondified。并不会返回资源的实体内容，而是告诉浏览器没有更新 可以使用本地缓存的内容。\n如果服务器的资源发生改变了 则会重新向客户端发送更新后的资源，或者浏览器使用Ctrl + F5强制从服务器获取资源而无论资源是否有更新。\nETag服务端用一串编码对资源进行标记，这串编码就是ETag。ETag是服务器来生成的，生成的方式可以自定义，比如可以先计算哈希值 然后将这个哈希值作为ETag。\n如果一个文件的Etag没有变化 那这个文件的内容也没有变化。浏览器向服务器请求某个资源，服务器响应这个资源时在相应HTTP头部中添加ETag标签 比如：ETag: 50d0e11a7d7a4d0b5。\n当浏览器再次请求这个资源 会在HTTP请求头部添加If-None-Match: 50d0e11a7d7a4d0b5来询问服务器这个资源的Etag值还是这个吗？如果没有改变 服务器则响应304 Not Mondified。 \nETag是在HTTP/1.1中支持的缓存协商方法 主要是为了解决Last-Modified的一些缺点，比负载均衡环境中 很难保证各节点文件时间戳是完全相同的，这样客户端在不同的服务端轮询请求 无论内容是否改变 服务端都会发送全部的内容，这个时候只要使用ETag则可以避免这个问题。\n但是ETag的生成会比Last-Modified更消耗CPU资源，而Last-Modified则对HTTP/1.0也有支持，Nginx则会同时返回这两个字段。\nExpires\nHTTP缓存的存在就是为了消灭不必要的请求 而Last-Modified和ETag明显还是存在请求和响应的，接下来的这两个协议就是完全不会发送HTTP请求的。\n\nExpires告诉浏览器资源什么时候过期，在资源过期期间 浏览器会直接使用已缓存的资源而不会向服务器发起任何询问。\nExpires的值是允许资源缓存到什么时候的一个时间戳 比如：Expires: Thu, 15 Feb 2018 08:04:16 GMT，浏览器根据当前时间和资源的过期时间进行对比 如果资源没有过期的话则直接使用资源。如果资源过期 并且存在ETag或者Last-Modified的情况 浏览器则会根据这两个字段询问服务器。\nCache-Control如果浏览器的时间跟服务器的时间不一致 比如浏览器比服务器时间快了十分钟，那对于缓存五分钟的资源来说 浏览器总是认为资源是过期的，这时候Expires就无法正常工作了。\n幸运的是Cache-Control是用来补足Expires的不足，Cache-Control的格式是Cache-Control: max-age=&lt;second&gt;。max-age指定了缓存过期的相对本地时间 单位是秒。比如这个资源可以缓存3600秒，那么在3600秒内 浏览器都不会询问资源是否有更新了。\n使用Ctrl + F5的方式刷新页面 会忽略缓存协议 所有内容都直接向服务端重新请求而使用F5或者点击浏览器的刷新按钮，它允许浏览器在请求中附加必要的缓存协议，但是不允许直接使用本地缓存，也就是说 它能让Last-Modified或ETag生效 但是会让Expires或Cache-Control失效\n浏览器请求过程\n代码优化\n代码优化主要在提升用户体验上，这样即使用户网络质量不好的情况下 也经尽可能的提升用户体验。比如当网络质量不好 页面加载缓慢的情况下 可以提供一个loading的画面给用户 也可以显著的提升用户体验。\n\nHTML的渲染过程\n想知道一个页面是怎么出现在用户面前的 就需要了解浏览器是如何渲染html的\n\n浏览器在网络上获取到HTML的相应字节时就开始对HTML进行构建了，但是由于浏览器渲染的一些机制 遇到某些情况浏览器页面就被阻塞了，这也就是用户看到页面卡住而无法操作的的原因，这种情况是非常影响用户体验的。\n当遇到以下情况时 浏览器的UI界面会被阻塞\n\nHTML的数据流被阻塞在了网络中 或者网络质量太差导致数据包接收过慢\n未加载完的脚本或者脚本执行时间过长\n遇到了script节点 但是此时还有未加载完的样式文件\n\n将css样式文件放到HTML文档中head标签内，js脚本文件最好放到body标签中的最下面，这样可以一定程度的避免js脚本的执行过程中导致浏览器UI阻塞了。\n懒加载技术\n大家在查看百度图片的时候 会发现不断的滚动页面 就会有更多的图片加载出来，这个就是图片的懒加载技术。\n\n当业务查询出的数据量特别大时，如果全部传输给浏览器 不仅对浏览器 对服务器也会照成很大的压力。而采用按需加载的方式，用户选择某个单元的时候 再加载这个单元需要的数据，这样既节约了系统相应时间，还提升了系统性能，更提高了用户体验 所以懒加载技术是非常有价值的。\n懒加载技术也同样适用于Vue, Angular2等SPA框架(single page web application)。通过webpack打包的SPA应用是非常大的，浏览器第一次加载的时候可能会非常耗时，所以可以将不同路由对应的组件分割成不同的代码块，然后当路由被访问的时候才加载对应组件，这样就更加高效了。\n使用Ajax交换数据大部分的HTML页面渲染过程是在服务端完成的，但是通过Ajax技术可以在浏览器页面加载之后异步向服务器发送HTTP请求，获取到动态的数据后由客户端的JavaScript来将数据渲染到HTML页面中。这样后端只提供一套Web接口，数据的渲染部分由前端完成，后端不仅拥有了更高的通用性，也省去了对HTML页面渲染的CPU开销。\n加载动画当不得不存在一些耗时的页面时，使用加载动画 增加页面的趣味性也不失是一个好方法。可以在需要用户等待的页面时提供一个加载动画，然后数据准备完毕后移除动画。有了加载动画的存在 可以降低用户看到一片空白的等待页面由于不耐烦而关闭页面的概率。\n传输优化\nHTML文档在到达浏览器这段中可以有哪些优化呢\n\n减少数据传输量浏览器减少http请求在页面中引用一个js文件和将js代码写入到html文档中 对于页面渲染结果来说是相同的，但是对于页面中引用js文件 浏览器需要向后端发送两次HTTP请求，而HTTP的请求和响应头部数据也是数据流的一部分，如果能减少HTTP的请求数量 也可以提升一部分浏览器渲染速度。\n但是将css和js甚至图片都写入到一个html文档 显然是非常降低文档的可读性的，对日后的维护等影响也比较大。但是可以使用webpack等打包工具，将前端页面写完后 利用webpack打包成单个或者多个文件，浏览器只需要加载打包后的文件就可以了。而且webpack在打包过程中还会对代码进行压缩 去掉代码中没必要的空格、换行符，将代码中的变量名用a, b, c等简短的变量代替，打包后的代码大小也会大大减少。\n启用Keep-Alive普通的一次HTTP请求 在服务器响应后就会关闭这次的TCP连接，下一个HTTP请求会继续开启和关闭一个TCP连接。如果能重用这个TCP连接就能省掉TCP连接和关闭的开销了，而Keep-Alive就是为此而生的。\n只需要在HTTP头部加入Connection: Keep-Alive就可以启用Keep-Alive了，目前浏览器都支持HTTP/1.1协议，在HTTP/1.1协议中Keep-Alive是默认开启的。\ngzip压缩数据文本类型的数据拥有很大的压缩比，几乎可以达到80%以上 也就是说一个100KB的文档，通过gzip压缩后的大小可能只有20KB左右，在提升网络数据传输上效果是非常显著的。\ngzip压缩需要web服务器开启压缩功能，浏览器也需要在请求头部设置接受gzip压缩的字段：Accept-Encoding: gzip, deflate，表明浏览器支持gzip和deflate这两种压缩方式。\n服务器接受到请求后判断浏览器是否支持压缩 如果支持就将数据压缩后传输。浏览器接受到数据后判断是否是已压缩的，如果是压缩的就先解压。\n需要注意的是 有些数据类型即使压缩也不会有很大的压缩比的 比如大部分的图片和视频文件，对它们进行压缩不仅浪费宝贵的CPU资源 也获得不了很大的实际效果。所以需要在服务器配置排除掉对这些数据的压缩。\n减少Cookie的大小由于HTTP是无状态的协议，服务器需要知道用户的身份就将用户数据放入到Cookie中，Cookie也是HTTP请求头部的一个字段，Cookie的值的大小浏览器限制不得超过4KB。\n浏览器在对某个域发起HTTP请求时，如果存在这个域的Cookie数据，那么就会携带上Cookie进行请求。如果Cookie过大的话 显然也会降低数据的传输效率，而且Cookie是不安全的数据存放方式 除非必须 应该尽量避免掉 换用更安全的Session技术。\nCDN加速CDN的全称是Content Delivery Network，即内容分发网络。CDN系统将数据分发到各CDN节点(其实就是缓存服务器)，当用户访问时智能的选择离用户最近的CND节点。\nCND对用户访问体验可以带来很大的提升，但是也要面临数据更新同步到各CDN节点再到用户浏览器中有一定的延迟问题。\n选择更合适的宽带总所周知联通的线路和电信的线路互通性并不是太好，BGP机房就是服务器租用商通过技术的手段，实现不同运营商能共同访问一个IP，并且不同运营商之间都能达到最快的接入速度的相关网络技术。BGP机房在一定程度上解决了各用户南北互通的问题，提高了用户的访问速度。\n服务端优化\n服务端优化指服务端的负载均衡器、Web静态资源服务器、真实后端服务器等程序的优化\n\n应用服务器\n这里将Web静态资源服务器和后端服务器都作为应用服务器\n\n程序多进程使用多进程来提升服务器的并发能力和提高CPU的利用率。在Linux中和客户端每建立的一个TCP连接都作为一个进程打开的文件描述符，Linux对单个进程默认限制最大打开1024个文件描述符，能处理的Socket文件描述符就更少了。\n除了提升Linux对最大文件描述符的限制外 通过多进程同时对外提供服务显然是更合适的方法，可以更高效的利用多核处理器的处理能力。\n在Linux上使用ulimit -n可以查看当前最大文件描述符限制，使用ulimit -n 4096可以将最大文件描述符设置为4096。可以通过检索/proc/&lt;PID&gt;/limits文件查看正在运行的进程的最大文件描述符限制\nNginx中 修改worker_processes的值可以配置Nginx启动多少个worker进程 一般建立配置为auto。Apache的prefork模型，就是采用大量的进程来处理用户请求，当用户接入时，fork一个进程去处理。这样的好处是每个用户的请求相对隔离，不会因为一个用户请求处理进程崩溃而影响到其他用户的请求。但是在高并发下 内存的大量消耗和频繁的上下文切换可能成为瓶颈。php-fpm的fastcgi中 预先初始化多个cgi进程等待web服务器的动态页面请求，这样可以减少进程创建和销毁的开销。\nLinux还有一个OOM机制(Out Of Memory killer)和进程的优先级机制(nice值)。\nOOM机制会监控那些占用内存过大，尤其是瞬间很快消耗大量内存的进程，为了防止内存耗尽而内核会把该进程杀掉。为了防止重要的进程触发OOM机制而被杀死 可以设置进程/proc/&lt;PID&gt;/oom_adj文件的值为-17来临时关闭对这个进程的监控。但是最好还是不要对这些耗内存大的程序使用 否则照成sshd等重要的进程被杀死就得不偿失了。\n优先级呢通过配置进程的nice值来更改进程占用CPU的百分比，nice值得范围是-20到+19，值越低 程序可以获取更多的CPU执行时间。使用nice -n -19 nginx 可以将Nginx进程的nice值设置为-19。Nginx派生的子进程也会继承这个nice值。对于已经存在的进程可以通过renice -n 10 &lt;PID&gt;将该进程的nice值设置为10，但是并不会对该进程的子进程生效。\n多线程和多进程不同的是当客户建立连接后，派生一个线程去处理用户请求。线程的创建和销毁开销是低于进程的，内存使用也会减少一些。比如Apache的worker模型 同时使用了多进程和多线程，所有的线程共享同一个进程内存空间，如果一个线程崩溃 可能会影响到整个进程。\n协程大家可能对进程和线程比较熟悉 而对协程比较陌生。原生支持协程的语言并不多 但是协程非常适合在高并发环境下使用。\n协程没有抢占式调度，由代码内主动放弃执行权切换到其他协程执行 因此也不存在上下文切换的开销。协程始终是运行在单线程内 所以也不存在变量共享的锁竞争。\nGo语言对协程有良好的支持 所以非常适合高并发的服务端网络编程，Python语言yield关键字提供了对协程的基本支持，Gevent、Tornado等库都对协程有良好的支持。Python3.5之后引入async/await关键字对协程则有了非常好的支持。\n优化系统调用使用strace命令对Nginx的worker进程进行系统调用跟踪，可以分析出用户一次请求共进行了多少次系统调用。比如如果存在日志记录，那一定会存在每处理一条用户请求 都会向日志写入一条记录。每次对日志进行一次write操作 都是一次系统调用，如果关闭日志记录功能 就可以省掉一次日志写入的系统调用。但是对于Web服务器 日志存在的价值显然是高于能节约的响应时间。\n使用strace -c -p &lt;PID&gt;可以对已启动的进程进行系统调用统计，使用Ctrl+C结束统计\nroot@ubuntu:~# strace -c -p 18803\nstrace: Process 18803 detached\n% time     seconds  usecs/call     calls    errors syscall\n------ ----------- ----------- --------- --------- ----------------\n100.00    0.000200          50         4           stat\n0.00    0.000000           0         1           write\n0.00    0.000000           0         1           open\n0.00    0.000000           0         2           close\n0.00    0.000000           0         1           fstat\n0.00    0.000000           0         1           writev\n0.00    0.000000           0         1           sendfile\n0.00    0.000000           0         2           recvfrom\n0.00    0.000000           0         2           setsockopt\n0.00    0.000000           0         2           epoll_wait\n0.00    0.000000           0         1           epoll_ctl\n0.00    0.000000           0         1           accept4\n------ ----------- ----------- --------- --------- ----------------\n100.00    0.000200                    19           total\n这里是Nginx的worker进行一次用户请求处理的系统调用统计，可以看到Nginx使用sendfile调用向用户发送数据。使用sendfile等更高效的大文件传输方式，尽量将操作在内核中完成，减少数据在内核态和用户态的复制。\n使用更高效的系统调用方式和减少不必要的系统调用 就是对系统调用的优化了。\n尽量避免锁竞争只要涉及到多进程或多线程的变量共享问题 就会涉及到锁竞争了。只要使用了锁，多进程或多线程就变成了线性的等待锁资源，对于高并发状态 锁竞争会严重降低系统性能。所以在设计后端的时候 开发者需要尽量避免变量共享问题。\n更高效的IO模型Nginx的高并发能力源自它采用了多路IO就绪通知机制，常见的机制有select, poll, epoll等 其中Linux下性能最好的是epoll，跨平台的是select。\n程序代码跟踪分析很多语言都有代码性能分析工具，利用这些工具可以分析出一段代码运行各部分的耗时。通过优化这些耗时的代码 可以更好的提升性能和对用户的响应。\n可以使用xhprof对PHP的程序进行性能分析，使用cProfile对Python的代码进行性能分析。\n缓存\n这个缓存是在服务端的缓存\n\n字节码缓存PHP、Python等动态语言的执行首先需要将源代码编译为字节码，比如PHP的字节码是在Zend虚拟机中运行，Python的字节码是在Python虚拟机中运行。\n这些脚本在执行过程中会先将源代码编译为字节码，而直接将字节码缓存起来就可以省掉编译的过程了。比如PHP的XCache。而Python可以通过python -m compileall &lt;PATH&gt;将单个py文件或者目录中全部的py文件编译为.pyc文件（Python3之后是生成在__pycache__目录中）。\n页面缓存\n后端生成的html页面 也可以先缓存起来 这样就不用重新生成了。\n\n页面缓存又分为三种\n\n静态内容缓存\n\n在Web服务器上将html, css, js等静态页面缓存到内存中或者Memcached等分布式缓存中。总所周知内存的速度是非常快的，对比从内存中取数据，从磁盘上取数据可以说是非常满的了。\n如果存在代理服务器，在代理服务器上完成缓存可以更快的返回给用户 这样都不需要经过后端程序了。\n\n动态内容缓存\n\n动态页面的渲染后端可能需要从数据库中取数据 然后将数据渲染到html模板中 最后生成动态页面。对于一些时效性要求不高的页面，可以选择将页面缓存起来，提供一个缓存过期时间，在未过期之前就直接向用户返回缓存的页面。这样可以有效的减少对数据库的读写和CPU的页面渲染。\n动态页面缓存也最好配置在代理服务器上。Redis的键值过期机制也非常适合做这种缓存服务器。\n\n局部无缓存\n\n如果一个页面中只有一部分的数据是需要更新的 其他部分的数据都不变 可以采用这种缓存方式。\n比如采用SSI技术 只更新页面中动态的内容。但是需要服务器读取shtml模板页面，匹配和修改更新的内容，需要较大的CPU开销。\n数据库读写缓存\n如果能将数据库的查询结果也缓存起来 就可以避免某些对数据库的查询了。\n\n读缓存\n可以将select语句的查询结果缓存到缓存服务器中，当再次遇到相同的sql查询语句时就可以直接从缓存服务器获取结果而不必再次查询数据库了。但是需要注意缓存的生命周期，如果数据已经更新 而缓存还在生效 就会导致页面显示更新不及时。\n写缓存\n将频繁的数据库写入操作尝试合并为一次写入，比如累计用户登陆次数，先将数据存入memcached中，累计登陆10次后写入数据库中。但是这样想要获取准确的用户登陆次数信息 就要同时获取数据库记录而缓存服务器记录数的相加结果了，而且还要承受缓存服务器意外宕机导致的数据丢失问题。\n数据共享后端服务器群中的数据共享问题，比如用户上传了头像或者照片，因为负载均衡的原因只上传到了一台服务器上，这样下次用户换个设备登陆的时候可能就找不到上传的图片了。这个时候就需要让所有服务器共享一个数据存储。\n数据可以通过rsync或者scp进行同步 但是服务器如果比较多 而站点刚好是用户上传数据比较频繁的类型，这两种方式显然就不适合了。还可以采用NFS或者Samba共享等方式，有条件的话可以使用NAS网络存储，或者使用开源的分布式文件系统，比如FastDFS，HDFS等。\nWeb组件分离\n随着业务的扩展和服务器规模的扩大，就需要对业务组件进行拆分了，将不同的组件部署在不同的服务器上。\n\n不同组件使用不同的域名比如百度知道的域名为zhidao.baidu.com，而百度知道中的图片存放在域名为gss0.bdstatic.com的服务器上。不同的域名可以指定不同的IP，不同的业务便可以分散到不同的服务器上了。\n另一个好处是可以避开浏览器对同一个域名的并发数限制，将资源分散到不同的域名也增快了页面最终呈现的速度。\n数据库连接优化大多数的后端程序都有数据库连接池的概念，由数据库连接池来维护与数据库的连接，程序只用从数据库连接池中获取和释放连接就可以。程序对数据库连接池的获取和释放连接是非常廉价的，而数据库连接池会保证池内拥有一定量可用的数据库连接。\n反向代理和负载均衡\n当单台主机无法承受业务访问量的时候 就需要多台服务器同时工作了。而如何将用户请求均衡的分发到各后端服务器 就是负载均衡器的工作了，一般负载均衡器也是反向代理服务器。\n\n动静分离将网站的静态资源和动态页面分离，一般PHP等后端服务并不擅长处理静态资源，这个时候就需要使用专业的静态资源服务器来处理网站的静态资源了。\n比如以高并发著称的Nginx就非常适合做这件事情，由Nginx处理静态资源，动态内容则转发到后端的应用服务器处理。Nginx在这里也就是反向代理服务器了。\n负载均衡通常由负载均衡软件或者专业的负载均衡设备来将用户请求分发到不同的后端服务器。\n负载均衡器通常会根据一些算法来对用户请求进行分发，比如常用的轮询、加权轮询、ip_hash等。\n负载均衡器往往还会对后端服务器进行健康检查，剔除意外宕机的后端服务器 以免某个用户刚好访问到宕机的服务器。同时负载均衡器上还要注意用户的登陆状态保持功能。\n还可以在负载均衡器上配置ssl 这样就可以免去配置所有的后端服务器而获得一个https的网站了。\n负载均衡的方式Nginx或者HAProxy四层负载均衡只根据传输层协议内容进行转发，而不关心传输层以上的数据。七层负载均衡则根据应用层协议内容进行转发，可以对应用层协议进行更精确的控制，比如可以判断用户的访问设备，然后根据设备发送不同的页面。\n而Nginx和HAProxy对则四层负载均衡和七层负载均衡都有较好的支持。\nHTTP重定向通过返回302状态码将用户请求按照算法重定向到其他的服务器域名。\n优点是比较简单，容易实现，负载均衡器只做请求分发 所以不会是IO瓶颈。缺点是浏览器需要两次请求服务器才能完成一次访问，性能略差，302状态码还有可能降低搜索引擎的排名。\nDNS简单轮询同一个域名添加多条A记录，用户进行DNS查询时依照轮询算法返回某一个服务器的IP地址。\n优点是将负载均衡工作交给了DNS，省去维护负载均衡器的麻烦，同时DNS支持基于地理位置的解析，可以返回给用户最近的服务器地址。缺点：DNS是多级解析，每一级都可能有缓存，修改了DNS可能不会立即生效，控制权在运营商手里。实际上大型网站经常利用DNS作为第一级的负载均衡。\nLVS负载均衡器\nLVS负载均衡器是所有软件负载均衡器中性能最高的了 甚至比肩专业的负载均衡器设备。这里就单独拿出来介绍下LVS的三种负载方式。\n\nLVS-NAT\nNAT模式 负载均衡工作在网络层 修改用户数据包的目标地址并转发到相应的后端服务器，后端服务器的默认网关应该指向NAT主机，LVS服务器收到回应后再将源地址改为自己的地址。但是此模式中 负载均衡器对所有的流量进行转发 所以随着后端服务器的增加，负载均衡器容易成为流量瓶颈。\nLVS-DR\n直接路由模式 负载均衡工作在数据链路层，通过修改数据包中的目标MAC地址，将数据包转发到后端服务器。最后数据直接由选中的后端服务器返回给用户，所以后端服务器也必须接入互联网。这时候LVS服务器不会是流量的瓶颈了 但是所有的后端服务器都需要有公网IP，而且必须和负载均衡器在同一个交换机上。\nLVS-TUN\nIP隧道模式 和直接路由工作原理相似，可以跨机房，服务器之间通过IP隧道连接 拥有直接路由模式模式的优点。但是IP隧道实际上是对数据包的又一层封装，IP隧道数据包的封装和解包都会有一定的开销。\n硬件升级\n可能的情况下 升级硬件设备对性能的提升是非常巨大的。当然在升级硬件的时候也要考虑主板是否支持这些硬件。\n\nCPU在选择CPU一般会考虑CPU的主频、核心数、制作工艺以及支持的指令集。\n一般来说 CPU的主频越高 性能越强 但是功耗也会越高。核心数越多表示可以同时运行的进程越多，Intel的超线程技术 可以将一个物理核心数模拟为两个逻辑核心数，总性能大约可以提升20%左右。而随着CPU制作工艺的提升 芯片的体积可以越来越小 功耗也会更小。\n内存选购内存一般考虑类型和主频。现在内存已经进入了DDR4时代 但是服务器硬件更新迭代的比较慢 大部分服务器依旧使用DDR3内存，DDR4有着比DDR3更高的主频，更快的速度，和更低的功耗\n硬盘机械硬盘机械硬盘的单位容量更为廉价，也是服务器采用最多的存储方式。但是机械硬盘属于损耗品 大约工作5年左右就会出现故障，一般企业会选择磁盘阵列技术来对硬盘的数据进行容错和提升性能。服务器硬盘的转速多为10000rpm或者15000rpm 转速越高 硬盘的读写性能越强。\n下面看看几种常见的磁盘阵列方式\nRaid 1: 至少需要两块硬盘 其中一块作为数据备份，读取性能高，且允许故障一块硬盘，但是空间利用率只有50%。\nRaid 5: 性能 数据安全 和存储成本兼顾的方案 至少三块硬盘的话 允许故障一块，空间利用率为硬盘总数减1，因为有差不多一块盘的空间用于存储奇偶校验信息，并散列存储在所有的硬盘上。\nRaid 10: 集合Raid0的高性能读写和Raid1的安全 至少需要4块硬盘 最多允许坏两块硬盘 空间利用率也只有50%。\n固态硬盘企业级固态硬盘的成本非常，但是性能也是非常强的。固态硬盘理论上支持无限次的读取，但是对擦写是由次数限制的。程序的运行很大一部分时间耗在了等待IO上，而使用固态硬盘可以大大提升文件的读写速度，程序的执行效率提升可以很明显的增强。通过对比使用固态硬盘的机器和机械硬盘的机器开机速度可以很明显的对比出固态硬盘对系统流畅度的提升。\n几种常见的固态硬盘使用的闪存芯片\nTLC闪存: 速度慢 寿命短 约500次擦写寿命 稳定性比较差 但是成本低。MLC闪存: 速度一般 寿命一般 3千到1万次擦写寿命 稳定性适中 成本适中。SLC闪存: 速度快 寿命长 10万次擦写寿命 稳定性强 企业级闪存 但是成本非常高。\n网卡使用千兆网卡，并使用多网卡做bond，数据链路层的负载均衡，提高网卡可用性和最大带宽。\n数据库优化\n数据库可以说是Web站点的最后一部分了，后端程序执行很可能很大一部分时间是等待数据库返回需要的数据，提高数据库的查询速度可以很明显的提升Web站点性能。\n\n数据分区\n当随着数据的增多 单台数据库实例已经无法承受站点日益增多的数据 就需要考虑对数据进行分区了。\n\n垂直分区如果数据库写操作频繁 从库则会将大量时间花在复制上 照成性能浪费。这时候就需要将写操作分散到不同的服务器上。最简单的就是将无关的库分散到不同的服务器上，然后不同的数据写入到不同的服务器上。为了方便日后数据库的垂直分区，设计数据库表结构的时候应该尽量减少外键约束和联合查询。\n水平分区当单表的数据了日益增多，也达到了写操作的极限，垂直分区就不适用了。这个时候就可以通过特定的算法将同一数据表的数据写入到不同的数据库中，这就是水平分区了。\n比如说将id为奇数的数据放入数据库A，为偶数的放入数据库B。如果需要分散到更多的数据库中，可以对id进行取余计算。需要注意的是 程序也需要知道相应的算法而从正确的数据库取数据。\n也可以使用分区反向代理，Spock Proxy可以帮助应用程序实现水平分区的访问调度，我们也不应该在程序中维护分区对应关系。\n集群和读写分离主从复制多台数据库之间数据同步，查询可以从多台服务器上进行 减少单台服务器的压力。\n读写分离使用数据库反向代理 比如Mysql Proxy对后端数据库进行读写分离和负载平衡。读写分离的原理是让主数据库处理事务性查询，让从库处理数据查询，通过主从复制的方式将主库的数据更新到从库。\n性能优化\n对数据库软件的性能调优\n\n选择合适的存储引擎对于MySQL数据库 常用的数据引擎有MyISAM和InnoDB，随着Innodb的不断更新改进，从MySQL5.5已经成为了默认存储引擎。\nInnoDB: 行级锁 共享表空间 支持事务和外键 写性能比较好 支持热备份。MyISAM: 表级锁 独立表空间 不支持事务和外键 读性能比较好 不支持热备份。\n所以如果网站的写操作比较多适合选择InnoDB，读操作比较多的话适合选择MyISAM。\nInnodb缓存池大小InnoDB会在内存中维护一个缓冲池，用于缓存数据和索引。当用户执行查询操作时 如果缓存池中有数据会直接返回结果，否则会从磁盘读取数据，然后放到缓冲池中。配置一个合理的缓存池大小 可以将尽量多的数据缓存到内存中。如果MySQL数据库独占单个服务器，可以将缓存池的大小配置为物理内存的80%。\n建立索引对经常作为查询条件的字段建立索引，这样查询的时候就不需要对表数据进行完整的扫描。但是索引有时候会比整体数据还要大。\n减少表锁定等待MyISAM的UPDATE操作会排斥对当前表的所有其他操作，只有更新结束后才可以继续查询。InnoDB支持行级锁，在写操作比较多的情况下性能会好于MyISAM。\n使用查询缓存将select查询的结果缓存在内存中 当下次遇到相同的select语句将直接。默认情况下 mysql是没有开启查询缓存的，修改配置文件query_cache项开启。\n但是需要注意，如果对这个表的数据进行了插入或更改 MySQL将会清除这个表所有的缓存。在对表读写频繁的情况下 查询缓存可能会添乱。但是如果有大量的相同或相似的查询，而且很少修改表中的数据就非常适合了。\n缓存线程池在配置文件中配置thread_cache_size，让MySQL创建的线程可以被重复利用，减少线程的创建和销毁的开销。\n表结构设计和查询语句优化设计合理的表结构和编写高效的查询语句，将相关的数据尽量不要使用多表查询，联合查询等方式。\n使用NoSQL放弃关系型数据库，根据项目选用更合适的非关系型数据库吧。。。\n附录\nPNG版脑图\nSVG版脑图\n\n","categories":["Web优化"],"tags":["Web优化"]},{"title":"LXC Linux系统容器","url":"/2019/09/23/2019/LXC%20Linux%E7%B3%BB%E7%BB%9F%E5%AE%B9%E5%99%A8/","content":"简介\nLXC 是 Linux Container 的简写。Linux Container 是一种内核虚拟化技术，可以提供轻量级的虚拟化以便隔离进程和资源。大名鼎鼎的 Docker 在早期版本使用的底层容器引擎便是 LXC，不过 Docker 的目标是创建应用级容器，而 LXC 的目标是创建系统级容器，所以使用 LXC 更容易获得接近虚拟机的体验。\n\n\n环境LXC 也是利用了 Linux 内核的 cgroup 和 namespace 特性来实现容器的资源隔离，因此也对 Linux 的内核版本有较高的要求。这里使用 Ubuntu 18.04 Server 作为容器的宿主机，内核版本为 4.15.0-58-generic\n教程安装安装命令行工具安装非常简单，在 Ubuntu 上使用 apt-get install lxc 即可。lxc 包里包含了所有的命令，之后就可以看到系统多了很多 lxc- 开头的命令。\nroot@localhost:~# lxc-\nlxc-attach         lxc-checkpoint     lxc-create         lxc-freeze         lxc-snapshot       lxc-unfreeze       lxc-wait\nlxc-autostart      lxc-config         lxc-destroy        lxc-info           lxc-start          lxc-unshare        \nlxc-cgroup         lxc-console        lxc-device         lxc-ls             lxc-stop           lxc-update-config  \nlxc-checkconfig    lxc-copy           lxc-execute        lxc-monitor        lxc-top            lxc-usernsexec\nLXC 安装成功后会自动创建一个叫 lxcbr0 的网桥，如下：\nlxcbr0: flags=4099&lt;UP,BROADCAST,MULTICAST&gt;  mtu 1500\n        inet 10.0.2.1  netmask 255.255.255.0  broadcast 0.0.0.0\n        ether 00:16:3e:00:00:00  txqueuelen 1000  (Ethernet)\n        RX packets 0  bytes 0 (0.0 B)\n        RX errors 0  dropped 0  overruns 0  frame 0\n        TX packets 0  bytes 0 (0.0 B)\n        TX errors 0  dropped 0 overruns 0  carrier 0  collisions 0\n之后运行的容器的虚拟网卡都会接入到这个网桥了。LXC 还为这个网桥配置了一个 DHCP 服务，配置文件在 /etc/dnsmasq.d/lxc。这样容器支持 DHCP 的话就可以直接获取到可用的 IP 地址了。\n快速开始创建容器lxc 安装后 在 /usr/share/lxc/templates 为我们提供了几个容器安装的模板： \n\nlxc-download：通过网络获取容器镜像来创建容器。\nlxc-local：通过本地已有的镜像来创建容器。\nlxc-busybox：使用 busybox 来创建最基本的容器。\nlxc-oci：通过 oci 标准的镜像来创建容器。\n\n创建容器通过使用 lxc-create 命令来完成，此命令会调用指定的模板来完成容器的创建，我们先通过 lxc-busybox 这个模板创建一个最简单的容器：\nlxc-create -t busybox -n busybox\nlxc-create 命令通过 -t 参数指定要使用的模板，-n 参数指定创建的容器的名称。之后使用 lxc-ls 可以看到所有已经创建的容器，所有的容器默认都保存在 /var/lib/lxc 中。\nroot@localhost:~# ls /var/lib/lxc/\nbusybox\nroot@localhost:~# ls /var/lib/lxc/busybox/\nconfig  rootfs\nroot@localhost:~# ls /var/lib/lxc/busybox/rootfs/\nbin      dev  home  lib64  null  ram0  sbin     sys  tty   tty1  urandom  var\nconsole  etc  lib   mnt    proc  root  selinux  tmp  tty0  tty5  usr      zero\nroot@localhost:~#\n每个容器对应 /var/lib/lxc 下的每个目录，目录内存放着这个容器的配置文件和根文件系统。lxc-create 还可以指定使用 lvm、Ceph RBD、zfs、loop 文件系统来作为容器的根目录，默认使用的是 dir 的方式与宿主机共享文件系统。目录的方式胜在简单，但是却无法支持其他文件系统带来的高级特性，比如磁盘配额、快照等。\n启动容器使用 lxc-info 命令可以查看指定容器的状态，使用 lxc-start 来启动容器：\nroot@localhost:~# lxc-info busybox\nName:           busybox\nState:          STOPPED\nroot@localhost:~# lxc-start busybox\nroot@localhost:~# lxc-info busybox\nName:           busybox\nState:          RUNNING\nPID:            5288\nCPU use:        0.01 seconds\nBlkIO use:      0 bytes\nMemory use:     1.77 MiB\nKMem use:       1.40 MiB\nLink:           veth7F3KFW\nTX bytes:      1.51 KiB\nRX bytes:      1.87 KiB\nTotal bytes:   3.37 KiB\nroot@localhost:~#\n容器启动后的第一个进程的 ID 是 5288，查看此进程的父进程可以看到是一个内核进程：\nroot@localhost:~# cat /proc/5288/status |grep PPid\nPPid:    5281\nroot@localhost:~# ps 5281\nPID TTY      STAT   TIME COMMAND\n5281 ?        Ss     0:00 [lxc monitor] /var/lib/lxc busybox\nroot@localhost:~# \n连接到容器容器启动后，我们可以通过 lxc-attach 命令来运行容器内的命令，默认会运行容器内的 shell 来供我们操作容器。\nroot@localhost:~# lxc-attach busybox \n\nBusyBox v1.27.2 (Ubuntu 1:1.27.2-2ubuntu3.2) built-in shell (ash)\nEnter &apos;help&apos; for a list of built-in commands.\n\n~ # ifconfig\neth0      Link encap:Ethernet  HWaddr 00:16:3E:88:E3:4A  \n        inet6 addr: fe80::216:3eff:fe88:e34a/64 Scope:Link\n        UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n        RX packets:25 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:15 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:1000 \n        RX bytes:2526 (2.4 KiB)  TX bytes:1962 (1.9 KiB)\n\nlo        Link encap:Local Loopback  \n        inet addr:127.0.0.1  Mask:255.0.0.0\n        inet6 addr: ::1/128 Scope:Host\n        UP LOOPBACK RUNNING  MTU:65536  Metric:1\n        RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:1000 \n        RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\n~ # \n进入容器后就可以执行容器内的所有命令了，可以看到，容器默认分配了一个 eth0 的网卡，但是并没有获取到 IP 地址。LXC 容器会尽量让一个容器就像是一个虚拟机一样，因此在容器内可以自主的配置 IP，甚至使用 reboot 命令重启容器都可以。接下来给容器分配一个 IP 地址，然后看看是否可以与主机互访。\n容器内操作：\n~ # ifconfig eth0 10.0.2.100\n~ # ip ro add default via 10.0.2.1\n~ # ping 180.76.76.76\nPING 180.76.76.76 (180.76.76.76): 56 data bytes\n64 bytes from 180.76.76.76: seq=0 ttl=127 time=4.649 ms\n64 bytes from 180.76.76.76: seq=1 ttl=127 time=7.460 ms\n64 bytes from 180.76.76.76: seq=2 ttl=127 time=4.998 ms\n64 bytes from 180.76.76.76: seq=3 ttl=127 time=4.852 ms\n\n--- 180.76.76.76 ping statistics ---\n4 packets transmitted, 4 packets received, 0% packet loss\nround-trip min/avg/max = 4.649/5.489/7.460 ms\n~ # \n需要注意的是，给容器分配的 IP 地址要和宿主机的 lxcbr0 网桥的地址在同一网段，并且容器内将默认网关设置为宿主机网桥的 IP 即可实现容器内联网。接着执行 telnetd 命令允许在外部通过 telnet 程序远程连接到此容器。\n宿主机已经可以 ping 通容器：\nroot@localhost:~# ping -c 4 10.0.2.100\nPING 10.0.2.100 (10.0.2.100) 56(84) bytes of data.\n64 bytes from 10.0.2.100: icmp_seq=1 ttl=64 time=0.046 ms\n64 bytes from 10.0.2.100: icmp_seq=2 ttl=64 time=0.058 ms\n64 bytes from 10.0.2.100: icmp_seq=3 ttl=64 time=0.047 ms\n64 bytes from 10.0.2.100: icmp_seq=4 ttl=64 time=0.045 ms\n\n--- 10.0.2.100 ping statistics ---\n4 packets transmitted, 4 received, 0% packet loss, time 3070ms\nrtt min/avg/max/mdev = 0.045/0.049/0.058/0.005 ms\nroot@localhost:~#\n除了使用 lxc-attach 还可以使用 lxc-console 来登陆容器，此命令会连接到容器内 Linux 的控制台，所以必须提供必要的用户名和密码才可以登陆进容器内部。\n更改容器内密码：\n~ # passwd\npasswd: no record of root in /etc/shadow, using /etc/passwd\nChanging password for root\nNew password: \nBad password: too weak\nRetype password: \npasswd: password for root changed by root\n~ # \n宿主机使用 lxc-console 来登陆容器：\nroot@localhost:~# lxc-console busybox\n\nConnected to tty 1\nType &lt;Ctrl+a q&gt; to exit the console, &lt;Ctrl+a Ctrl+a&gt; to enter Ctrl+a itself\n\nbusybox login: root\nPassword: \n\nBusyBox v1.27.2 (Ubuntu 1:1.27.2-2ubuntu3.2) built-in shell (ash)\nEnter &apos;help&apos; for a list of built-in commands.\n\n~ # \n可以看到，成功输入用户名和密码后也进入了容器。\n停止并删除容器使用 lxc-stop 来停止容器，使用 lxc-destroy 来彻底删除容器。\nroot@localhost:~# lxc-stop busybox\nroot@localhost:~# lxc-destroy busybox\nlxc-destroy: busybox: tools/lxc_destroy.c: main: 271 Destroyed container busybox\nroot@localhost:~#\n需要注意的是，如果想直接删除一个正在运行的容器，可以使用 lxc-destroy -f 来强制删除。\n容器管理\n在快速开始一章中，已经体验了 LXC 的基本用法，下面的章节将会讲解如何对容器进行更高级的管理，让容器运行的更像是虚拟机一样。\n\n创建容器容器的创建分两种，一种是由 root 用户创建的特权容器，一种是由普通用户创建的非特权容器。非特权容器有一些限制，比如无法创建设备节点等。而在特权模式下，让 Docker 运行在 LXC 中，甚至 LXC 嵌套 LXC 运行都成了可能。下面所有的例子创建的都是特权容器。\n获取镜像模板busybox 只提供了一个极小的更适合用于嵌入式 Linux 的基本文件系统，下面就看看如何使用 LXC 运行 CentOS、Ubuntu 等完整的 Linux 发行版吧！\n例如，想要运行一个基于 CentOS 发行版的容器，首先需要下载 CentOS 的容器镜像模板，之后需要运行容器时，会自动从下载好的模板解压出容器的根文件系统到指定的 lvm、zfs、loop 或者 dir 等存储设备，并启动容器。\nLXC 提供了 lxc-download 模板来通过网络获取容器镜像：\nroot@localhost:~# lxc-create -t download -n ubuntu-1604\nSetting up the GPG keyring\nDownloading the image index\n---\nDIST    RELEASE    ARCH    VARIANT    BUILD\n---\nalpine    3.10    amd64    default    20190923_13:00\nalpine    3.10    arm64    default    20190923_13:00\n.\n.\n.\n---\n\nDistribution: \nubuntu\nRelease: \nxenial\nArchitecture: \namd64\n\nDownloading the image index\nDownloading the rootfs\nDownloading the metadata\nThe image cache is now ready\nUnpacking the rootfs\n\n---\nYou just created an Ubuntu xenial amd64 (20190923_07:42) container.\n\nTo enable SSH, run: apt install openssh-server\nNo default root or user password are set by LXC.\n命令执行后会列出所有镜像的索引，接着会让你输入要下载的发行版、版本号、架构信息。经过片刻等待，Ubuntu 16.04 的容器就创建成功了。所有下载的镜像都缓存在 /var/cache/lxc/download 中，下一次创建此镜像模板的容器时就不会再次通过网络下载了。\n也可以使用 lxc-create -t download --help 来查看模板支持的一些命令，例如安装 CentOS 7 过程可以省略为 lxc-create -t download -n centos7 -- -d centos -r 7 -a amd64。需要注意的是命令行当中的 -- 参数，此参数之后的参数才会会当作模板参数传递给模板。\n启动容器接着启动此容器，并验证是否是 Ubuntu 16.04 的发行版：\nroot@localhost:~# lxc-start ubuntu-1604\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# python3 -m platform\nLinux-4.15.0-58-generic-x86_64-with-Ubuntu-16.04-xenial\nroot@ubuntu-1604:~#\nlxc-start 默认在后台启动容器，如果想切换至前端启动，可以使用 -F 参数，同时容器启动过程中的一些控制台输出也会被打印出来了。\n远程连接容器LXC 没有提供远程连接容器的方式，如果打算为 LXC 写一套 Web 管理工具，并想实现在 Web 端操作容器，可以采用将 lxc-attach 或者 lxc-console 的输入输出通过 WebSocket 的方式与前端通信。\n或者通过 SSH 的方式远程连接到容器，这样就需要在每个容器内配置 SSH 服务。例如在刚才创建好的容器中安装 SSH 服务：\nroot@ubuntu-1604:~# apt-get install openssh-server -y\nroot@ubuntu-1604:~# netstat -anpt\nActive Internet connections (servers and established)\nProto Recv-Q Send-Q Local Address           Foreign Address         State       PID/Program name\ntcp        0      0 0.0.0.0:22              0.0.0.0:*               LISTEN      610/sshd        \ntcp6       0      0 :::22                   :::*                    LISTEN      610/sshd        \nroot@ubuntu-1604:~#\n由于新启动的容器还是空密码，所以还需要设置一个密码才可以登录：\nroot@ubuntu-1604:~# passwd\nEnter new UNIX password: \nRetype new UNIX password: \npasswd: password updated successfully\nroot@ubuntu-1604:~#\n允许使用 root 用户登录并重启服务：\nsed -i &apos;s/^PermitRootLogin prohibit-password/PermitRootLogin yes/g&apos; /etc/ssh/sshd_config\nservice ssh restart\n这样就可以在宿主机上通过 ssh 连接到容器了，如果想在局域网内也可以 ssh 连接到容器，可以将 lxcbr0 与物理网卡桥接起来，并配置局域网的 IP 地址。\n容器资源限制对于虚拟机来说，在创建虚拟机时为虚拟机分配的内存大小 就是对虚拟机能使用的内存的限制。对于容器而言，限制容器可使用的硬件资源 都是通过 cgroup 来实现的。\nLXC 提供了 lxc-cgroup 命令来操作容器的控制组，默认容器是没有任何限制的。\n限制内存使用在容器内使用 free -m 命令查看内存使用情况：\nroot@ubuntu-1604:~# free -m\n            total        used        free      shared  buff/cache   available\nMem:           3921          18        3802           8          99        3902\nSwap:          3920           0        3920\nroot@ubuntu-1604:~#\n可以看到总内存是和宿主机内存相同的，接下来使用 lxc-cgroup 来限制内存的使用：\n宿主机上执行：\nroot@ubuntu-1604:~# lxc-cgroup ubuntu-1604 memory.limit_in_bytes 256M\n容器内查看：\nroot@ubuntu-1604:~# free -m\n            total        used        free      shared  buff/cache   available\nMem:            256          18         137           8          99         237\nSwap:          3920           0        3920\nroot@ubuntu-1604:~#\n可以看到允许使用的最大内存已经变成了 256M。但是这样只是临时更改了容器允许使用的内存，在容器重启后限制就会消失，如果想在重启重启后也保持这样的限制，可以更改每个容器的配置文件。\n例如容器 ubuntu-1604 的配置文件就在 /var/lib/lxc/ubuntu-1604/config 在文件的最后添加如下内容：\nlxc.cgroup.memory.limit_in_bytes = 512M\n接着使用 lxc-stop ubuntu-1604 和 lxc-start ubuntu-1604 停止并启动容器，直接在容器内使用 reboot 命令是无效的。\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# free -m\n            total        used        free      shared  buff/cache   available\nMem:            512          11         492           8           8         500\nSwap:          3920           0        3920\nroot@ubuntu-1604:~#\n容器重启后可用内存变为了 512M。对于交换分区，我们也可以通过 cgroup 来限制其使用，其限制字段名为 memory.memsw.limit_in_bytes，但是限制交换分区使用后通过 free 命令看到的依旧是宿主机的交换分区大小。\n限制CPU使用与内存限制的简单粗暴不同，对于 CPU 资源的限制复杂了一些，因为 CPU 有不同维度的限制条件，例如仅允许容器运行在 CPU 的某个核心上，或者仅允许容器在一段时间内获取多久的 CPU 执行时间片。这里只简单的限制容器可以在哪几个核心上使用。\n宿主机上执行：\nroot@ubuntu-1604:~# lxc-cgroup ubuntu-1604 cpuset.cpus &quot;0,1&quot;\n表示仅允许容器使用 CPU 的第 0 个和第 1 个核心。容器内查看：\nroot@ubuntu-1604:~# cat /proc/cpuinfo |grep processor\nprocessor    : 0\nprocessor    : 1\nroot@ubuntu-1604:~#\n容器内只可以看到 CPU 的两个核心了。同样，如果想要在容器重启后限制依然生效，可以修改容器的配置文件 新增以下内容：\nlxc.cgroup.cpuset.cpus = &quot;0,1&quot;\n限制存储空间如果容器的存储使用的是 dir 则与宿主机共享存储，如果使用了 lvm、zfs 等文件系统则可以通过给容器分配独立的分区方式来限制容器可用的存储空间。这里使用 loop 设备模拟硬盘分区的方式来限制容器存储使用。\n创建使用 loop 设备的容器并启动：\nlxc-create -B loop -t download -n ubuntu-1604-loop --fssize 1G -- -d ubuntu -r xenial -a amd64lxc-start ubuntu-1604-loop\n可以看到，dir 和 loop 的区别如下：\nroot@localhost:~# ls /var/lib/lxc/ubuntu-1604\nconfig  rootfs\nroot@localhost:~# ls /var/lib/lxc/ubuntu-1604-loop/\nconfig  rootdev  rootfs\nroot@localhost:~# cat /var/lib/lxc/ubuntu-1604/config |grep rootfs\nlxc.rootfs.path = dir:/var/lib/lxc/ubuntu-1604/rootfs\nroot@localhost:~# cat /var/lib/lxc/ubuntu-1604-loop/config |grep rootfs\nlxc.rootfs.path = loop:/var/lib/lxc/ubuntu-1604-loop/rootdev\nroot@localhost:~# ls /var/lib/lxc/ubuntu-1604-loop/rootfs\nroot@localhost:~# ls -lh /var/lib/lxc/ubuntu-1604-loop/rootdev \n-rw------- 1 root root 1.1G Sep 25 03:36 /var/lib/lxc/ubuntu-1604-loop/rootdev\nroot@localhost:~#\n虽然 ubuntu-1604-loop 容器依然保留了 rootfs 目录，但内容确是空的。容器内也可以看到根文件系统的总空间只有 1G 了：\nroot@localhost:~# lxc-attach ubuntu-1604-loop \nroot@ubuntu-1604-loop:~# df -hT\nFilesystem     Type   Size  Used Avail Use% Mounted on\n/dev/loop0     ext4   976M  372M  537M  41% /\nnone           tmpfs  492K     0  492K   0% /dev\ntmpfs          tmpfs  2.0G     0  2.0G   0% /dev/shm\ntmpfs          tmpfs  2.0G  8.1M  2.0G   1% /run\ntmpfs          tmpfs  5.0M     0  5.0M   0% /run/lock\ntmpfs          tmpfs  2.0G     0  2.0G   0% /sys/fs/cgroup\nroot@ubuntu-1604-loop:~#\n网卡接口限速对容器网卡流量进行限制使用了 Linux 内核的流量控制功能，通过 tc 命令进行管理。tc 命令的操作比较复杂，所幸有人封装好了对接口进行限速的脚本并开源到了 Github 上，我们只需要下载下来使用就可以了。\n宿主机上安装 wondershaper 工具：\ngit clone https://github.com/magnific0/wondershaper.gitcp wondershaper/wondershaper /usr/local/sbin/\nwindershaper 工具使用非常简单，使用 -a 参数指定网卡接口名称，-c 清理所有规则，-d 限制下载速率，-u 限制上传速率，单位是 Kbps。需要注意的是 Linux 并不能很准确的控制下载速度，而且对于提供服务的容器或虚拟机而言，一般需要限制的是上传速率。\nroot@localhost:~# wondershaper\nUSAGE: /usr/local/sbin/wondershaper [-hcs] [-a &lt;adapter&gt;] [-d &lt;rate&gt;] [-u &lt;rate&gt;]\n\nLimit the bandwidth of an adapter\n\nOPTIONS:\n-h           Show this message\n-a &lt;adapter&gt; Set the adapter\n-d &lt;rate&gt;    Set maximum download rate (in Kbps) and/or\n-u &lt;rate&gt;    Set maximum upload rate (in Kbps)\n-p           Use presets in /etc/conf.d/wondershaper.conf\n-c           Clear the limits from adapter\n-s           Show the current status of adapter\n-v           Show the current version\n\nMODES:\nwondershaper -a &lt;adapter&gt; -d &lt;rate&gt; -u &lt;rate&gt;\nwondershaper -c -a &lt;adapter&gt;\nwondershaper -s -a &lt;adapter&gt;\n\nEXAMPLES:\nwondershaper -a eth0 -d 1024 -u 512\nwondershaper -a eth0 -u 512\nwondershaper -c -a eth0\n\nroot@localhost:~#\n接着找到要限制流量的容器对应的网卡接口 并限制容器的上行速度为 1Mbps：\nroot@localhost:~# lxc-info ubuntu-1604 | egrep &quot;IP|Link&quot;\nIP:             10.0.2.238\nLink:           vethQFAM44\nroot@localhost:~# wondershaper -a vethQFAM44 -c\nroot@localhost:~# wondershaper -a vethQFAM44 -d 1024\nroot@localhost:~# \n我也不清楚为什么设置容器的上行速率使用的是 -d 参数，实际测试发现此参数能控制容器的上传速率。\n在容器内运行一个 Web 服务进行测试：\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# dd if=/dev/zere of=img bs=1M count=128\ndd: failed to open &apos;/dev/zere&apos;: No such file or directory\nroot@ubuntu-1604:~# dd if=/dev/zero of=img bs=1M count=128\n128+0 records in\n128+0 records out\n134217728 bytes (134 MB, 128 MiB) copied, 0.0789097 s, 1.7 GB/s\nroot@ubuntu-1604:~# python3 -m http.server 80\nServing HTTP on 0.0.0.0 port 80 ...\n宿主机上使用 wget 命令下载测试：\nroot@localhost:~# wget http://10.0.2.238/img \n--2019-09-25 08:47:46--  http://10.0.2.238/img\nConnecting to 10.0.2.238:80... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 134217728 (128M) [application/octet-stream]\nSaving to: ‘img’\n\nimg        0%[                     ]   1.04M   120KB/s    eta 18m 4s\n可以看到，速度保持在了 1Mbps 下。\n挂起和恢复容器正在运行中的容器可以随时暂停和恢复，使用 lxc-freeze 命令挂起一个容器，此时容器内所有正在运行的程序都将被强制挂起：\nroot@localhost:~# lxc-freeze ubuntu-1604\nroot@localhost:~# ps aux |grep python3\nroot       7921  0.0  0.4  55988 17520 pts/4    D+   07:33   0:01 python3 -m http.server 80\nroot       8222  0.0  0.0  13136  1104 pts/2    S+   09:07   0:00 grep --color=auto python3\nroot@localhost:~# cat /proc/7921/status |grep State\nState:    D (disk sleep)\nroot@localhost:~# kill -9 7921\nroot@localhost:~# cat /proc/7921/status |grep State\nState:    D (disk sleep)\nroot@localhost:~#\n可以看到，刚才容器内运行的 python 进程已经是不可中断的休眠状态了，此时即使使用 kill -9 也依然无法杀掉此状态的进程。使用 lxc-unfreeze 解除容器的挂起状态：\nroot@localhost:~# lxc-unfreeze ubuntu-1604\nroot@localhost:~# cat /proc/7921/status |grep State\ncat: /proc/7921/status: No such file or directory\nroot@localhost:~#\n在容器内可以看到 python 进程已经退出，并显示 Killed，看来 kill -9 可能会迟到，但永远不会缺席。\n容器状态监控LXC 有三个命令工具提供了容器状态监控，分别是 lxc-monitor、lxc-top、lxc-wait。\nlxc-monitor这个命令可以监控单个或多个容器的状态变化，例如监听所有名称以 ubuntu 开头的容器状态：\nlxc-monitor ubuntu*\n接着打开另外一个终端，重启一个容器：\nroot@localhost:~# lxc-stop ubuntu-1604-loop\nroot@localhost:~# lxc-start ubuntu-1604-loop\nroot@localhost:~#\n可以看到，lxc-monitor 输出了被监听的容器的状态变化：\nroot@localhost:~# lxc-monitor ubuntu*\n&apos;ubuntu-1604-loop&apos; exited with status [0]\n&apos;ubuntu-1604-loop&apos; changed state to [STOPPING]\n&apos;ubuntu-1604-loop&apos; changed state to [STOPPED]\n&apos;ubuntu-1604-loop&apos; changed state to [STARTING]\n&apos;ubuntu-1604-loop&apos; changed state to [RUNNING]\nlxc-wait此命令是等待容器到达某一状态后便退出。\nroot@localhost:~# lxc-wait ubuntu-1604-loop -s RUNNING\nroot@localhost:~# lxc-wait ubuntu-1604-loop -s STOPPED\nubuntu-1604-loop 容器已经是运行状态，所以命令直接就退出了，而等待容器状态变化为 STOPPED 是，命令发送了阻塞。接着停止此容器，可以看到 lxc-wait 发现被监控容器是 STOPPED 状态后就退出了。\n如果想同时监听多个状态，可以使用 lxc-wait ubuntu-1604-loop -s &quot;RUNNING|STOPPED&quot; 这种方式。\nlxc-top此命令可以查看所有容器的运行状态\nContainer                   CPU          CPU          CPU                                BlkIO        Mem       KMem\nName                       Used          Sys         User                    Total(Read/Write)       Used       Used\nubuntu-1604                0.39         0.25         0.10         4.00 KiB(  0.00   /4.00 KiB)  17.83 MiB   4.53 MiB\nubuntu-1604-loop           2.24         1.48         0.28      54.32 MiB(54.14 MiB/180.00 KiB)  72.16 MiB   6.16 MiB\nTOTAL 2 of 2               2.63         1.73         0.38      54.32 MiB(54.14 MiB/184.00 KiB)  89.99 MiB  10.68 MiB\nroot@localhost:~#\n网卡管理网卡配置项容器启动后默认只有一个可用的 eth0 网卡接口，查看容器的配置文件可以找到网卡相关的配置项：\ncat /var/lib/lxc/ubuntu-1604/config\n...\n# Network configuration\nlxc.net.0.type = veth\nlxc.net.0.link = lxcbr0\nlxc.net.0.flags = up\nlxc.net.0.hwaddr = 00:16:3e:bc:27:d1\n...\n网卡相关配置如下：\n\nlxc.net.0.type：第 0 块网卡的类型，如果是第二块网卡，则为 lxc.net.1.type 可选类型如下：\nempty：不创建网卡，容器仅有 lo 网卡\nveth：创建一个对等网卡，该网卡的一端分配给容器，另一端与 lxc.net.0.link 指定的网桥桥接\nvlan：创建一个由 lxc.net.0.link 指定的虚拟局域网接口分配给容器，vlan的标识符可由 lxc.net.0.vlan.id 指定\nphys：将 lxc.net.0.link 指定的网卡接口分配给容器。\nmacvlan：创建一个 macvlan 接口，该接口和由 lxc.net.0.link 指定的接口相连接\n\n\nlxc.net.0.name：指定虚拟网卡接口的名称，默认是 eth 开头。\nlxc.net.0.link：指定进行真实网络通信的网卡。\nlxc.net.0.flags：指定网卡的状态，up 激活接口，down 关闭接口。\nlxc.net.0.hwaddr：指定虚拟网卡的 MAC 地址，默认情况该值会自动分配。\n\n分配物理网卡给容器为容器新增一块虚拟网卡非常简单，只需要模范示例配置，将其中的 0 改为 1 就会新增一块 eth1 的网卡了，下面试试直接分配一块物理网卡给容器，需要先保证宿主机有一块额外的物理网卡，如果是虚拟机可以先为宿主机新增一块。\n将以下内容追加到容器配置文件，将物理网卡分配给容器：\nlxc.net.1.type = phys\nlxc.net.1.link = ens35\nlxc.net.1.flags = up\nens35 是宿主机上第二块物理网卡的名称，不同的 Linux 环境网卡接口名称也不尽相同。然后重启被修改的容器：\nroot@localhost:~# lxc-stop ubuntu-1604 &amp;&amp; lxc-start ubuntu-1604\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# ifconfig\nens35     Link encap:Ethernet  HWaddr 00:0c:29:95:b4:7b  \n        inet6 addr: fe80::20c:29ff:fe95:b47b/64 Scope:Link\n        UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n        RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:9 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:1000 \n        RX bytes:0 (0.0 B)  TX bytes:726 (726.0 B)\n\neth0      Link encap:Ethernet  HWaddr 00:16:3e:bc:27:d1  \n        inet addr:10.0.2.238  Bcast:10.0.2.255  Mask:255.255.255.0\n        inet6 addr: fe80::216:3eff:febc:27d1/64 Scope:Link\n        UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n        RX packets:13 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:12 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:1000 \n        RX bytes:1519 (1.5 KB)  TX bytes:1452 (1.4 KB)\n\nlo        Link encap:Local Loopback  \n        inet addr:127.0.0.1  Mask:255.0.0.0\n        inet6 addr: ::1/128 Scope:Host\n        UP LOOPBACK RUNNING  MTU:65536  Metric:1\n        RX packets:0 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:0 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:1000 \n        RX bytes:0 (0.0 B)  TX bytes:0 (0.0 B)\n\nroot@ubuntu-1604:~#\n可以看到容器内部也可以使用这块网卡了，接着为此网卡配置一个静态 IP，看看从外部是否可以直接访问：\nroot@ubuntu-1604:~# ifconfig ens35 10.0.1.11/24\nroot@ubuntu-1604:~#\n需要注意的是，这个 IP 必须是此物理网卡所在网段的 IP 才可以。在 Windows 下直接访问容器：\nMicrosoft Windows [版本 10.0.18362.356]\n(c) 2019 Microsoft Corporation。保留所有权利。\n\nC:\\Users\\yunfwe\\Desktop&gt;ssh root@10.0.1.11\nThe authenticity of host &apos;10.0.1.11 (10.0.1.11)&apos; can&apos;t be established.\nECDSA key fingerprint is SHA256:WGzRElNn4jypkZLIwVzDcqbDDi7vqCb29UyAPbC8Oqs.\nAre you sure you want to continue connecting (yes/no)? yes\nWarning: Permanently added &apos;10.0.1.11&apos; (ECDSA) to the list of known hosts.\nroot@10.0.1.11&apos;s password:\nWelcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.15.0-58-generic x86_64)\n\n* Documentation:  https://help.ubuntu.com\n* Management:     https://landscape.canonical.com\n* Support:        https://ubuntu.com/advantage\nLast login: Wed Sep 25 01:58:44 2019\nroot@ubuntu-1604:~#\n桥接物理网卡直接分配物理网卡虽然实现了在外部直接访问宿主机内部的容器了，但是显然太浪费资源，每一个容器都要分配一个物理网卡。我们可以在宿主机创建一个网桥，然后将物理网卡接入到网桥内，之后再将容器的虚拟网卡也接入到网桥，这样就可以实现桥接模式了。\n首先删除之前为容器分配物理网卡的配置项并重启容器，然后在宿主机上新增网桥，并将第二块物理网卡加入到网桥中。\n宿主机执行：\nroot@localhost:~# brctl addbr netbr0 \nroot@localhost:~# brctl addif netbr0 ens35\nroot@localhost:~# ifconfig netbr0 up\nroot@localhost:~# ifconfig ens35 up\nroot@localhost:~# brctl show\nbridge name    bridge id        STP enabled    interfaces\nlxcbr0        8000.00163e000000    no        vethA75TNV\n                                        vethWL2CSX\nnetbr0        8000.000c2995b47b    no        ens35\nroot@localhost:~#\nlxcbr0 是 LXC 自动帮我们创建的网桥，网桥内已经有两个接口，对端便是两个容器的 eth0 网卡。接下来我们可以重新创建一个容器，然后将容器配置文件中的 lxc.net.0.link 改为我们新创建的网桥，或者在现有的容器中新增一块虚拟网卡，然后连接到网桥上。\n修改容器配置文件，新增如下配置：\nlxc.net.1.type = veth\nlxc.net.1.link = netbr0\nlxc.net.1.flags = up\n重启此容器并查看 netbr0 网桥已经有多少个接口：\nroot@localhost:~# lxc-stop ubuntu-1604 &amp;&amp; lxc-start ubuntu-1604\nroot@localhost:~# brctl show\nbridge name    bridge id        STP enabled    interfaces\nlxcbr0        8000.00163e000000    no        vethA75TNV\n                                        vethGHBNA6\nnetbr0        8000.000c2995b47b    no        ens35\n                                        veth479Q5D\nroot@localhost:~#\n为容器内接口分配 IP 并远程连接：\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# ifconfig eth1 10.0.1.11/24\nroot@ubuntu-1604:~# ifconfig eth1\neth1      Link encap:Ethernet  HWaddr 66:15:70:46:7e:bf  \n        inet addr:10.0.1.11  Bcast:10.0.1.255  Mask:255.255.255.0\n        inet6 addr: fe80::6415:70ff:fe46:7ebf/64 Scope:Link\n        UP BROADCAST RUNNING MULTICAST  MTU:1500  Metric:1\n        RX packets:44 errors:0 dropped:0 overruns:0 frame:0\n        TX packets:22 errors:0 dropped:0 overruns:0 carrier:0\n        collisions:0 txqueuelen:1000 \n        RX bytes:4625 (4.6 KB)  TX bytes:1588 (1.5 KB)\n\nroot@ubuntu-1604:~#\nWindows 上远程连接成功：\nC:\\Users\\yunfwe\\Desktop&gt;ssh root@10.0.1.11\nroot@10.0.1.11&apos;s password:\nWelcome to Ubuntu 16.04.6 LTS (GNU/Linux 4.15.0-58-generic x86_64)\n\n* Documentation:  https://help.ubuntu.com\n* Management:     https://landscape.canonical.com\n* Support:        https://ubuntu.com/advantage\nLast login: Thu Sep 26 03:01:21 2019 from 10.0.1.1\nroot@ubuntu-1604:~#\n当前网桥的配置是临时生效的，如果需要开机自动配置 还请查看你当前所使用的发行版的网络管理器如何配置网桥。\n设备管理LXC 提供了 lxc-device 命令将宿主机的硬件设备直接分配给容器。其实运用到的技术是 cgroup 的设备白名单和在容器内创建设备相应的设备文件。\nlxc-device 命令的使用非常简单，使用 add 直接指定要将宿主机 /dev 目录下的哪个设备分配给容器就可以了，删除可以使用 del\n分配硬盘分区到容器宿主机执行：\nlxc-device ubuntu-1604 add /dev/sda2\n容器内查看：\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# ls /dev/sda2 \n/dev/sda2\nroot@ubuntu-1604:~# mount /dev/sda2 /mnt/\nroot@ubuntu-1604:~# ls /mnt/\nbin   cdrom  etc   initrd.img      lib    lost+found  mnt  proc  run   snap  swap.img  tmp  var      vmlinuz.old\nboot  dev    home  initrd.img.old  lib64  media       opt  root  sbin  srv   sys       usr  vmlinuz\nroot@ubuntu-1604:~#\n分配 tunnel 设备到容器默认在容器内是没有 /dev/net/tun 设备文件的，因此一大部分的 VPN 应用都无法在容器内正常运行。利用 lxc-device 命令可以很方便的将 tunnel 设备分配给容器：lxc-device ubuntu-1604 add /dev/net/tun，但是用这种方法在容器重启后分配的设备文件将失效。\n我们可以在配置文件中指定容器允许的设备文件白名单，容器在启动过程中会默认分配一些设备文件，在容器的配置文件中有一行是 lxc.include = /usr/share/lxc/config/common.conf 打开此文件，可以看到这些默认会创建的设备文件：\n## Allow specific devices\n### /dev/null\nlxc.cgroup.devices.allow = c 1:3 rwm\n### /dev/zero\nlxc.cgroup.devices.allow = c 1:5 rwm\n### /dev/full\nlxc.cgroup.devices.allow = c 1:7 rwm\n### /dev/tty\nlxc.cgroup.devices.allow = c 5:0 rwm\n### /dev/console\nlxc.cgroup.devices.allow = c 5:1 rwm\n### /dev/ptmx\nlxc.cgroup.devices.allow = c 5:2 rwm\n### /dev/random\nlxc.cgroup.devices.allow = c 1:8 rwm\n### /dev/urandom\nlxc.cgroup.devices.allow = c 1:9 rwm\n### /dev/pts/*\nlxc.cgroup.devices.allow = c 136:* rwm\n### fuse\nlxc.cgroup.devices.allow = c 10:229 rwm\nLinux tunnel 设备号是 c 10 200，如果我们需要在将来创建的容器都默认分配 tunnel 设备，可以直接修改 /usr/share/lxc/config/common.conf，否则只修改容器的配置文件即可：\n容器配置文件最后添加以下内容：\n### tunnel \nlxc.cgroup.devices.allow = c 10:200 rwm\n现在只是允许了容器内使用 /dev/net/tun 设备，容器并不会自动创建此设备文件，我们可以在容器的 /etc/rc.local 中写入创建设备文件的命令来完成启动容器后自动创建。\n编辑容器内的 /etc/rc.local 在最后的 exit 0 之前写入以下内容：\nmkdir /dev/net -p\nmknod /dev/net/tun c 10 200\n然后重启容器：\nroot@localhost:~# lxc-stop ubuntu-1604 &amp;&amp; lxc-start ubuntu-1604\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# ls /dev/net/tun\n/dev/net/tun\nroot@ubuntu-1604:~#\n目录挂载如果想在多个容器内共享同一个目录，可以采用挂载宿主机同一目录的方式。\n首先在宿主机创建一个目录用于容器见共享：\nroot@localhost:~# mkdir /data\nroot@localhost:~# echo hello &gt; /data/world\nroot@localhost:~#\n修改容器配置文件，新增如下内容：\nlxc.mount.entry = /data data none rw,bind,create=dir 0 0\nlxc.mount.entry 的写法跟 /etc/fstab 的写法一样，上面的内容就是将宿主机的 /data 目录挂载到容器内的 /data 目录，容器内的路径开头不可以写 / 否则会无法挂载。rw,bind,create=dir 是挂载选项，表示以读写方式挂载，如果容器内文件夹不存在则自动创建。\nroot@localhost:~# lxc-stop ubuntu-1604 &amp;&amp; lxc-start ubuntu-1604\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# ls /data\nworld\nroot@ubuntu-1604:~# cat /data/world \nhello\nroot@ubuntu-1604:~# \n我们还可以利用挂载的特性，将设备文件直接挂载到容器内，比如上面的 tunnel 设备文件还可以用以下方式自动挂载：\nlxc.mount.entry = /dev/net/tun dev/net/tun none rw,bind,create=file 0 0\n容器权限在 Linux2.2 内核开始将超级用户的权限分为若干独立的子权限，每个子权限可独立的禁止或者打开，注意，一旦剥夺了根用户的某一权限，那么除非重启系统，否则无法恢复该权限。下面对这些权限进行简单的介绍： \n\nCAP_CHOWN：允许改变文件的所有权 \nCAP_DAC_OVERRIDE：忽略对文件的所有 DAC 访问限制 \nCAP_DAC_READ_SEARCH：忽略所有对读、搜索操作的限制 \nCAP_FOWNER：如果文件属于进程的 UID，就取消对文件的限制 \nCAP_FSETID：允许设置 setuid 位 \nCAP_KILL：允许对不属于自己的进程发送信号 \nCAP_SETGID：允许改变组 ID \nCAP_SETUID：允许改变用户 ID \nCAP_SETPCAP：允许向其它进程转移能力以及删除其它进程的任意能力 \nCAP_LINUX_IMMUTABLE：允许修改文件的不可修改 (IMMUTABLE) 和只添加 (APPEND-ONLY) 属性 \nCAP_NET_BIND_SERVICE： 允许绑定到小于 1024 的端口 \nCAP_NET_BROADCAST：允许网络广播和多播访问 \nCAP_NET_ADMIN：允许执行网络管理任务：接口、防火墙和路由等。 \nCAP_NET_RAW：允许使用原始 (raw) 套接字 \nCAP_IPC_LOCK：允许锁定共享内存片段 \nCAP_IPC_OWNER： 忽略 IPC 所有权检查 \nCAP_SYS_MODULE： 插入和删除内核模块 \nCAP_SYS_RAWIO：允许对 ioperm/iopl 的访问 \nCAP_SYS_CHROOT：允许使用 chroot() 系统调用 \nCAP_SYS_PTRACE：允许跟踪任何进程 \nCAP_SYS_PACCT：允许配置进程记帐 (process accounting) \nCAP_SYS_ADMIN：允许执行系统管理任务：加载/卸载文件系统、设置磁盘配额、开/关交换设备和文件等。 \nCAP_SYS_BOOT：允许重新启动系统 \nCAP_SYS_NICE：允许提升优先级，设置其它进程的优先级 \nCAP_SYS_RESOURCE：忽略资源限制 \nCAP_SYS_TIME：允许改变系统时钟 \nCAP_SYS_TTY_CONFIG：允许配置 TTY 设备 \nCAP_MKNOD：允许使用 mknod() 系统调用 \nCAP_LEASE：Allow taking of leases on files \n\n容器的配置文件提供了 lxc.cap.drop 来允许我们运行的容器抛弃某些权限，例如我们要抛弃容器的创建设备文件和更改 IP 地址的权限，追加以下配置到容器的配置文件：\nlxc.cap.drop =  mknod net_admin\n权限的名称不需要写开头的 CAP_ 使用小写即可，接着重启容器：\nroot@localhost:~# lxc-stop ubuntu-1604 &amp;&amp; lxc-start ubuntu-1604\nroot@localhost:~# lxc-attach ubuntu-1604\nroot@ubuntu-1604:~# ifconfig eth1 10.0.1.11/24\nSIOCSIFADDR: Operation not permitted\nSIOCSIFFLAGS: Operation not permitted\nSIOCSIFNETMASK: Operation not permitted\nroot@ubuntu-1604:~# mknod test c 10 200\nmknod: test: Operation not permitted\nroot@ubuntu-1604:~#\n容器开机自启容器默认在系统启动时不会自动启动，但是提供了 lxc-autostart 命令来帮我们启动所有设置了开机自启的容器。 我们可以在容器的配置文件中添加以下内容来让容器自启动：\nlxc.start.auto = 1\nlxc.start.delay = 10\nlxc.group = onboot\nlxc.start.auto 表示允许自启。lxc.start.delay 表示启动延迟，在处理互相依赖的容器中，启动延迟会比较有用。lxc.group 表示定义启动组，这样就可以通过 lxc-autostart -g onboot 来启动所有属于 onboot 组的容器了。\n当设置好容器开机自启动后，将 lxc-autostart 命令添加到宿主机的 /etc/rc.local 中，这样就可以实现开机时自动启动容器了。\n容器备份可以在停掉或冻结要备份的容器后直接对 /var/lib/lxc/ 下的容器目录进行归档备份，如果想克隆容器，直接将容器目录复制一份，然后改下复制后的容器配置文件中的网卡配置相关冲突的地方即可。\n附录LXC 工具集的使用上还是比较原始简单，还有个更好用的 LXC 管理工具：LXD。该工具类似于 Docker，启动一个守护进程，然后通过 lxc 命令对容器和镜像进行管理，并提供了更灵活的配置和更完善的官方文档。还有容器快照、热迁移等高级功能。\n\nLXD官方文档：https://lxd.readthedocs.io/en/latest/\n\n","categories":["Linux"],"tags":["linux","lxc"]},{"title":"Web页面布局","url":"/2018/12/28/2018/Web%E9%A1%B5%E9%9D%A2%E5%B8%83%E5%B1%80/","content":"简介\n使用现代前端技术开发的应用，不管是 Web 页面，还是混合开发的手机 APP，都离不开页面元素的布局。而布局又可以说是页面开发里最麻烦的地方，不仅要兼容不同的设备，还要兼容不同的浏览器，还很可能一不小心改错了一个值就造成整个页面的雪崩。这里汇总下关于页面布局的基础知识以及一些开发中的经验。\n\n环境\n\n\n软件\n版本\n\n\n\n\n操作系统\nWindows 10\n\n\nChrome浏览器\n70\n\n\n\n教程\n这里假使读者已经有了基础的 CSS 知识。如果对这些基础知识还没有概念的话，如果继续往下看，可能会觉得比较难以理解和接受。\n\n布局基础\nCSS 布局重点在于  三大特性、盒子模型、浮动 和 定位 这几个方面，其他的背景啊、边框啊也都是细节，而这几个才是整个页面布局的基础。\n\n显示模式网页的标签非常多，并且不同的标签用于不同的场合，因此不同的标签也有不同的显示模式。比如两个 a 标签默认是可以放在一行显示的，而 p 标签则不可以，默认在页面上独占一行或多行。\n块级元素p 标签就是常见的块级元素，以及我们经常用来布局的 div 标签、h1 ~ h6 标签等，默认都是块级元素。块级元素由于可以对其设置宽高、对齐，因此常用于网页布局和结构搭建。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        h1 &#123;            background-color: #8a8a8a;        &#125;        p &#123;            background-color: #5e68ea;        &#125;        div &#123;            background-color: #ff7171;            padding: 3px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;h1&gt;第一行&lt;/h1&gt;    &lt;p&gt;第二行&lt;/p&gt;    &lt;div&gt;        &lt;p&gt;第三行&lt;/p&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n可以看到块级元素的几个特性：\n\n独占一行或多行\n宽高、内外边距都可以控制\n宽度默认是占满整个容器\n可以容器其他行内元素、块级元素\n\n需要注意的是，p 标签和 h1 ~ h6 等文字类块级标签不可以容纳其他块级元素。\n浏览器默认给一些块元素提供了外边距，所以页面上元素与元素之间还会有块空白。一般在实际开发中，都会重置所有元素的内外边距：\n* &#123;    margin: 0;    padding: 0;&#125;\n\n这样页面上就不会有这么多无法掌控的情况了。\n行内元素行内元素不占有独立的区域，仅仅靠自身的字体大小和图像尺寸来支撑结构，一般不可以设置宽度、高度、对齐等属性，常用于控制页面中文本的样式。常见的行内元素有 a, b, del, i, span 等。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        * &#123;            margin: 0;            padding: 0;        &#125;        a, b, del, i, span &#123;            margin: 5px;            padding: 5px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div&gt;        &lt;a href=\"#\"&gt;&lt;span&gt;超文本链接&lt;/span&gt;&lt;/a&gt;        &lt;b&gt;加粗&lt;/b&gt;        &lt;del&gt;删除&lt;/del&gt;        &lt;i&gt;斜体&lt;/i&gt;        &lt;span&gt;没有预设样式&lt;/span&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\nspan 元素最为纯粹，可塑性非常高，所以经常会使用 span 标签来为文本添加各种样式。\n行内元素的特点：\n\n不会独占一行，会和相邻的行内元素在一行上显示。\n无法设置高和宽，以及上下内外边距，但是左右内外边距可以设置。\n它的内容有多宽，容器就被撑多宽\n行内元素只能容纳文本或则其他行内元素。\n\na 标签比较特殊，也可以容纳块级元素。\n行内块元素行内块元素可以说就是允许设置宽高、内外边距（包括上下）、对齐属性的行内元素，比如常见的 img 标签，input 标签。下面看看行内块元素的显示：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        * &#123;            margin: 0;            padding: 0;        &#125;        img &#123;            width: 150px;            height: 150px;            border: 1px solid #3280f3;            vertical-align: bottom        &#125;        input &#123;            width: 200px;            height: 30px;            border: 1px solid #f37932;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div&gt;        &lt;img src=\"css.png\"&gt;        &lt;input type=\"text\" placeholder=\"这是一个输入框\"&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\nimg 标签和 input 标签都可以设置宽高，img 标签默认与其他一行的元素以基线对齐（baseline），这里改为底部对齐（bottom）的方式让显示的更好看一些。还有个问题可以发现，即使已经设置了 margin: 0 和 padding: 0，可是两个行内块元素中间依然有个缝隙。下面总结行内块元素的特点：\n\n和相邻行内或行内块元素在一行上，但是中间有空白缝隙。\n默认宽度是它本身内容把它撑开的宽度。\n宽高、内外边距都可以控制。\n\n顺便一提 img 标签和文字在一行时的一些显示：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        * &#123;            margin: 0;            padding: 0;        &#125;        img &#123;            width: 150px;            height: 150px;            border: 1px solid #3280f3;            /* vertical-align: bottom */        &#125;        span &#123;            border: 1px solid #d052d3;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div&gt;        &lt;img src=\"css.png\"&gt;        &lt;span&gt;一些文字&lt;/span&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\nvertical-align 可以设置行内和行内块元素垂直对其的方式。img 和其他行内元素默认的对齐方式并不是底线对其的！所以可以看到 img 比 span 高出了几个像素。同样这个问题也会出现，当使用一个 div 去包裹 img 的时候，img 并不是铺满整个 div 的。而是底边会留有几个像素：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        div &#123;            border: 1px solid #3280f3;            display: inline-block;        &#125;        img &#123;            width: 150px;            height: 150px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div&gt;        &lt;img src=\"black.png\"&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n解决方法也很简单，将 img 的垂直对其方式设置为底边对其，或者 将 img 的显示模式转换为块元素\n显示模式转换通过 display 属性可以转换元素的默认显示模式：.box &#123;    display: inline;        /* 转换为行内元素 */    display: block;         /* 转换为块级元素 */    display: inline-block;  /* 转换为行内块元素 */&#125;\n下面看一个例子：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        span &#123;            display: block;            width: 100px;            height: 100px;            border: 1px solid #3a65e2;            margin: 5px;        &#125;        div &#123;            display: inline;            border: 1px solid #f459b7        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;span&gt;span现在是块级元素了&lt;/span&gt;    &lt;span&gt;拥有块级元素的特性&lt;/span&gt;    &lt;div&gt;div成了行内元素&lt;/div&gt;&lt;div&gt;可以一行显示了&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n上面的 img 显示问题也可以通过显示转换来解决：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        div &#123;            border: 1px solid #3280f3;        &#125;        img &#123;            width: 150px;            height: 150px;            display: block;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div&gt;        &lt;img src=\"black.png\"&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n其他显示模式这三种基本的显示模式几乎可以应付大部分的页面布局了，其中还有一些非常好用的显示模式，比如 display: flex 可以用来做另外一种页面布局，但是对老旧的电脑浏览器存在一些兼容性问题（比如 IE），如果是手机页面开发，display: flex 几乎可以想怎么用就怎么用了。\n浏览器开发者模式中可以看到所有支持的显示模式：\n\n三大特性层叠性所谓层叠性，是指如果一个元素被应用了多个相同的 CSS 属性，那么浏览器如何处理这种冲突呢？先看一个例子。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        #app &#123;            width: 100px;            height: 100px;            background-color: red;        &#125;        #app &#123;            width: 100px;            height: 100px;            background-color: gray;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=\"app\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n在浏览器中查看效果，显示的是灰色的盒子：\n\n接着把两个颜色替换下看看效果#app &#123;    width: 100px;    height: 100px;    background-color: gray;&#125;#app &#123;    width: 100px;    height: 100px;    background-color: red;&#125;\n盒子变成红色：\n\n可以看到，是最后一次定义的 background-color 生效。也就是说，相同的 CSS 样式互相覆盖，只有最上面的一层 CSS 样式才最终被我们看到。\n继承性几乎所有（未来不知道有没有）的应用与文字上的样式，都具有继承性。也就是说，在父标签定义好的一些关于文字的样式，子元素都不需要重新定义。如果子元素需要不同的样式，只能通过在子元素上应用新的样式来层叠掉父元素继承来的样式。\n子元素可以继承的样式有 text-, font-, line- 开头的所有元素以及 color 元素。下面看一个例子：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        html &#123;            color: green;        &#125;        #father &#123;            color: blue;            font-size: 24px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    从HTML标签继承来的color为绿色    &lt;div id=\"father\"&gt;        #father层叠了继承来的color为蓝色&lt;br&gt;        并定义了字号样式为 20px        &lt;div id=\"son\"&gt;            #son继承了来自#father的字体颜色和字号        &lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n结果：\n优先级给元素定义样式的方式有好多种，比如ID选择器、类和伪类选择器、标签选择器等。如果通过不同的选择器给相同样式定义了不同的值，这时候样式的层叠就不太一样了。\nCSS 给通过不同的选择器定义的样式提供不同的优先级，CSS 的层叠只发生在相同的优先级下，比如上面 CSS 层叠性的代码中，都是通过 ID 选择器来定义的样式。\nCSS 使用一套权重系统来计算优先级，使用 0,0,0,0 这种值来计算权重，不同的选择器或者定义样式的方法（内联样式、继承来的样式、!important申明的样式）会给权重系统提供不同的贡献，最后根据总贡献值来确定哪一套样式会覆盖了哪一套，如果贡献值相同，那么就应用最后定义的那套。这个过程就叫做层叠。\n下面这个表格表明了不同的选择器或定义样式的方式的贡献值：\n\n\n\n方式\n贡献值\n\n\n\n\n继承来的样式\n0,0,0,0\n\n\n通配符选择器（*）\n0,0,0,0\n\n\n标签选择器\n0,0,0,1\n\n\n类、伪类选择器\n0,0,1,0\n\n\nID选择器\n0,1,0,0\n\n\n内联样式\n1,0,0,0\n\n\n!important申明\n无穷大\n\n\n\n可以将 0,0,0,0 的每一位当成一个级别，0,0,0,1 &gt; 0,0,0,0，0,0,1,0 &gt; 0,0,0,1，所以，!important &gt; 内联样式 &gt; ID选择器 &gt; 类、伪类选择器 &gt; 标签选择器 &gt; 通配符选择器（*）和继承来的样式。\n下面看一个例子：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        #app &#123;            width: 300px;            height: 300px;            color: blue;        &#125;        .box &#123;            color: green        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=\"app\" class=\"box\"&gt;            字体颜色是蓝色，因为类选择器的优先级低于ID选择器    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n结果：\n优先级是可以叠加的，比如：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        #app &#123;            width: 300px;            height: 300px;        &#125;        .inner &#123;            color: blue;        &#125;        .box &gt; .inner &#123;            color: green;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=\"app\" class=\"box\"&gt;        &lt;span class=\"inner\"&gt;            字体颜色是绿色，因为两个类的贡献值比一个类的贡献值大        &lt;/span&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n通过计算，.inner 的权重是 0,0,1,0，而 .box &gt; .inner 的权重是 0,0,2,0，所以 .box &gt; .inner 定义的样式会覆盖掉 .inner 定义的样式。同理，如果再加上 #app &gt; .inner 还会覆盖掉 .box &gt; .inner 定义的选择器，因为 #app &gt; .inner 的优先级是 0,1,1,0。\n需要注意的是！CSS 的优先级没有进位，一百个类选择器定义的样式优先级也不会比一个ID选择器定义的样式优先级高！现在测试下 !important 的效果：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        #app &#123;            width: 300px;            height: 300px;        &#125;        .inner &#123;            color: blue;        &#125;        .box &gt; .inner &#123;            color: green;        &#125;        * &#123;            color: purple!important;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div id=\"app\" class=\"box\"&gt;        &lt;span class=\"inner\"&gt;            而!important简直六亲不认，            即使毫无贡献值的通配符选择器定义的color样式，也秒杀一切        &lt;/span&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n盒子模型页面上每一个元素都像是一个盒子，盒子里面放的就是我们要展示的文字、图片或者其他的盒子。然后我们通过摆放盒子的位置来使内容合理的呈现在页面上。\n内外边距和边框在现代浏览器中，每一个盒子都由 内容区域、内边距、边框、外边距 组成。\n\n盒子模型可以比喻成我们拆快递，快递包装的厚度可以想象为边框，快递为了保护里面的东西会有一些填充物，这个填充物就可以当成内边距，而快递里面的东西就是实际的内容了。如果有多个快递，快递与快递之间的距离就是外边距了。下面看代码：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .box &#123;            width: 100px;            height: 100px;            padding: 10px;            border: 5px solid pink;            margin: 15px;            background-color: blue;            display: inline-block        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n这里将两个 div 元素设置为行内块显示，然后开发者模式查看他们的盒模型：\n\n可以看到，给元素设置的宽高实际上是给盒子的内容区域设置的，而元素占的实际空间大小是要加上内外边距还有边框的。我们也可以单独为每一个边设置不同的内外边距还有边框，或者通过将盒子左右外边距设置为 auto 来让浏览器自动计算实现盒子居中显示：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .box &#123;            width: 100px;            height: 100px;            padding: 10px;            border: 5px solid pink;            margin: 15px auto;            background-color: blue;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n块元素的上下外边距合并现在 .box 的显示模式是块元素了，如果相邻的两个块元素，上下外边距会有什么不同呢？\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .box &#123;            width: 100px;            height: 100px;            padding: 10px;            border: 5px solid pink;            margin: 15px auto;            background-color: blue;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n如果两个盒子的外边距不同，则会以外边距最大的元素为准：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .box &#123;            width: 100px;            height: 100px;            padding: 10px;            border: 5px solid pink;            margin: 15px auto;            background-color: blue;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;    &lt;div class=\"box\" style=\"margin: 25px auto\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n如何消除这个影响呢？也很简单，用一个父盒子将其中一个盒子嵌套起来，并给父盒子设置一个 overflow: hidden：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .box &#123;            width: 100px;            height: 100px;            padding: 10px;            border: 5px solid pink;            margin: 15px auto;            background-color: blue;        &#125;        .father &#123;            overflow: hidden;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box\"&gt;&lt;/div&gt;    &lt;/div&gt;    &lt;div class=\"box\" style=\"margin: 25px auto\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n添加 overfiow: hidden 可以防止 margin 合并的原理是 .father 的盒子触发了浏览器的 BFC 机制，形成了自己的独立空间，但是它的元素占用空间是由里面的子元素撑起来的，父元素的外边距为 0，所以也不会与下一行的块元素发生重叠（如果给父元素设置了外边距，依然会跟下一行的重叠）。那么什么是 BFC 呢？\nBFC（块级格式化上下文）BFC 就是页面上的一个隔离的独立容器，容器里面的子元素不会影响到外面的元素。反之也如此。包括浮动，和外边距合并等等，因此，有了这个特性，我们布局的时候就不会出现意外情况了。\n元素如何才能形成 BFC 呢？满足如下几个条件之一即可：\n\nfloat 的值不为 none\nposition 的值不为 static 或 relative\ndisplay 的值为 table-cell、table-caption、inline-block、flex 或 inline-flex\noverflow 的值不为 visibility\n\n利用 BFC 我们能做些什么呢？\n\n上一节的例子已经看到，BFC 可以防止两个元素上下外边距合并的问题。\n清除父元素内部的子元素浮动问题。\n父元素内部右侧盒子自适应。\n\n下面看一个例子：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 350px;            /* height: 350px; */            border: 1px solid blue;            /* overflow: hidden; */            /* display: flex; */            /* position: absolute; */            /* float: left; */        &#125;                .box1 &#123;            width: 100px;            height: 100px;            background: #f66;            /* float: left; */        &#125;                .box2 &#123;            height: 200px;            width: 200px;            background: #fcc;            display: none;            /* overflow: hidden; */        &#125;        .other &#123;            height: 120px;            width: 120px;            background-color: #649ddd;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;            文字文字文字文字文字文字文字文字文字文字文字文字文字文字文字            文字文字文字文字文字文字文字文字文字文字文字文字文字文字文字        &lt;/div&gt;    &lt;/div&gt;    &lt;div class=\"other\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n当前元素都一行一行的正常排列着：\n\n当我们给 .box1 添加浮动，一切都改变了：\n\n.father 的内容高度变为了 0，变成了只剩靠 2px 的边框维持的一条线。.box1 与 .other 发生了重叠，这个就是因为父元素内部子元素浮动产生的问题，我们看看如何来解决这个问题：\n\n我们给 .father 设置了高度，这样看似解决了问题，但是这个高度不是因为内部子元素自动撑开的，而是我们手动设置的，如果内部子元素的高度发生变化，我们还得相应的修改父元素高度以适应，这样显然不是太合理。接下来看看如何使用 BFC 来解决这个问题：\n\n首先尝试了使用 overflow: hidden 的方式，似乎完美解决了问题，但是如果内部盒子的宽度大于父盒子，则会被隐藏。接着使用 display: flex 的方式，这使用了 flex 布局。当使用了 position: absolute 和 float: left 的时候，虽然父元素形成了 BFC，并由内部子元素自动撑开了高度，但是却脱离了文档流，依然与下面的元素发生重叠。\n在看看最后一个可以利用 BFC 解决的问题：“父元素内部右侧盒子自适应”。首先给父元素提供一个高度，然后将 .box2 的 display: none 状态取消：\n\n可以看到由于 .box1 的浮动，与 .box2 产生了重叠，并让 .box2 的文字与它产生了环绕效果。当我们让 .box2 形成 BFC 会产生什么效果呢？\n\n当使用 overflow: hidden 触发 BFC 后，.box2 的左边框紧贴着 .box1 的右边框。当取消手动指定的 .box2 宽度后，.box2 自动适应了 .father 剩余的宽度。\n更改盒模型默认我们对块元素设置宽高是内容区域的宽高，如果对这个盒子进行增加内边距和边框，都会使这个元素变大，这个默认模型是 content-box。还有一个常用的模型，让内边距和边框都包含到元素的宽高中，这种模型就是 border-box。\n我们可以通过 box-sizing 来更改盒子模型：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .box1 &#123;            width: 100px;            height: 100px;            background-color: pink;            padding: 10px;            border: 5px solid gray;            margin: 20px;        &#125;        .box2 &#123;            box-sizing: border-box;            width: 100px;            height: 100px;            background-color: blue;            padding: 10px;            border: 5px solid gray;            margin: 20px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box1\"&gt;&lt;/div&gt;    &lt;div class=\"box2\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n.box2 由于使用了 border-box 模型，所以去掉边框和内边距占用的区域，内容区域只剩下 70 × 70 了，看起来也比 .box1 小了很多。\n定位机制文档流不给元素添加浮动或者定位的话，元素就放在文档流（或标准流）中。文档流实际上就是网页内的元素从左往右，从上往下依次排列的布局方式。如果给某个元素添加了浮动或者定位，那么它的显示就不会按照文档流的规则，我们称之为：脱离文档流。\n当某个元素脱离的文档流，就不会占用文档流的位置了，所以经常会发现多个元素发生了重叠的现象。脱离了文档流的元素的层级会比文档流中的元素层级高，因此大多情况下都是脱离文档流的元素遮住文档流的元素。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .box1 &#123;            width: 100px;            height: 100px;            background-color: pink;            float: left;        &#125;        .box2 &#123;            width: 120px;            height: 120px;            background-color: blue;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box1\"&gt;&lt;/div&gt;    &lt;div class=\"box2\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n浮动浮动最早是用来控制图片，为了让其他元素特别是文字实现环绕图片的效果。后来发现浮动可以让任何盒子排在一行，而且中间没有间隙（inline-block 的两个盒子中间有间隙），慢慢的人们就会浮动的特性来布局了。\n元素设置了浮动样式，会脱离文档流的控制，并移动到浮动样式设置的地方。浮动元素依然受限于父级元素，子元素浮动，父元素依然在文档流中。如果多个子元素都添加了浮动，那么这些元素都有了 inline-block 元素的特性\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 300px;            border: 1px solid blue;            padding: 10px;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;            float: left;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            float: left;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;            float: right;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;span class=\"box3\"&gt;&lt;/span&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n可以看到，所有添加了浮动的标签，都有了行内块元素的特性，但是会两边贴合没有缝隙。元素会按照浮动样式的值进行漂移，如果是 left 则会贴着父元素的左边排列，right 会贴着父元素的右边排列。但是子元素不会超出父元素的内边距距离。\n浮动的特性：脱离文档流、不占用原本在文档流中的位置、会影响原本文档流的布局、只有左右浮动或者不浮动。\n定位我们如果想移动某个元素的位置，或者将某个元素直接放置到页面中一个固定的位置，如果不使用定位就非常麻烦或者不可能完成了。就连页面中各种各样的动画，也几乎都是通过定位来做的。\n元素的定位属性主要包括定位模式和边偏移两部分，定位属性常用的有四种：static，relative，absolute，fixed。边偏移样式：top，bottom，left，right。一般偏移样式 top 和 bottom 只使用一个就够了，left 和 right 同理，不要既给元素设置了 left 然后又设置了 right。\n偏移量不仅可以使用 px 等单位，还可以使用百分比：\n.box &#123;    top: 20px;    left: 10%;&#125;\n并且元素如果添加了定位（除了static定位）都会像给元素添加了浮动一样，将元素模式转换为行内块模式。因此即使是行内元素，也可以直接设置高度和内外上下边距。\nstatic文档流中的所有元素都默认是这个定位方式，而且没法通过边偏移样式进行改变元素位置。\nrelative相对定位：相对与自身原本在文档流中的位置进行边偏移。不脱离文档流，元素原本的占位依然保留。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 300px;            border: 1px solid blue;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            position: relative;            top: 0px;            left: 0px;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n给 .box2 添加了相对定位，并与原来位置的顶部保持 0px 的像素偏移和相对与原来位置的左边保持 0px 的像素偏移，然后浏览器开发者模式中手动调整这两个值试试看：\n\n相对于 top 设置偏移时，如果值小于 0 则向上偏移，如果值大于 0 则向下偏移。left 如果值小于 0 则向左偏移，如果值大于 0 则向右偏移。\nabsolute绝对定位：将元素根据最近的已经定位（相对、绝对、固定都可以）的父级或祖先级元素进行定位，如果所有的父元素都没有定位，则以 document 文档为基准进行定位。完全脱离文档流，元素原本的占位不保留。\n因此如果想让某个元素以它的某个父或祖先元素进行定位，就需要给这个元素设置绝对定位，并给父或祖先元素也设置合适的定位方式，如果不想改变父或祖先元素的位置，也不想让父或祖先元素脱离文档流，那最好的方式就是给父或祖先元素设置相对定位。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 1000px;            border: 1px solid blue;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            position: absolute;            top: 0px;            left: 0px;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n这里将 .father 的长度设置为 1000px 使页面产生滚动条，然后将 .box2 改为绝对定位：\n\n由于 .box2 的祖先都没有设置定位，因此它的绝对定位是以 document 整个页面为基准。完全脱离了文档流，所以它原来的位置被 .box3 所占据，并且当文档滚动时它也跟着滚动。如果想让它以 .father 元素为基准进行定位，又不想改变 .father 元素的位置，那么就最好给 .father 元素设置相对定位：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 1000px;            border: 1px solid blue;            position: relative;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            position: absolute;            top: 0px;            left: 0px;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n.box2 以 .father 为基准定位，所以覆盖了 .box1。如果想要元素相对于父元素水平和垂直居中对齐，可以将四个修改偏移的样式都设置为 0 ，然后将 margin 设置为 auto，看下面示例：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 400px;            border: 1px solid blue;            position: relative;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            position: absolute;            /* top: 0px; */            /* left: 0px; */            /* bottom: 0; */            /* right: 0; */            margin: auto;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n通过不同的偏移组合，可以将 .box1 定位到父元素中的 8 个位置上。\nfixed固定定位：永远以浏览器窗口为基准，不随页面滚动而滚动。完全脱离文档流，元素原本的占位不保留。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 1000px;            border: 1px solid blue;            position: relative;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            position: fixed;            top: 0px;            left: 0px;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n将 .box2 设置为固定定位，可以看到它并不随着页面的滚动而滚动。我们经常看到的页面双侧广告，是不是就是这样子的？固定定位也可以像绝对定位那样，通过将四个偏移样式都设置为 0，然后将 margin 设置为 auto 的方式实现元素相对于浏览器窗口永远水平和垂直居中：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 400px;            border: 1px solid blue;            position: fixed;            top: 0;            bottom: 0;            left: 0;            right: 0;            margin: auto;                    &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\nstickyCSS3 新增的样式，粘性定位，这个就比较有意思了。它相当于 relative 和 fixed 混合。最初会被当作是 relative，相对于原来的位置进行偏移。一旦超过一定阈值之后，会被当成 fixed，相对于视口进行定位。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 1000px;            height: 1000px;            border: 1px solid blue;            position: relative;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            position: sticky;            top: 20px;            left: 20px;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n有点意思吧！不是实际好像用的并不多。\n层级如果对元素使用了定位，就非常容易发生元素重叠的情况，我们可以使用 z-index 来调整定位元素的堆叠顺序，其取值可以为负整数、0 和正整数，值越大，则定位的元素越居上，如果值相同，则后定义的元素居上。\nz-index 的默认值是 0，并且只有相对定位、绝对定位和固定定位才有此属性。其余标准流，浮动，静态定位都无此属性，也不可指定此属性。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 400px;            border: 1px solid blue;            position: relative;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;            position: absolute;            z-index: 0;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            position: absolute;            top: 20px;            left: 20px;            z-index: 0;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;            position: absolute;            top: 40px;            left: 40px;            z-index: 0;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n显示与隐藏CSS 中可以控制元素显示与隐藏的样式最常用的有三个，一个是 display，一个是 visibility，另一个是 overflow。\ndisplay如果将元素的 display 设置为 none 将会使这个元素彻底的隐藏掉，元素原来的位置也不再保留：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 400px;            border: 1px solid blue;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            display: none;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n可以看到 .box3 显示在原来 .box2 的位置。于此对应的是，将一个隐藏元素的 display 设置为原来的显示模式（一般是 block），元素就可以再出现了。\nvisibilityvisibility 与 display 不同的是，隐藏元素后，会保留原来的位置。visibility 的值为 hidden 时元素隐藏不可见，值为 visible 时元素显示出来。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 400px;            height: 400px;            border: 1px solid blue;        &#125;        .box1 &#123;            width: 100px;            height: 100px;            background-color: #ff9d6f;        &#125;        .box2 &#123;            width: 100px;            height: 100px;            background-color: #8000ff;            visibility: hidden;        &#125;        .box3 &#123;            width: 100px;            height: 100px;            background-color: #ff2f97;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;&lt;/div&gt;        &lt;div class=\"box2\"&gt;&lt;/div&gt;        &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\noverflowoverflow 和上面两个的作用就不太一样了，它主要用于设置当对象的内容超过其指定高度及宽度时如何管理内容。\n\noverflow: visible：默认值，不剪切内容，也不添加滚动条。\noverflow: auto：超出自动添加滚动条，否则不加\noverflow: hidden：超出部分隐藏掉\noverflow: scroll：不管是否超出，都显示滚动条\n\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        [class^=box] &#123;            display: inline-block;            width: 100px;            height: 100px;            background-color: #ff9d6f;            vertical-align: top;        &#125;        .content &#123;            margin: 10px auto;            width: 30px;            height: 200px;            background-color: #4ed869;        &#125;        .box1 &#123;            overflow: visible;        &#125;        .box2 &#123;            overflow: auto;        &#125;        .box3 &#123;            overflow: hidden;        &#125;        .box4 &#123;            overflow: scroll;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box1\"&gt;        &lt;div class=\"content\"&gt;&lt;/div&gt;    &lt;/div&gt;    &lt;div class=\"box2\"&gt;        &lt;div class=\"content\"&gt;&lt;/div&gt;    &lt;/div&gt;    &lt;div class=\"box3\"&gt;        &lt;div class=\"content\"&gt;&lt;/div&gt;    &lt;/div&gt;    &lt;div class=\"box4\"&gt;        &lt;div class=\"content\"&gt;&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n屏幕与像素常用单位页面开发中，我们用的最多的就是使用 px 作为单位来编写样式了，偶尔也会用到百分比来写一些元素自适应父元素的样式。但是在移动开发中，为了让一套页面可以适应多套屏幕尺寸，px 就不太适用了。\n\n图中可以看到，当我们给元素设置宽高时，IDE 给我们显示出了所有可用的单位。\n单位描述%相对于父元素相同属性的百分比。px像素点，跟屏幕的物理性质相关。in英寸，跟 px 的换算是 1in == 96px （基于屏幕为 96 DPI计算）cm厘米，并非生活中的厘米，这里 1cm == 37.8pxmm毫米，1mm == .1cm == 3.78pxem基于当前容器的字体大小，font-size 是多少，1em就是多少rem与 em 类似，不过 rem 是基于根元素（html）的字体大小pt印刷行业常用单位，1pt == 1/72英寸\n\n屏幕 DPI（PPI）现在电脑屏幕的主流分辨率都是 1920 × 1080 了，而手机屏幕也大多都是这个分辨率，那么电脑上看到的 100px 和手机看到的 100px 能一样长吗？答案当然是不一样。\n\n我们常用英寸来表示屏幕尺寸（屏幕对角线长度），比如现在手机屏幕尺寸大多都是 5.5 英寸，笔记本电脑的屏幕有 13英寸、15英等，显示器的尺寸就更大了，21英寸、23英寸、甚至现在的电视剧都 55英寸以上。屏幕分辨率则以像素作度量的，屏幕分辨率这些年也越来越高，当年的 720p 的屏幕，现在 1080p 的分辨率是主流，甚至高端产品有 2k 屏甚至 4k 屏。\n屏幕尺寸的不同和分辨率的不同，则构成了各种设备的差异。DPI 是硬刷行业中用来表示打印机每英寸可以喷的墨汁点数，显示器也借鉴了这个概念，不过是将墨汁点换成了像素。屏幕英寸一般指对角线，在知道屏幕宽和高的像素后，可以通过勾股定理计算出每英寸可容纳的像素点，这个就是 DPI（PPI）。\n\nfunction ppi(w,h,n)&#123;    let p = Math.sqrt(w**2+h**2) / n    return Math.round(p)&#125;\n我们以 23 英寸的显示器屏幕，1920 × 1080 的分辨率，计算下这个屏幕的 DPI（PPI）：\n&gt; console.log(ppi(1920,1080,23))\n&lt; 96\n所以上面常用单位中的 1 英寸是以 96px 来计算的，再计算下我当前手机的 DPI（PPI）：\n&gt; ppi(1920,1080,5.5)\n&lt; 401\n\n和在手机上查询到的的确相同。如果想让显示器上通过肉眼看到的元素大小和手机屏幕上看到的元素大小差不多，那么理论上就需要让手机上的元素增大 401/96 倍，但实际并没有这么简单，影响手机上显示元素的大小和电脑上显示不同的因素还有很多。\n设备独立像素前面讲到的显示器分辨率 1920 × 1080 这个指实际的物理像素，是屏幕渲染图像的最小单位。而我们在 CSS 中编写的 px 实际上是一种逻辑上的像素。这个逻辑上的像素就是设备独立像素，可以由操作系统或浏览器来管理物理像和素设备独立像素的比例（DPR）。通过 BOM 的 devicePixelRatio 属性可以查询到物理像素和设备独立像素的实际比例：\n&gt; window.screen.width\n&lt; 1920\n&gt; window.screen.height\n&lt; 1080\n&gt; window.devicePixelRatio\n&lt; 1\n默认是 1:1，所以我们在 CSS 样式中写的 100px 和实际物理像素是相同的。当我们在页面上调整缩放比例时，页面元素也跟着变化。当缩放比达到 2 倍的时候，设备独立像素是物理像素的 4 倍：(200×200)/(100×100)。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        * &#123;            margin: 0;            padding: 0;        &#125;        div &#123;            display: inline-block;        &#125;        .box &#123;            width: 100px;            height: 100px;            background-color: #23d3e7;        &#125;     &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\nDPR（物理像素/设备独立像素）控制着由我们在 CSS 中编写的 px 到物理像素的映射比例：\n\n当设备像素比为1:1时，使用1（1×1）个设备像素显示1个CSS像素\n当设备像素比为2:1时，使用4（2×2）个设备像素显示1个CSS像素\n当设备像素比为3:1时，使用9（3×3）个设备像素显示1个CSS像素\n\n\n这样，在相同尺寸高清屏上和普通屏上，通过不同的 DPR 就可以让两个元素看起来大小差不多了。而设备独立像素和 DPR 就是为了解决随着技术发展，屏幕不断更新，不同 DPI（PPI）的屏幕显示图像大小差距的问题。\n智能手机和平板设备，厂家在设备出厂时已经预设好了 DPR，同样可以通过 window.devicePixelRatio 来获取。需要注意的是，大多数的移动设备通过 window.screen.width 和 window.screen.height 无法像 PC 设备一样获取准确的屏幕物理像素！\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt;    &lt;p class=\"info\"&gt;&lt;/p&gt;    &lt;script&gt;        let info = document.querySelector(\".info\")        info.innerHTML = \"\"        info.innerHTML += \"devicePixelRatio: \" + window.devicePixelRatio        info.innerHTML += \"&lt;br&gt;screen.width: \" + window.screen.width        info.innerHTML += \"&lt;br&gt;screen.height: \" + window.screen.height        info.innerHTML += \"&lt;br&gt;documentElement.clientWidth: \" +                             document.documentElement.clientWidth;        info.innerHTML += \"&lt;br&gt;documentElement.clientHeight: \" +                             document.documentElement.clientHeight;    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\nApple 6s Plus:\nVivo X9:\n浏览器上，通过 window.screen 获取了屏幕的物理像素，通过 window.documentElement 获取了页面文档的像素尺寸。而在手机上，却获取了两对奇怪的值。安卓手机的不难发现，screen.width × devicePixelRatio 刚好等于物理像素的 1080，screen.height × devicePixelRatio 刚好等于物理像素的 1920，而苹果手机则设置的大了一些。这个就涉及到了视口的概念。\n视口（viewport）视口的概念是在移动设备才存在的。由于移动设备的屏幕一般都比较小，而且大部分网站都是为 PC 端准备的，移动设备不得不做一些处理才能让 PC 的页面正常显示在手机上。\n布局视口布局视口（layout viewpoer）是指我们可以进行页面布局的区域，相当于浏览器的窗口大小决定页面如何布局。移动设备的浏览器窗口是没法改变大小的，默认宽度就是屏幕的宽度。但是移动厂商并没有直接将屏幕的物理像素宽度直接给布局视口用，而是使用了一个默认值，并允许我们自行设置。这个值在大多数的设备上都是 980px 也就是我们通过 document.documentElement.clientWidth 获取的值。一般情况下我们都不关心页面的高度，因为如果高度超出会自动出现滚动条。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        * &#123;            margin: 0;            padding: 0;        &#125;        div &#123;            width: 245px;            height: 200px;            float: left;        &#125;        .box1 &#123;            background-color: #23d3e7;        &#125;         .box2 &#123;            background-color: #2b2bff;        &#125;        .box3 &#123;            background-color: #777777;        &#125;        .box4 &#123;            background-color: #ff3e9e;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box1\"&gt;&lt;/div&gt;    &lt;div class=\"box2\"&gt;&lt;/div&gt;    &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;div class=\"box4\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n4 个宽度为 245px 的盒子刚好平铺一行，当我们把其中一个盒子的宽度增加 1 像素，立马最后一个盒子被挤下去了：\n\n稍后再讲如何自定义这个值。\n理想视口理想视口（ideal viewport）是设备的屏幕区域，是以设备的独立像素作为单位，并由 devicePixelRatio 的值自动映射为屏幕物理像素。这个值是不可能被改变的，我们可以通过 window.screen.width 和 window.screen.height 来获取。这也刚好解释了为什么获取到的值刚好或差不多比屏幕物理像素小 devicePixelRatio 倍。\n至于为什么选择 360px，375px 这样的值，大概是因为智能手机刚发展的时候屏幕物理像素大部分都是 480*320px，之后手机屏幕的技术发展，出现了 960*640px 到 1920*1080px 甚至 2K 屏的时候，为了页面尺寸兼容以前的手机，所以 devicePixelRatio 由 1 变成了 2，然后变成了 3 又变成了 4。\n视口控制我们可以在 head 标签中添加 &lt;meta name=&quot;viewport&quot; content=&quot;&quot;&gt; 来对页面进行控制。可以控制的属性如下表：\n\n\n\n属性\n可取值\n含义\n\n\n\n\nwidth\n数值或 device-width\nlayout viewport 的宽度\n\n\nheight\n数值或 device-width\nlayout viewport 的高度\n\n\ninitital-scale\n数值，可以是小数\n页面的初始缩放值\n\n\nmaximum-scale\n数值，可以是小数\n允许用户最大缩放值\n\n\nminimum-scale\n数值，可以是小数\n允许用户最小缩放值\n\n\nuser-scalable\nno 或者 yes\n是否用户进行缩放\n\n\n\n移动端浏览器上，如果页面过大，要么出现滚动条，那么缩放显得很小。理想状态下应该是既不发生缩放，也不出现横向滚动条，看看如何通过配置实现吧。\n我们可以将 layout viewport 的宽度设置的和 ideal viewport 一样，这样就不会出现横向的滚动条了。设置方法是将 width 的值设置为 device-width：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;meta name=\"viewport\" content=\"width=device-width\"&gt;    &lt;style&gt;        * &#123;            margin: 0;            padding: 0;        &#125;        div &#123;            width: 100px;            height: 100px;            float: left;        &#125;        .box1 &#123;            background-color: #23d3e7;        &#125;         .box2 &#123;            background-color: #2b2bff;        &#125;        .box3 &#123;            background-color: #777777;        &#125;        .box4 &#123;            background-color: #ff3e9e;        &#125;        p &#123;            clear: both;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"box1\"&gt;&lt;/div&gt;    &lt;div class=\"box2\"&gt;&lt;/div&gt;    &lt;div class=\"box3\"&gt;&lt;/div&gt;    &lt;div class=\"box4\"&gt;&lt;/div&gt;    &lt;p class=\"info\"&gt;&lt;/p&gt;    &lt;script&gt;        let info = document.querySelector(\".info\")        info.innerHTML = \"\"        info.innerHTML += \"devicePixelRatio: \" + window.devicePixelRatio        info.innerHTML += \"&lt;br&gt;screen.width: \" + window.screen.width        info.innerHTML += \"&lt;br&gt;screen.height: \" + window.screen.height        info.innerHTML += \"&lt;br&gt;documentElement.clientWidth: \" +                             document.documentElement.clientWidth;        info.innerHTML += \"&lt;br&gt;documentElement.clientHeight: \" +                             document.documentElement.clientHeight;    &lt;/script&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n可以看到，4 个盒子的宽度是 100px 但是页面只有 360px，所以最后一个盒子被挤到了下面，接下来将 width 的值设置为 400：\n&lt;meta name=\"viewport\" content=\"width=400\"&gt;\n\n还有一个 initital-scale 可以设置 layout viewport，它的值是页面初始的缩放比例，相当于 ideal viewport / layout viewport，所以 width=device-width 就相当于 initial-scale=1。如果值为一般为了兼容性问题，这两个属性都要写。\nmaximum-scale 和 minimum-scale 是允许用户最大和最小的缩放值，超过或小于设置的值，用户就没法继续放大或缩小页面了。\n还有一个比较常用的设置是 user-scalable，将它设置为 no 的时候用户就没法用双指对页面进行缩放了。添加新的设置无需创建新的 meta 标签，用逗号分隔，直接写到一起即可：\n&lt;meta name=\"viewport\" content=\"width=device-width,initial-scale=0.5,user-scalable=no\"&gt;\n页面布局随着设备越来越丰富，传统 PC 页面并不能完美的展现在各种屏幕上，为不同的设备再单独开发一套页面来成本也比较大，那么如何让一套页面适应各种屏幕就非常重要了。除了传统的 PC 页面静态布局方式之外，移动互联网的发展也促进了布局方式的发展。\n流式布局流式布局（Liquid）是页面元素的宽度按照屏幕分辨率进行适配调整，但整体布局不变。代表作栅栏系统（网格系统）。网页中主要的划分区域的尺寸使用百分数（搭配 min-*、max-* 属性使用）。\n栅栏系统说到栅栏系统，就不得不说大名鼎鼎的 bootstrap。bootstrap 将整个页面或某个局部元素的行平均分成 12 等列，然后我们再分配好某个元素在不同的设备下的显示占 12 等列的具体多少列。然后通过媒体查询的方式对页面进行自适应。\n看一个例子： 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;link rel=\"stylesheet\" href=\"https://cdn.jsdelivr.net/npm/bootstrap@3.3.7/dist/css/bootstrap.min.css\"&gt;    &lt;style&gt;        .row &gt; div &#123;            border: 1px solid #c9c1d5;            border-radius: 5px;            height: 50px;        &#125;        .row &gt; div:nth-last-of-type(2n)&#123;            background-color: #ccc;        &#125;        .row &#123;            margin-bottom: 20px;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"container-fluid\"&gt;        &lt;div class=\"row\"&gt;                &lt;div class=\"col-md-1 col-sm-3 col-xs-6\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 col-sm-3 col-xs-6\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 col-sm-3 hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 col-sm-3 hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 hidden-sm hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 hidden-sm hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 hidden-sm hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 hidden-sm hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 hidden-sm hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 hidden-sm hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 hidden-sm hidden-xs\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-1 hidden-sm hidden-xs\"&gt;&lt;/div&gt;            &lt;/div&gt;            &lt;div class=\"row\"&gt;                &lt;div class=\"col-md-8 col-sm-4\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-4 col-sm-8 hidden-xs\"&gt;&lt;/div&gt;            &lt;/div&gt;            &lt;div class=\"row\"&gt;                &lt;div class=\"col-md-3 col-sm-4 col-xs-6\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-3 col-sm-4 col-xs-6\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-3 col-sm-4 col-xs-6\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-3 col-sm-4 col-xs-6\"&gt;&lt;/div&gt;            &lt;/div&gt;                &lt;div class=\"row\"&gt;                &lt;div class=\"col-md-6\"&gt;&lt;/div&gt;                &lt;div class=\"col-md-6 hidden-sm hidden-xs\"&gt;&lt;/div&gt;            &lt;/div&gt;        &lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n可以通过类名的方式设置页面元素在哪种屏幕下所占的比例是多少，以及在哪种屏幕下隐藏元素。没有隐藏的元素，当屏幕不够时会自动换行显示。具体的细节可以翻阅 bootstrap 中文文档\nFlex布局2009 年的时候，W3C 提出了 Flex 布局，可以非常方便快捷的实现各种页面布局，并且还是响应式的。目前PC 端，如果页面要求兼容 IE10 以下，那么 Flex 布局就不要想了，但是现在的移动端几乎全部支持 Flex。\nFlex 意为弹性盒子，任何一个盒子将 display 设置为 flex 都可以指定为 Flex 布局，行内元素也可以设置为 inline-flex 来使用 Flex 布局。Flex 自成 BFC 区域，所以只会影响到当前的盒子。设为 Flex 布局后，子元素就无法使用 float，clear，vertical-align 属性了。\n基本概念\n\n主轴：Flex 的子元素默认按照主轴的方向从左往右排列\n侧轴：与主轴垂直的轴，默认从上到下。\n\n当给父容器设置为 Flex 布局后，子元素都转为了 Flex 项目，并且在父容器内按主轴排列。每个子元素占主轴的空间叫主轴尺寸，占侧轴的空间叫侧轴尺寸。\n先来体验一下 Flex 布局：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 80%;            height: 300px;            border: 1px solid blue;            margin: 100px auto;            display: flex;            text-align: center;        &#125;        [class^=box]&#123;            font-size: 24px;            color: #808080        &#125;        .box1 &#123;            background-color: #f4a8b9;            width: 100px;        &#125;        .box2 &#123;            background-color: #bdaeee;            flex: 2;        &#125;        .box3 &#123;            background-color: #77c5ee;            flex: 1;        &#125;        .box4 &#123;            background-color: #aef1ab;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;1&lt;/div&gt;        &lt;div class=\"box2\"&gt;2&lt;/div&gt;        &lt;div class=\"box3\"&gt;3&lt;/div&gt;        &lt;div class=\"box4\"&gt;内容撑开盒子&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n首先给 box1 设置了固定的宽高，那么它就会独占这么多空间，box2 通过 flex 设置它占据 Flex 容器的 2 份剩余空间，box3 占据 1 份 Flex 容器的剩余空间。之所以是剩余空间，因为 Flex 会优先给设置了固定宽高以及内容撑开的盒子分配空间，之后才会将剩余空间按照 flex 指定的份数继续分配。不过若是给 box1 也设置了 flex 属性，那么给 box1 手动设置的宽高将失效！\n当对窗体进行拉伸，改变了父容器的大小时，子元素也会自动适应。这就是为什么叫弹性盒子的原因了。\n排列方向默认 4 个盒子的排列方向是从左往右，我们也可以改成从右向左，从上到下甚至从下到上。通过 flex-direction 属性可以实现，默认属性值是 row。\n从右向左排列给父容器添加 flex-direction: row-reverse：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-direction: row-reverse;&#125;\n\n盒子主轴起始方向变成了右边。\n从上向下排列将父容器的 flex-direction 设置为 column 原来的侧轴就变成了主轴，元素将默认从上向下排列：\n.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-direction: column;&#125;\n\n.box1 由于固定了宽度，因为空出一大片空白。\n从下往上排列将父容器的 flex-direction 设置为 column-reverse：\n.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-direction: column-reverse;&#125;\n\n调整主轴对齐如果子元素没有占满父元素，那么就会留下空白。这种情况我们就能调整子元素间如何对齐\njustify-content 属性用来调整子元素在主轴上的对齐方式，目前可用的值有 6 个：flex-start、flex-end、center、space-between、space-around、space-evenly。\n一定要注意，调整主轴对齐会受主轴方向的影响！（flex-direction）。\n主轴开始位置对齐 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 80%;            height: 300px;            border: 1px solid blue;            margin: 100px auto;            display: flex;            text-align: center;            justify-content: flex-start;        &#125;        [class^=box]&#123;            font-size: 24px;            color: #808080;            width: 100px;            height: 100px;        &#125;        .box1 &#123;            background-color: #f4a8b9;        &#125;        .box2 &#123;            background-color: #bdaeee;        &#125;        .box3 &#123;            background-color: #77c5ee;        &#125;        .box4 &#123;            background-color: #aef1ab;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;1&lt;/div&gt;        &lt;div class=\"box2\"&gt;2&lt;/div&gt;        &lt;div class=\"box3\"&gt;3&lt;/div&gt;        &lt;div class=\"box4\"&gt;4&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n默认就是 flex-start 对齐。\n主轴结束位置对齐将父容器的 justify-content 设置为 flex-end：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    justify-content: flex-end;&#125;\n\n主轴中间位置对齐将父容器的 justify-content 设置为 center：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    justify-content: center;&#125;\n\n空白在子元素之间将父容器的 justify-content 设置为 space-between：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    justify-content: space-between;&#125;\n\n空白环绕子元素将父容器的 justify-content 设置为 space-around：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    justify-content: space-around;&#125;\n\n子元素平分空白区域将父容器的 justify-content 设置为 space-evenly：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    justify-content: space-evenly;&#125;\n\n这个和 space-around 有点像，不同的是 space-around 子元素的两边空白相等，所以两个子元素中间就有两倍的空白。而 space-evenly 子元素之间和父容器之间的空白都是相等的。\n调整侧轴对齐通过调整侧轴对齐相当于调整垂直方向的对齐方式，通过 align-items 来调整。默认值是 stretch，在没有给定子元素固定高度的情况下，会让子元素自动适应父容器的高度。如果设置为其他值，则子元素的高度由子元素的内容区域撑开。\n\n顶部对其将父容器的 align-items 设置为 flex-start。如果没有给子元素指定高度，则默认由子元素内容区域撑开：\n.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    justify-content: space-evenly;    align-items: flex-start;&#125;\n\n底部对齐将父容器的 align-items 设置为 flex-end：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    justify-content: space-evenly;    align-items: flex-end;&#125;\n\n垂直居中对齐将父容器的 align-items 设置为 center：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    justify-content: space-evenly;    align-items: center;&#125;\n\n换行规则如果子元素过多，总宽度超过父容器的宽度了，默认是不会换行的，所有的盒子会挤到一起。可以通过 flex-wrap 来改变这个规则。flex-wrap 只有三个值：nowrap，wrap，wrap-reverse。\n还有一个 flex-flow 相当于 flex-direction 和 flex-wrap 的综合体，可以同时对这两个属性的值进行设置。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 80%;            height: 300px;            border: 1px solid blue;            margin: 100px auto;            display: flex;            text-align: center;        &#125;        [class^=box]&#123;            font-size: 24px;            color: #808080;            width: 100px;            height: 100px;        &#125;        .box1 &#123;            background-color: #f4a8b9;        &#125;        .box2 &#123;            background-color: #bdaeee;        &#125;        .box3 &#123;            background-color: #77c5ee;        &#125;        .box4 &#123;            background-color: #aef1ab;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;1&lt;/div&gt;        &lt;div class=\"box2\"&gt;2&lt;/div&gt;        &lt;div class=\"box3\"&gt;3&lt;/div&gt;        &lt;div class=\"box4\"&gt;4&lt;/div&gt;        &lt;div class=\"box1\"&gt;5&lt;/div&gt;        &lt;div class=\"box2\"&gt;6&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n添加两个盒子，盒子的宽度被自动压缩了：\n\n正常换行将父容器的 flex-wrap 设置为 wrap：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-wrap: wrap;&#125;\n\n反转换行将父容器的 flex-wrap 设置为 wrap-reverse：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-wrap: wrap-reverse;&#125;\n\n多行情况下的侧轴对齐前面讲到的 align-items 是设置只有单行情况下的侧轴对齐，还有一个 align-content 用来设置多行情况下的侧轴对其。align-content 的使用必须在 flex-direction: row 和 flex-wrap: wrap 或 flex-wrap: wrap-reverse 的情况下才可以使用。\n与 align-items 的性质也一样，默认 stretch，子元素没设置高度会自动拉伸。\n.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-flow: row wrap;&#125;\n\n顶部对齐将父容器的 align-content 设置为 flex-start：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-flow: row wrap;    align-content: flex-start;&#125;\n\n中心对齐将父容器的 align-content 设置为 center：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-flow: row wrap;    align-content: center;&#125;\n\n底部对齐将父容器的 align-content 设置为 flex-end：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-flow: row wrap;    align-content: flex-end;&#125;\n\n各行之间留空将父容器的 align-content 设置为 space-between：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-flow: row wrap;    align-content: space-between;&#125;\n\n各行前后都留空将父容器的 align-content 设置为 space-around：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-flow: row wrap;    align-content: space-around;&#125;\n\n各行平分空白将父容器的 align-content 设置为 space-evenly：.father &#123;    width: 80%;    height: 300px;    border: 1px solid blue;    margin: 100px auto;    display: flex;    text-align: center;    flex-flow: row wrap;    align-content: space-evenly;&#125;\n\n子元素的一些属性上面讲到的属性都是应用与父容器的，通过各种属性的配置已经可以实现很多复杂的布局。还有一些用于子元素的属性，可以让 Flex 布局的灵活性更高一层。\n调整子元素顺序给子元素的 order 属性设置不同的值，值越大的越靠后，默认是 0 。\n.box3 &#123;    background-color: #77c5ee;    order: -1&#125;\n只给 .box3 应用了 order 属性，-1 比其他子元素的 order 都小，所以会排在第一个：\n\n子元素放大比例使用 flex-grow 可以配置当某一行拥有剩余空间的话，将某个元素放大到剩余空间的倍数。值默认是 0 ，不进行放大。\n.box4 &#123;    background-color: #aef1ab;    flex-grow: 0.5;&#125;\n\n0.5 倍表示如果一行的剩余空间为 80px 那么 .box4 最多会被放大到 140px，因为剩余空间的 0.5 倍是 40px。\n子元素缩小比例使用 flex-shrink 设置一行空间不足时，子元素自动缩小的比例。默认是 1。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 80%;            height: 300px;            border: 1px solid blue;            margin: 100px auto;            display: flex;            text-align: center;        &#125;        [class^=box]&#123;            font-size: 24px;            color: #808080;            width: 100px;            flex-shrink: 1;        &#125;        .box1 &#123;            background-color: #f4a8b9;        &#125;        .box2 &#123;            background-color: #bdaeee;        &#125;        .box3 &#123;            background-color: #77c5ee;            order: -1        &#125;        .box4 &#123;            background-color: #aef1ab;            flex-shrink: 0;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;1&lt;/div&gt;        &lt;div class=\"box2\"&gt;2&lt;/div&gt;        &lt;div class=\"box3\"&gt;3&lt;/div&gt;        &lt;div class=\"box4\"&gt;4&lt;/div&gt;        &lt;div class=\"box1\"&gt;5&lt;/div&gt;        &lt;div class=\"box2\"&gt;6&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n当其他元素的 flex-shrink 为 1，.box4 为 0 的时候，如果没有剩余空间，那么其他元素都会缩小，而 .box4 不会。\n子元素占据固定空间flex-basis 属性定义了分配多余空间之前，项目占据的主轴空间尺寸。如果 flex-direction 是 row，那么 flex-basic就相当于 width，如果 flex-direction 是 column，它就相当于 height。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 80%;            height: 300px;            border: 1px solid blue;            margin: 100px auto;            display: flex;            text-align: center;            flex-flow: column wrap;            align-content: space-evenly;        &#125;        [class^=box]&#123;            font-size: 24px;            color: #808080;            width: 100px;            flex-basis: 120px;        &#125;        .box1 &#123;            background-color: #f4a8b9;        &#125;        .box2 &#123;            background-color: #bdaeee;        &#125;        .box3 &#123;            background-color: #77c5ee;            order: -1        &#125;        .box4 &#123;            background-color: #aef1ab;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;1&lt;/div&gt;        &lt;div class=\"box2\"&gt;2&lt;/div&gt;        &lt;div class=\"box3\"&gt;3&lt;/div&gt;        &lt;div class=\"box4\"&gt;4&lt;/div&gt;        &lt;div class=\"box1\"&gt;5&lt;/div&gt;        &lt;div class=\"box2\"&gt;6&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n子元素所占空余空间份数flex 属性设置子元素占据空余空间的份数，这个在 Flex 布局的刚开始就演示了，这里就不再多说。\n子元素设置特有的对齐方式默认子元素的对齐方式是从父容器的 align-items 继承来的，通过 align-self 属性来进行设置，值是 auto。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;meta charset=\"UTF-8\"&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;style&gt;        .father &#123;            width: 80%;            height: 300px;            border: 1px solid blue;            margin: 100px auto;            display: flex;            text-align: center;            flex-flow: row wrap;            align-items: flex-start;        &#125;        [class^=box]&#123;            font-size: 24px;            color: #808080;            width: 100px;            height: 100px;        &#125;        .box1 &#123;            background-color: #f4a8b9;        &#125;        .box2 &#123;            background-color: #bdaeee;        &#125;        .box3 &#123;            background-color: #77c5ee;            align-self: flex-end;        &#125;        .box4 &#123;            background-color: #aef1ab;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;    &lt;div class=\"father\"&gt;        &lt;div class=\"box1\"&gt;1&lt;/div&gt;        &lt;div class=\"box2\"&gt;2&lt;/div&gt;        &lt;div class=\"box3\"&gt;3&lt;/div&gt;        &lt;div class=\"box4\"&gt;4&lt;/div&gt;    &lt;/div&gt;&lt;/body&gt;&lt;/html&gt;\n\n\n\n媒体查询基本概念媒体查询是响应式开发中重要的知识点，比如 bootstrap 的响应式布局本质上就是借助媒体查询实现的，那么到底什么是媒体查询呢？其实就是查询屏幕的宽度，然后针对不同的屏幕宽度设置不同的样式来适应不同的屏幕。简单来说，就是给不同屏幕尺寸编写不同的样式，然后 CSS 会自动根据实际的屏幕来应用我们预先编写好的样式。\nbootstrap 中给不同的设备预定义了一些尺寸，这些只是作为建议：\n\n\n\n设备\n尺寸\n\n\n\n\n超小屏幕，手机等设备\nw &lt; 768px\n\n\n小屏设备，平板等设备\n768 &lt;= w &lt; 992\n\n\n中等屏幕，桌面显示器等设备\n992 &lt;= w &lt; 1200\n\n\n超大屏幕，大型的显示器\nw &gt;= 1200\n\n\n\n语法规则@media mediatype and|not|only (media feature) &#123;    CSS-Code;&#125;\n或者针对不同的媒体使用不同的外部样式表：\n&lt;link rel=\"stylesheet\" media=\"mediatype and|not|only (media feature)\" href=\"mystylesheet.css\"&gt;\nmediatype 的可选值除了已经废弃的有如下几种：\n\n\n\n值\n说明\n\n\n\n\nall\n用于所有设备\n\n\nprint\n用于打印机\n\n\nscreen\n用于电脑屏幕、平板电脑、手机等\n\n\nspeech\n应用于屏幕阅读器等发声设备\n\n\n\nand|not|only 实现简单的逻辑，媒体功能（media feature）最常用的就是 min-width 和 max-width 了。\n接下来看看具体如何编写媒体查询吧。\n自适应实现我们现在要编写一套和 bootstrap 一样的媒体查询功能，首先编写屏幕像素小于 768px 的媒体查询：\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\"&gt;    &lt;style&gt;        @media screen and (max-width: 768px) &#123;            body &#123;                background-color: #b4e9bd;            &#125;        &#125;    &lt;/style&gt;&lt;/head&gt;&lt;body&gt;&lt;/body&gt;&lt;/html&gt;\n这条规则白话文来说就是：如果我们在使用电脑或手机屏幕，并且屏幕的尺寸最大 768px，那么就将页面的背景变成淡绿色。接下来添加大于 768px 小于 992px 的规则：\n&lt;style&gt;    @media screen and (max-width: 768px) &#123;        body &#123;            background-color: #b4e9bd;        &#125;    &#125;    @media screen and (min-width: 768px) and (max-width: 992px) &#123;        body &#123;          background-color: #f4a8b9;        &#125;    &#125;&lt;/style&gt;\n这条规则意思是：当屏幕尺寸最小 768px 并且最大 992px 的时候，将页面背景变成淡红色。接下来添加大于 992px 小于 1200px 的规则：\n&lt;style&gt;    @media screen and (max-width: 768px) &#123;        body &#123;            background-color: #b4e9bd;        &#125;    &#125;    @media screen and (min-width: 768px) and (max-width: 992px) &#123;        body &#123;            background-color: #f4a8b9;        &#125;    &#125;    @media screen and (min-width: 992px) and (max-width: 1200px) &#123;        body &#123;            background-color: #f4a8b9;        &#125;    &#125;&lt;/style&gt;\n当屏幕尺寸最小 992px 并且最大 1200px 的时候，将页面背景变成淡紫色。屏幕尺寸大于 1200px 的规则：\n&lt;style&gt;    @media screen and (max-width: 768px) &#123;        body &#123;            background-color: #b4e9bd;        &#125;    &#125;    @media screen and (min-width: 768px) and (max-width: 992px) &#123;        body &#123;            background-color: #f4a8b9;        &#125;    &#125;    @media screen and (min-width: 992px) and (max-width: 1200px) &#123;        body &#123;            background-color: #f4a8b9;        &#125;    &#125;    @media screen and (min-width: 1200px) &#123;        body &#123;          background-color: #77c5ee;        &#125;      &#125;&lt;/style&gt;\n屏幕大于 1200px 时，页面背景变成淡蓝色，接下来看看实际表现如何：\n\n代码优化上面的代码虽然已经实现了我们希望的功能，但是一般并不会这么啰嗦的写。我们可以借助设置默认样式和 CSS 的样式覆盖特性来简化代码：\n&lt;style&gt;    body &#123;        background-color: #b4e9bd;    &#125;    @media screen and (min-width: 768px)&#123;        body &#123;        background-color: #f4a8b9;        &#125;    &#125;    @media screen and (min-width: 992px) &#123;        body &#123;        background-color: #bdaeee;        &#125;    &#125;    @media screen and (min-width: 1200px) &#123;        body &#123;        background-color: #77c5ee;        &#125;    &#125;&lt;/style&gt;\n我们先设置个默认的背景色，然后随着屏幕尺寸变大，当满足大于 768px 的时候，就自动应用了相应的样式并覆盖掉默认的样式。接着屏幕继续变大，当满足大于 992px 的时候，又将大于 768px 的样式覆盖掉。以此类推，当屏幕大于 1200px 的时候就没有可以覆盖掉它的媒体查询了。\n媒体查询有好处也有坏处，坏处就是移动端和桌面端所需要的样式是并不相同的，甚至移动端有一些页面元素也不需要显示，但是依然会将所有的代码都下载下来，甚至不需要显示的一些图片等资源也会被下载下来。\nrem布局rem 屏幕与像素的一章中有讲到，是一个尺寸单位。有一个与它类似的单位是 em，这个单位与 px 的换算基于当前容器的字号，则字号所以经常被用在段落首行缩进上：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;  &lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /&gt;    &lt;style&gt;        div &#123;            text-indent: 2em;        &#125;    &lt;/style&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;div&gt;        这是一段话。这是一段话。这是一段话。        这是一段话。这是一段话。这是一段话。        这是一段话。这是一段话。这是一段话。        这是一段话。这是一段话。这是一段话。    &lt;/div&gt;    &lt;div&gt;        这是一段话。这是一段话。这是一段话。        这是一段话。这是一段话。这是一段话。    &lt;/div&gt;  &lt;/body&gt;&lt;/html&gt;\n\n\n\n但是 em 并不适合布局，浏览器默认字号是 16px，但是每一个页面元素的字号并不全部相同，那么 1em 在不同的元素中可能都不相同，会给我们带来换算上的麻烦。而 rem 基于根标签（html）的字号，这样整个页面中 1rem 的值每个元素中都是相同的。\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;  &lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /&gt;    &lt;style&gt;        html &#123;            font-size: 20px;        &#125;        .box &#123;            width: 10rem;            height: 10rem;            background-color: #69ccf1;            position: relative;            top: 100px;            left: 100px;        &#125;    &lt;/style&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;  &lt;/body&gt;&lt;/html&gt;\n\n\n\n将 html 的字号改为 20px，10rem 的确相当于 200px。这样的好处是什么呢，那就是我们可以只更改根元素的字号，就可以让页面其他使用 rem 的元素都进行改变而不用改它们的样式。最简单的方法就是配合媒体查询，不同的屏幕像素，然后给根元素一个不同的字号。\n这个字号该如何计算呢？这个并没有一个标准，我们可以将屏幕分成 20 份，然后将每一份的值做为字号。比如移动端如果 viewport 的 device-width 为 360 像素，我们就可以将字号设置为 360 / 20 = 18px。下面看代码实现：\n 点击显示/隐藏代码\n&lt;!DOCTYPE html&gt;&lt;html lang=\"en\"&gt;  &lt;head&gt;    &lt;title&gt;Document&lt;/title&gt;    &lt;meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" /&gt;    &lt;style&gt;        @media screen and (device-width: 360px) &#123;            html &#123;                font-size: 18px;            &#125;        &#125;        @media screen and (device-width: 375px) &#123;            html &#123;                font-size: 18.75px;            &#125;        &#125;        @media screen and (device-width: 768px) &#123;            html &#123;                font-size: 38.4px;            &#125;        &#125;        .box &#123;            width: 10rem;            height: 10rem;            background-color: #69ccf1;            margin: 2em auto;        &#125;        .info &#123;            text-align: center;        &#125;    &lt;/style&gt;  &lt;/head&gt;  &lt;body&gt;    &lt;div class=\"box\"&gt;&lt;/div&gt;    &lt;p class=\"info\"&gt;&lt;/p&gt;    &lt;script&gt;        let box = document.querySelector(\".box\")        let info = document.querySelector(\".info\")        info.innerHTML = \"box width: \" + box.clientWidth + \"&lt;/br&gt;\"        info.innerHTML += \"box height: \" + box.clientHeight + \"&lt;/br&gt;\"        info.innerHTML += \"screen width: \" + window.screen.width + \"&lt;/br&gt;\"        info.innerHTML += \"screen height: \" + window.screen.height + \"&lt;br&gt;\"    &lt;/script&gt;  &lt;/body&gt;&lt;/html&gt;\n\n\n安卓端显示：\n\n苹果手机显示：\n\niPad显示：\n\nPC端显示：\n\n由于 PC 端 Win10 的原因，对显示器进行了 1.25 的缩放，所以 1536 × 1.25 = 1920 才是实际的分辨率。\n附录\nbootstrap\nFlex - 阮一峰\n媒体查询\n\n","categories":["Web"],"tags":["web","css","flex"]},{"title":"Supervisor 进程管理工具","url":"/2019/08/27/2019/Supervisor%20%E8%BF%9B%E7%A8%8B%E7%AE%A1%E7%90%86%E5%B7%A5%E5%85%B7/","content":"简介\nSupervisor 是用 Python 开发的一个 C/S 架构的进程管理工具，只可以用 Linux/Unix 系统下。在 Linux 系统上，通常的做法是为每个需要控制的服务编写 rc.d 脚本，之后通过 service 或者 systemctl 来管理和控制服务，但是在程序崩溃的时候却无法自动重启项目。Supervisor 将它管理的服务作为它的子进程，所以可以简单且精确的管理和控制这些服务。官方文档\n\n\n环境\nSupervisor 仅支持 Linux/Unix 系统，推荐使用 Python 2.7 或 Python 3.4 之上的版本来运行 Supervisor。\n\n系统环境\n\n\n系统类型\n发行商\n版本号\n\n\n\n\nLinux\nUbuntu\n18.04.3\n\n\n\n软件环境\n\n\n软件\n版本\n\n\n\n\nPython\n3.6.8\n\n\nSupervisor\n4.0.4\n\n\n\n教程安装Ubuntu 可以直接通过 apt install supervisor 进行安装，但是这样安装的版本不会是最新版，并且还会安装一些其他依赖。这里选择适用性更广的虚拟环境来安装。\napt install python3-venv -y     # 安装 python3 虚拟环境库mkdir -p /data/venv             # 创建一个目录供放置虚拟环境cd /data/venvpython3 -m venv supervisor      # 创建一个叫 supervisor 的虚拟环境source /data/venv/supervisor/bin/activatepip install supervisor\n安装好之后，执行 supervisord -v 可以看到当前安装的版本号。\n(supervisor) root@ubuntu:/data/venv# supervisord -v\n4.0.4\n(supervisor) root@ubuntu:/data/venv#\n快速开始\n接下来演示 Supervisor 最基本的使用\n\n提供一个配置文件Supervisor 会首先在当前目录查找 supervisord.conf，如果没有找到 则会使用 /etc/supervisord.conf，如果此文件依然不存在，则会使用程序内置的配置。或者，我们可以用 -c 参数，来为 supervisor 指明一个配置文件。为了让进程运行的更清晰，建议通过 -c 参数来指明配置文件。\n接下来就是提供一个配置文件给 supervisor。supervisor 提供了一个 echo_supervisord_conf 的命令，此命令的执行会打印一个 supervisor 的模板示例。\necho_supervisord_conf\n以下是打印的配置文件示例内容：\n 点击显示/隐藏代码\n; Sample supervisor config file.;; For more information on the config file, please see:; http://supervisord.org/configuration.html;; Notes:;  - Shell expansion (\"~\" or \"$HOME\") is not supported.  Environment;    variables can be expanded using this syntax: \"%(ENV_HOME)s\".;  - Quotes around values are not supported, except in the case of;    the environment= options as shown below.;  - Comments must have a leading space: \"a=b ;comment\" not \"a=b;comment\".;  - Command will be truncated if it looks like a config file comment, e.g.;    \"command=bash -c 'foo ; bar'\" will truncate to \"command=bash -c 'foo \".;; Warning:;  Paths throughout this example file use /tmp because it is available on most;  systems.  You will likely need to change these to locations more appropriate;  for your system.  Some systems periodically delete older files in /tmp.;  Notably, if the socket file defined in the [unix_http_server] section below;  is deleted, supervisorctl will be unable to connect to supervisord.[unix_http_server]file=/tmp/supervisor.sock   ; the path to the socket file;chmod=0700                 ; socket file mode (default 0700);chown=nobody:nogroup       ; socket file uid:gid owner;username=user              ; default is no username (open server);password=123               ; default is no password (open server); Security Warning:;  The inet HTTP server is not enabled by default.  The inet HTTP server is;  enabled by uncommenting the [inet_http_server] section below.  The inet;  HTTP server is intended for use within a trusted environment only.  It;  should only be bound to localhost or only accessible from within an;  isolated, trusted network.  The inet HTTP server does not support any;  form of encryption.  The inet HTTP server does not use authentication;  by default (see the username= and password= options to add authentication).;  Never expose the inet HTTP server to the public internet.;[inet_http_server]         ; inet (TCP) server disabled by default;port=127.0.0.1:9001        ; ip_address:port specifier, *:port for all iface;username=user              ; default is no username (open server);password=123               ; default is no password (open server)[supervisord]logfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.loglogfile_maxbytes=50MB        ; max main logfile bytes b4 rotation; default 50MBlogfile_backups=10           ; # of main logfile backups; 0 means none, default 10loglevel=info                ; log level; default info; others: debug,warn,tracepidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pidnodaemon=false               ; start in foreground if true; default falseminfds=1024                  ; min. avail startup file descriptors; default 1024minprocs=200                 ; min. avail process descriptors;default 200;umask=022                   ; process file creation umask; default 022;user=supervisord            ; setuid to this UNIX account at startup; recommended if root;identifier=supervisor       ; supervisord identifier, default is 'supervisor';directory=/tmp              ; default is not to cd during start;nocleanup=true              ; don't clean up tempfiles at start; default false;childlogdir=/tmp            ; 'AUTO' child log dir, default $TEMP;environment=KEY=\"value\"     ; key value pairs to add to environment;strip_ansi=false            ; strip ansi escape codes in logs; def. false; The rpcinterface:supervisor section must remain in the config file for; RPC (supervisorctl/web interface) to work.  Additional interfaces may be; added by defining them in separate [rpcinterface:x] sections.[rpcinterface:supervisor]supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface; The supervisorctl section configures how supervisorctl will connect to; supervisord.  configure it match the settings in either the unix_http_server; or inet_http_server section.[supervisorctl]serverurl=unix:///tmp/supervisor.sock ; use a unix:// URL  for a unix socket;serverurl=http://127.0.0.1:9001 ; use an http:// url to specify an inet socket;username=chris              ; should be same as in [*_http_server] if set;password=123                ; should be same as in [*_http_server] if set;prompt=mysupervisor         ; cmd line prompt (default \"supervisor\");history_file=~/.sc_history  ; use readline history if available; The sample program section below shows all possible program subsection values.; Create one or more 'real' program: sections to be able to control them under; supervisor.;[program:theprogramname];command=/bin/cat              ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1                    ; number of processes copies to start (def 1);directory=/tmp                ; directory to cwd to before exec (def no cwd);umask=022                     ; umask for process (default None);priority=999                  ; the relative start priority (default 999);autostart=true                ; start at supervisord start (default: true);startsecs=1                   ; # of secs prog must stay up to be running (def. 1);startretries=3                ; max # of serial start failures when starting (default 3);autorestart=unexpected        ; when to restart if exited after running (def: unexpected);exitcodes=0                   ; 'expected' exit codes used with autorestart (default 0);stopsignal=QUIT               ; signal used to kill process (default TERM);stopwaitsecs=10               ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false             ; send stop signal to the UNIX process group (default false);killasgroup=false             ; SIGKILL the UNIX process group (def false);user=chrism                   ; setuid to this UNIX account to run the program;redirect_stderr=true          ; redirect proc stderr to stdout (default false);stdout_logfile=/a/path        ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10     ; # of stdout logfile backups (0 means none, default 10);stdout_capture_maxbytes=1MB   ; number of bytes in 'capturemode' (default 0);stdout_events_enabled=false   ; emit events on stdout writes (default false);stdout_syslog=false           ; send stdout to syslog with process name (default false);stderr_logfile=/a/path        ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10     ; # of stderr logfile backups (0 means none, default 10);stderr_capture_maxbytes=1MB   ; number of bytes in 'capturemode' (default 0);stderr_events_enabled=false   ; emit events on stderr writes (default false);stderr_syslog=false           ; send stderr to syslog with process name (default false);environment=A=\"1\",B=\"2\"       ; process environment additions (def no adds);serverurl=AUTO                ; override serverurl computation (childutils); The sample eventlistener section below shows all possible eventlistener; subsection values.  Create one or more 'real' eventlistener: sections to be; able to handle event notifications sent by supervisord.;[eventlistener:theeventlistenername];command=/bin/eventlistener    ; the program (relative uses PATH, can take args);process_name=%(program_name)s ; process_name expr (default %(program_name)s);numprocs=1                    ; number of processes copies to start (def 1);events=EVENT                  ; event notif. types to subscribe to (req'd);buffer_size=10                ; event buffer queue size (default 10);directory=/tmp                ; directory to cwd to before exec (def no cwd);umask=022                     ; umask for process (default None);priority=-1                   ; the relative start priority (default -1);autostart=true                ; start at supervisord start (default: true);startsecs=1                   ; # of secs prog must stay up to be running (def. 1);startretries=3                ; max # of serial start failures when starting (default 3);autorestart=unexpected        ; autorestart if exited after running (def: unexpected);exitcodes=0                   ; 'expected' exit codes used with autorestart (default 0);stopsignal=QUIT               ; signal used to kill process (default TERM);stopwaitsecs=10               ; max num secs to wait b4 SIGKILL (default 10);stopasgroup=false             ; send stop signal to the UNIX process group (default false);killasgroup=false             ; SIGKILL the UNIX process group (def false);user=chrism                   ; setuid to this UNIX account to run the program;redirect_stderr=false         ; redirect_stderr=true is not allowed for eventlisteners;stdout_logfile=/a/path        ; stdout log path, NONE for none; default AUTO;stdout_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB);stdout_logfile_backups=10     ; # of stdout logfile backups (0 means none, default 10);stdout_events_enabled=false   ; emit events on stdout writes (default false);stdout_syslog=false           ; send stdout to syslog with process name (default false);stderr_logfile=/a/path        ; stderr log path, NONE for none; default AUTO;stderr_logfile_maxbytes=1MB   ; max # logfile bytes b4 rotation (default 50MB);stderr_logfile_backups=10     ; # of stderr logfile backups (0 means none, default 10);stderr_events_enabled=false   ; emit events on stderr writes (default false);stderr_syslog=false           ; send stderr to syslog with process name (default false);environment=A=\"1\",B=\"2\"       ; process environment additions;serverurl=AUTO                ; override serverurl computation (childutils); The sample group section below shows all possible group values.  Create one; or more 'real' group: sections to create \"heterogeneous\" process groups.;[group:thegroupname];programs=progname1,progname2  ; each refers to 'x' in [program:x] definitions;priority=999                  ; the relative start priority (default 999); The [include] section can just contain the \"files\" setting.  This; setting can list multiple files (separated by whitespace or; newlines).  It can also contain wildcards.  The filenames are; interpreted as relative to this file.  Included files *cannot*; include files themselves.;[include];files = relative/directory/*.ini\n\n\n为了方便查看配置，这里只写入没有被注释掉的配置项到配置文件：\necho_supervisord_conf |grep -v '^;' |uniq &gt; /etc/supervisord.confcat /etc/supervisord.conf\n以下是配置文件内容：\n[unix_http_server]\nfile=/tmp/supervisor.sock   ; the path to the socket file\n\n[supervisord]\nlogfile=/tmp/supervisord.log ; main log file; default $CWD/supervisord.log\nlogfile_maxbytes=50MB        ; max main logfile bytes b4 rotation; default 50MB\nlogfile_backups=10           ; # of main logfile backups; 0 means none, default 10\nloglevel=info                ; log level; default info; others: debug,warn,trace\npidfile=/tmp/supervisord.pid ; supervisord pidfile; default supervisord.pid\nnodaemon=false               ; start in foreground if true; default false\nminfds=1024                  ; min. avail startup file descriptors; default 1024\nminprocs=200                 ; min. avail process descriptors;default 200\n\n[rpcinterface:supervisor]\nsupervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n\n[supervisorctl]\nserverurl=unix:///tmp/supervisor.sock ; use a unix:// URL  for a unix socket\n启动 Supervisord如果已经进入 supervisor 的虚拟环境，可以直接使用 supervisord 命令启动：\nsupervisord -c /etc/supervisord.conf\n或者没有进入虚拟环境的话，可以使用 supervisord 命令的绝对路径启动：\n/data/venv/supervisor/bin/supervisord -c /etc/supervisord.conf\n可以看到 supervisord 已经运行起来了：\n(supervisor) root@ubuntu:~# pgrep supervisord \n1990\n(supervisor) root@ubuntu:~# ls /tmp/\nsupervisor.sock  supervisord.log  supervisord.pid\n(supervisor) root@ubuntu:~#\n管理一个进程接下来为 supervisor 添加被它管理的第一个进程。将下面配置项追加到 /etc/supervisord.conf：\n[program:pyhttp]\ncommand=/usr/bin/python3 -m http.server 8080\ndirectory=/tmp/\nstdout_logfile=/tmp/pyhttp.log\nautostart=true\nautorestart=true\n接着执行 supervisorctl 命令，这个命令是 supervisord 的命令行管理工具，也就是 C/S 架构中的 C 了。进入 supervisorctl 交互命令行后，执行 update 命令会通知 supervisord 进程更新进程管理相关的配置项，这样刚才添加的配置项就生效了：\n(supervisor) root@ubuntu:~# supervisorctl -c /etc/supervisord.conf\nsupervisor&gt; update\npyhttp: added process group\nsupervisor&gt; status\npyhttp                           RUNNING   pid 2107, uptime 0:00:11\nsupervisor&gt;\n使用 status 命令可以查看当前被 supervisord 管理的所有进程状态，exit 命令可以退出交互模式。\n注意： 也可以直接使用 supervisorctl update 或者 supervisorctl status 来达到相同的效果而不需要进入 supervisorctl 的交互模式。运行 supervisorctl 命令也应当指定 supervisord 所使用的配置文件。\n进程控制通过 stop、start、restart 命令可以对进程进行 停止、启动、重启 的操作：\n(supervisor) root@ubuntu:~# supervisorctl -c /etc/supervisord.conf\npyhttp                           RUNNING   pid 2107, uptime 0:09:31\nsupervisor&gt; stop pyhttp \npyhttp: stopped\nsupervisor&gt; status\npyhttp                           STOPPED   Aug 28 06:00 AM\nsupervisor&gt; start pyhttp\npyhttp: started\nsupervisor&gt; restart pyhttp\npyhttp: stopped\npyhttp: started\nsupervisor&gt; status\npyhttp                           RUNNING   pid 2135, uptime 0:00:03\nsupervisor&gt; \n停止 Supervisord在停止 supervisord 进程前，我们应该先停止 supervisord 管理的所有子进程，以免造成 supervisord 停止后，子进程没有主动停止被 init 进程接管的现象。下面演示下强制杀掉 supervisord 进程后造成子进程逃逸的现象：\n(supervisor) root@ubuntu:~# netstat -anpt |grep python3\ntcp    0    0 0.0.0.0:8080      0.0.0.0:*       LISTEN    2221/python3        \n(supervisor) root@ubuntu:~# pgrep supervisord \n2191\n(supervisor) root@ubuntu:~# cat /proc/2221/status |grep PPid\nPPid:    2191\n(supervisor) root@ubuntu:~# kill -9 2191\n(supervisor) root@ubuntu:~# pgrep supervisord \n(supervisor) root@ubuntu:~# cat /proc/2221/status |grep PPid\nPPid:    1\n(supervisor) root@ubuntu:~# \nsupervisor 提供了安全的方式关闭 supervisord 进程，在 supervisorctl 中使用 shutdown 命令即可：\n(supervisor) root@ubuntu:~# supervisorctl -c /etc/supervisord.conf\npyhttp                           RUNNING   pid 2251, uptime 0:00:10\nsupervisor&gt; shutdown \nReally shut the remote supervisord process down y/N? y\nShut down\nsupervisor&gt; status\nunix:///tmp/supervisor.sock no such file\nsupervisor&gt; \n(supervisor) root@ubuntu:~# netstat -anpt |grep 8080\n(supervisor) root@ubuntu:~#\n使用 Web 管理Supervisor 提供了一套简易的 Web 页面来远程管理进程，但是由于安全考虑默认是关闭的。将以下配置项加入配置文件则可以开启这个功能：\n[inet_http_server]\nport=0.0.0.0:9001\nusername=admin\npassword=123456\n服务监听在 0.0.0.0:9001，登录用户名为 admin，密码为 123456。接着重启 supervisord 进程：\nkill -HUP `pgrep supervisord`\n向 supervisord 进程发送 HUP 信号会通知进程重新初始化，supervisord 会重新加载配置文件，已经启动的子进程会重启！还有一点需要注意，pgrep 命令会列出所有的 supervisord 进程，如果主机上正运行着多个 supervisord 实例，这会触发所有 supervisord 重新初始化！\n(supervisor) root@ubuntu:~# netstat -anpt |grep python3\ntcp    0   0 0.0.0.0:9001        0.0.0.0:*        LISTEN     2264/python3        \ntcp    0   0 0.0.0.0:8080        0.0.0.0:*        LISTEN     2644/python3        \n(supervisor) root@ubuntu:~# kill -HUP `pgrep supervisord`\n(supervisor) root@ubuntu:~# netstat -anpt |grep python3\ntcp    0   0 0.0.0.0:9001        0.0.0.0:*        LISTEN     2264/python3        \ntcp    0   0 0.0.0.0:8080        0.0.0.0:*        LISTEN     2650/python3    \n可以看到，当我又一次重启 supervisord 后，监听 8080 端口的 python3 进程的 PID 发生了变化，而 supervisord 的没有。\n接着通过浏览器访问 supervisord 的 Web 页面：\n\n我们可以通过 Web 页面对 supervisord 做一些简单的操作。\n注意： 生产环境请勿开启此项，会有安全隐患。\n命令行程序\nsupervisor 安装完毕后会提供四个命令行工具：supervisord、supervisorctl、echo_supervisord_conf、pidproxy。下面对这些命令行工具进行详细说明。\n\nsupervisord命令帮助这个就是 supervisor 最重要的进程了，这个命令会在后台启动一个守护进程，对子进程的管理实际上就是通过这个进程。执行 supervisord --help 可以看到此命令的所有参数：\n(supervisor) root@ubuntu:~# supervisord --help\nsupervisord -- run a set of applications as daemons.\n\nUsage: /data/venv/supervisor/bin/supervisord [options]\n\nOptions:\n-c/--configuration FILENAME -- configuration file path (searches if not given)\n-n/--nodaemon -- run in the foreground (same as &apos;nodaemon=true&apos; in config file)\n-h/--help -- print this usage message and exit\n-v/--version -- print supervisord version number and exit\n-u/--user USER -- run supervisord as this user (or numeric uid)\n-m/--umask UMASK -- use this umask for daemon subprocess (default is 022)\n-d/--directory DIRECTORY -- directory to chdir to when daemonized\n-l/--logfile FILENAME -- use FILENAME as logfile path\n-y/--logfile_maxbytes BYTES -- use BYTES to limit the max size of logfile\n-z/--logfile_backups NUM -- number of backups to keep when max bytes reached\n-e/--loglevel LEVEL -- use LEVEL as log level (debug,info,warn,error,critical)\n-j/--pidfile FILENAME -- write a pid file for the daemon process to FILENAME\n-i/--identifier STR -- identifier used for this instance of supervisord\n-q/--childlogdir DIRECTORY -- the log directory for child process logs\n-k/--nocleanup --  prevent the process from performing cleanup (removal of\n                old automatic child log files) at startup.\n-a/--minfds NUM -- the minimum number of file descriptors for start success\n-t/--strip_ansi -- strip ansi escape codes from process output\n--minprocs NUM  -- the minimum number of processes available for start success\n--profile_options OPTIONS -- run supervisord under profiler and output\n                            results based on OPTIONS, which  is a comma-sep&apos;d\n                            list of &apos;cumulative&apos;, &apos;calls&apos;, and/or &apos;callers&apos;,\n                            e.g. &apos;cumulative,callers&apos;)\n\n(supervisor) root@ubuntu:~#\n由于我们几乎不会通过命令行参数来运行 supervisord，所以各个参数的含义都不再说明，只需要知道通过 -c 或者 --configuration 来指明 supervisord 的配置文件即可。\n信号处理当 supervisord 进程接收到不同的信号时，会有不同的反应，我们在外部还可以通过信号来控制 supervisord 的一些行为：\n\nSIGTERM：这个信号也是 kill 命令默认的信号，supervisord 会关闭所有子进程，然后退出。这可能需要几秒钟的时间。\nSIGINT：相当于将 supervisord 的进程 Ctrl-C 掉，supervisord 的处理同对 SIGTERM 信号的处理。\nSIGQUIT：同对 SIGTERM 信号的处理。\nSIGHUP：supervisord 将停止所有进程，然后重新加载配置文件，并启动所有进程。\nSIGUSR2：supervisord 将关闭并重新打开主日志文件和子日志文件。\n\nsupervisorctl命令帮助这个命令是 supervisord 守护进程的命令行管理工具，我们大多时候都是通过这个命令来管理 supervisord 的。下面是这个命令的帮助：\n(supervisor) root@ubuntu:~# supervisorctl --help\nsupervisorctl -- control applications run by supervisord from the cmd line.\n\nUsage: /data/venv/supervisor/bin/supervisorctl [options] [action [arguments]]\n\nOptions:\n-c/--configuration FILENAME -- configuration file path (searches if not given)\n-h/--help -- print usage message and exit\n-i/--interactive -- start an interactive shell after executing commands\n-s/--serverurl URL -- URL on which supervisord server is listening\n    (default &quot;http://localhost:9001&quot;).\n-u/--username USERNAME -- username to use for authentication with server\n-p/--password PASSWORD -- password to use for authentication with server\n-r/--history-file -- keep a readline history (if readline is available)\n\naction [arguments] -- see below\n\nActions are commands like &quot;tail&quot; or &quot;stop&quot;.  If -i is specified or no action is\nspecified on the command line, a &quot;shell&quot; interpreting actions typed\ninteractively is started.  Use the action &quot;help&quot; to find out about available\nactions.\n连接 supervisordsupervisorctl 默认是通过 unix 套接字跟 supervisord 通信，也就是用之前使用 supervisorctl 的方式。如果 supervisord 开启了远程监听（web访问），则 supervisorctl 也可以远程连接其他主机的 supervisor，连接方式主要是以下两种：\n(supervisor) root@ubuntu:~# supervisorctl -s http://10.0.1.15:9001 -u admin -p 123456 status\npyhttp                           RUNNING   pid 2728, uptime 0:00:48\n(supervisor) root@ubuntu:~# supervisorctl -s http://10.0.1.15:9001 \nServer requires authentication\nUsername:admin\nPassword:\n\npyhttp                           RUNNING   pid 2728, uptime 0:03:48\nsupervisor&gt; \n(supervisor) root@ubuntu:~#\n使用 -s 指定服务监听地址，-u 提供登录的用户名，-p 提供密码，如果是进入交互模式，没有在命令行提供用户名和密码，supervisorctl 则会询问。\n控制命令除了最常用的 stop、start、restart 命令，supervisorctl 还支持非常多的控制命令，通过 help 命令可以获取所有支持的命令：\n(supervisor) root@ubuntu:~# supervisorctl -c /etc/supervisord.conf \npyhttp                           RUNNING   pid 2728, uptime 0:36:59\nsupervisor&gt; help\n\ndefault commands (type help &lt;topic&gt;):\n=====================================\nadd    exit      open  reload  restart   start   tail   \navail  fg        pid   remove  shutdown  status  update \nclear  maintail  quit  reread  signal    stop    version\n\nsupervisor&gt;\n通过 help &lt;command&gt; 可以查看命令帮助：\nsupervisor&gt; help help\nhelp        Print a list of available actions\nhelp &lt;action&gt;    Print help for &lt;action&gt;\nsupervisor&gt;\n下面对所以支持的命令进行一一介绍\nupdate\n重新读取配置文件\n\n用法：\n\nupdate            根据配置文件的改动添加或移除项目，将会重启或停止受影响的项目\nupdate all        和 update 一样，根据配置文件的改动添加或移除项目，将会重启或停止受影响的项目\nupdate &lt;gname&gt; [...]    更新指定的组，可以提供多个组名\n\n示例：\n为了演示效果，我们修改配置文件，添加一个进程，并为它们创建一个进程组。将以下配置项写入配置文件，并更新 supervisord：\n[program:pyhttp1]\ncommand=/usr/bin/python3 -m http.server 8081\ndirectory=/tmp/\nstdout_logfile=/tmp/pyhttp1.log\n\n[program:pyhttp2]\ncommand=/usr/bin/python3 -m http.server 8082\ndirectory=/tmp/\nstdout_logfile=/tmp/pyhttp2.log\n\n[group:simpleHttp]\nprograms=pyhttp1,pyhttp2\nsupervisorctl -c /etc/supervisord.conf update\n(supervisor) root@ubuntu:~# supervisorctl -c /etc/supervisord.conf update\nsimpleHttp: added process group\n注意：update 方法不会影响没有修改配置的进程，所以重复执行也是安全的\nstatus\n查看进程的状态信息\n\n用法：\n\nstatus：获取所有进程状态信息\nstatus &lt;name&gt;：        获取指定名称的进程状态信息\nstatus &lt;gname&gt;:*：    获取指定进程组名称的所有进程信息\nstatus &lt;name&gt; &lt;name&gt;：    获取指定的多个名称的进程信息\n\n示例：\n(supervisor) root@ubuntu:~# supervisorctl -c /etc/supervisord.conf \npyhttp                           RUNNING   pid 2851, uptime 0:02:20\nsimpleHttp:pyhttp1               RUNNING   pid 2860, uptime 0:00:29\nsimpleHttp:pyhttp2               RUNNING   pid 2861, uptime 0:00:29\nsupervisor&gt; status pyhttp \npyhttp                           RUNNING   pid 2851, uptime 0:02:25\nsupervisor&gt; status simpleHttp:*\nsimpleHttp:pyhttp1               RUNNING   pid 2860, uptime 0:00:39\nsimpleHttp:pyhttp2               RUNNING   pid 2861, uptime 0:00:39\nsupervisor&gt;\nstop\n停止进程\n\n用法：\n\nstop &lt;name&gt;        停止指定名称的进程\nstop &lt;gname&gt;:*        停止指定进程组内的所有进程\nstop &lt;name&gt; &lt;name&gt;    停止指定的多个进程或进程组\nstop all        停止所有进程\n\n示例：\nsupervisor&gt; stop pyhttp\npyhttp: stopped\nsupervisor&gt; stop simpleHttp:*\nsimpleHttp:pyhttp1: stopped\nsimpleHttp:pyhttp2: stopped\nsupervisor&gt; status\npyhttp                           STOPPED   Aug 28 01:23 PM\nsimpleHttp:pyhttp1               STOPPED   Aug 28 01:24 PM\nsimpleHttp:pyhttp2               STOPPED   Aug 28 01:24 PM\nsupervisor&gt;\nstart\n启动进程\n\n用法：\n\nstart &lt;name&gt;        启动指定名称的进程\nstart &lt;gname&gt;:*        启动指定进程组内的所有进程\nstart &lt;name&gt; &lt;name&gt;    启动指定的多个进程或进程组\nstart all        启动所有进程\n\n示例：\nsupervisor&gt; start pyhttp\npyhttp: started\nsupervisor&gt; start all\nsimpleHttp:pyhttp1: started\nsimpleHttp:pyhttp2: started\nsupervisor&gt; status\npyhttp                           RUNNING   pid 3351, uptime 0:00:06\nsimpleHttp:pyhttp1               RUNNING   pid 3352, uptime 0:00:03\nsimpleHttp:pyhttp2               RUNNING   pid 3353, uptime 0:00:03\nsupervisor&gt;\nrestart\n重启进程\n\n用法：\n\nrestart &lt;name&gt;        重启指定名称的进程\nrestart &lt;gname&gt;:*    重启指定进程组内的所有进程\nrestart &lt;name&gt; &lt;name&gt;    重启指定的多个进程或进程组\nrestart all        重启所有进程\n\n示例：\nsupervisor&gt; restart all\npyhttp: stopped\nsimpleHttp:pyhttp1: stopped\nsimpleHttp:pyhttp2: stopped\npyhttp: started\nsimpleHttp:pyhttp1: started\nsimpleHttp:pyhttp2: started\nsupervisor&gt;\npid\n获取 PID\n\n用法：\n\npid            获取 supervisord 的 PID\npid &lt;name&gt;        获取指定名称的进程的 PID\npid all            获取所有进程的 PID\n\n示例：\nsupervisor&gt; pid all\n3357\n3358\n3359\nsupervisor&gt; pid\n2727\nsupervisor&gt; pid pyhttp \n3357\nsupervisor&gt; \nreload\n通知 supervisord 进程重新重新初始化。会关闭所有进程，然后重新读取配置文件后启动进程\n\n用法：\n\nreload         重启远程的 supervisord\n\n此命令类似于直接向 supervisord 进程发送 HUP 信号一样，会通知 supervisord 进程重新初始化。为了演示效果，我们修改下进程组 simpleHttp 的成员，将 pyhttp2 换成 pyhttp：\n[group:simpleHttp]\nprograms=pyhttp1,pyhttp\n示例：\nsupervisor&gt; reload\nReally restart the remote supervisord process y/N? y\nRestarted supervisord\nsupervisor&gt; status\npyhttp2                          RUNNING   pid 3502, uptime 0:00:07\nsimpleHttp:pyhttp                RUNNING   pid 3504, uptime 0:00:07\nsimpleHttp:pyhttp1               RUNNING   pid 3503, uptime 0:00:07\nsupervisor&gt;\n注意：生产环境应该尽量避免执行这个命令，因为会重启所有的进程，除非在修改了 supervisord 服务本身的配置项的时候，比如修改了 supervisord 服务监听地址的时候，才需要使用 reload 命令，修改了项目相关配置项的时候 应当使用 update 代替。关于 supervisor 的配置文件，下面会有详细说明。\nremove\n移除一个已停止的进程，相当于禁用\n\n用法：\n\nremove &lt;name&gt; [...]    从当前活跃的配置中，移除指定的进程名或进程组\n\n示例：\nsupervisor&gt; stop pyhttp2\npyhttp2: stopped\nsupervisor&gt; remove pyhttp2 \npyhttp2: removed process group\nsupervisor&gt; status\nsimpleHttp:pyhttp                RUNNING   pid 3510, uptime 0:05:42\nsimpleHttp:pyhttp1               RUNNING   pid 3509, uptime 0:05:42\nsupervisor&gt; \n必须要先停止要移除的进程，移除后再执行 status 被移除的进程就不可见了。\navail\n显示所有已配置的进程\n\n用法：\n\navail 显示所有已配置的进程\n\n示例：\nsupervisor&gt; avail \nsimpleHttp:pyhttp                in use    auto      999:999\nsimpleHttp:pyhttp1               in use    auto      999:999\npyhttp2                          avail     auto      999:999\nsupervisor&gt;\n可以看到所有的进程，包括正在使用的，和可用的。\nadd\n添加一个被移除后的进程，相当于启用\n\n用法：\n\nadd &lt;name&gt; [...] 从已移除的项目中，重新启用指定的进程名或进程组\n\n示例：\nsupervisor&gt; add pyhttp2\npyhttp2: added process group\nsupervisor&gt; status\npyhttp2                          RUNNING   pid 3613, uptime 0:00:07\nsimpleHttp:pyhttp                RUNNING   pid 3510, uptime 0:11:37\nsimpleHttp:pyhttp1               RUNNING   pid 3509, uptime 0:11:37\nsupervisor&gt;\n注意：用 update 也会使已禁用的进程重新启用。但是和 add 还是有本质上的区别，如果禁用这个进程后，修改了这个进程的配置文件，用 add 只能启用未修改前这个进程的配置，而 update 则会重新读取新的配置。\nreread\n重新读取项目的配置文件\n\n用法：\n\nreread 重新加载配置文件，但是不会自动执行 add 和 remove\n\n也就是说，reread 会比 update 柔和，当修改了正在运行的进程的配置项后，它也不会停止被修改的进程。即使添加了新的进程配置项，它也不会主动启动新进程。现在我们修改配置文件，将 pyhttp2 的名称改为 pyhttp3：\n[program:pyhttp3]\ncommand=/usr/bin/python3 -m http.server 8082\ndirectory=/tmp/\nstdout_logfile=/tmp/pyhttp2.log\n示例：\nsupervisor&gt; reread\npyhttp2: disappeared\npyhttp3: available\nsupervisor&gt; status\npyhttp2                          RUNNING   pid 3616, uptime 0:01:12\nsimpleHttp:pyhttp                RUNNING   pid 3510, uptime 0:24:57\nsimpleHttp:pyhttp1               RUNNING   pid 3509, uptime 0:24:57\nsupervisor&gt; avail \nsimpleHttp:pyhttp                in use    auto      999:999\nsimpleHttp:pyhttp1               in use    auto      999:999\npyhttp3                          avail     auto      999:999\nsupervisor&gt;\n可以看到，pyhttp2 进程依然在运行，pyhttp3 只存在于 avail 中。接下来复原配置文件，并执行 update ：\n[program:pyhttp2]\ncommand=/usr/bin/python3 -m http.server 8082\ndirectory=/tmp/\nstdout_logfile=/tmp/pyhttp2.log\ntail\n显示进程的标准输出或错误输出，用法类似于 linux 的 tail 命令\n\n命令格式：tail [-f] &lt;name&gt; [stdout|stderr] (default stdout)\n用法：\n\ntail -f &lt;name&gt;        连续的获取指定进程名的标准输出，Ctrl-C 退出。\ntail -100 &lt;name&gt;    获取指定进程名的最后 100 个字节的标准输出。\ntail &lt;name&gt; stderr    获取指定进程名的最后 1600 个字节的错误输出。\n\n由于 supervisord 没有获取到 python -m http.server 的输出流，所以 tail 命令看不到任何数据，具体原因我也懒得排查了。。。\nmaintail\n显示 supervisord 进程的日志，用法和 tail 命令类似\n\n用法：\n\nmaintail -f     连续的获取 supervisord 的日志，Ctrl-C 退出。\nmaintail -100    获取 supervisord 的日志的最后 100 个字节。\nmaintail    last  获取 supervisord 的日志的最后 1600 个字节。\n\n示例：\nsupervisor&gt; maintail -100 \nINFO success: pyhttp2 entered RUNNING state, process has stayed up for &gt; than 1 seconds (startsecs)\nclear\n清理进程日志\n\n用法：\n\nclear &lt;name&gt;        清理指定进程名的日志文件。\nclear &lt;name&gt; &lt;name&gt;    清理指定的多个进程名的日志文件\nclear all        清理所有进程的日志文件。\n\n示例：\nsupervisor&gt; clear all\nsimpleHttp:pyhttp1: cleared\nsimpleHttp:pyhttp: cleared\npyhttp2: cleared\nsupervisor&gt;\nversion\n显示 supervisord 的版本\n\n用法：\n\nversion 显示远程 supervisord 进程的版本。\n\n示例：\nsupervisor&gt; version\n4.0.4\nsupervisor&gt;\nfg\n在前台模式连接一个进程，本质上是连接到了进程的标准输入\n\n用法：\n\nfg &lt;process&gt; 在前台模式连接一个进程\n\n首先我们需要先编写一个可以获取标准输入的程序，然后才可以用 fg 命令来做测试。\n编辑 /root/fgtest.py 写入以下内容：\nwhile True:    print(\"hello \", input())\n编辑 /etc/supervisord.conf 添加如下内容：\n[program:fgtest]\ncommand=/usr/bin/python3 /root/fgtest.py\nstdout_logfile=/tmp/fgtest.log\n接着更新 supervisord，并测试 fg 命令：\nsupervisor&gt; update\nfgtest: added process group\nsupervisor&gt; status\nfgtest                           RUNNING   pid 3722, uptime 0:00:06\npyhttp2                          RUNNING   pid 3699, uptime 0:03:17\nsimpleHttp:pyhttp                RUNNING   pid 3701, uptime 0:03:17\nsimpleHttp:pyhttp1               RUNNING   pid 3700, uptime 0:03:17\nsupervisor&gt; fg fgtest \n==&gt; Press Ctrl-C to exit &lt;==\naaa\nhello  aaa\nExiting foreground\nsupervisor&gt; tail fgtest \nhello  aaa\n\nsupervisor&gt;\n的确如我们所愿，当我们输入了 aaa，进程成功的回显了 hello aaa，并且 tail 命令也正确的输出了结果。\nsignal\n给子进程发送信号，类似于 linux 的 kill 命令\n\n用法：\n\nsignal &lt;signal name&gt; &lt;name&gt;        向指定的进程名发送指定的信号\nsignal &lt;signal name&gt; &lt;gname&gt;:*        向指定的进程组发送指定的信号\nsignal &lt;signal name&gt; &lt;name&gt; &lt;name&gt;    向指定的多个进程名发送指定的信号\nsignal &lt;signal name&gt; all        向所有进程发送指定的信号\n\nlinux 可用的信号如下所示：\nroot@ubuntu:~# kill -l\n1) SIGHUP     2) SIGINT     3) SIGQUIT     4) SIGILL     5) SIGTRAP\n2) SIGABRT     7) SIGBUS     8) SIGFPE     9) SIGKILL    10) SIGUSR1\n3)  SIGSEGV    12) SIGUSR2    13) SIGPIPE    14) SIGALRM    15) SIGTERM\n4)  SIGSTKFLT    17) SIGCHLD    18) SIGCONT    19) SIGSTOP    20) SIGTSTP\n5)  SIGTTIN    22) SIGTTOU    23) SIGURG    24) SIGXCPU    25) SIGXFSZ\n6)  SIGVTALRM    27) SIGPROF    28) SIGWINCH    29) SIGIO    30) SIGPWR\n7)  SIGSYS    34) SIGRTMIN    35) SIGRTMIN+1    36) SIGRTMIN+2    37) SIGRTMIN+3\n8)  SIGRTMIN+4    39) SIGRTMIN+5    40) SIGRTMIN+6    41) SIGRTMIN+7    42) SIGRTMIN+8\n9)  SIGRTMIN+9    44) SIGRTMIN+10    45) SIGRTMIN+11    46) SIGRTMIN+12    47) SIGRTMIN+13\n10) SIGRTMIN+14    49) SIGRTMIN+15    50) SIGRTMAX-14    51) SIGRTMAX-13    52) SIGRTMAX-12\n11) SIGRTMAX-11    54) SIGRTMAX-10    55) SIGRTMAX-9    56) SIGRTMAX-8    57) SIGRTMAX-7\n12) SIGRTMAX-6    59) SIGRTMAX-5    60) SIGRTMAX-4    61) SIGRTMAX-3    62) SIGRTMAX-2\n13) SIGRTMAX-1    64) SIGRTMAX    \n我们前面已经了解到，可以通过给 supervisord 发送 HUP(1) 信号来通知进程重新初始化。平常我们通过 Ctrl-C 来终止程序本质上就是发送 INT(2) 信号给进程。以及最常用的也是 kill 命令默认发出的 TERM(15) 信号，还有六亲不认的 KILL(9) 信号。\n示例：\nsupervisor&gt; status fgtest \nfgtest                           RUNNING   pid 3737, uptime 0:00:36\nsupervisor&gt; signal INT fgtest \nfgtest: signalled\nsupervisor&gt; status fgtest \nfgtest                           RUNNING   pid 3738, uptime 0:00:03\nsupervisor&gt; signal 9 fgtest \nfgtest: signalled\nsupervisor&gt; status fgtest \nfgtest                           STARTING  \nsupervisor&gt; status fgtest \nfgtest                           RUNNING   pid 3739, uptime 0:00:03\nsupervisor&gt; \n我们可以通过信号的名称，或者信号的编号来用作发送给进程，可以看到，给进程发送了终止，或者强制杀死的信号后，supervisord 把挂掉的进程重启了！这也是 supervisord 的特性之一。\nhelp\n查看帮助\n\n用法：\n\nhelp 列出所有的可用命令\nhelp &lt;command&gt; 查看指定的命令的帮助\n\n示例：\nsupervisor&gt; help \n\ndefault commands (type help &lt;topic&gt;):\n=====================================\nadd    exit      open  reload  restart   start   tail   \navail  fg        pid   remove  shutdown  status  update \nclear  maintail  quit  reread  signal    stop    version\n\nsupervisor&gt; help start\nstart &lt;name&gt;        Start a process\nstart &lt;gname&gt;:*        Start all processes in a group\nstart &lt;name&gt; &lt;name&gt;    Start multiple processes or groups\nstart all        Start all processes\nsupervisor&gt; \nopen\n连接远程的 supervisord 进程，可以通过 unix 套接字，也可以通过 http 协议。\n\n用法：\n\nopen &lt;url&gt; 连接远程的 supervisord 进程。\n\n示例：\nsupervisor&gt; open http://127.0.0.1:9001\nServer requires authentication\nUsername:admin\nPassword:\n\npyhttp2                          RUNNING   pid 3616, uptime 0:33:55\nsimpleHttp:pyhttp                RUNNING   pid 3510, uptime 0:57:40\nsimpleHttp:pyhttp1               RUNNING   pid 3509, uptime 0:57:40\nsupervisor&gt; open unix:///tmp/supervisor.sock\npyhttp2                          RUNNING   pid 3616, uptime 0:34:58\nsimpleHttp:pyhttp                RUNNING   pid 3510, uptime 0:58:43\nsimpleHttp:pyhttp1               RUNNING   pid 3509, uptime 0:58:43\nsupervisor&gt;\nquit\n退出当前 supervisorctl 交互界面。\n\n用法：\n\nquit 退出 supervisorctl 交互。\n\n示例：\nsupervisor&gt; quit\n\n(supervisor) root@ubuntu:~#\nexit\n退出当前 supervisorctl 交互界面，同 quit。\n\n用法：\n\nexit 退出 supervisorctl 交互。\n\n示例：\nsupervisor&gt; exit\n\n(supervisor) root@ubuntu:~#\nshutdown\n关闭 supervisord 以及所有正在被管理的子进程。\n\n用法：\n\nshutdown 关闭远程 supervisord 进程。\n\n示例：\nsupervisor&gt; shutdown \nReally shut the remote supervisord process down y/N? y\nShut down\nsupervisor&gt;\nsupervisor&gt; status\nunix:///tmp/supervisor.sock no such file\nsupervisor&gt;\necho_supervisord_conf这个命令很简单，就是打印 supervisord.conf 的模板示例。\npidproxy对于一些启动比较特殊的服务，例如 mysqld，当我们启动 mysqld 的时候，通常执行的是 mysqld_safe 脚本，然后它再去调用 mysqld 程序来启动服务。\nsupervisord 是通过给进程发送信号的方式来关闭程序的，但是 supervisord 只能获取 mysqld_safe 的 PID，而 mysqld_safe 会忽略进程退出相关的信号，只有它的子进程 mysqld 才会处理信号，所以如果使用 supervisord 来管理 mysqld，就需要让 supervisord 知道 mysqld 进程的实际 PID。\n幸运的是，大多数进程启动后，都会创建一个 .pid 的文件，文件里保存进程的实际 PID，pidproxy 可以帮助我们启动进程后，根据提供的 .pid 文件位置来获取实际要控制的进程。\n用法：\n\npidproxy &lt;pidfile name&gt; &lt;command&gt; [&lt;cmdarg1&gt; ...]\n\n示例：\n[program：mysqld] \ncommand = /data/venv/supervisor/bin/pidproxy /var/run/mysqld.pid mysqld_safe\n配置文件详解默认配置文件查找supervisord 和 supervisorctl 共同使用 supervisord.conf 这个配置文件，如果没有使用 -c 参数指定配置文件的话，程序将依次从以下位置查找并使用找到的第一个配置文件：\n\n./supervisord.conf 当前用户所在路径下的 supervisord.conf 文件。\n./etc/supervisord.conf 当前用户所在路径下的 etc/supervisord.conf 文件。\n/etc/supervisord.conf 系统绝对路径 /etc/supervisord.conf 文件。\n/etc/supervisor/supervisord.conf 系统绝对路径，但是从 3.3.0 版本才开始支持。\n../etc/supervisord.conf 相对于程序所在路径的 ../etc/supervisord.conf。\n../supervisord.conf 相对于程序所在路径的 ../supervisord.conf。\n\n配置文件格式supervisord.conf 使用 Windows-INI 风格的配置文件。由不同的配置单元，配置单元中通过键值对的方式记录配置信息，格式如下：\n[program:pyhttp1]command=/usr/bin/python3 -m http.server 8081directory=/tmp/stdout_logfile=/tmp/pyhttp1.log[program:pyhttp2]command=/usr/bin/python3 -m http.server 8082directory=/tmp/stdout_logfile=/tmp/pyhttp2.log\n每一个 [] 开始都表示一个配置单元，直到下一个配置单元为止。在 supervisord.conf 中，配置单元中的值还可以使用 %(ENV_ENVNAME)s 的方式。supervisord 启动的时候，会将其中的值根据对应的环境变量替换成实际的值，例如在配置文件中使用了 %(ENV_ENVNAME)s，则对应环境变量 ENVNAME 的值会替换了配置文件中变量的部分。下面举个例子来看：\n配置文件中追加新的配置项：\n[program:envtest]\ncommand=/usr/bin/python3 -m http.server 8083\nstdout_logfile=/tmp/%(ENV_LOGFILE)s\n因为通过环境变量传递值给 supervisord.conf 的方式，必须保证 supervisord 进程可以继承到这些环境变量，我们在添加 LOGFILE 这个环境变量后必须重新启动 supervisord 进程才可以\n(supervisor) root@ubuntu:~# supervisorctl shutdown\nShut down\n(supervisor) root@ubuntu:~# env LOGFILE=&quot;log_from_env.log&quot; supervisord -c /etc/supervisord.conf\n(supervisor) root@ubuntu:~# supervisorctl status\nenvtest                          RUNNING   pid 4944, uptime 0:00:04\nfgtest                           RUNNING   pid 4945, uptime 0:00:04\npyhttp2                          RUNNING   pid 4946, uptime 0:00:04\nsimpleHttp:pyhttp                RUNNING   pid 4948, uptime 0:00:04\nsimpleHttp:pyhttp1               RUNNING   pid 4947, uptime 0:00:04\n(supervisor) root@ubuntu:~# ls /tmp/log_from_env.log \n/tmp/log_from_env.log\n(supervisor) root@ubuntu:~#\n我们配置了一个只针对 supervisord 进程生效的环境变量 LOGFILE，可以看到 log_from_env.log 文件被成功读取并替换到配置文件中。\n配置单元\n下面详细讲解 supervisord.conf 都支持哪些配置项。\n\n[unix_http_server]该配置项用于定义 supervisord 监听 UNIX 套接字提供 HTTP/XML-RPC 服务的相关配置。\nfile\nsupervisord 将监听 UNIX 套接字的路径。\n\n默认值：无是否必填：否例子：file = /tmp/supervisor.sock\nchmod\n设置 UNIX 套接字文件的权限。\n\n默认值：0700是否必填：否例如：chmod = 0777\nchown\n设置 UNIX 套接字文件的属主和属组。可以是用户名，也可以用冒号分割用户名和组 例如：nobody:nogroup。\n\n默认值：默认使用启动 supervisord 进程的用户名和组。是否必填：否例如：chown= nobody:nogroup\nusername\nHTTP/XML-RPC 服务的认证用户名，如果提供，supervisorctl 则需要用户认证才可连接。\n\n默认值：无是否必填：否例如：username = admin\npassword\nHTTP/XML-RPC 服务的认证密码。可以是明文密码，也可以使用密码经过 sha-1 哈希后的值，需要用 {SHA} 标识是一个哈希串，例如： {SHA}82ab876d1387bfafe46cc1c8a2ef074eae50cb1d \n\n默认值：无是否必填：否例如：password = password 或者 password = {SHA}5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8\n[inet_http_server]该项用于定义 supervisord 监听 TCP 套接字提供 HTTP/XML-RPC 服务的相关配置。启动此监听后 supervisord 可以通过网络来管理和控制。默认 supervisord 不会启动 TCP 的监听，因为这非常的不安全。\nport\n监听的地址和端口\n\n默认值：如果有 [inet_http_server] 配置项则必填是否必填：否例如：port = 127.0.0.1:9001\nusername\nHTTP/XML-RPC 服务的认证用户名，如果提供，supervisorctl 则需要用户认证才可连接。\n\n默认值：无是否必填：否例如：username = admin\npassword\nHTTP/XML-RPC 服务的认证密码。可以是明文密码，也可以使用密码经过 sha-1 哈希后的值，需要用 {SHA} 标识是一个哈希串，例如： {SHA}82ab876d1387bfafe46cc1c8a2ef074eae50cb1d \n\n默认值：无是否必填：否例如：password = password 或者 password = {SHA}5baa61e4c9b93f3f0682250b6cf8331b7ee68fd8\n[supervisord]此配置项定义 supervisord 进程的一些配置信息\nlogfile\nsupervisord 进程的日志输出文件。\n\n默认值：当前目录下的 supervisord.log 文件是否必填：否例如：logfile = /tmp/supervisord.log\n注意：如果 logfile 的值是特殊文件，比如 /dev/stdout 则必须设置 logfile_maxbytes = 0 来禁止日志轮转。\nlogfile_maxbytes\n日志超过多大的尺寸将会被分割轮转，如果设置为 0 则表示无限大。\n\n默认值：50MB是否必填：否例如：logfile_maxbytes = 50MB\nlogfile_backups\n由于日志文件轮转导致的备份数量，如果设置为 0 则不会对因为轮转被分割的日志文件进行备份。\n\n默认值：10是否必填：否例如：logfile_backups = 10\nloglevel\nsupervisord 进程记录日志的级别，可选值为 critical, error, warn, info, debug, trace, blather。\n\n默认值：info是否必填：否例如：loglevel = info\npidfile\nsupervisord 进程 pid 文件的位置。\n\n默认值：当前路径下的 supervisord.pid是否必填：否例如：pidfile = /tmp/supervisord.pid\numask\nsupervisord 进程的 umask。将会影响 supervisord 进程创建文件的权限，包括记录子进程日志的文件权限。\n\n默认值：022是否必填：否例如：umask = 022\nnodaemon\n是否以非守护进程方式运行 supervisord 进程，如果 true，supervisord 进程将在前台运行。\n\n默认值：false是否必填：否例如：nodaemon = false\nminfds\nsupervisord 进程在成功运行之前会调整自身的最小可用文件描述符的数量。\n\n默认值：1024是否必填：否例如：minfds = 1024\nminprocs\nsupervisord 进程在成功运行之前会调整自身的最小进程描述符的数量。\n\n默认值：200是否必填：否例如：minprocs = 200\nnocleanup\n子进程的 stdout 和 stderr 的输出如果没有配置重定向则默认保存为临时文件（子进程日志路径为 AUTO 的情况），此项配置 supervisord 启动时是否清理这些临时文件。\n\n默认值：false是否必填：否例如：nocleanup = false\nchildlogdir\n当子进程日志路径为 AUTO 的时候，子进程日志文件的存放路径。\n\n默认值：/tmp是否必填：否例如：childlogdir = /tmp\nuser\n在使用 root 用户运行 supervisord 进程时，进程将切换到此配置指定的用户。\n\n默认值：不切换用户是否必填：否例如：user = nobody\ndirectory\n运行 supervisord 守护进程时切换到此目录。\n\n默认值：不切换是否必填：否例如：directory = /tmp\nstrip_ansi\n是否清除子进程日志中的 ansi 序列，比如 \\n, \\t 这些字符。\n\n默认值：false是否必填：否例如：strip_ansi = false\nenvironment\n用于设置 supervisord 进程启动时的环境变量。supervisord 进程启动时会从 linux 系统继承当前的环境变量，这里可以设置 supervisord 进程特有的一些环境变量。当 supervisord 进程启动子进程时，子进程也会继承系统的和这些特有的环境变量。\n\n默认值：无是否必填：否例如：environment = LOGFILE=&quot;/tmp/process.log&quot;\n注意：多个环境变量用逗号隔开。\nidentifier\nsupervisord 进程的标识符，主要用于通过 XML_RPC 统一管理时，用于区分不同 supervisord 进程的标识符。\n\n默认值：supervisor是否必填：否例如：identifier = supervisor\n[supervisorctl]此配置项主要是针对 supervisorctl 的一些配置。\nserverurl\nsupervisorctl 默认连接的 supervisord 地址，可以是 unix 套接字地址，也可以是 http 地址。\n\n默认值：http://localhost:9001是否必填：否例如：serverurl = unix:///tmp/supervisor.sock\n注意：没看错，默认值的确是 http 的连接。\nusername\nsupervisorctl 认证 HTTP/XML-RPC 服务时使用的用户名。\n\n默认值：无是否必填：否例如：username = admin\npassword\nsupervisorctl 认证 HTTP/XML-RPC 服务时使用的密码，这个值必须是明文的。\n\n默认值：无是否必填：否例如：password = password\nprompt\nsupervisorctl 命令交互页面的提示符，默认是 supervisor，所以进入 supervisorctl 后提示符都是 supervisor&gt;。\n\n默认值：supervisor是否必填：否例如：prompt = supervisor\nhistory_file\n保存 supervisorctl 命令输入历史的文件，和 shell 的 hisotry 类似。默认是没有开启，开启后我们则可以用过上下键来查找之前执行过的命令。\n\n默认值：没有文件是否必填：否例如：history_file = ~/.sc_history\n[program:xxx]这个配置项就是定义子进程的配置了，[program:xxx] 中的 xxx 可以是任意名字。\ncommand\n进程的启动命令，进程必须在前台运行模式才可以被 supervisord 进程管理。\n\n默认值：无是否必填：是例如：command = python3 -m http.server\nprocess_name\n进程名，如果下面的 numprocs 参数才 1，就不需要管这个参数。它的值默认是 %(program_name)s 也就是 [program:xxx] 中的 xxx。如果 numprocs 有多个，那不同的进程名就必须是不同的名字了。\n\n默认值：$(program_name)s是否必填：否例如：process_name = $(program_name)s\nnumprocs\nsupervisord 进程将启动此子进程的多个实例。如果 numprocs 大于 1，则 process_name 的值中必须包含 $(process_num)s 的表达式。\n\n默认值：1是否必填：否例如：numprocs = 1\n备注：如果 numproces 的值大于 1，配置文件可以这样写：\n[program:fgtest]\ncommand=/usr/bin/python3 /root/fgtest.py\nstdout_logfile=/tmp/fgtest.log\nprocess_name = %(program_name)s-%(process_num)s\nnumprocs=10\nupdate 后可以看到：\nsupervisor&gt; status\nenvtest                          RUNNING   pid 8319, uptime 1:18:29\nfgtest:fgtest-0                  RUNNING   pid 8580, uptime 0:00:02\nfgtest:fgtest-1                  RUNNING   pid 8581, uptime 0:00:02\nfgtest:fgtest-2                  RUNNING   pid 8582, uptime 0:00:02\nfgtest:fgtest-3                  RUNNING   pid 8583, uptime 0:00:02\nfgtest:fgtest-4                  RUNNING   pid 8584, uptime 0:00:02\nfgtest:fgtest-5                  RUNNING   pid 8585, uptime 0:00:02\nfgtest:fgtest-6                  RUNNING   pid 8586, uptime 0:00:02\nfgtest:fgtest-7                  RUNNING   pid 8587, uptime 0:00:02\nfgtest:fgtest-8                  RUNNING   pid 8588, uptime 0:00:02\nfgtest:fgtest-9                  RUNNING   pid 8589, uptime 0:00:02\npyhttp2                          RUNNING   pid 8321, uptime 1:18:29\nsimpleHttp:pyhttp                RUNNING   pid 8323, uptime 1:18:29\nsimpleHttp:pyhttp1               RUNNING   pid 8322, uptime 1:18:29\nsupervisor&gt;\nnumprocs_start\n上面可以看到，%(process_num)s 是从 0 开始计算。这个配置用于更改 %(process_num)s 的偏移量，例如 numproces_start 等于 1，则会生成 fgtest:fgtest-1 到 fgtest:fgtest-10。\n\n默认值：0是否必填：否例如：numprocs_start = 0\npriority\n进程的优先级，高优先级的程序将最后一个启动和第一个关闭。主要可以用于处理进程之间的依赖关系。\n\n默认值：999是否必填：否例如：priority = 999\nautostart\n子进程是否随着 supervisord 进程的启动而启动。\n\n默认值：true是否必填：否例如：autostart = true\nstartsecs\n子进程启动多少秒之后，如果状态依然是 RUNNGIN，则我们认为它启动成功了。\n\n默认值：1是否必填：否例如：startsecs = 1\nstartretries\n当进程启动失败后，最大尝试启动的次数。默认是 3 次，当超过 3 次后，supervisord 将把此进程的状态设置为 FAIL。\n\n默认值：3是否必填：否例如：startretries = 3\nautorestart\n如果进程已处于 RUNNING 状态后进程退出，supervisord 是否应该自动重启子进程。有三种选项：false 表示不自动重启， unexpected 表示只有进程退出码为下面 exitcodes 里定义的退出码时才重启， true 表示总是重启。\n\n默认值：unexpected是否必填：否例如：autorestart = unexpected\nexitcodes\n进程退出码列表，与 autorestart 配合使用。\n\n默认值：0是否必填：否例如：exitcodes = 0 或者 exitcodes = 0,2\nstopsignal\n进程停止信号，可以为 TERM, HUP, INT, QUIT, KILL, USR1, USR2 等信号。将执行 stop 命令的时候，supervisord 将用指定的信号杀死进程。\n\n默认值：TERM是否必填：否例如：stopsignal = TERM\nstopwaitsecs\n向子进程发送 stopsignal 后，到子进程退出，系统返回信息到 supervisord 所等待的时间。如果超时，supervisord 进程将强制杀死子进程。\n\n默认值：10是否必填：否例如：stopwaitsecs = 10\nstopasgroup\n如果子进程也有子进程，supervisord 仅仅干掉子进程的话，子进程的子进程可能会变成孤儿进程。该选项定义是否把整个子进程组全部停止。该选项发送的是终止信号。\n\n默认值：false是否必填：否例如：stopasgroup = false\nkillasgroup\n与 stopasgroup 道理相同，不过 killasgroup 会强制杀死子进程。\n\n默认值：false是否必填：否例如：killasgroup = false\nuser\nsupervisord 进程启动子进程时，使用哪个用户身份运行子进程。只有 supervisord 进程以 root 用户启动才生效。\n\n默认值：不切换是否必填：否例如：user = user\n注意：supervisord 仅仅使用 setuid 更改用户，并不会处理用户的环境变量，所以不会更改 USER、HOME 等环境变量的值。如果子进程依赖这些环境变量的话，可以通过下面的 environment 选项来配置。\nredirect_stderr\n将子进程的错误输出也写入标准输出的日志文件中。\n\n默认值：false是否必填：否例如：redirect_stderr = false\nstdout_logfile\n将子进程的标准输出写入到指定的文件，如果配置了 redirect_stderr 则错误输出也会写入到这个文件。如果未设置 stdout_logfile 或者此设置的值为 AUTO，supervisord 将自动选择文件位置，并在重启时清理这些文件。如果设置为 NONE，则 supervisord 不会创建任何日志文件。\n\n默认值：AUTO是否必填：否例如：stdout_logfile = /tmp/process.log\n注意：如果将 stdout_logfile 设置为 /dev/stdout 等特殊文件，则必须通过设置 stdout_logfile_maxbytes = 0 来禁用日志轮转。\nstdout_logfile_maxbytes\n子进程日志文件在被轮转前最大字节数，将此值设置为 0 表示无限制。\n\n默认值：50MB是否必填：否例如：stdout_logfile_maxbytes = 50MB\nstdout_logfile_backups\n由于日志文件轮转导致的备份数量，如果设置为 0 则不会对因为轮转被分割的日志文件进行备份。\n\n默认值：10是否必填：否例如：stdout_logfile_backups = 10\nstdout_capture_maxbytes\n设置捕获模式管道的大小，当值不为 0 的时候，子进程可以从 stdout 发送消息，而 supervisord 可以根据信息发送相应的事件。\n\n默认值：0是否必填：否例如：stdout_capture_maxbytes = 1MB\nstdout_events_enabled\n当设置为 true，子进程向 stdout 文件描述符写数据的时候，supervisord 将发送 PROCESS_LOG_STDOUT 类型的事件。\n\n默认值：0是否必填：否例如：stdout_events_enabled = 0\nstdout_syslog\n如果为 true，则子进程标准输出与子进程的名字一同被定向到 syslog。\n\n默认值：false是否必填：否例如：stdout_syslog = false\nstderr_logfile\nredirect_stderr = false 的情况下，子进程的错误输出写入指定的文件。\n\n默认值：AUTO是否必填：否例如：stderr_logfile = /tmp/process-stderr.log\nstderr_logfile_maxbytes\n作用与 stdout_logfile_maxbytes 相同，只不过作用与子进程的错误输出。\n\n默认值：50MB是否必填：否例如：stderr_logfile_maxbytes = 50MB\nstderr_logfile_backups\n作用与 stdout_logfile_backups 相同，只不过作用与子进程的错误输出。\n\n默认值：10是否必填：否例如：stderr_logfile_backups = 10\nstderr_capture_maxbytes\n作用与 stdout_capture_maxbytes 相同，只不过作用与子进程的错误输出。\n\n默认值：0是否必填：否例如：stderr_capture_maxbytes = 1MB\nstderr_events_enabled\n作用与 stdout_events_enabled 相同，只不过作用与子进程的错误输出。\n\n默认值：0是否必填：否例如：stderr_events_enabled = 0\nstderr_syslog\n作用与 stdout_syslog 相同，只不过作用与子进程的错误输出。\n\n默认值：false是否必填：否例如：stderr_syslog = false\nenvironment\n用于设置子进程启动时的环境变量。\n\n默认值：无是否必填：否例如：environment = HOME=&quot;/home/user&quot;,USER=&quot;user&quot;\n注意：多个环境变量用逗号隔开，此环境变量是子进程独享的，不与其他进程共享。\ndirectory\n运行子进程前，会先切换到这个目录。\n\n默认值：继承 supervisord 的目录是否必填：否例如：directory = /tmp\numask\n子进程创建文件的 umask。\n\n默认值：继承 supervisord 的 umask是否必填：否例如：umask = 022\nserverurl\nsupervisord 将 serverurl 的值通过环境变量传递给子进程，子进程可以通过读取环境变量 SUPERVISOR_SERVER_URL 来获取值。\n\n默认值：AUTO是否必填：否例如：serverurl = AUTO\n[include]此配置项用于定义包含其他配置文件。\nfiles\n定义其他配置文件的路径，可以使用通配符来匹配文件。\n\n默认值：无是否必填：否例如：files = /etc/supervisord.d/*.conf\n注意：我们应该养成良好的习惯，将子进程相关的配置放到 /etc/supervisord.d/ 下而不是和 supervisord.conf 放到一起。\n[group:xxx]进程组相关的配置。[group:xxx] 中的 xxx 是分组名称。\nprograms\n配置哪些进程属于这个分组\n\n默认值：无是否必填：是例如：programs = bar,foo\npriority\n进程组的优先级\n\n默认值：999是否必填：否例如：priority = 999\n[fcgi-program:xxx]提供对 fast-cgi 程序的支持，这里不做过多讲解。\n[eventlistener:xxx]事件监听器相关配置，地位和 program 一样，也是 supervisord 的子进程，只不过主要功能用于订阅 supervisord 发送的事件，我们可以在事件监听器中做一系列的处理。supervisor 中事件监听相关的用法，后面的章节会详细介绍。\n事件监听器除了支持 program 所有的配置外，还支持以下几个特有的配置\nbuffer_size\n事件监听器的事件队列缓冲区大小，当事件缓冲区溢出时，将丢弃缓冲区中最旧的事件。\n\n默认值：10是否必填：否例如：buffer_size = 10\nevents\n事件的类型，只有在这里定义了的事件才会被发送给事件的订阅者。\n\n默认值：无是否必填：是例如：events = PROCESS_STATE_STARTING\nresult_handler\n一个 pkg_resources 入口点的字符串解析为 Python 可调用。默认值是 supervisor.dispatchers:default_handler。\n\n默认值：supervisor.dispatchers:default_handler是否必填：否例如：result_handler = supervisor.dispatchers:default_handler\n[rpcinterface:supervisor]这个配置项作用与 HTTP/XML-RPC，如果想使用 Web 管理或者 supervisorctl 管理 supervisord，则必须开启此项。如果想添加 RPC 接口来自定义 supervisor 的功能，可以查看官方文档获取更详细的教程。\nsupervisor.rpcinterface_factory\nRPC 接口的入口工厂函数。\n\n默认值：supervisor.rpcinterface:make_main_rpcinterface是否必填：否例如：supervisor.rpcinterface_factory = supervisor.rpcinterface:make_main_rpcinterface\n子进程状态\nSTOPPED：通过 stop 命令停止或从未启动过的进程状态。\nSTARTING：接收到 start 命令进程正在启动中。\nRUNNING：进程正在运行。\nBACKOFF：进程进入 STARTING 状态后退出太快而无法进入 RUNNING 状态。\nSTOPPING： 接收到 stop 命令进程正在停止中。\nEXITED：进程意外的从 RUNNING 状态退出。\nFATAL：程序无法启动成功。\nUNKNOWN：未知状态，一般属于 supervisord 进程的错误。\n\n事件处理\n事件是 supervisor 的一个高级特性，常用于被管理的子进程崩溃的时候发送报警等额外操作。\n\nsupervisord 会在子进程运行的各各阶段发出不同的事件，只要定义了事件监听器，并订阅相应的事件，就可以在事件触发后对这些事件进行额外的处理。事件监听器是作为 supervisord 的子进程存在，事件通知协议是通过子进程的标准输入和标准输出来通信。supervisord 将特殊格式的字符串通过标准输入传递给子进程，子进程将结果通过标准输出返回给 supervisord。因此 事件监听器可以由任何语言来写，但是 supervisor 为 Python 提供了 supervisor.childutils 模块来简化了通信过程，因此会比其他语言更方便些。\n事件通知消息格式\n在编写事件监听器之前我们需要先知道 supervisord 和事件监听器交流的数据格式是什么。\n\n消息 head事件通知消息分为两部分 head 和 body。以下是 head 部分的格式样例：\nver:3.0 server:supervisor serial:15 pool:pyhttp_eventlistener poolserial:2 eventname:PROCESS_STATE_RUNNING len:66\n\n\n\n键\n描述\n示例\n\n\n\n\nver\n事件协议的版本\n3.0\n\n\nserver\nsupervisord 的标识符\nsupervisor\n\n\nserial\n事件编号\n15\n\n\npool\n生成此事件的事件侦听器池的名称\npyhttp_eventlistener\n\n\npoolserial\n事件池的编号\n2\n\n\neventname\n事件名称\nPROCESS_STATE_RUNNING\n\n\nlen\ndata长度，这个非常重要\n66\n\n\n\n消息 body根据 head 中的 len 字段，可以得知 data 的长度，然后通过长度可以读取到完整的 data 内容了。以下是 data 部分示例：\nprocessname:pyhttp2 groupname:pyhttp2 from_state:STARTING pid:9896\n\n\n\n键\n描述\n示例\n\n\n\n\nprocessname\n进程名\npyhttp2\n\n\ngroupname\n进程组名\npyhttp2\n\n\nfrom_state\n上一次的进程状态\nSTARTING\n\n\npid\n进程ID\n9896\n\n\n\n事件监听器消息通知\n事件监听器也有自己的状态和事件需要通知给 supervisord，例如在某个事件监听器正在工作，没法处理新事件时，supervisord 将不会发送通知给这个事件监听器。\n\n事件监听器状态事件监听器主要有三种状态：\n\n\n\n键\n描述\n\n\n\n\nACKNOWLEDGED\n事件监听器已确认（接受或拒绝）事件发送\n\n\nREADY\n事件监听器已就绪\n\n\nBUSY\n事件监听器正在工作\n\n\n\n事件监听器首次启动时， supervisord 会自动将其设置为 ACKNOWLEDGED 状态，只有当监听器通过标准输出发送 READY\\n 时，supervisord 才会将事件通知给这个监听器，此时监听器将处于 BUSY 状态。直到事件监听器向 supervisord 发送 RESULT 2\\nOK 或者 RESULT 2\\nFAIL 时，监听器才会重新回到 ACKNOWLEDGED 状态。当监听器再次向 supervisord 发送 READY\\n 后才可以继续接收到新的事件。\n事件监听器示例编辑 /root/listener.py 写入如下内容：\nimport sysimport osdef write_stdout(s):    sys.stdout.write(s)    sys.stdout.flush()    def main():    while 1:        # transition from ACKNOWLEDGED to READY        write_stdout('READY\\n')        # read header line and print it to stderr        line = sys.stdin.readline()        with open('event.log', 'a') as f:            f.write(line)        headers = dict([ x.split(':') for x in line.split() ])        data = sys.stdin.read(int(headers['len']))        with open('event.log', 'a') as f:            f.write(data)            f.write('\\n\\n')        write_stdout('RESULT 2\\nOK')        if __name__ == '__main__':    main()\n这段代码简单的将从 supervisord 接收到的事件通知写入 event.log 文件，然后继续下一次的接受通知。\n接着将以下配置项追加到 /etc/supervisord.conf：\n[eventlistener:pyhttp_eventlistener]\ncommand=python3 /root/listener.py\nevents=PROCESS_STATE\n这个事件监听器订阅了 PROCESS_STATE 事件，这个事件会在子进程状态改变时触发。更新 supervisord：\n(supervisor) root@ubuntu:~# supervisorctl update\npyhttp_eventlistener: stopped\npyhttp_eventlistener: updated process group\n(supervisor) root@ubuntu:~# supervisorctl status\npyhttp2                          RUNNING   pid 9896, uptime 0:55:57\npyhttp_eventlistener             RUNNING   pid 10056, uptime 0:00:05\nsimpleHttp:pyhttp                RUNNING   pid 9889, uptime 0:56:35\nsimpleHttp:pyhttp1               RUNNING   pid 9888, uptime 0:56:35\n(supervisor) root@ubuntu:~#\n接着我们重启一个子进程，就可以看到 event.log 的内容了：\n(supervisor) root@ubuntu:~# supervisorctl restart simpleHttp:pyhttp\nsimpleHttp:pyhttp: stopped\nsimpleHttp:pyhttp: started\n(supervisor) root@ubuntu:~# cat event.log \nver:3.0 server:supervisor serial:76 pool:pyhttp_eventlistener poolserial:2 eventname:PROCESS_STATE_STOPPING len:67\nprocessname:pyhttp groupname:simpleHttp from_state:RUNNING pid:9889\n\nver:3.0 server:supervisor serial:77 pool:pyhttp_eventlistener poolserial:3 eventname:PROCESS_STATE_STOPPED len:68\nprocessname:pyhttp groupname:simpleHttp from_state:STOPPING pid:9889\n\nver:3.0 server:supervisor serial:78 pool:pyhttp_eventlistener poolserial:4 eventname:PROCESS_STATE_STARTING len:66\nprocessname:pyhttp groupname:simpleHttp from_state:STOPPED tries:0\n\nver:3.0 server:supervisor serial:79 pool:pyhttp_eventlistener poolserial:5 eventname:PROCESS_STATE_RUNNING len:69\nprocessname:pyhttp groupname:simpleHttp from_state:STARTING pid:10068\n日志中记录了 simpleHttp:pyhttp 进程从退出到重启成功过程中所有的事件。\n如果使用 Python 编写监听器，supervisor.childutils 可以更方便的帮助我们处理事件：\nimport osimport sysimport jsonfrom supervisor import childutilsdef main():    while 1:        headers, payload = childutils.listener.wait(sys.stdin, sys.stdout)                with open('event.pro.log', 'a') as f:            f.write(json.dumps(headers))        childutils.listener.ok(sys.stdout)if __name__ == '__main__':    main()\nsupervisord 将事件监听器也当作普通子进程管理，所以事件监听器的配置项包含了所有 [program:xxx] 的配置，不过事件监听器配置项必须存在一个 events 的配置用来定义监听器订阅的事件。\n事件类型\n以下是可以被订阅的所有事件名和它的作用。\n\nEVENT基本事件类型，所有事件的父类，订阅此事件会接收所有的事件类型，但永远不会接收到此事件。\nPROCESS_STATE表示进程由一种状态转为另一种状态，订阅者永远不会收到此类型的事件，但是订阅此事件可以接收所有此事件类型的子类。\nPROCESS_STATE_STARTING进程状态变成 STARTING 时会触发此事件。父类是 PROCESS_STATE。\n事件内容示例：\nprocessname:cat groupname:cat from_state:STOPPED tries:0\nPROCESS_STATE_RUNNING进程状态变成 RUNNING 时会触发此事件。父类是 PROCESS_STATE。\n事件内容示例：\nprocessname:cat groupname:cat from_state:STARTING pid:2766\nPROCESS_STATE_BACKOFF进程状态变成 BACKOFF 时会触发此事件，表示进程未成功启动。父类是 PROCESS_STATE。\n事件内容示例：\nprocessname:cat groupname:cat from_state:STOPPED tries:0\ntries 字段表示已经尝试重启的次数。\nPROCESS_STATE_STOPPING进程状态变成 STOPPING 时会触发此事件。父类是 PROCESS_STATE。\n事件内容示例：\nprocessname:cat groupname:cat from_state:STARTING pid:2766\nPROCESS_STATE_EXITED进程状态变成 EXITED 时会触发此事件。父类是 PROCESS_STATE。\n事件内容示例：\nprocessname:cat groupname:cat from_state:RUNNING expected:0 pid:2766\nexpected 字段用来标识进程是否是正常退出，如果是非正常退出，它的值是 0。\nPROCESS_STATE_STOPPED进程状态变成 STOPPED 时会触发此事件。父类是 PROCESS_STATE。\n事件内容示例：\nprocessname:cat groupname:cat from_state:STOPPING pid:2766\nPROCESS_STATE_FATAL进程状态变成 FATAL 时会触发此事件。父类是 PROCESS_STATE。\n事件内容示例：\nprocessname:cat groupname:cat from_state:BACKOFF\nPROCESS_STATE_UNKNOWN进程状态变成 UNKNOWN 时会触发此事件，只有 supervisord 发生错误时才会导致此状态。父类是 PROCESS_STATE。\n事件内容示例：\nprocessname:cat groupname:cat from_state:BACKOFF\nREMOTE_COMMUNICATION在 supervisord 的 RPC 接口上调用 supervisor.sendRemoteCommEvent() 方法时触发。父类是 EVENT。\n事件内容示例：\ntype:type\ndata\nPROCESS_LOG进程写入 stdout 或 stderr 时触发。只有 stdout_events_enabled 或 stderr_events_enabled 为 true 时且未处于捕获模式才生效。订阅者永远不会收到此类型的事件，但是订阅此事件可以接收所有此事件类型的子类。\nPROCESS_LOG_STDOUT表示子进程已经写入了 stdout 文件描述符。\n事件内容示例：\nprocessname:name groupname:name pid:pid\ndata\nPROCESS_LOG_STDERR表示子进程已经写入了 stderr 文件描述符。\n事件内容示例：\nprocessname:name groupname:name pid:pid\ndata\nPROCESS_COMMUNICATION只有 stdout_capture_maxbytes 或 stderr_capture_maxbytes 的值不为 0 时，子进程在向 stdout 或者 stderr 中输出 &lt;!--XSUPERVISOR:BEGIN--&gt; 和 &lt;!--XSUPERVISOR:END--&gt; 标签时会触发此类型事件的子类。标签中的内容会被作为事件日志发送给订阅者。\nPROCESS_COMMUNICATION_STDOUT子进程通过 stdout 向 supervisord 发送消息。\n例如子进程在 stdout 中输出了 &lt;!--XSUPERVISOR:BEGIN--&gt;message_from:fgtest&lt;!--XSUPERVISOR:END--&gt;，订阅此事件的监听者会收到：\nprocessname:fgtest groupname:fgtest pid:10902\nmessage_from:fgtest\nPROCESS_COMMUNICATION_STDERR子进程通过 stderr 向 supervisord 发送消息。\nSUPERVISOR_STATE_CHANGE当 supervisord 进程的状态发送变化时引发的事件类型。订阅者永远不会收到此类型的事件，但是订阅此事件可以接收所有此事件类型的子类。\nSUPERVISOR_STATE_CHANGE_RUNNINGsupervisord 进程启动会发送此事件，事件消息体为空字符串。\nSUPERVISOR_STATE_CHANGE_STOPPINGsupervisord 进程停止会发送此事件，事件消息体为空字符串。\nTICK监听者会隔 5、60、360 秒被事件唤醒，订阅者永远不会收到此类型的事件，但是订阅此事件可以接收所有此事件类型的子类。\nTICK_5每隔 5 秒会通过此类型事件唤醒监听者。\n事件内容示例：\nwhen:1201063880\nTICK_60每隔 60 秒会通过此类型事件唤醒监听者。\n事件内容示例：\nwhen:1201063880\nTICK_3600每隔 3600 秒会通过此类型事件唤醒监听者。\n事件内容示例：\nwhen:1201063880\nPROCESS_GROUP将进程组从 supervisord 中添加或删除会触发的事件类型。订阅者永远不会收到此类型的事件，但是订阅此事件可以接收所有此事件类型的子类。\nPROCESS_GROUP_ADDED添加进程组将会触发这个事件\n事件内容示例：\ngroupname:cat\nPROCESS_GROUP_REMOVED删除进程组将会触发这个事件\n事件内容示例：\ngroupname:cat\n附录配置开机自启 supervisord将 /data/venv/supervisor/bin/supervisord -c /etc/supervisord.conf 添加到 /etc/rc.local 即可。\n","categories":["Python"],"tags":["python","supervisor"]},{"title":"PHP基础学习","url":"/2018/03/12/2018/PHP%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0/","content":"简介\nPHP全称PHP Hypertext Preprocessor，是一种通用开源脚本语言。语法吸收了C语言、Java和Perl的特点，利于学习，使用广泛，主要适用于Web开发领域。PHP 独特的语法混合了C、Java、Perl以及PHP自创的语法。它可以比CGI或者Perl更快速地执行动态网页。用PHP做出的动态页面与其他的编程语言相比，PHP是将程序嵌入到HTML文档中去执行，执行效率比完全生成HTML标记的CGI要高许多；PHP还可以执行编译后代码，编译可以达到加密和优化代码运行，使代码运行更快。\n\n环境搭建Windows开发环境\n系统环境为Windows 10，这里使用当前最新版，Windows版PHP下载地址为：点此打开\n\n\n当前最新版PHP为7.2.3 点此下载\nF盘中创建phpstudy目录\n在phpstudy目录中创建php-7.2.3、src目录\n将下载好的php-7.2.3-nts-Win32-VC15-x64.zip解压到php-7.2.3目录中\n将php-7.2.3目录下的php.ini-development重命名为php.ini\n创建start.bat文件，并写入以下内容F:\\phpstudy\\php-7.2.3\\php.exe -S 127.0.0.1:8088 -t F:\\phpstudy\\src\n\n\n当前目录结构应该如下所示：\n双击start.bat会打开一个cmd窗口 显示内容如下：\nF:\\phpstudy&gt;F:\\phpstudy\\php-7.2.3\\php.exe -S 127.0.0.1:8088 -t F:\\phpstudy\\src\nPHP 7.2.3 Development Server started at Tue Mar  6 13:00:13 2018\nListening on http://127.0.0.1:8088\nDocument root is F:\\phpstudy\\src\nPress Ctrl-C to quit.\n\n在src目录下创建phpinfo.php文件，并写入以下内容\n&lt;?php    phpinfo();?&gt;\n\n打开浏览器访问: http://127.0.0.1:8088/phpinfo.php 出现如下信息 PHP开发环境就搭建完成了。\n\n\n语法基本语法PHP标记PHP只会解析文档中&lt;?php ... ?&gt;代码块的内容，其他的内容都会忽略\n如果文件内容是纯PHP代码，最好在文件末尾删除PHP的结束标记，这样可以避免在PHP结束标记之后万一意外加入了空格或者换行符，会导致 PHP 开始输出这些空白，而脚本中此时并无输出的意图。\n&lt;?php    echo \"Hello World\";    // Other Code    echo \"Last statement\"    // 脚本结束，不需要 ?&gt; 作为结束标记\nPHP还有一种标记方式&lt;script language=\"php\"&gt;        echo 'Hello World';&lt;/script&gt;\n显然&lt;?php ... ?&gt;的方式更为方便\n嵌入到HTML文档因为PHP只会解析文档中的PHP标记，所以可以很方便的将PHP嵌入到HTML文档中&lt;p&gt;This is going to be ignored by PHP and displayed by the browser.&lt;/p&gt;&lt;?php echo 'While this is going to be parsed.'; ?&gt;&lt;p&gt;This will also be ignored by PHP and displayed by the browser.&lt;/p&gt;\n将文档保存为src目录下的index.php，然后浏览器访问http://127.0.0.1:8088/。可以看到三条语句都被打印出来了，但是通过PHP的echo打印的语句需要先解析，所以速度肯定是比较慢的。\nPHP解析器遇到?&gt;结束标记时就简单的将其后内容原样输出直到再碰到下一个&lt;?php标记。例外的是出于条件语句中间时，PHP解析器会根据条件判断来决定哪些输出，哪些跳过。如下所示：&lt;?php if (true): ?&gt;  This will show if the expression is true.&lt;?php else: ?&gt;  Otherwise this will show.&lt;?php endif; ?&gt;\n当if的条件为true时，输出This will show if the expression is true.，否则输出Otherwise this will show.。要输出大段文本时，跳出PHP解析模式通常比将文本通过echo或print输出更有效率。\n指令分隔符PHP和C或者Perl一样，每条语句的末尾使用分号结束指令。如果指令是PHP代码的最后一行，则可以省略掉分号。\n&lt;?phpecho \"First line&lt;br&gt;\";echo \"Last line\"?&gt;\n如果想要省略掉?&gt; 则最后一行语句必须有分号&lt;?phpecho \"First line&lt;br&gt;\";echo \"Last line\";\n注释PHP支持三种注释方法&lt;?php// This is a one-line c++ style comment/*This is a multi line commentyet another line of comment*/# This is a one-line shell-style comment?&gt;\n类型\nPHP支持9种原始数据类型，其中有四种标量类型，三种复合类型，两种特殊类型\n\n标量类型boolean 布尔型要指定一个布尔值，使用常量TRUE和FALSE，两个都不区分大小写。\n&lt;?php$a = true;$b = false;?&gt;\n当整数和浮点数的零，空字符串，空数组，NULL，从空标记生成的SimpleXML对象转换为布尔型时 都会认为是FALSE，其他的值都被认为是TRUE\n&lt;?phpvar_dump((bool) \"\");var_dump((bool) 0);var_dump((bool) 0.0);var_dump((bool) []);var_dump((bool) NULL);?&gt;\ninteger 整型所有的正整数和负整数都属于整数\n&lt;?php$a = 1234;          // 十进制数$a = -123;          // 负数$a = 0123;          // 八进制数 (等于十进制 83)$a = 0x1A;          // 十六进制数 (等于十进制 26)$a = 0b11111111;    // 二进制数字 (等于十进制 255)?&gt;\n其他类型转为整数时，FALSE会转为0，TRUE会转为1，浮点型会向下取整。\n注意：32位平台整数最大为2147483647，64位平台整数最大为9223372036854775807。溢出后将自动转为浮点型。\nfloat 浮点型浮点型就是带小数位的数，可以用以下任一语法定义：&lt;?php$a = 1.234; $b = 1.2e3; $c = 7E-10;?&gt;\nstring 字符串一个字符串就是由一系列的字符组成，其中每个字符等同于一个字节。这意味着PHP只能支持256的字符集，因此不支持Unicode 。\nPHP的字符串有四种方式表达\n\n单引号\n双引号\nheredoc语法结构\nnowdoc语法结构 (PHP 5.3.0 起)\n\n单引号定义一个字符串的最简单的方法是用单引号把它包围起来（字符 ‘）。\n要表达一个单引号自身，需在它的前面加个反斜线（\\）来转义。要表达一个反斜线自身，则用两个反斜线（\\\\）。其它任何方式的反斜线都会被当成反斜线本身：也就是说如果想使用其它转义序列例如 \\r 或者 \\n，并不代表任何特殊含义，就单纯是这两个字符本身。\n&lt;?phpecho 'this is a simple string';echo 'You can also have embedded newlines in strings this way as it isokay to do';echo 'Arnold once said: \"I\\'ll be back\"';echo 'You deleted C:\\\\*.*?';echo 'You deleted C:\\*.*?';echo 'This will not expand: \\n a newline';echo 'Variables do not $expand $either';?&gt;\n输出：\nthis is a simple string\nYou can also have embedded newlines in strings this way as it is okay to do\nArnold once said: &quot;I&apos;ll be back&quot;\nYou deleted C:\\*.*?\nYou deleted C:\\*.*?\nThis will not expand: \\n a newline\nVariables do not $expand $either\n双引号如果字符串是包围在双引号(&quot;)中， PHP 将对一些特殊的字符进行解析：\n转义字符\n\n序列含义\\n换行（ASCII 字符集中的 LF 或 0x0A）\\r回车（ASCII 字符集中的 CR 或 0x0D）\\t水平制表符（ASCII 字符集中的 HT 或 0x09）\\v垂直制表符（ASCII 字符集中的 VT 或 0x0B）（自PHP 5.2.5 起）\\eEscape（ASCII 字符集中的 ESC 或 0x1B）（自PHP 5.4.0 起）\\f换页（ASCII 字符集中的 FF 或 0x0C）（自PHP 5.2.5 起）\\反斜线\\$美元标记\\”双引号[0-7]{1,3}符合该正则表达式序列的是一个以八进制方式来表达的字符\\x[0-9A-Fa-f]{1,2}符合该正则表达式序列的是一个以十六进制方式来表达的字符\n\n\n用双引号定义的字符串最重要的特征是变量会被解析\n&lt;?php$a = \"World\";echo \"Hello $a\";?&gt;\n输出：\nHello World\nHeredoc结构第三种表达字符串的方法是用 heredoc 句法结构：&lt;&lt;&lt;。在该运算符之后要提供一个标识符，然后换行。接下来是字符串 string 本身，最后要用前面定义的标识符作为结束标志。\n结束时所引用的标识符必须在该行的第一列，而且，标识符的命名也要像其它标签一样遵守 PHP 的规则：只能包含字母、数字和下划线，并且必须以字母和下划线作为开头。\n&lt;?php$str = &lt;&lt;&lt;ENDExample of stringspanning multiple lines&lt;/br&gt;END;echo $str;$name = 'MyName';echo &lt;&lt;&lt;ENDMy name is $name.END;?&gt;\n输出：\nExample of string spanning multiple lines.\nMy name is MyName.\n自 PHP 5.3.0 起还可以在 Heredoc 结构中用双引号来声明标识符：\n&lt;?phpecho &lt;&lt;&lt;\"FOOBAR\"Hello World!FOOBAR;?&gt;\nNowdoc 结构就象 heredoc 结构类似于双引号字符串，Nowdoc 结构是类似于单引号字符串的。Nowdoc 结构很象 heredoc 结构，但是 nowdoc 中不进行解析操作。\n一个 nowdoc 结构也用和 heredocs 结构一样的标记&lt;&lt;&lt;， 但是跟在后面的标识符要用单引号括起来，即&lt;&lt;&lt;&#39;END&#39;。Heredoc 结构的所有规则也同样适用于 Nowdoc 结构，尤其是结束标识符的规则。\n&lt;?php$str = &lt;&lt;&lt;'END'Example of stringspanning multiple lines&lt;/br&gt;END;echo $str;$name = 'MyName';echo &lt;&lt;&lt;'END'My name is $name.END;?&gt;\n输出：\nExample of string spanning multiple lines\nMy name is $name.\n变量解析当使用双引号或者Heredoc结构定义时，其中的变量将会解析。\n变量解析有两种语法规则，一种简单规则，一种复杂规则。简单规则最常见和方便，它可以用最少的代码在一个string中嵌入一个变量、一个array的值、或一个object的属性。\n复杂规则是用花括号包围的表达式。\n简单规则\n&lt;?php$name = 'Tom';echo \"Hello $name&lt;/br&gt;\";$juices = array(\"apple\", \"orange\", \"koolaid1\" =&gt; \"purple\");echo \"He drank some $juices[0] juice.&lt;/br&gt;\";echo \"He drank some $juices[koolaid1] juice.&lt;/br&gt;\";class people &#123;    public $john = \"John Smith\";&#125;$people = new people();echo \"My name is $people-&gt;john.\";?&gt;\n输出：\nHello Tom\nHe drank some apple juice.\nHe drank some purple juice.\nMy name is John Smith.\n复杂规则\n复杂语法不是因为其语法复杂而得名，而是因为它可以使用复杂的表达式。\n任何具有 string 表达的标量变量，数组单元或对象属性都可使用此语法。只需简单地像在 string 以外的地方那样写出表达式，然后用花括号把它括起来即可。\n&lt;?php$name = &apos;Tom&apos;;echo &quot;Hello &#123;$name&#125;&lt;/br&gt;&quot;;$juices = array(&quot;apple&quot;, &quot;orange&quot;, &quot;koolaid1&quot; =&gt; &quot;purple&quot;);echo &quot;He drank some &#123;$juices[0]&#125; juice.&lt;/br&gt;&quot;;echo &quot;He drank some &#123;$juices[&apos;koolaid1&apos;]&#125; juice.&lt;/br&gt;&quot;;class people &#123;    public $john = &quot;John Smith&quot;;&#125;$people = new people();echo &quot;My name is &#123;$people-&gt;john&#125;.&quot;;?&gt;\n注意：只有通过花括号才能正确解析带引号的键名{$juices[&#39;koolaid1&#39;]}\n输出：\nHello Tom\nHe drank some apple juice.\nHe drank some purple juice.\nMy name is John Smith.\n存取和修改字符串string 中的字符可以通过一个从 0 开始的下标，用类似 array 结构中的方括号包含对应的数字来访问和修改，比如 $str[42]。可以把 string 当成字符组成的 array。函数 substr() 和 substr_replace() 可用于操作多于一个字符的情况。\n小提示：string 也可用花括号访问，比如 $str{42}。\n&lt;?php$str = 'This is a test';echo \"First: $str[1]&lt;/br&gt;\";$last = $str[strlen($str)-1];echo \"Last: $last&lt;/br&gt;\";$str = 'Look at the sea';$str[strlen($str)-1] = 'e';echo \"$str\";?&gt;\n输出：\nFirst: h\nLast: t\nLook at the see\n复合类型array 数组PHP 中的数组实际上是一个有序映射。映射是一种把 values 关联到 keys 的类型。此类型在很多方面做了优化，因此可以把它当成真正的数组，或列表（向量），散列表（是映射的一种实现），字典，集合，栈，队列以及更多可能性。由于数组元素的值也可以是另一个数组，树形结构和多维数组也是允许的。\n定义数组：可以用 array() 语言结构来新建一个数组。它接受任意数量用逗号分隔的 键（key） =&gt; 值（value）对。\n数组的键可以是一个整数或字符串，值可以是任意类型的值。自 5.4 开始可以使用[]代替array()。\n&lt;?php$array = array(    \"foo\" =&gt; \"bar\",    \"bar\" =&gt; \"foo\",);// 自 5.4 开始$array = [    \"foo\" =&gt; \"bar\",    \"bar\" =&gt; \"foo\",];// 没有键名的索引数组$array = [\"foo\", \"bar\", 6=&gt;\"hello\", \"world\"];var_dump($array);?&gt;\n如果键名重复，则会使用最后一个键名，前面的都被覆盖了。没有键名的索引数组，键名默认从0开始，如果只对部分单元指定键名，其后面的键名会根据这个单元的键名开始。\n输出：\narray(4) { \n    [0]=&gt; string(3) &quot;foo&quot; \n    [1]=&gt; string(3) &quot;bar&quot; \n    [6]=&gt; string(5) &quot;hello&quot; \n    [7]=&gt; string(5) &quot;world&quot; \n}\n使用方括号访问和修改数组单元\n&lt;?php$array = array(    \"foo\" =&gt; \"bar\",    42    =&gt; 24,    \"multi\" =&gt; array(         \"dimensional\" =&gt; array(             \"array\" =&gt; \"foo\"         )    ));echo \"\\$array['foo'] = &#123;$array['foo']&#125;&lt;/br&gt;\";echo \"\\$array[42] = $array[42]&lt;/br&gt;\";echo \"\\$array['multi']['dimensional']['array'] =     &#123;$array['multi']['dimensional']['array']&#125;&lt;/br&gt;\";?&gt;\n输出：\n$array[&apos;foo&apos;] = bar\n$array[42] = 24\n$array[&apos;multi&apos;][&apos;dimensional&apos;][&apos;array&apos;] = foo\n小提示：和字符串一样 数组也可以使用花括号访问单元 例如 array{&#39;foo&#39;}\n要修改某个值，通过其键名给该单元赋一个新值，要删除某个键值对，对其调用unset()函数。\n&lt;?php$arr = array(5 =&gt; 1, 12 =&gt; 2);$arr[] = 56;    // This is the same as $arr[13] = 56;                // at this point of the script$arr[\"x\"] = 42; // This adds a new element to                // the array with key \"x\"       unset($arr[5]); // This removes the element from the arrayunset($arr);    // This deletes the whole array?&gt;\nobject 对象要创建一个新的对象 object，使用 new 语句实例化一个类：\n&lt;?phpclass foo&#123;    function do_foo()    &#123;        echo \"Doing foo.\";     &#125;&#125;$bar = new foo;$bar-&gt;do_foo();?&gt;\ncallable 可调用一些函数如 call_user_func() 或 usort() 可以接受用户自定义的回调函数作为参数。回调函数不止可以是简单函数，还可以是对象的方法，包括静态类方法。除了普通的用户自定义函数外，也可传递匿名函数给回调参数。\n特殊类型resource 资源资源 resource 是一种特殊变量，保存了到外部资源的一个引用。资源是通过专门的函数来建立和使用的。由于资源类型变量保存有为打开文件、数据库连接、图形画布区域等的特殊句柄，因此将其它类型的值转换为资源没有意义。引用计数系统是 Zend 引擎的一部分，可以自动检测到一个资源不再被引用了（和 Java 一样）。这种情况下此资源使用的所有外部资源都会被垃圾回收系统释放。因此，很少需要手工释放内存。\nNULL 无类型特殊的 NULL 值表示一个变量没有值。NULL 类型唯一可能的值就是 NULL。\n在下列情况下一个变量被认为是 NULL：\n\n被赋值为 NULL。\n尚未被赋值。\n被 unset()。\n\nPHP 包括几个函数可以判断变量的类型，例如：gettype()，is_array()，is_float()，is_int()，is_object() 和 is_string()\n变量基础PHP 中的变量用一个美元符号后面跟变量名来表示。变量名是区分大小写的。$this 是一个特殊的变量，它不能被赋值。\n&lt;?php$var = 'Bob';$Var = 'Joe';echo \"$var, $Var\";      // 输出 \"Bob, Joe\"$4site = 'not yet';     // 非法变量名；以数字开头$_4site = 'not yet';    // 合法变量名；以下划线开头$i站点is = 'mansikka';  // 合法变量名；可以用中文?&gt;\nPHP 也提供了另外一种方式给变量赋值：引用赋值。这意味着新的变量简单的引用了原始变量。改动新的变量将影响到原始变量，反之亦然。使用引用赋值，简单地将一个 &amp; 符号加到将要赋值的变量前。例如，下列代码片断将输出“My name is Bob”两次：\n&lt;?php$foo = 'Bob';              // 将 'Bob' 赋给 $foo$bar = &amp;$foo;              // 通过 $bar 引用 $foo$bar = \"My name is $bar\";  // 修改 $bar 变量echo \"$bar&lt;/br&gt;\";echo $foo;                 // $foo 的值也被修改?&gt;\n预定义变量对于全部脚本而言，PHP 提供了大量的预定义变量。这些变量将所有的外部变量表示成内建环境变量，并且将错误信息表示成返回头。\n\n超全局变量 — 超全局变量是在全部作用域中始终可用的内置变量\n$GLOBALS — 引用全局作用域中可用的全部变量\n$_SERVER — 服务器和执行环境信息\n$_GET — HTTP GET 变量\n$_POST — HTTP POST 变量\n$_FILES — HTTP 文件上传变量\n$_REQUEST — HTTP Request 变量\n$_SESSION — Session 变量\n$_ENV — 环境变量\n$_COOKIE — HTTP Cookies\n$php_errormsg — 前一个错误信息\n$HTTP_RAW_POST_DATA — 原生POST数据\n$http_response_header — HTTP 响应头\n$argc — 传递给脚本的参数数目\n$argv — 传递给脚本的参数数组\n\n变量范围一个局部函数范围将被引入。任何用于函数内部的变量按缺省情况将被限制在局部函数范围内。例如：\n&lt;?php$a = 1; /* global scope */function Test()&#123;    echo $a; /* reference to local scope variable */&#125;Test();?&gt;\n这个脚本不会有任何输出，因为 echo 语句引用了一个局部版本的变量 $a，而且在这个范围内，它并没有被赋值。你可能注意到 PHP 的全局变量和 C 语言有一点点不同，在 C 语言中，全局变量在函数中自动生效，除非被局部变量覆盖。这可能引起一些问题，有些人可能不小心就改变了一个全局变量。PHP 中全局变量在函数中使用时必须声明为 global。\n&lt;?php$a = 1;$b = 2;function Sum()&#123;    global $a, $b;    $b = $a + $b;&#125;Sum();echo $b;?&gt;\n在全局范围内访问变量的第二个办法，是用特殊的 PHP 自定义$GLOBALS 数组。前面的例子可以写成：\n&lt;?php$a = 1;function Sum()&#123;    $GLOBALS['b'] = $GLOBALS['a'] + $GLOBALS['b'];&#125;Sum();echo $b;?&gt;\n$GLOBALS 是一个关联数组，每一个变量为一个元素，键名对应变量名，值对应变量的内容。$GLOBALS 之所以在全局范围内存在，是因为 $GLOBALS 是一个超全局变量。\n可变变量可变变量，就是一个变量的变量名可以动态的设置和使用。语法形式是PHP的特殊语法，其他语言中少见。\n&lt;?php$a = 'hello';$$a = 'world';  // 相当于$hello = 'world'echo \"$a $&#123;$a&#125;&lt;/br&gt;\";echo \"$a $hello\";?&gt;\n输出：\nhello world\nhello world\n来自PHP之外的变量HTML表单（GET和POST）当一个表单提交给 PHP 脚本时，表单中的信息会自动在脚本中可用。有很多方法访问此信息，例如：\ntest.html&lt;html&gt;&lt;body&gt;    &lt;form action=\"welcome.php\" method=\"post\"&gt;        Name: &lt;input type=\"text\" name=\"name\"&gt;&lt;br&gt;        E-mail: &lt;input type=\"text\" name=\"email\"&gt;&lt;br&gt;        &lt;input type=\"submit\"&gt;    &lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\nwelcome.php&lt;html&gt;&lt;body&gt;    Welcome &lt;?php echo $_POST[\"name\"]; ?&gt;&lt;br&gt;    Your email address is: &lt;?php echo $_POST[\"email\"]; ?&gt;&lt;/body&gt;&lt;/html&gt;\n访问 http://127.0.0.1:8088/test.html，输入信息后提交，可以看到跳转到了http://127.0.0.1:8088/welcome.php页面，并且前面输入的数据已经被PHP通过_POST获取了。\nGET也类似，只需要将test.html中的method=&quot;post&quot;改为method=&quot;get&quot;，然后将welcome.php中的$_POST改为$_GET就可以了。但是在上传敏感数据的时候比如用户密码时最好使用POST方法，GET方法会将数据编码到URL上，这样其他用户也可能会获取密码信息了。\nIMAGE SUBMIT 变量名当提交表单时，可以用一幅图像代替标准的提交按钮，用类似这样的标记：\n&lt;input type=\"image\" src=\"image.gif\" name=\"sub\" /&gt;\n当用户点击到图像中的某处时，相应的表单会被传送到服务器，并加上两个变量 sub_x 和 sub_y。它们包含了用户点击图像的坐标。有经验的用户可能会注意到被浏览器发送的实际变量名包含的是一个点而不是下划线（即 sub.x 和 sub.y），但 PHP 自动将点转换成了下划线。\nHTTP Cookies使用$_COOKIE可以获取HTTP Cookies数据，在获取前可以使用setcookie()函数设定cookies。\n&lt;?phpif (isset($_COOKIE['count'])) &#123;    $count = $_COOKIE['count'] + 1;&#125; else &#123;    $count = 1;&#125;setcookie('count', $count, time()+3600);echo $count;?&gt;\n浏览器访问然后刷新数据，可以看到每刷新一次数字就增加1。\n常量常量表示脚本执行期间不能改变值。传统上常量标识符总是大写的。\n可以使用const关键字定义常量，而且一旦定义就不可以再修改或者取消定义。常量只能包含boolean、integer、float、string，虽然也可以定义resource常量，但应该尽量避免。与变量不同，不应该在常量前面加上$符号。用get_defined_constants()获取所有已定义的常量列表。\n&lt;?phpdefine(\"CONSTANT\", \"Hello world1.&lt;/br&gt;\");echo CONSTANT;const CONSTANT2 = 'Hello world2.&lt;/br&gt;';echo CONSTANT2;?&gt;\n输出：\nHello world1.\nHello world2.\n小提示：和使用 define() 来定义常量相反的是，使用 const 关键字定义常量必须处于最顶端的作用区域，因为用此方法是在编译时定义的。这就意味着不能在函数内，循环内以及 if 语句之内用 const 来定义常量。\n魔法常量PHP 向它运行的任何脚本提供了大量的预定义常量。不过很多常量都是由不同的扩展库定义的，只有在加载了这些扩展库时才会出现，或者动态加载后，或者在编译时已经包括进去了。\n有八个魔术常量它们的值随着它们在代码中的位置改变而改变。例如 __LINE__ 的值就依赖于它在脚本中所处的行来决定。这些特殊的常量不区分大小写，如下：\n\n\n\n名称\n说明\n\n\n\n\n__LINE__\n文件中的当前行号。\n\n\n__FILE__\n文件的完整路径和文件名。\n\n\n__DIR__\n文件所在的目录。\n\n\n__FUNCTION__\n函数名称。\n\n\n__CLASS__\n类的名称。\n\n\n__TRAIT__\nTrait 的名字。Trait 名包括其被声明的作用区域。\n\n\n__METHOD__\n类的方法名。返回该方法被定义时的名字。\n\n\n__NAMESPACE__\n当前命名空间的名称。\n\n\n\n运算符运算符优先级下表按照优先级从高到低列出了运算符。同一行中的运算符具有相同优先级，此时它们的结合方向决定求值顺序。\n结合方向运算符附加信息无clone newclone 和 new左[array()右**算术运算符右++–类型和递增／递减无instanceof类型右!逻辑运算符左/%算术运算符左+-.算术运算符和字符串运算符左&lt;&lt;&gt;&gt;位运算符无&lt;&lt;=&gt;&gt;=比较运算符无== !====!==&lt;&gt;&lt;=&gt;比较运算符左&amp;位运算符和引用左^位运算符左|位运算符左&amp;&amp;逻辑运算符左||逻辑运算符左??比较运算符左?:三元运算符右=+=-==**=/=.=%=&amp;=|=^=&lt;&lt;=&gt;&gt;=赋值运算符左and逻辑运算符左xor逻辑运算符左or逻辑运算符\n\n\n\n算术运算符\n\n\n例子\n名称\n结果\n\n\n\n\n-$a\n取反\n$a 的负值。\n\n\n$a + $b\n加法\n$a 和 $b 的和。\n\n\n$a - $b\n减法\n$a 和 $b 的差。\n\n\n$a * $b\n乘法\n$a 和 $b 的积。\n\n\n$a / $b\n除法\n$a 除以 $b 的商。\n\n\n$a % $b\n取模\n$a 除以 $b 的余数。\n\n\n$a ** $b\n取幂\n$a 的 $b 次方。\n\n\n\n赋值运算符基本的赋值运算符是“=”。一开始可能会以为它是“等于”，其实不是的。它实际上意味着把右边表达式的值赋给左边的运算数。\n赋值运算表达式的值也就是所赋的值。也就是说，“$a = 3”的值是 3。这样就可以做一些小技巧：&lt;?php$a = ($b = 4) + 5; // $a 现在成了 9，而 $b 成了 4。?&gt;\n在基本赋值运算符之外，还有适合于所有二元算术，数组集合和字符串运算符的“组合运算符”，这样可以在一个表达式中使用它的值并把表达式的结果赋给它，例如：\n&lt;?php$a = 3;$a += 5; // sets $a to 8, as if we had said: $a = $a + 5;$b = \"Hello \";$b .= \"There!\"; // 将 $b 的值设置为 \"Hello There!\", 相当于 $b = $b . \"There!\";?&gt;\n小提示：.在PHP中用作两个字符串连接。\nPHP 支持引用赋值，使用“$var = &amp;$othervar;”语法。引用赋值意味着两个变量指向了同一个数据，没有拷贝任何东西。\n&lt;?php$a = 3;$b = &amp;$a; // $b 是 $a 的引用print \"$a\\n\"; // 输出 3print \"$b\\n\"; // 输出 3$a = 4; // 修改 $aprint \"$a\\n\"; // 输出 4print \"$b\\n\"; // 也输出 4，因为 $b 是 $a 的引用，因此也被改变?&gt;\n位运算符例子名称结果$a &amp; $bAnd（按位与）将把 $a 和 $b 中都为 1 的位设为 1。$a | $bOr（按位或）将把 $a 和 $b 中任何一个为 1 的位设为 1。$a ^ $bXor（按位异或）将把 $a 和 $b 中一个为 1 另一个为 0 的位设为 1。~ $aNot（按位取反）将 $a 中为 0 的位设为 1，反之亦然。$a &lt;&lt; $bShift left（左移）将 $a 中的位向左移动 $b 次（每一次移动都表示“乘以 2”）。$a &gt;&gt; $bShift right（右移）将 $a 中的位向右移动 $b 次（每一次移动都表示“除以 2”）。\n\n比较运算符例子名称结果$a == $b等于TRUE，如果类型转换后 $a 等于 $b。$a === $b全等TRUE，如果 $a 等于 $b，并且它们的类型也相同。$a != $b不等TRUE，如果类型转换后 $a 不等于 $b。$a &lt;&gt; $b不等TRUE，如果类型转换后 $a 不等于 $b。$a !== $b不全等TRUE，如果 $a 不等于 $b，或者它们的类型不同。$a &lt; $b小与TRUE，如果 $a 严格小于 $b。$a &gt; $b大于TRUE，如果 $a 严格大于 $b。$a &lt;= $b小于等于TRUE，如果 $a 小于或者等于 $b。$a &gt;= $b大于等于TRUE，如果 $a 大于或者等于 $b。$a &lt;=&gt; $b太空船运算符当$a小于、等于、大于$b时 分别返回一个小于、等于、大于0的integer 值。 PHP7开始提供.$a ?? $b ?? $cNULL 合并操作符从左往右第一个存在且不为 NULL 的操作数。如果都没有定义且不为 NULL，则返回 NULL。PHP7开始提供。\n\n错误控制运算符PHP 支持一个错误控制运算符：@。当将其放置在一个 PHP 表达式之前，该表达式可能产生的任何错误信息都被忽略掉。\n如果用 set_error_handler() 设定了自定义的错误处理函数，仍然会被调用，但是此错误处理函数可以（并且也应该）调用 error_reporting()，而该函数在出错语句前有 @ 时将返回 0。\n@ 运算符只对表达式有效。\n执行运算符PHP 支持一个执行运算符：反引号（``）。注意这不是单引号！PHP 将尝试将反引号中的内容作为 shell 命令来执行，并将其输出信息返回。使用反引号运算符`的效果与函数 shell_exec() 相同。\n&lt;?phpecho `ipconfig`;?&gt;\n注意：反引号运算符在激活了安全模式或者关闭了 shell_exec() 时是无效的。\n递增／递减运算符\n\n\n例子\n名称\n效果\n\n\n\n\n++$a\n前加\n$a 的值加一，然后返回 $a。\n\n\n$a++\n后加\n返回 $a，然后将 $a 的值加一。\n\n\n–$a\n前减\n$a 的值减一， 然后返回 $a。\n\n\n$a–\n后减\n返回 $a，然后将 $a 的值减一。\n\n\n\n逻辑运算符例子名称结果$a and $bAnd（逻辑与）TRUE，如果 $a 和 $b 都为 TRUE。$a or $bOr（逻辑或）TRUE，如果 $a 或 $b 任一为 TRUE。$a xor $bXor（逻辑异或）TRUE，如果 $a 或 $b 任一为 TRUE，但不同时是。!$aNot（逻辑非）TRUE，如果 $a 不为 TRUE。$a &amp;&amp;$bAnd（逻辑与）TRUE，如果 $a 和 $b 都为 TRUE。$a || $bOr（逻辑或）TRUE，如果 $a 或 $b 任一为 TRUE。\n\n字符串运算符有两个字符串（string）运算符。第一个是连接运算符 .，它返回其左右参数连接后的字符串。第二个是连接赋值运算符 .=，它将右边参数附加到左边的参数之后。\n&lt;?php$a = \"Hello \";$b = $a . \"World!\"; // 现在 $b 等于 \"Hello World!\"$a = \"Hello \";$a .= \"World!\";     // 现在 $a 等于 \"Hello World!\"?&gt;\n数组运算符例子名称结果$a + $b联合$a 和 $b 的联合。$a == $b相等如果 $a 和 $b 具有相同的键／值对则为 TRUE。$a === $b全等如果 $a 和 $b 具有相同的键／值对并且顺序和类型都相同则为 TRUE。$a != $b不等如果 $a 不等于 $b 则为 TRUE。$a &lt;&gt;$b不等如果 $a 不等于 $b 则为 TRUE。$a !== $b不全等如果 $a 不全等于 $b 则为 TRUE。\n\n类型运算符instanceof 用于确定一个 PHP 变量是否属于某一类 class 的实例：\n&lt;?phpclass MyClass &#123;&#125;class NotMyClass&#123;&#125;$a = new MyClass;var_dump($a instanceof MyClass);echo '&lt;/br&gt;';var_dump($a instanceof NotMyClass);?&gt;\n输出：\nbool(true) \nbool(false)\n流程控制任何 PHP 脚本都是由一系列语句构成的。一条语句可以是一个赋值语句，一个函数调用，一个循环，一个条件语句或者甚至是一个什么也不做的语句（空语句）。语句通常以分号结束。此外，还可以用花括号将一组语句封装成一个语句组。语句组本身可以当作是一行语句。\n条件判断if语法：\n&lt;?php\nif (expr) {\n    statement\n}\n?&gt;\n如果有多个表达式，使用花括号括起来\n例子：\n&lt;?phpif ($a &gt; $b) &#123;    echo \"a is greater than b\";&#125;?&gt;\nif-else语法：\n&lt;?php\nif (expr) {\n    statement\n} else {\n    statement\n}\n?&gt;\n例子：\n&lt;?php$a = 2;$b = 4;if ($a &gt; $b) &#123;  echo \"a is greater than b\";&#125; else &#123;  echo \"a is NOT greater than b\";&#125;?&gt;\nif-elseif-else语法：\n&lt;?php\nif (expr) {\n    statement\n} elseif (expr) {\n    statement\n} else {\n    statement\n}\n?&gt;\n例子：\n&lt;?php$a = 2;$b = 2;if ($a &gt; $b) &#123;    echo \"a is bigger than b\";&#125; elseif ($a == $b) &#123;    echo \"a is equal to b\";&#125; else &#123;    echo \"a is smaller than b\";&#125;?&gt;\n在同一个 if 语句中可以有多个 elseif 部分，其中第一个表达式值为 TRUE 的 elseif 部分将会执行。在 PHP 中，也可以写成”else if”，它和”elseif”的行为完全一样。\n流程控制的替代语法PHP 提供了一些流程控制的替代语法，包括 if，while，for，foreach 和 switch。替代语法的基本形式是把左花括号 { 换成冒号 : ，把右花括号 } 分别换成 endif;，endwhile;，endfor;，endforeach; 以及 endswitch;。\n&lt;?php $a = 5; ?&gt;&lt;?php if ($a == 5): ?&gt;    A is equal to 5&lt;?php endif; ?&gt;\n同样还可以用在 else 和 elseif 中\n&lt;?php$a = 6;if ($a == 5):    echo \"a equals 5\";    echo \"...\";elseif ($a == 6):    echo \"a equals 6\";    echo \"!!!\";else:    echo \"a is neither 5 nor 6\";endif;?&gt;\n注意：不支持在同一个控制块内混合使用两种语法。\n循环while循环while 循环是 PHP 中最简单的循环类型。它和 C 语言中的 while 表现地一样。while 语句的基本格式是：\nwhile (expr) {\n    statement\n}\n如果表达式只有一句 也可以将花括号省略掉。\nwhile 语句的含义很简单，只要 while 的表达式值为 TRUE ，就重复执行嵌套中的循环语句，表达式的值在每次开始循环时检查，直到表达式为 FALSE 为止。\n&lt;?php$a = 0;while ($i &lt;= 10) &#123;    echo $i++;&#125;?&gt;\ndo-while循环do-while 循环是先循环 后判断，所以 do-while 不管表达式是否为 TRUE 都会至少循环一次。\n&lt;?php$i = 0;do &#123;   echo $i++;&#125; while ($i &lt;= 10);?&gt;\nfor循环for循环是相对比较复杂但同时更强大的循环方法。for循环的语法是：\nfor (expr1; expr2; expr3) {\n    statement\n}\n第一个表达式(expr1)在循环前执行一次。第二个表达式在每次循环开始前执行，如果值为 TRUE 则继续执行，FALSE 则跳出循环。第三个表达式在每次循环之后被执行。\n每个表达式都可以为空或包括逗号分隔的多个表达式，表达式 expr2 中，所有用逗号分隔的表达式都会计算，但只取最后一个结果。expr2 为空意味着将无限循环下去。如果死循环，可以在循环语句中使用break跳出去。\n&lt;?phpfor ($i = 1; $i &lt;= 10; $i++) &#123;    echo $i;&#125;echo \"&lt;/br&gt;\";for ($i = 1; ; $i++) &#123;    if ($i &gt; 10) &#123;        break;    &#125;    echo $i;&#125;?&gt;\nPHP 也支持用冒号的 for 循环的替代语法。\nfor (expr1; expr2; expr3):\n    statement;\n    ...\nendfor;\nforeachforeach 语法结构提供了遍历数组的简单方式。foreach 仅能够应用于数组和对象，如果尝试应用于其他数据类型的变量，或者未初始化的变量将发出错误信息。有两种语法：\nforeach (array_expression as $value)\n    statement\nforeach (array_expression as $key =&gt; $value)\n    statement\n第一种格式遍历给定的 array_expression 数组。每次循环中，当前单元的值被赋给 $value 并且数组内部的指针向前移一步（因此下一次循环中将会得到下一个单元）。\n第二种格式做同样的事，只除了当前单元的键名也会在每次循环中被赋给变量 $key。\n可以很容易地通过在 $value 之前加上 &amp; 来修改数组的元素。此方法将以引用赋值而不是拷贝一个值。\n&lt;?php$arr = array(1, 2, 3, 4);foreach ($arr as &amp;$value) &#123;    $value = $value * 2;&#125;// $arr is now array(2, 4, 6, 8)unset($value); // 最后取消掉引用?&gt;\nPHP 5.5 增添了遍历一个数组的数组的功能并且把嵌套的数组解包到循环变量中，只需将 list() 作为值提供。\n&lt;?php$array = [    [1, 2],    [3, 4],];foreach ($array as list($a, $b)) &#123;    // $a contains the first element of the nested array,    // and $b contains the second element.    echo \"A: $a; B: $b\\n\";&#125;?&gt;\nlist() 中的单元可以少于嵌套数组的，此时多出来的数组单元将被忽略。如果 list() 中列出的单元多于嵌套数组则会发出一条消息级别的错误信息。\nbreak 跳出循环break 结束当前 for，foreach，while，do-while 或者 switch 结构的执行。\nbreak 可以接受一个可选的数字参数来决定跳出几重循环。\n&lt;?php$arr = array('one', 'two', 'three', 'four', 'stop', 'five');while (list (, $val) = each($arr)) &#123;    if ($val == 'stop') &#123;        break;    /* You could also write 'break 1;' here. */    &#125;    echo \"$val&lt;br /&gt;\\n\";&#125;/* 使用可选参数 */$i = 0;while (++$i) &#123;    switch ($i) &#123;    case 5:        echo \"At 5&lt;br /&gt;\\n\";        break 1;  /* 只退出 switch. */    case 10:        echo \"At 10; quitting&lt;br /&gt;\\n\";        break 2;  /* 退出 switch 和 while 循环 */    default:        break;    &#125;&#125;?&gt;\n注意：在PHP 5.4.0 之后，取消变量作为参数传递（例如 $num = 2; break $num;）。\ncontinue 跳出本次循环continue 在循环结构用用来跳过本次循环中剩余的代码并在条件求值为真时开始执行下一次循环。\n小提示：注意在 PHP 中 switch 语句被认为是可以使用 continue 的一种循环结构。continue 接受一个可选的数字参数来决定跳过几重循环到循环结尾。默认值是 1，即跳到当前循环末尾。\n&lt;?phpwhile (list ($key, $value) = each($arr)) &#123;    if (!($key % 2)) &#123; // skip odd members        continue;    &#125;    do_something_odd($value);&#125;$i = 0;while ($i++ &lt; 5) &#123;    echo \"Outer&lt;br /&gt;\\n\";    while (1) &#123;        echo \"Middle&lt;br /&gt;\\n\";        while (1) &#123;            echo \"Inner&lt;br /&gt;\\n\";            continue 3;        &#125;        echo \"This never gets output.&lt;br /&gt;\\n\";    &#125;    echo \"Neither does this.&lt;br /&gt;\\n\";&#125;?&gt;\n注意：在PHP 5.4.0 之后，取消变量作为参数传递（例如 $num = 2; continue $num;）。\nswitch 分支选择switch 语句类似于具有同一个表达式的一系列 if 语句。很多场合下需要把同一个变量（或表达式）与很多不同的值比较，并根据它等于哪个值来执行不同的代码。这正是 switch 语句的用途。\n小提示：注意和其它语言不同，continue 语句作用到 switch 上的作用类似于 break。如果在循环中有一个 switch 并希望 continue 到外层循环中的下一轮循环，用 continue 2。\nswitch 结构示例：\n&lt;?phpswitch ($i) &#123;    case 0:        echo \"i equals 0\";        break;    case 1:        echo \"i equals 1\";        break;    case 2:        echo \"i equals 2\";        break;    default:        echo \"i is not equal to 0, 1 or 2\";&#125;?&gt;\nswitch 结构中 case 的目标还可以是字符串。case 会依次执行。如果没有 break 将会继续执行下面的 case 代码。default 是所有的 case 都没有匹配时执行。\ndeclaredeclare 结构用来设定一段代码的执行指令。declare 的语法和其它流程控制结构相似：\ndeclare (directive)\n    statement\ndirective 部分允许设定 declare 代码段的行为。目前只认识两个指令：ticks 以及 encoding，declare 调试内部程序使用.\ndeclare(ticks=n) 和 register_tick_function(&#39;handel_function&#39;) 一般是配合使用的。ticks 参数表示运行多少语句调用一次 register_tick_function 的函数。并且declare支持两种写法：\ndeclare(ticks = 1); //整个脚本declare(ticks = 1) &#123;     ......  // 内部的代码做记录&#125;\n例如：\n&lt;?phpdeclare(ticks=1);// A function called on each tick eventfunction tick_handler()&#123;    echo \"tick_handler() called\\n\";&#125;register_tick_function('tick_handler');$a = 1;if ($a &gt; 0) &#123;    $a += 2;    print($a);&#125;?&gt;\nencoding 指令来对每段脚本指定其编码方式。\n&lt;?phpdeclare(encoding='ISO-8859-1');// code here?&gt;\n在 PHP 5.3 中除非在编译时指定了 --enable-zend-multibyte，否则 declare 中的 encoding 值会被忽略。\nreturn如果在一个函数中调用 return 语句，将立即结束此函数的执行并将它的参数作为函数的值返回。return 也会终止 eval() 语句或者脚本文件的执行。\n如果在全局范围中调用，则当前脚本文件中止运行。如果当前脚本文件是被 include 的或者 require 的，则控制交回调用文件。此外，如果当前脚本是被 include 的，则 return 的值会被当作 include 调用的返回值。如果在主脚本文件中调用 return，则脚本中止运行。如果当前脚本文件是在 php.ini 中的配置选项 auto_prepend_file 或者 auto_append_file所指定的，则此脚本文件中止运行。\nrequirerequire 和 include 几乎完全一样，除了处理失败的方式不同之外。require 在出错时产生 E_COMPILE_ERROR 级别的错误。换句话说将导致脚本中止而 include 只产生警告 E_WARNING ，脚本会继续运行。\n还有一个和 require 作用完全相同的是 require_once，不同的是如果这个文件已经被包含，require_once 则不会再次包含这个文件。\ninclude被包含文件先按参数给出的路径寻找，如果没有给出目录（只有文件名）时则按照 include_path 指定的目录寻找。如果在 include_path 下没找到该文件则 include 最后才在调用脚本文件所在的目录和当前工作目录下寻找。如果最后仍未找到文件则 include 结构会发出一条警告；这一点和 require 不同，后者会发出一个致命错误。include_path 是在 php.ini 配置文件中定义的。\n如果定义了路径——不管是绝对路径还是当前目录的相对路径 include_path 都会被完全忽略。例如一个文件以 ../ 开头，则解析器会在当前目录的父目录下寻找该文件。\n当一个文件被包含时，其中所包含的代码继承了 include 所在行的变量范围。从该处开始，调用文件在该行处可用的任何变量在被调用的文件中也都可用。不过所有在包含文件中定义的函数和类都具有全局作用域。\nvars.php&lt;?php$color = 'green';$fruit = 'apple';?&gt;\ntest.php&lt;?phpecho \"A $color $fruit\"; // Ainclude 'vars.php';echo \"A $color $fruit\"; // A green apple?&gt;\n如果 include 出现于调用文件中的一个函数里，则被调用的文件中所包含的所有代码将表现得如同它们是在该函数内部定义的一样。所以它将遵循该函数的变量范围。\ntest2.php&lt;?phpfunction foo() &#123;    global $color;    include 'vars.php';    echo \"A $color $fruit\";&#125;foo();                      // A green appleecho \"A $color $fruit\";     // A green?&gt;\ninclude_once 可以用于在脚本执行期间同一个文件有可能被包含超过一次的情况下，想确保它只被包含一次以避免函数重定义，变量重新赋值等问题。\ngoto 跳转goto 操作符可以用来跳转到程序中的另一位置。该目标位置可以用目标名称加上冒号来标记，而跳转指令是 goto 之后接上目标位置的标记。PHP 中的 goto 有一定限制，目标位置只能位于同一个文件和作用域，也就是说无法跳出一个函数或类方法，也无法跳入到另一个函数。也无法跳入到任何循环或者 switch 结构中。可以跳出循环或者 switch，通常的用法是用 goto 代替多层的 break。\n&lt;?phpgoto a;echo 'Foo'; a:echo 'Bar';?&gt;\n跳出循环示例：\n&lt;?phpfor($i=0,$j=50; $i&lt;100; $i++) &#123;  while($j--) &#123;    if($j==17) goto end;   &#125;  &#125;echo \"i = $i\";end:echo 'j hit 17';?&gt;\ngoto 可以跳出循环 而不可以跳进循环内。\n函数自定义函数任何有效的 PHP 代码都有可能出现在函数内部，甚至包括其它函数和类定义。\n&lt;?phpfoo();bar();function foo() &#123;    function bar() &#123;        echo \"I don't exist until foo() is called.\";    &#125;&#125;?&gt;\n可以看到，函数并非只有定义后才能调用。而且bar()函数只有foo()函数调用后才会创建的。\nPHP 中的所有函数和类都具有全局作用域，可以定义在一个函数之内而在之外调用，反之亦然。PHP 不支持函数重载，也不可能取消定义或者重定义已声明的函数。PHP 的函数支持可变数量的参数和默认参数。\n在 PHP 中还可以递归调用函数，但是要避免递归超过100-200层，因为可能会使堆栈崩溃从而使当前脚本终止。 无限递归可视为编程错误。\n函数参数普通参数通过参数列表可以传递信息到函数。\n&lt;?phpfunction takes_array($input)&#123;    echo \"$input[0] + $input[1] = \", $input[0]+$input[1];&#125;takes_array([2, 4]);?&gt;\n传递引用默认情况下，函数参数通过值传递。如果希望允许函数修改它的参数值，必须通过引用传递参数。\n&lt;?phpfunction add_some_extra(&amp;$string)&#123;    $string .= 'and something extra.';&#125;$str = 'This is a string, ';add_some_extra($str);echo $str;    // outputs 'This is a string, and something extra.'?&gt;\n参数默认值在函数中可以给参数提供一个默认值\n&lt;?phpfunction makecoffee($type = \"cappuccino\")&#123;    return \"Making a cup of $type.\\n\";&#125;echo makecoffee();echo makecoffee(null);echo makecoffee(\"espresso\");?&gt;\n默认值必须是常量表达式，不能是诸如变量，类成员，或者函数调用等。\n注意：当使用默认参数时，任何默认参数必须放在任何非默认参数的右侧。否则，函数将不会按照预期的情况工作。\n比如下面代码将不能正确运行：\n&lt;?phpfunction makeyogurt($type = \"acidophilus\", $flavour)&#123;    return \"Making a bowl of $type $flavour.\\n\";&#125;echo makeyogurt(\"raspberry\");   // won't work as expected?&gt;\n类型声明类型声明允许函数在调用时要求参数为特定类型。 如果给出的值类型不对，那么将会产生一个错误： 在PHP 5中，这将是一个可恢复的致命错误，而在PHP 7中将会抛出一个TypeError异常。\n为了指定一个类型声明，类型应该加到参数名前。这个声明可以通过将参数的默认值设为NULL来实现允许传递NULL。\n可用类型：\n\n\n\n类型\n描述\n最低PHP版本\n\n\n\n\n类/接口名\n参数必须是特定的类或接口的名称\nPHP 5.0.0\n\n\nself\n参数必须是自身的方法\nPHP 5.0.0\n\n\narray\n参数必须是一个数组\nPHP 5.1.0\n\n\ncallable\n参数必须是一个可调用对象\nPHP 5.4.0\n\n\nbool\n参数必须是一个布尔值\nPHP 7.0.0\n\n\nfloat\n参数必须是一个浮点数\nPHP 7.0.0\n\n\nint\n参数必须是一个整型\nPHP 7.0.0\n\n\nstring\n参数必须是一个字符串\nPHP 7.0.0\n\n\n\n基础类类型声明：&lt;?phpclass C &#123;&#125;class D extends C &#123;&#125;// This doesn't extend C.class E &#123;&#125;function f(C $c) &#123;    echo get_class($c).\"\\n\";&#125;f(new C);f(new D);f(new E);       // 这里会报错，因为f()只接受C类和C类的子类的实例?&gt;\n可变参数PHP 在用户自定义函数中支持可变数量的参数列表。在 PHP 5.6 及以上的版本中，由 ... 语法实现；在 PHP 5.5 及更早版本中，使用函数 func_num_args()，func_get_arg()，和 func_get_args() 。\n在 PHP 5.6+&lt;?phpfunction sum(...$numbers) &#123;    $acc = 0;    foreach ($numbers as $n) &#123;        $acc += $n;    &#125;    return $acc;&#125;echo sum(1, 2, 3, 4);?&gt;\n还可以使用 ... 来提供参数\n&lt;?phpfunction add($a, $b) &#123;    return $a + $b;&#125;echo add(...[1, 2]);?&gt;\n在 PHP 5.5 和之前版本访问参数列表\n&lt;?phpfunction sum() &#123;    $acc = 0;    foreach (func_get_args() as $n) &#123;        $acc += $n;    &#125;    return $acc;&#125;echo sum(1, 2, 3, 4);?&gt;\n返回值值通过使用可选的返回语句返回。可以返回包括数组和对象的任意类型。返回语句会立即中止函数的运行，并且将控制权交回调用该函数的代码行。如果省略了 return，则返回值为 NULL。\n示例：\n&lt;?phpfunction square($num)&#123;    return $num * $num;&#125;echo square(4);   // outputs '16'.?&gt;\n函数不能返回多个值，但可以通过返回一个数组来得到类似的效果。\n&lt;?phpfunction small_numbers()&#123;    return array (0, 1, 2);&#125;list ($zero, $one, $two) = small_numbers();?&gt;\n从函数返回一个引用，必须在函数声明和指派返回值给一个变量时都使用引用运算符 &amp;：\n&lt;?phpfunction &amp;returns_reference()&#123;    return $someref;&#125;$newref =&amp; returns_reference();?&gt;\n返回一个对象：\n&lt;?phpclass C &#123;&#125;function getC(): C &#123;    return new C;&#125;var_dump(getC());?&gt;\n可变函数PHP 支持可变函数的概念。这意味着如果一个变量名后有圆括号，PHP 将寻找与变量的值同名的函数，并且尝试执行它。可变函数可以用来实现包括回调函数，函数表在内的一些用途。\n可变函数不能用于例如 echo，print，unset()，isset()，empty()，include，require 以及类似的语言结构。需要使用自己的包装函数来将这些结构用作可变函数。\n示例：&lt;?phpfunction foo() &#123;    echo \"In foo()&lt;br /&gt;\\n\";&#125;function bar($arg = '') &#123;    echo \"In bar(); argument was '$arg'.&lt;br /&gt;\\n\";&#125;// 使用 echo 的包装函数function echoit($string)&#123;    echo $string;&#125;$func = 'foo';$func();        // 将调用 foo()$func = 'bar';$func('test');  // 将调用 bar()$func = 'echoit';$func('test');  // 将调用 echoit()?&gt;\n也可以用可变函数的语法来调用一个对象的方法。\n&lt;?phpclass Foo &#123;    function Variable() &#123;        $name = 'Bar';        $this-&gt;$name(); // This calls the Bar() method    &#125;    function Bar() &#123;        echo \"This is Bar\";    &#125;&#125;$foo = new Foo();$funcname = \"Variable\";$foo-&gt;$funcname();   // This calls $foo-&gt;Variable()?&gt;\n内置函数PHP 有很多标准的函数和结构。还有一些函数需要和特定地 PHP 扩展模块一起编译，否则在使用它们的时候就会得到一个致命的“未定义函数”错误。例如，要使用 image 函数中的 imagecreatetruecolor()，需要在编译 PHP 的时候加上 GD 的支持。或者，要使用 mysql_connect() 函数，就需要在编译 PHP 的时候加上 MySQL 支持。有很多核心函数已包含在每个版本的 PHP 中如字符串和变量函数。调用 phpinfo() 或者 get_loaded_extensions() 可以得知 PHP 加载了那些扩展库。\n匿名函数匿名函数也叫闭包函数，就是创建一个没有函数名的函数。最经常用作回调函数。\n闭包函数也可以作为变量的值来使用。PHP 会自动把此种表达式转换成内置类 Closure 的对象实例。把一个 closure 对象赋值给一个变量的方式与普通变量赋值的语法是一样的，最后也要加上分号：\n&lt;?php$greet = function($name)&#123;    printf(\"Hello %s\\r\\n\", $name);&#125;;$greet('World');$greet('PHP');?&gt;\n闭包可以从父作用域中继承变量。 任何此类变量都应该用 use 语言结构传递进去。 PHP 7.1 起，不能传入此类变量： superglobals、 $this 或者和参数重名。\n从父作用域继承变量&lt;?php$message = 'hello';// 没有 \"use\"$example = function () &#123;    var_dump($message);&#125;;echo $example().\"&lt;/br&gt;\";// 继承 $message$example = function () use ($message) &#123;    var_dump($message);&#125;;echo $example().\"&lt;/br&gt;\";// 继承变量的值是在定义函数时，而不是在调用时定义的$message = 'world';echo $example().\"&lt;/br&gt;\";// 重新设置 $message$message = 'hello';// 继承引用$example = function () use (&amp;$message) &#123;    var_dump($message);&#125;;echo $example().\"&lt;/br&gt;\";// 父作用域中的更改值反映在函数调用中。$message = 'world';echo $example().\"&lt;/br&gt;\";// 匿名函数也可以接受参数。$example = function ($arg) use ($message) &#123;    var_dump($arg . ' ' . $message);&#125;;$example(\"hello\");?&gt;\n输出：\nNotice: Undefined variable: message in F:\\phpstudy\\src\\index.php on line 6\nNULL \nstring(5) &quot;hello&quot; \nstring(5) &quot;hello&quot; \nstring(5) &quot;hello&quot; \nstring(5) &quot;world&quot; \nstring(11) &quot;hello world&quot;\n这些变量都必须在函数或类的头部声明。 从父作用域中继承变量与使用全局变量是不同的。全局变量存在于一个全局的范围，无论当前在执行的是哪个函数。而闭包的父作用域是定义该闭包的函数。\n小提示：可以在闭包中使用 func_num_args()，func_get_arg() 和 func_get_args()。\n类与对象自 PHP 5 起完全重写了对象模型以得到更佳性能和更多特性。这是自 PHP 4 以来的最大变化。PHP 5 具有完整的对象模型。PHP 5 中的新特性包括访问控制，抽象类和 final 类与方法，附加的魔术方法，接口，对象复制和类型约束。PHP 对待对象的方式与引用和句柄相同，即每个变量都持有对象的引用，而不是整个对象的拷贝。\n基本概念每个类的定义都以关键字 class 开头，后面跟着类名，后面跟着一对花括号，里面包含有类的属性与方法的定义。一个类可以包含有属于自己的常量，变量（称为”属性”）以及函数（称为”方法”）。\n类的定义一个简单的类定义：&lt;?phpclass SimpleClass&#123;    // 属性声明    public $var = 'a default value';    // 方法声明    public function displayVar() &#123;        echo $this-&gt;var;    &#125;&#125;?&gt;\n$this 伪变量当一个方法在类定义内部被调用时，有一个可用的伪变量 $this。$this 是一个到主叫对象的引用\n$this 的使用示例：&lt;?phpclass A &#123;    function foo() &#123;        if (isset($this)) &#123;            echo '$this is defined (';            echo get_class($this);            echo \")\\n\";        &#125; else &#123;            echo \"\\$this is not defined.\\n\";        &#125;    &#125;&#125;class B &#123;    function bar() &#123;        A::foo();    &#125;&#125;$a = new A();$a-&gt;foo();A::foo();$b = new B();$b-&gt;bar();B::bar();?&gt;\n输出：\n$this is defined (A) \n$this is not defined. \n$this is not defined. \n$this is not defined.\nnew 创建实例要创建一个类的实例，必须使用 new 关键字。当创建新对象时该对象总是被赋值，除非该对象定义了构造函数并且在出错时抛出了一个异常。\n如果在 new 之后跟着的是一个包含有类名的字符串，则该类的一个实例被创建。如果该类属于一个名字空间，则必须使用其完整名称。\n创建一个实例：&lt;?php$instance = new SimpleClass();// 也可以这样做$className = 'Foo';$instance = new $className(); // Foo()?&gt;\n当把一个对象已经创建的实例赋给一个新变量时，新变量会访问同一个实例，就和用该对象赋值一样。此行为和给函数传递入实例时一样。可以用克隆给一个已创建的对象建立一个新实例。\n&lt;?phpclass SimpleClass &#123;&#125;;$instance = new SimpleClass();$assigned   =  $instance;$reference  =&amp; $instance;$instance-&gt;var = '$assigned will have this value';$instance = null; // $instance and $reference become nullvar_dump($instance);echo '&lt;/br&gt;';var_dump($reference);echo '&lt;/br&gt;';var_dump($assigned);?&gt;\n输出：\nNULL \nNULL \nobject(SimpleClass)#1 (1) { \n    [&quot;var&quot;]=&gt; string(30) &quot;$assigned will have this value&quot; \n}\n::class自 PHP 5.5 起，关键词 class 也可用于类名的解析。使用 ClassName::class 你可以获取一个字符串，包含了类 ClassName 的完全限定名称。这对使用了 命名空间 的类尤其有用。\n示例：&lt;?phpnamespace NS &#123;    class ClassName &#123; &#125;    echo ClassName::class;&#125;?&gt;\n输出：\nNS\\ClassName\n属性类的变量成员叫做”属性”，属性声明是由关键字 public，protected 或者 private 开头，然后跟一个普通的变量声明来组成。属性中的变量可以初始化，但是初始化的值必须是常数，这里的常数是指 PHP 脚本在编译阶段时就可以得到其值，而不依赖于运行时的信息才能求值。\n在类的成员方法里面，可以用 -&gt;（对象运算符）：$this-&gt;property（其中 property 是该属性名）这种方式来访问非静态属性。静态属性则是用 ::（双冒号）：self::$property 来访问。更多静态属性与非静态属性的区别参见 static 关键字。\n属性声明：\n&lt;?phpclass SimpleClass&#123;   // 错误的属性声明   public $var1 = 'hello ' . 'world';   public $var2 = &lt;&lt;&lt;EODhello worldEOD;   public $var3 = 1+2;   public $var4 = self::myStaticMethod();   public $var5 = $myVar;   // 正确的属性声明   public $var6 = myConstant;   public $var7 = array(true, false);   //在 PHP 5.3.0 及之后，下面的声明也正确   public $var8 = &lt;&lt;&lt;'EOD'hello worldEOD;&#125;?&gt;\n类常量可以把在类中始终保持不变的值定义为常量。在定义和使用常量的时候不需要使用 $ 符号。常量的值必须是一个定值，不能是变量，类属性，数学运算的结果或函数调用。\n定义和使用一个常量：&lt;?phpclass MyClass&#123;    const constant = 'constant value';    function showConstant() &#123;        echo  self::constant . \"\\n\";    &#125;&#125;echo MyClass::constant . \"\\n\";$classname = \"MyClass\";echo $classname::constant . \"\\n\"; // 自 5.3.0 起$class = new MyClass();$class-&gt;showConstant();echo $class::constant.\"\\n\"; // 自 PHP 5.3.0 起?&gt;\n类的自动加载在编写面向对象程序时，很多开发者为每个类新建一个 PHP 文件。 这会带来一个烦恼：每个脚本的开头，都需要 include 一个长长的列表。\n在 PHP 5 中，已经不再需要这样了。 spl_autoload_register() 函数可以注册任意数量的自动加载器，当使用尚未被定义的类和接口时自动去加载。通过注册自动加载器，脚本引擎在 PHP 出错失败前有了最后一个机会加载所需的类。\n尝试分别从 MyClass1.php 和 MyClass2.php 文件中加载 MyClass1 和 MyClass2 类。\nMyClass1.php&lt;?phpclass MyClass1 &#123;    const VAR = 'MyClass1&lt;/br&gt;';&#125;;?&gt;\nMyClass2.php&lt;?phpclass MyClass2 &#123;    const VAR = 'MyClass2&lt;/br&gt;';&#125;;?&gt;\nMyClass3.php&lt;?phpspl_autoload_register(function ($class_name) &#123;    require_once $class_name . '.php';&#125;);$obj  = new MyClass1();$obj2 = new MyClass2();echo $obj::VAR;echo $obj2::VAR;?&gt;\n当 new 一个尚未定义的类 MyClass1 时，将自动寻找文件名为类名的 php 文件，也就是 MyClass1.php 文件。\n当加载的类文件不存在时，将抛出一个异常，可以用 try/catch 进行异常处理\n抛出一个异常并在 try/catch 语句块中演示：&lt;?phpspl_autoload_register(function ($name) &#123;    echo \"Want to load $name.\\n\";    throw new Exception(\"Unable to load $name.\");&#125;);try &#123;    $obj = new NonLoadableClass();&#125; catch (Exception $e) &#123;    echo $e-&gt;getMessage(), \"\\n\";&#125;?&gt;\n输出：\nWant to load NonLoadableClass.\nUnable to load NonLoadableClass.\n构造函数和析构函数构造函数PHP 5 允行开发者在一个类中定义一个方法作为构造函数。具有构造函数的类会在每次创建新对象时先调用此方法，所以非常适合在使用对象之前做一些初始化工作。\n如果子类中定义了构造函数则不会隐式调用其父类的构造函数。要执行父类的构造函数，需要在子类的构造函数中调用 parent::__construct()。如果子类没有定义构造函数则会如同一个普通的类方法一样从父类继承。\n&lt;?phpclass BaseClass &#123;    function __construct() &#123;        print \"In BaseClass constructor&lt;/br&gt;\";    &#125;&#125;class SubClass extends BaseClass &#123;    function __construct() &#123;        parent::__construct();        print \"In SubClass constructor&lt;/br&gt;\";    &#125;&#125;class OtherSubClass extends BaseClass &#123; &#125;$obj = new BaseClass();$obj = new SubClass();$obj = new OtherSubClass();?&gt;\n输出：\nIn BaseClass constructor\nIn BaseClass constructor\nIn SubClass constructor\nIn BaseClass constructor\n为了实现向后兼容性，如果 PHP 5 在类中找不到 __construct() 函数并且也没有从父类继承一个的话，它就会尝试寻找旧式的构造函数，也就是和类同名的函数。因此唯一会产生兼容性问题的情况是：类中已有一个名为 __construct() 的方法却被用于其它用途时。\n与其它方法不同，当 __construct() 被与父类 __construct() 具有不同参数的方法覆盖时，PHP 不会产生一个 E_STRICT 错误信息。\n自 PHP 5.3.3 起，在命名空间中，与类名同名的方法不再作为构造函数。这一改变不影响不在命名空间中的类。\n析构函数PHP 5 引入了析构函数的概念，这类似于其它面向对象的语言，如 C++。析构函数会在到某个对象的所有引用都被删除或者当对象被显式销毁时执行。\n&lt;?phpclass MyDestructableClass &#123;   function __construct() &#123;       print \"In constructor&lt;/br&gt;\";       $this-&gt;name = \"MyDestructableClass\";   &#125;   function __destruct() &#123;       print \"Destroying \" . $this-&gt;name . \"&lt;/br&gt;\";   &#125;&#125;$obj = new MyDestructableClass();?&gt;\n和构造函数一样，父类的析构函数不会被引擎暗中调用。要执行父类的析构函数，必须在子类的析构函数体中显式调用 parent::__destruct()。此外也和构造函数一样，子类如果自己没有定义析构函数则会继承父类的。\n析构函数即使在使用 exit() 终止脚本运行时也会被调用。在析构函数中调用 exit() 将会中止其余关闭操作的运行。\n访问控制对属性或方法的访问控制，是通过在前面添加关键字 public（公有），protected（受保护）或 private（私有）来实现的。被定义为公有的类成员可以在任何地方被访问。被定义为受保护的类成员则可以被其自身以及其子类和父类访问。被定义为私有的类成员则只能被其定义所在的类访问。\n属性的访问控制类属性必须定义为公有，受保护，私有之一。如果没有定义 默认是公有。\n&lt;?php/** * Define MyClass */class MyClass &#123;    public $public = 'Public';    protected $protected = 'Protected';    private $private = 'Private';    function printHello() &#123;        echo $this-&gt;public;        echo $this-&gt;protected;        echo $this-&gt;private;    &#125;&#125;$obj = new MyClass();echo $obj-&gt;public; // 这行能被正常执行echo $obj-&gt;protected; // 这行会产生一个致命错误echo $obj-&gt;private; // 这行也会产生一个致命错误$obj-&gt;printHello(); // 输出 Public、Protected 和 Private/** * Define MyClass2 */class MyClass2 extends MyClass &#123;    // 可以对 public 和 protected 进行重定义，但 private 而不能    protected $protected = 'Protected2';    function printHello() &#123;        echo $this-&gt;public;        echo $this-&gt;protected;        echo $this-&gt;private;    &#125;&#125;$obj2 = new MyClass2();echo $obj2-&gt;public; // 这行能被正常执行echo $obj2-&gt;private; // 未定义 privateecho $obj2-&gt;protected; // 这行会产生一个致命错误$obj2-&gt;printHello(); // 输出 Public、Protected2 和 Undefined?&gt;\n方法的访问控制类中的方法可以被定义为公有，私有或受保护。如果没有设置这些关键字，则该方法默认为公有。\n&lt;?php/** * Define MyClass */class MyClass &#123;    // 声明一个公有的构造函数    public function __construct() &#123; &#125;    // 声明一个公有的方法    public function MyPublic() &#123; &#125;    // 声明一个受保护的方法    protected function MyProtected() &#123; &#125;    // 声明一个私有的方法    private function MyPrivate() &#123; &#125;    // 此方法为公有    function Foo() &#123;        $this-&gt;MyPublic();        $this-&gt;MyProtected();        $this-&gt;MyPrivate();    &#125;&#125;$myclass = new MyClass;$myclass-&gt;MyPublic(); // 这行能被正常执行$myclass-&gt;MyProtected(); // 这行会产生一个致命错误$myclass-&gt;MyPrivate(); // 这行会产生一个致命错误$myclass-&gt;Foo(); // 公有，受保护，私有都可以执行/** * Define MyClass2 */class MyClass2 extends MyClass&#123;    // 此方法为公有    function Foo2() &#123;        $this-&gt;MyPublic();        $this-&gt;MyProtected();        $this-&gt;MyPrivate(); // 这行会产生一个致命错误    &#125;&#125;$myclass2 = new MyClass2;$myclass2-&gt;MyPublic(); // 这行能被正常执行$myclass2-&gt;Foo2(); // 公有的和受保护的都可执行，但私有的不行class Bar &#123;    public function test() &#123;        $this-&gt;testPrivate();        $this-&gt;testPublic();    &#125;    public function testPublic() &#123;        echo \"Bar::testPublic&lt;/br&gt;\";    &#125;        private function testPrivate() &#123;        echo \"Bar::testPrivate&lt;/br&gt;\";    &#125;&#125;class Foo extends Bar &#123;    public function testPublic() &#123;        echo \"Foo::testPublic&lt;/br&gt;\";    &#125;        private function testPrivate() &#123;        echo \"Foo::testPrivate&lt;/br&gt;\";    &#125;&#125;$myFoo = new foo();$myFoo-&gt;test(); // 输出：Bar::testPrivate                 // 输出：Foo::testPublic?&gt;\n对象继承继承已为大家所熟知的一个程序设计特性，PHP 的对象模型也使用了继承。继承将会影响到类与类，对象与对象之间的关系。比如，当扩展一个类，子类就会继承父类所有公有的和受保护的方法。除非子类覆盖了父类的方法，被继承的方法都会保留其原有功能。 继承对于功能的设计和抽象是非常有用的，而且对于类似的对象增加新功能就无须重新再写这些公用的功能。\n一个类可以在声明中用 extends 关键字继承另一个类的方法和属性。PHP不支持多重继承，一个类只能继承一个基类。被继承的方法和属性可以通过用同样的名字重新声明被覆盖。但是如果父类定义方法时使用了 final，则该方法不可被覆盖。可以通过 parent:: 来访问被覆盖的方法或属性。当覆盖方法时，参数必须保持一致否则 PHP 将发出 E_STRICT 级别的错误信息。但构造函数例外，构造函数可在被覆盖时使用不同的参数。\n简单的继承示例：\n&lt;?phpclass foo &#123;    public function printItem($string)  &#123;        echo 'Foo: ' . $string . '&lt;/br&gt;';    &#125;        public function printPHP() &#123;        echo 'PHP is great.' . '&lt;/br&gt;';    &#125;&#125;class bar extends foo &#123;    public function printItem($string) &#123;        echo 'Bar: ' . $string . '&lt;/br&gt;';    &#125;&#125;$foo = new foo();$bar = new bar();$foo-&gt;printItem('baz'); // Output: 'Foo: baz'$foo-&gt;printPHP();       // Output: 'PHP is great' $bar-&gt;printItem('baz'); // Output: 'Bar: baz'$bar-&gt;printPHP();       // Output: 'PHP is great'?&gt;\n继承后可以重新定义父类的方法\n&lt;?phpclass SimpleClass &#123;    function displayVar() &#123;        echo 'a default value';    &#125;&#125;class ExtendClass extends SimpleClass &#123;    // 重新定义父类方法    function displayVar() &#123;        echo \"Extending class&lt;/br&gt;\";        parent::displayVar();    &#125;&#125;$extended = new ExtendClass();$extended-&gt;displayVar();?&gt;\n输出：\nExtending class\na default value\n范围解析操作符(::)范围解析操作符或者更简单地说是一对冒号，可以用于访问静态成员，类常量，还可以用于覆盖类中的属性和方法。\n当在类定义之外引用到这些项目时，要使用类名。\n在类的外部使用::操作符&lt;?phpclass MyClass &#123;    const CONST_VALUE = 'A constant value&lt;/br&gt;';&#125;$classname = 'MyClass';echo $classname::CONST_VALUE; // 自 PHP 5.3.0 起echo MyClass::CONST_VALUE;?&gt;\n输出：\nA constant value\nA constant value\n在类的内部使用::操作符&lt;?phpclass MyClass &#123;    const CONST_VALUE = 'A constant value&lt;/br&gt;';&#125;class OtherClass extends MyClass &#123;    public static $my_static = 'static var';    public static function doubleColon() &#123;        echo parent::CONST_VALUE;        echo self::$my_static . \"&lt;/br&gt;\";    &#125;&#125;$classname = 'OtherClass';$classname::doubleColon(); // 自 PHP 5.3.0 起OtherClass::doubleColon();?&gt;\n输出：\nA constant value\nstatic var\nA constant value\nstatic var\nstatic 关键字声明类属性或方法为静态，就可以不实例化类而直接访问。静态属性不能通过一个类已实例化的对象来访问（但静态方法可以）。如果没有指定访问控制，属性和方法默认为公有。由于静态方法不需要通过对象即可调用，所以伪变量 $this 在静态方法中不可用。静态属性不可以由对象通过 -&gt; 操作符来访问。用静态方式调用一个非静态方法会导致一个 E_STRICT 级别的错误。就像其它所有的 PHP 静态变量一样，静态属性只能被初始化为文字或常量，不能使用表达式。所以可以把静态属性初始化为整数或数组，但不能初始化为另一个变量或函数返回值，也不能指向一个对象。可以用一个变量来动态调用类。但该变量的值不能为关键字 self，parent 或 static。\n静态属性示例：\n&lt;?phpclass Foo &#123;    public static $my_static = 'foo';    public function staticValue() &#123;        return self::$my_static;    &#125;&#125;class Bar extends Foo &#123;    public function fooStatic() &#123;        return parent::$my_static;    &#125;&#125;print Foo::$my_static . \"&lt;/br&gt;\";$foo = new Foo();print $foo-&gt;staticValue() . \"&lt;/br&gt;\";print $foo-&gt;my_static . \"&lt;/br&gt;\";      // Undefined \"Property\" my_static print $foo::$my_static . \"&lt;/br&gt;\";$classname = 'Foo';print $classname::$my_static . \"&lt;/br&gt;\"; // As of PHP 5.3.0print Bar::$my_static . \"&lt;/br&gt;\";$bar = new Bar();print $bar-&gt;fooStatic() . \"&lt;/br&gt;\";?&gt;\n静态方法示例:\n&lt;?phpclass Foo &#123;    public static function aStaticMethod() &#123; &#125;&#125;Foo::aStaticMethod();$classname = 'Foo';$classname::aStaticMethod(); // 自 PHP 5.3.0 起?&gt;\n抽象类PHP 5 支持抽象类和抽象方法。定义为抽象的类不能被实例化。任何一个类，如果它里面至少有一个方法是被声明为抽象的，那么这个类就必须被声明为抽象的。被定义为抽象的方法只是声明了其调用方式（参数），不能定义其具体的功能实现。\n继承一个抽象类的时候，子类必须定义父类中的所有抽象方法；另外，这些方法的访问控制必须和父类中一样（或者更为宽松）。例如某个抽象方法被声明为受保护的，那么子类中实现的方法就应该声明为受保护的或者公有的，而不能定义为私有的。此外方法的调用方式必须匹配，即类型和所需参数数量必须一致。例如，子类定义了一个可选参数，而父类抽象方法的声明里没有，则两者的声明并无冲突。 这也适用于 PHP 5.4 起的构造函数。在 PHP 5.4 之前的构造函数声明可以不一样的。\n抽象类示例：&lt;?phpabstract class AbstractClass &#123;    // 强制要求子类定义这些方法    abstract protected function getValue();    abstract protected function prefixValue($prefix);    // 普通方法（非抽象方法）    public function printOut() &#123;        print $this-&gt;getValue() . \"&lt;/br&gt;\";    &#125;&#125;class ConcreteClass1 extends AbstractClass &#123;    protected function getValue() &#123;        return \"ConcreteClass1\";    &#125;    public function prefixValue($prefix) &#123;        return \"&#123;$prefix&#125;ConcreteClass1\";    &#125;&#125;class ConcreteClass2 extends AbstractClass &#123;    public function getValue() &#123;        return \"ConcreteClass2\";    &#125;    public function prefixValue($prefix) &#123;        return \"&#123;$prefix&#125;ConcreteClass2\";    &#125;&#125;$class1 = new ConcreteClass1;$class1-&gt;printOut();echo $class1-&gt;prefixValue('FOO_') .\"&lt;/br&gt;\";$class2 = new ConcreteClass2;$class2-&gt;printOut();echo $class2-&gt;prefixValue('FOO_') .\"&lt;/br&gt;\";?&gt;\n输出：\nConcreteClass1\nFOO_ConcreteClass1\nConcreteClass2\nFOO_ConcreteClass2\n子类定义可选参数\n&lt;?phpabstract class AbstractClass &#123;    // 我们的抽象方法仅需要定义需要的参数    abstract protected function prefixName($name);&#125;class ConcreteClass extends AbstractClass &#123;    // 我们的子类可以定义父类签名中不存在的可选参数    public function prefixName($name, $separator = \".\") &#123;        if ($name == \"Pacman\") &#123;            $prefix = \"Mr\";        &#125; elseif ($name == \"Pacwoman\") &#123;            $prefix = \"Mrs\";        &#125; else &#123;            $prefix = \"\";        &#125;        return \"&#123;$prefix&#125;&#123;$separator&#125; &#123;$name&#125;\";    &#125;&#125;$class = new ConcreteClass;echo $class-&gt;prefixName(\"Pacman\"), \"&lt;/br&gt;\";echo $class-&gt;prefixName(\"Pacwoman\"), \"&lt;/br&gt;\";?&gt;\n输出：\nMr. Pacman\nMrs. Pacwoman\n对象接口使用接口，可以指定某个类必须实现哪些方法，但不需要定义这些方法的具体内容。接口是通过 interface 关键字来定义的，就像定义一个标准的类一样，但其中定义所有的方法都是空的。接口中定义的所有方法都必须是公有，这是接口的特性。\n要实现一个接口，使用 implements 操作符。类中必须实现接口中定义的所有方法，否则会报一个致命错误。类可以实现多个接口，用逗号来分隔多个接口的名称。\n实现多个接口时，接口中的方法不能有重名。接口也可以继承其他接口，通过使用 extends 操作符，接口允许多继承。类要实现接口，必须使用和接口中所定义的方法完全一致的方式。否则会导致致命错误。\n实现接口接口示例：\n&lt;?php// 声明一个'iTemplate'接口interface iTemplate &#123;    public function setVariable($name, $var);    public function getHtml($template);&#125;// 实现接口// 下面的写法是正确的class Template implements iTemplate&#123;    private $vars = array();    public function setVariable($name, $var) &#123;        $this-&gt;vars[$name] = $var;    &#125;      public function getHtml($template) &#123;        foreach($this-&gt;vars as $name =&gt; $value) &#123;            $template = str_replace('&#123;' . $name . '&#125;', $value, $template);        &#125;        return $template;    &#125;&#125;// 下面的写法是错误的，会报错，因为没有实现 getHtml()：// Fatal error: Class BadTemplate contains 1 abstract methods// and must therefore be declared abstract (iTemplate::getHtml)class BadTemplate implements iTemplate &#123;    private $vars = array();    public function setVariable($name, $var) &#123;        $this-&gt;vars[$name] = $var;    &#125;&#125;?&gt;\n继承多个接口&lt;?phpinterface a &#123;    public function foo();&#125;interface b &#123;    public function bar();&#125;interface c extends a, b &#123;    public function baz();&#125;class d implements c &#123;    public function foo() &#123;&#125;    public function bar() &#123;&#125;    public function baz() &#123;&#125;&#125;?&gt;\n使用接口常量&lt;?phpinterface a &#123;    const b = 'Interface constant';&#125;// 输出接口常量echo a::b;// 错误写法，因为常量不能被覆盖。接口常量的概念和类常量是一样的。class b implements a &#123;    const b = 'Class constant';&#125;?&gt;\nTrait自 PHP 5.4.0 起，PHP 实现了一种代码复用的方法，称为 trait。可以将多个类中，共用的一些属性和方法提取出来做来公共trait类，就像是装配汽车的配件，如果你的类中要用到这些配件，就直接用 use 导入就可以了，相当于把 trait 中的代码复制到当前类中。因为 trait 不是类，所以不能有静态成员，类常量，当然也不可能被实例化。\ntrait 使用示例：&lt;?phptrait sayHello &#123;    public function say()&#123;        echo 'Hello';    &#125;&#125;class Base &#123;    use sayHello;&#125;$b = new Base();$b-&gt;say();?&gt;\n输出：\nHello\n优先级从基类继承的成员会被 trait 插入的成员所覆盖。优先顺序是：当前类成员 &gt; trait的方法 &gt; 当前类继承的方法\n&lt;?phpclass Base &#123;    public function sayHello() &#123;        echo 'Hello ';    &#125;&#125;trait SayWorld &#123;    public function sayHello() &#123;        parent::sayHello();        echo 'World!';    &#125;&#125;class MyHelloWorld extends Base &#123;    use SayWorld;&#125;$o = new MyHelloWorld();$o-&gt;sayHello();?&gt;\n输出：\nHello World!\n多个 trait通过逗号分隔，在 use 声明列出多个 trait，可以都插入到一个类中。\n&lt;?phptrait Hello &#123;    public function sayHello() &#123;        echo 'Hello ';    &#125;&#125;trait World &#123;    public function sayWorld() &#123;        echo 'World';    &#125;&#125;class MyHelloWorld &#123;    use Hello, World;    public function sayExclamationMark() &#123;        echo '!';    &#125;&#125;$o = new MyHelloWorld();$o-&gt;sayHello();$o-&gt;sayWorld();$o-&gt;sayExclamationMark();?&gt;\n输出：\nHello World!\n同名冲突如果两个 trait 都插入了一个同名的方法，如果没有明确解决冲突将会产生一个致命错误。为了解决多个 trait 在同一个类中的命名冲突，需要使用 insteadof 操作符来明确指定使用冲突方法中的哪一个。以上方式仅允许排除掉其它方法，as 操作符可以 为某个方法引入别名。 注意：as 操作符不会对方法进行重命名，也不会影响其方法。\n&lt;?phptrait A &#123;    public function smallTalk() &#123;        echo 'a';    &#125;    public function bigTalk() &#123;        echo 'A';    &#125;&#125;trait B &#123;    public function smallTalk() &#123;        echo 'b';    &#125;    public function bigTalk() &#123;        echo 'B';    &#125;&#125;class Talker &#123;    use A, B &#123;        B::smallTalk insteadof A;        A::bigTalk insteadof B;    &#125;&#125;class Aliased_Talker &#123;    use A, B &#123;        B::smallTalk insteadof A;        A::bigTalk insteadof B;        B::bigTalk as talk;    &#125;&#125;$a = new Aliased_Talker();$a-&gt;smallTalk();    // 输出 b$a-&gt;bigTalk();      // 输出 A$a-&gt;talk();         // 输出 B?&gt;\n修改方法的访问控制使用 as 语法还可以用来调整方法的访问控制。\n&lt;?phptrait HelloWorld &#123;    public function sayHello() &#123;        echo 'Hello World!';    &#125;&#125;// 修改 sayHello 的访问控制class MyClass1 &#123;    use HelloWorld &#123; sayHello as protected; &#125;&#125;// 给方法一个改变了访问控制的别名// 原版 sayHello 的访问控制则没有发生变化class MyClass2 &#123;    use HelloWorld &#123; sayHello as private myPrivateHello; &#125;&#125;?&gt;\n从 trait 来组成 trait正如 class 能够使用 trait 一样，其它 trait 也能够使用 trait。在 trait 定义时通过使用一个或多个 trait，能够组合其它 trait 中的部分或全部成员。\n&lt;?phptrait Hello &#123;    public function sayHello() &#123;        echo 'Hello ';    &#125;&#125;trait World &#123;    public function sayWorld() &#123;        echo 'World!';    &#125;&#125;trait HelloWorld &#123;    use Hello, World;&#125;class MyHelloWorld &#123;    use HelloWorld;&#125;$o = new MyHelloWorld();$o-&gt;sayHello();$o-&gt;sayWorld();?&gt;\n输出：\nHello World!\ntrait 的抽象成员为了对使用的类施加强制要求，trait 支持抽象方法的使用。\n&lt;?phptrait Hello &#123;    public function sayHelloWorld() &#123;        echo 'Hello '.$this-&gt;getWorld();    &#125;    abstract public function getWorld();&#125;class MyHelloWorld &#123;    private $world;    use Hello;    public function getWorld() &#123;        return $this-&gt;world;    &#125;    public function setWorld($val) &#123;        $this-&gt;world = $val;    &#125;&#125;$a = new MyHelloWorld();$a-&gt;setWorld(\"World!\");$a-&gt;sayHelloWorld();?&gt;\n输出：\nHello World!\ntrait 的静态成员Traits 可以定义静态变量和静态方法\n&lt;?phptrait StaticExample &#123;    public function inc() &#123;        static $c = 0;        $c = $c + 1;        echo \"$c\\n\";    &#125;    public static function doSomething() &#123;        return 'Doing something';    &#125;&#125;class Example &#123;    use StaticExample;&#125;$a = new Example();$a-&gt;inc();echo '&lt;/br&gt;';echo Example::doSomething();?&gt;\n输出：\n1 \nDoing something\n定义属性Trait 同样可以定义属性。\n&lt;?phptrait PropertiesTrait &#123;    public $x = 1;&#125;class PropertiesExample &#123;    use PropertiesTrait;&#125;$example = new PropertiesExample;echo $example-&gt;x;       // 输出 1?&gt;\nTrait 定义了一个属性后，类就不能定义同样名称的属性，否则会产生 fatal error。 有种情况例外：属性是兼容的（同样的访问可见度、初始默认值）。 在 PHP 7.0 之前，属性是兼容的，则会有 E_STRICT 的提醒。\n&lt;?phptrait PropertiesTrait &#123;    public $same = true;    public $different = false;&#125;class PropertiesExample &#123;    use PropertiesTrait;    public $same = true; // PHP 7.0.0 后没问题，之前版本是 E_STRICT 提醒    public $different = true; // 致命错误&#125;?&gt;\n匿名类PHP 7 开始支持匿名类。 匿名类很有用，可以创建一次性的简单对象。\n&lt;?php// PHP 7 之前的代码class Logger &#123;    public function log($msg) &#123;        echo $msg;    &#125;&#125;$util-&gt;setLogger(new Logger());// 使用了 PHP 7+ 后的代码$util-&gt;setLogger(new class &#123;    public function log($msg) &#123;        echo $msg;    &#125;&#125;);\n可以传递参数到匿名类的构造器，也可以 extend 其他类、实现接口，以及像其他普通的类一样使用 trait。\n&lt;?phpclass SomeClass &#123;&#125;interface SomeInterface &#123;&#125;trait SomeTrait &#123;&#125;var_dump(new class(10) extends SomeClass implements SomeInterface &#123;    private $num;    public function __construct($num)    &#123;        $this-&gt;num = $num;    &#125;    use SomeTrait;&#125;);\n匿名类被嵌套进普通 Class 后，不能访问这个外部类的 private、protected方法或者属性。为了访问外部类 protected 属性或方法，匿名类可以 extend 此外部类。 为了使用外部类的 private 属性，必须通过构造器传进来。\n&lt;?phpclass Outer&#123;    private $prop = 1;    protected $prop2 = 2;    protected function func1() &#123;        return 3;    &#125;    public function func2() &#123;        return new class($this-&gt;prop) extends Outer &#123;            private $prop3;            public function __construct($prop) &#123;                $this-&gt;prop3 = $prop;            &#125;            public function func3() &#123;                return $this-&gt;prop2 + $this-&gt;prop3 + $this-&gt;func1();            &#125;        &#125;;    &#125;&#125;echo (new Outer)-&gt;func2()-&gt;func3();     // 输出 6?&gt;\n重载PHP中的”重载”与其它绝大多数面向对象语言不同。传统的”重载”是用于提供多个同名的类方法，但各方法的参数类型和个数不同。PHP所提供的”重载”是指动态地”创建”类属性和方法。我们是通过魔术方法（magic methods）来实现的。当调用当前环境下未定义或不可见的类属性或方法时，重载方法会被调用。所有的重载方法都必须被声明为 public。\n属性重载public void __set ( string $name , mixed $value )public mixed __get ( string $name )public bool __isset ( string $name )public void __unset ( string $name )\n注：mixed 说明一个参数可以接受多种不同的类型。\n在给不可访问属性赋值时，__set() 会被调用。读取不可访问属性的值时，__get() 会被调用。当对不可访问属性调用 isset() 或 empty() 时，__isset() 会被调用。当对不可访问属性调用 unset() 时，__unset() 会被调用。参数 $name 是指要操作的变量名称。__set() 方法的 $value 参数指定了 $name 变量的值。属性重载只能在对象中进行。在静态方法中，这些魔术方法将不会被调用。所以这些方法都不能被 声明为 static。从 PHP 5.3.0 起, 将这些魔术方法定义为 static 会产生一个警告。\n示例：\n&lt;?phpclass PropertyTest &#123;     /**  被重载的数据保存在此  */    private $data = array();     /**  重载不能被用在已经定义的属性  */    public $declared = 1;     /**  只有从类外部访问这个属性时，重载才会发生 */    private $hidden = 2;    public function __set($name, $value)  &#123;        echo \"Setting '$name' to '$value'\\n\";        $this-&gt;data[$name] = $value;    &#125;    public function __get($name) &#123;        echo \"Getting '$name'\\n\";        if (array_key_exists($name, $this-&gt;data)) &#123;            return $this-&gt;data[$name];        &#125; else &#123;            return 'Not exists';        &#125;    &#125;    public function __isset($name) &#123;        echo \"Is '$name' set?\\n\";        return isset($this-&gt;data[$name]);    &#125;    public function __unset($name) &#123;        echo \"Unsetting '$name'\\n\";        unset($this-&gt;data[$name]);    &#125;    /**  非魔术方法  */    public function getHidden() &#123;        return $this-&gt;hidden;    &#125;&#125;echo \"&lt;pre&gt;\\n\";$obj = new PropertyTest;$obj-&gt;a = 1;echo $obj-&gt;a . \"\\n\\n\";var_dump(isset($obj-&gt;a));unset($obj-&gt;a);var_dump(isset($obj-&gt;a));echo \"\\n\";echo $obj-&gt;declared . \"\\n\\n\";echo \"Let's experiment with the private property named 'hidden':\\n\";echo \"Privates are visible inside the class, so __get() not used...\\n\";echo $obj-&gt;getHidden() . \"\\n\";echo \"Privates not visible outside of class, so __get() is used...\\n\";echo $obj-&gt;hidden . \"\\n\";?&gt;\n输出：\nSetting &apos;a&apos; to &apos;1&apos;\nGetting &apos;a&apos;\n1\n\nIs &apos;a&apos; set?\nbool(true)\nUnsetting &apos;a&apos;\nIs &apos;a&apos; set?\nbool(false)\n\n1\n\nLet&apos;s experiment with the private property named &apos;hidden&apos;:\nPrivates are visible inside the class, so __get() not used...\n2\nPrivates not visible outside of class, so __get() is used...\nGetting &apos;hidden&apos;\nNot exists\n方法重载public mixed __call ( string $name , array $arguments )public static mixed __callStatic ( string $name , array $arguments )\n在对象中调用一个不可访问方法时，__call() 会被调用。在静态上下文中调用一个不可访问方法时，__callStatic() 会被调用。$name 参数是要调用的方法名称。$arguments 参数是一个枚举数组，包含着要传递给方法 $name 的参数。\n&lt;?phpclass MethodTest &#123;    public function __call($name, $arguments) &#123;        // 注意: $name 的值区分大小写        echo \"Calling object method '$name' \"             . implode(', ', $arguments). \"\\n\";    &#125;    /**  PHP 5.3.0之后版本  */    public static function __callStatic($name, $arguments) &#123;        // 注意: $name 的值区分大小写        echo \"Calling static method '$name' \"             . implode(', ', $arguments). \"\\n\";    &#125;&#125;echo '&lt;pre&gt;';$obj = new MethodTest;$obj-&gt;runTest('in object context');MethodTest::runTest('in static context');  // PHP 5.3.0之后版本?&gt;\n输出：\nCalling object method &apos;runTest&apos; in object context\nCalling static method &apos;runTest&apos; in static context\n遍历对象PHP 5 提供了一种定义对象的方法使其可以通过单元列表来遍历，例如用 foreach 语句。默认情况下，所有可见属性都将被用于遍历。\n简单遍历&lt;?phpclass MyClass &#123;    public $var1 = 'value 1';    public $var2 = 'value 2';    public $var3 = 'value 3';    protected $protected = 'protected var';    private   $private   = 'private var';    function iterateVisible() &#123;       echo \"MyClass::iterateVisible:\\n\";       foreach($this as $key =&gt; $value) &#123;           print \"$key =&gt; $value\\n\";       &#125;    &#125;&#125;$class = new MyClass();echo '&lt;pre&gt;';foreach($class as $key =&gt; $value) &#123;    print \"$key =&gt; $value\\n\";&#125;$class-&gt;iterateVisible();?&gt;\n输出：\nvar1 =&gt; value 1\nvar2 =&gt; value 2\nvar3 =&gt; value 3\nMyClass::iterateVisible:\nvar1 =&gt; value 1\nvar2 =&gt; value 2\nvar3 =&gt; value 3\nprotected =&gt; protected var\nprivate =&gt; private var\n实现 iterator 接口更进一步，可以实现 Iterator 接口。可以让对象自行决定如何遍历以及每次遍历时那些值可用。\n&lt;?phpclass MyIterator implements Iterator &#123;    private $var = array();    public function __construct($array) &#123;        if (is_array($array)) &#123;            $this-&gt;var = $array;        &#125;    &#125;    public function rewind() &#123;        echo \"rewinding\\n\";        reset($this-&gt;var);    &#125;    public function current() &#123;        $var = current($this-&gt;var);        echo \"current: $var\\n\";        return $var;    &#125;    public function key() &#123;        $var = key($this-&gt;var);        echo \"key: $var\\n\";        return $var;    &#125;    public function next() &#123;        $var = next($this-&gt;var);        echo \"next: $var\\n\";        return $var;    &#125;    public function valid() &#123;        $var = $this-&gt;current() !== false;        echo \"valid: &#123;$var&#125;\\n\";        return $var;    &#125;&#125;$values = array(1,2,3);$it = new MyIterator($values);echo '&lt;pre&gt;';foreach ($it as $a =&gt; $b) &#123;    print \"$a: $b\\n\";&#125;?&gt;\n输出：\nrewinding\ncurrent: 1\nvalid: 1\ncurrent: 1\nkey: 0\n0: 1\nnext: 2\ncurrent: 2\nvalid: 1\ncurrent: 2\nkey: 1\n1: 2\nnext: 3\ncurrent: 3\nvalid: 1\ncurrent: 3\nkey: 2\n2: 3\nnext: \ncurrent: \nvalid: \n通过实现 IteratorAggregate可以用 IteratorAggregate 接口以替代实现所有的 Iterator 方法。IteratorAggregate 只需要实现一个方法 IteratorAggregate::getIterator()，其应返回一个实现了 Iterator 的类的实例。\n&lt;?php&lt;?phpclass MyIterator implements Iterator &#123;    private $var = array();    public function __construct($array) &#123;        if (is_array($array)) &#123;            $this-&gt;var = $array;        &#125;    &#125;    public function rewind() &#123;        echo \"rewinding\\n\";        reset($this-&gt;var);    &#125;    public function current() &#123;        $var = current($this-&gt;var);        echo \"current: $var\\n\";        return $var;    &#125;    public function key() &#123;        $var = key($this-&gt;var);        echo \"key: $var\\n\";        return $var;    &#125;    public function next() &#123;        $var = next($this-&gt;var);        echo \"next: $var\\n\";        return $var;    &#125;    public function valid() &#123;        $var = $this-&gt;current() !== false;        echo \"valid: &#123;$var&#125;\\n\";        return $var;    &#125;&#125;class MyCollection implements IteratorAggregate &#123;    private $items = array();    private $count = 0;    // Required definition of interface IteratorAggregate    public function getIterator() &#123;        return new MyIterator($this-&gt;items);    &#125;    public function add($value) &#123;        $this-&gt;items[$this-&gt;count++] = $value;    &#125;&#125;$coll = new MyCollection();$coll-&gt;add('value 1');$coll-&gt;add('value 2');$coll-&gt;add('value 3');foreach ($coll as $key =&gt; $val) &#123;    echo \"key/value: [$key -&gt; $val]\\n\\n\";&#125;?&gt;\n魔术方法__construct()， __destruct()， __call()， __callStatic()， __get()， __set()， __isset()， __unset()， __sleep()， __wakeup()， __toString()， __invoke()， __set_state()，__clone() 和 __debugInfo() 等方法在 PHP 中被称为”魔术方法”（Magic methods）。在命名自己的类方法时不能使用这些方法名，除非是想使用其魔术功能。\nPHP 将所有以 __（两个下划线）开头的类方法保留为魔术方法。所以在定义类方法时，除了上述魔术方法，建议不要以 __ 为前缀。\n\n\n\n魔法方法\n说明\n\n\n\n\n__sleep\n序列化对象前被调用，可用于清理对象\n\n\n__wakeup\n反序列化前被调用\n\n\n__toString\n可以将对象当成字符串 比如echo一个对象时调用\n\n\n__invoke\n可以让对象当函数进行调用\n\n\n__set_state\n调用 var_export() 导出类时此方法被调用\n\n\n__debugInfo\n调用 var_dump() 打印对象时被调用 PHP 5.6可用\n\n\n\n简单例子：\n&lt;?phpclass foo &#123;    public function __toString() &#123;        return \"This is \" . self::class . \"&lt;/br&gt;\";    &#125;    public function __debugInfo() &#123;        return [\"message\"=&gt;\"called __debugInfo()\"];    &#125;    public function __invoke() &#123;        return \"called __invoke()&lt;/br&gt;\";    &#125;&#125;$f = new foo;echo $f;echo $f();var_dump($f);?&gt;\nfinal 关键字PHP 5 新增了一个 final 关键字。如果父类中的方法被声明为 final，则子类无法覆盖该方法。如果一个类被声明为 final，则不能被继承。\nfinal 方法：\n&lt;?phpclass BaseClass &#123;   public function test() &#123;       echo \"BaseClass::test() called\\n\";   &#125;      final public function moreTesting() &#123;       echo \"BaseClass::moreTesting() called\\n\";   &#125;&#125;class ChildClass extends BaseClass &#123;   public function moreTesting() &#123;       echo \"ChildClass::moreTesting() called\\n\";   &#125;&#125;// Results in Fatal error: Cannot override final method BaseClass::moreTesting()?&gt;\nfinal 类：&lt;?phpfinal class BaseClass &#123;   public function test() &#123;       echo \"BaseClass::test() called\\n\";   &#125;      // 这里无论你是否将方法声明为final，都没有关系   final public function moreTesting() &#123;       echo \"BaseClass::moreTesting() called\\n\";   &#125;&#125;class ChildClass extends BaseClass &#123;&#125;// 产生 Fatal error: Class ChildClass may not inherit from final class (BaseClass)?&gt;\n对象复制在多数情况下，我们并不需要完全复制一个对象来获得其中属性。但有一个情况下确实需要：如果你有一个 GTK 窗口对象，该对象持有窗口相关的资源。你可能会想复制一个新的窗口，保持所有属性与原来的窗口相同，但必须是一个新的对象（因为如果不是新的对象，那么一个窗口中的改变就会影响到另一个窗口）。还有一种情况：如果对象 A 中保存着对象 B 的引用，当你复制对象 A 时，你想其中使用的对象不再是对象 B 而是 B 的一个副本，那么你必须得到对象 A 的一个副本。\n对象复制可以通过 clone 关键字来完成（如果可能，这将调用对象的 __clone() 方法）。对象中的 __clone() 方法不能被直接调用。\n当对象被复制后，PHP 5 会对对象的所有属性执行一个浅复制（shallow copy）。所有的引用属性 仍然会是一个指向原来的变量的引用。\n示例：&lt;?phpclass MyCloneable &#123;    public $val = \"val\";    public function __clone() &#123;        echo \"called __clone()&lt;/br&gt;\";    &#125;&#125;$obj = new MyCloneable();$obj2 = clone $obj;echo \"obj =&gt; \".$obj-&gt;val.'&lt;/br&gt;';echo \"obj2 =&gt; \".$obj2-&gt;val.'&lt;/br&gt;';$obj2-&gt;val = \"val2\";echo \"obj =&gt; \".$obj-&gt;val.'&lt;/br&gt;';echo \"obj2 =&gt; \".$obj2-&gt;val.'&lt;/br&gt;';?&gt;\n对象比较当使用比较运算符（==）比较两个对象变量时，比较的原则是：如果两个对象的属性和属性值都相等，而且两个对象是同一个类的实例，那么这两个对象变量相等。\n而如果使用全等运算符（===），这两个对象变量一定要指向某个类的同一个实例（即同一个对象）。\n&lt;?phpclass BaseClass &#123;&#125;$b1 = new BaseClass;$b2 = new BaseClass;$b3 = $b2;echo '&lt;pre&gt;';var_dump($b1 == $b2);       // truevar_dump($b1 === $b2);      // falsevar_dump($b2 === $b3);      // truevar_dump($b2 == $b3);       // false?&gt;\n类型约束PHP 5 可以使用类型约束。函数的参数可以指定必须为对象（在函数原型里面指定类的名字），接口，数组（PHP 5.1 起）或者 callable（PHP 5.4 起）。不过如果使用 NULL 作为参数的默认值，那么在调用函数的时候依然可以使用 NULL 作为实参。\n如果一个类或接口指定了类型约束，则其所有的子类或实现也都如此。\n类型约束不能用于标量类型如 int 或 string。Traits 也不允许。\n示例：&lt;?phpclass MyClass&#123;    // 测试函数 第一个参数必须为 OtherClass 类的一个对象    public function test(OtherClass $otherclass) &#123;        echo $otherclass-&gt;var;    &#125;    // 另一个测试函数 第一个参数必须为数组     public function test_array(array $input_array) &#123;        print_r($input_array);    &#125;&#125;    // 第一个参数必须为递归类型    public function test_interface(Traversable $iterator) &#123;        echo get_class($iterator);    &#125;    // 第一个参数必须为回调类型    public function test_callable(callable $callback, $data) &#123;        call_user_func($callback, $data);    &#125;&#125;// OtherClass 类定义class OtherClass &#123;    public $var = 'Hello World';&#125;$myclass = new MyClass;$otherclass = new OtherClass;// 致命错误：第一个参数必须是 OtherClass 类的一个对象$myclass-&gt;test('hello');// 致命错误：第一个参数必须为 OtherClass 类的一个实例$foo = new stdClass;$myclass-&gt;test($foo);// 致命错误：第一个参数不能为 null$myclass-&gt;test(null);// 正确：输出 Hello World $myclass-&gt;test($otherclass);// 致命错误：第一个参数必须为数组$myclass-&gt;test_array('a string');// 正确：输出数组$myclass-&gt;test_array(array('a', 'b', 'c'));// 正确：输出 ArrayObject$myclass-&gt;test_interface(new ArrayObject(array()));// 正确：输出 int(1)$myclass-&gt;test_callable('var_dump', 1);?&gt;\n类型约束不只是用在类的成员函数里，也能使用在函数里：\n&lt;?php// 如下面的类class MyClass &#123;    public $var = 'Hello World';&#125;// 测试函数 第一个参数必须是 MyClass 类的一个对象function MyFunction (MyClass $foo) &#123;    echo $foo-&gt;var;&#125;// 正确$myclass = new MyClass;MyFunction($myclass);?&gt;\n类型约束允许 NULL 值：\n&lt;?php/* 接受 NULL 值 */function test(stdClass $obj = NULL) &#123; &#125;test(NULL);test(new stdClass);?&gt;\n后期静态绑定自 PHP 5.3.0 起，PHP 增加了一个叫做后期静态绑定的功能，用于在继承范围内引用静态调用的类。\n准确说，后期静态绑定工作原理是存储了在上一个”非转发调用”（non-forwarding call）的类名。当进行静态方法调用时，该类名即为明确指定的那个（通常在 :: 运算符左侧部分）；当进行非静态方法调用时，即为该对象所属的类。所谓的”转发调用”（forwarding call）指的是通过以下几种方式进行的静态调用：self::，parent::，static:: 以及 forward_static_call()。可用 get_called_class() 函数来得到被调用的方法所在的类名，static:: 则指出了其范围。\n该功能从语言内部角度考虑被命名为”后期静态绑定”。”后期绑定”的意思是说，static:: 不再被解析为定义当前方法所在的类，而是在实际运行时计算的。也可以称之为”静态绑定”，因为它可以用于（但不限于）静态方法的调用。\nself:: 的限制&lt;?phpclass A &#123;    public static function who() &#123;        echo __CLASS__;    &#125;    public static function test() &#123;        self::who();    &#125;&#125;class B extends A &#123;    public static function who() &#123;        echo __CLASS__;    &#125;&#125;B::test();?&gt;\n输出：\nA\n后期静态绑定的用法&lt;?phpclass A &#123;    public static function who() &#123;        echo __CLASS__;    &#125;    public static function test() &#123;        static::who(); // 后期静态绑定从这里开始    &#125;&#125;class B extends A &#123;    public static function who() &#123;        echo __CLASS__;    &#125;&#125;B::test();?&gt;\n输出：\nB\n在非静态环境下，所调用的类即为该对象实例所属的类。由于 $this-&gt; 会在同一作用范围内尝试调用私有方法，而 static:: 则可能给出不同结果。另一个区别是 static:: 只能用于静态属性。\n对象和引用在php5 的对象编程经常提到的一个关键点是“默认情况下对象是通过引用传递的”。但其实这不是完全正确的。下面通过一些例子来说明。\nPHP 的引用是别名，就是两个不同的变量名字指向相同的内容。在 PHP 5，一个对象变量已经不再保存整个对象的值。只是保存一个标识符来访问真正的对象内容。 当对象作为参数传递，作为结果返回，或者赋值给另外一个变量，另外一个变量跟原来的不是引用的关系，只是他们都保存着同一个标识符的拷贝，这个标识符指向同一个对象的真正内容。\n&lt;?phpclass A &#123;    public $foo = 1;&#125;  $a = new A;$b = $a;     // $a ,$b都是同一个标识符的拷贝             // ($a) = ($b) = &lt;id&gt;$b-&gt;foo = 2;echo $a-&gt;foo.\"&lt;/br&gt;\";$c = new A;$d = &amp;$c;    // $c ,$d是引用             // ($c,$d) = &lt;id&gt;$d-&gt;foo = 2;echo $c-&gt;foo.\"&lt;/br&gt;\";$e = new A;function foo($obj) &#123;    // ($obj) = ($e) = &lt;id&gt;    $obj-&gt;foo = 2;&#125;foo($e);echo $e-&gt;foo.\"&lt;/br&gt;\";?&gt;\n输出：\n2\n2\n2\n对象序列化所有php里面的值都可以使用函数serialize()来返回一个包含字节流的字符串来表示。unserialize()函数能够重新把字符串变回php原来的值。 序列化一个对象将会保存对象的所有变量，但是不会保存对象的方法，只会保存类的名字。\n为了能够unserialize()一个对象，这个对象的类必须已经定义过。如果序列化类A的一个对象，将会返回一个跟类A相关，而且包含了对象所有变量值的字符串。 如果要想在另外一个文件中解序列化一个对象，这个对象的类必须在解序列化之前定义，可以通过包含一个定义该类的文件或使用函数spl_autoload_register()来实现。\nclassa.inc&lt;?phpclass A &#123;    public $one = 1;    public function show_one() &#123;        echo $this-&gt;one;    &#125;&#125;?&gt;\npage1.php&lt;?phpinclude(\"classa.inc\");$a = new A;$s = serialize($a);// 把变量$s保存起来以便文件page2.php能够读到file_put_contents('store', $s);?&gt;\npage2.php&lt;?php// 要正确了解序列化，必须包含下面一个文件include(\"classa.inc\");$s = file_get_contents('store');$a = unserialize($s);// 现在可以使用对象$a里面的函数 show_one()$a-&gt;show_one();?&gt;\n先执行 page1.php 再执行 page2.php 就可以看到结果了。\n命名空间命名空间概述什么是命名空间？从广义上来说，命名空间是一种封装事物的方法。在很多地方都可以见到这种抽象概念。例如，在操作系统中目录用来将相关文件分组，对于目录中的文件来说，它就扮演了命名空间的角色。具体举个例子，文件 foo.txt 可以同时在目录/home/greg 和 /home/other 中存在，但在同一个目录中不能存在两个 foo.txt 文件。另外，在目录 /home/greg 外访问 foo.txt 文件时，我们必须将目录名以及目录分隔符放在文件名之前得到 /home/greg/foo.txt。这个原理应用到程序设计领域就是命名空间的概念。\n在PHP中，命名空间用来解决在编写类库或应用程序时创建可重用的代码如类或函数时碰到的两类问题：\n\n用户编写的代码与PHP内部的类/函数/常量或第三方类/函数/常量之间的名字冲突。\n为很长的标识符名称(通常是为了缓解第一类问题而定义的)创建一个别名（或简短）的名称，提高源代码的可读性。\n\nPHP 命名空间提供了一种将相关的类、函数和常量组合到一起的途径。\n定义命名空间虽然任意合法的PHP代码都可以包含在命名空间中，但只有以下类型的代码受命名空间的影响，它们是：类（包括抽象类和traits）、接口、函数和常量。\n命名空间通过关键字namespace 来声明。如果一个文件中包含命名空间，它必须在其它所有代码之前声明命名空间，除了一个以外：declare关键字。\n&lt;?phpnamespace MyProject;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */  &#125;?&gt;\n在声明命名空间之前唯一合法的代码是用于定义源文件编码方式的 declare 语句。另外，所有非 PHP 代码包括空白符都不能出现在命名空间的声明之前：\n&lt;html&gt;&lt;?phpnamespace MyProject; // 致命错误 -　命名空间必须是程序脚本的第一条语句?&gt;\n另外，与PHP其它的语言特征不同，同一个命名空间可以定义在多个文件中，即允许将同一个命名空间的内容分割存放在不同的文件中。\n定义子命名空间与目录和文件的关系很象，PHP 命名空间也允许指定层次化的命名空间的名称。因此，命名空间的名字可以使用分层次的方式定义：\n&lt;?phpnamespace MyProject\\Sub\\Level;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */  &#125;?&gt;\n上面的例子创建了常量 MyProject\\Sub\\Level\\CONNECT_OK，类 MyProject\\Sub\\Level\\Connection 和函数 MyProject\\Sub\\Level\\connect。\n同一个文件多个命名空间也可以在同一个文件中定义多个命名空间。在同一个文件中定义多个命名空间有两种语法形式。\n简单组合语法：&lt;?phpnamespace MyProject;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */  &#125;namespace AnotherProject;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */  &#125;?&gt;\n不建议使用这种语法在单个文件中定义多个命名空间。建议使用下面的大括号形式的语法。\n大括号语法：&lt;?phpnamespace MyProject &#123;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */  &#125;&#125;namespace AnotherProject &#123;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */  &#125;&#125;?&gt;\n在实际的编程实践中，非常不提倡在同一个文件中定义多个命名空间。这种方式的主要用于将多个 PHP 脚本合并在同一个文件中。\n将全局的非命名空间中的代码与命名空间中的代码组合在一起，只能使用大括号形式的语法。全局代码必须用一个不带名称的 namespace 语句加上大括号括起来，例如：\n&lt;?phpnamespace MyProject &#123;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */  &#125;&#125;namespace &#123; // global codesession_start();$a = MyProject\\connect();echo MyProject\\Connection::start();&#125;?&gt;\n除了开始的declare语句外，命名空间的括号外不得有任何PHP代码。\n使用命名空间：基础在讨论如何使用命名空间之前，必须了解 PHP 是如何知道要使用哪一个命名空间中的元素的。可以将 PHP 命名空间与文件系统作一个简单的类比。在文件系统中访问一个文件有三种方式：\n\n相对文件名形式如foo.txt。它会被解析为 currentdirectory/foo.txt，其中 currentdirectory 表示当前目录。因此如果当前目录是 /home/foo，则该文件名被解析为 /home/foo/foo.txt。\n相对路径名形式如 subdirectory/foo.txt。它会被解析为 currentdirectory/subdirectory/foo.txt。\n绝对路径名形式如 /main/foo.txt。它会被解析为 /main/foo.txt。\n\nPHP 命名空间中的元素使用同样的原理。例如，类名可以通过三种方式引用：\n\n非限定名称，或不包含前缀的类名称，例如 $a=new foo(); 或 foo::staticmethod();。如果当前命名空间是 currentnamespace，foo 将被解析为 currentnamespace\\foo。如果使用 foo 的代码是全局的，不包含在任何命名空间中的代码，则 foo 会被解析为 foo。 警告：如果命名空间中的函数或常量未定义，则该非限定的函数名称或常量名称会被解析为全局函数名称或常量名称。\n限定名称，或包含前缀的名称，例如 $a = new subnamespace\\foo(); 或 subnamespace\\foo::staticmethod();。如果当前的命名空间是 currentnamespace，则 foo 会被解析为 currentnamespace\\subnamespace\\foo。如果使用 foo 的代码是全局的，不包含在任何命名空间中的代码，foo 会被解析为 subnamespace\\foo。\n完全限定名称，或包含了全局前缀操作符的名称，例如，$a = new \\currentnamespace\\foo(); 或 \\currentnamespace\\foo::staticmethod();。在这种情况下，foo 总是被解析为代码中的文字名 currentnamespace\\foo。\n\n示例：\nfile1.php&lt;?phpnamespace Foo\\Bar\\subnamespace;const FOO = 1;function foo() &#123;&#125;class foo &#123;    static function staticmethod() &#123;&#125;&#125;?&gt;\nfile2.php&lt;?phpnamespace Foo\\Bar;include 'file1.php';const FOO = 2;function foo() &#123;&#125;class foo &#123;    static function staticmethod() &#123;&#125;&#125;/* 非限定名称 */foo(); // 解析为方法 Foo\\Bar\\foo foo::staticmethod(); // 解析为类 Foo\\Bar\\foo 的静态方法 staticmethod。echo FOO; // 解析为常量 Foo\\Bar\\FOO/* 限定名称 */subnamespace\\foo(); // 解析为函数 Foo\\Bar\\subnamespace\\foosubnamespace\\foo::staticmethod(); // 解析为类 Foo\\Bar\\subnamespace\\foo 的静态方法 staticmethodecho subnamespace\\FOO; // 解析为常量 Foo\\Bar\\subnamespace\\FOO                                  /* 完全限定名称 */\\Foo\\Bar\\foo(); // 解析为函数 Foo\\Bar\\foo\\Foo\\Bar\\foo::staticmethod(); // 解析为类 Foo\\Bar\\foo, 以及类的方法 staticmethodecho \\Foo\\Bar\\FOO; // 解析为常量 Foo\\Bar\\FOO?&gt;\n注意：访问任意全局类、函数或常量，都可以使用完全限定名称，例如 \\strlen() 或 \\Exception 或 \\INI_ALL。\n命名空间和动态语言特征PHP 命名空间的实现受到其语言自身的动态特征的影响。因此，如果要将下面的代码转换到命名空间中：\nexample1.php&lt;?phpclass classname &#123;    function __construct() &#123;        echo __METHOD__,\"\\n\";    &#125;&#125;function funcname() &#123;    echo __FUNCTION__,\"\\n\";&#125;const constname = \"global\";$a = 'classname';$obj = new $a; // prints classname::__construct$b = 'funcname';$b(); // prints funcnameecho constant('constname'), \"\\n\"; // prints global?&gt;\n必须使用完全限定名称（包括命名空间前缀的类名称）。注意因为在动态的类名称、函数名称或常量名称中，限定名称和完全限定名称没有区别，因此其前导的反斜杠是不必要的。\nexample2.php&lt;?phpnamespace namespacename;class classname &#123;    function __construct() &#123;        echo __METHOD__,\"\\n\";    &#125;&#125;function funcname() &#123;    echo __FUNCTION__,\"\\n\";&#125;const constname = \"namespaced\";include 'example1.php';$a = 'classname';$obj = new $a; // prints classname::__construct$b = 'funcname';$b(); // prints funcnameecho constant('constname'), \"\\n\"; // prints global/* note that if using double quotes, \"\\\\namespacename\\\\classname\" must be used */$a = '\\namespacename\\classname';$obj = new $a; // prints namespacename\\classname::__construct$a = 'namespacename\\classname';$obj = new $a; // also prints namespacename\\classname::__construct$b = 'namespacename\\funcname';$b(); // prints namespacename\\funcname$b = '\\namespacename\\funcname';$b(); // also prints namespacename\\funcnameecho constant('\\namespacename\\constname'), \"\\n\"; // prints namespacedecho constant('namespacename\\constname'), \"\\n\"; // also prints namespaced?&gt;\n__NAMESPACE__常量PHP支持两种抽象的访问当前命名空间内部元素的方法，__NAMESPACE__ 魔术常量和 namespace 关键字。\n__NAMESPACE__ 示例：\n&lt;?phpnamespace MyProject;echo __NAMESPACE__;     // 输出 MyProject?&gt;\n全局代码：echo __NAMESPACE__;     // 输出空白 __NAMESPACE__为空字符串。\n常量 __NAMESPACE__ 在动态创建名称时很有用，例如：\n&lt;?phpnamespace MyProject;function get($classname)&#123;    $a = __NAMESPACE__ . '\\\\' . $classname;    return new $a;&#125;?&gt;\nnamespace关键字关键字 namespace 可用来显式访问当前命名空间或子命名空间中的元素。它等价于类中的 self 操作符。\n&lt;?phpnamespace MyProject;use blah\\blah as mine; // 查看下一节内容 使用命名空间：别名/导入blah\\mine(); // 调用函数 MyProject\\blah\\mine()namespace\\blah\\mine(); // 调用函数 MyProject\\blah\\mine()namespace\\func(); // 调用函数 MyProject\\func()namespace\\sub\\func(); // 调用函数 MyProject\\sub\\func()namespace\\cname::method(); // 调用 MyProject\\cname 类的静态方法 \"method\" of class $a = new namespace\\sub\\cname(); // MyProject\\sub\\cname 类的实例对象$b = namespace\\CONSTANT; // 将 MyProject\\CONSTANT 的常量赋值给 $b?&gt;\n使用命名空间：别名/导入允许通过别名引用或导入外部的完全限定名称，是命名空间的一个重要特征。这有点类似于在类 unix 文件系统中可以创建对其它的文件或目录的符号连接。\n所有支持命名空间的PHP版本支持三种别名或导入方式：为类名称使用别名、为接口使用别名或为命名空间名称使用别名。PHP 5.6开始允许导入函数或常量或者为它们设置别名。\n在PHP中，别名是通过操作符 use 来实现的. 下面是一个使用所有可能的五种导入方式的例子：\n&lt;?phpnamespace foo;use My\\Full\\Classname as Another;// 下面的例子与 use My\\Full\\NSname as NSname 相同use My\\Full\\NSname;// 导入一个全局类use ArrayObject;// importing a function (PHP 5.6+)use function My\\Full\\functionName;// aliasing a function (PHP 5.6+)use function My\\Full\\functionName as func;// importing a constant (PHP 5.6+)use const My\\Full\\CONSTANT;$obj = new namespace\\Another; // 实例化 foo\\Another 对象$obj = new Another; // 实例化 My\\Full\\Classname　对象NSname\\subns\\func(); // 调用函数 My\\Full\\NSname\\subns\\func$a = new ArrayObject(array(1)); // 实例化 ArrayObject 对象// 如果不使用 \"use \\ArrayObject\" ，则实例化一个 foo\\ArrayObject 对象func(); // calls function My\\Full\\functionNameecho CONSTANT; // echoes the value of My\\Full\\CONSTANT?&gt;\n注意对命名空间中的名称（包含命名空间分隔符的完全限定名称如 Foo\\Bar以及相对的不包含命名空间分隔符的全局名称如 FooBar）来说，前导的反斜杠是不必要的也不推荐的，因为导入的名称必须是完全限定的，不会根据当前的命名空间作相对解析。为了简化操作，PHP还支持在一行中使用多个use语句\n&lt;?phpuse My\\Full\\Classname as Another, My\\Full\\NSname;$obj = new Another; // 实例化 My\\Full\\Classname 对象NSname\\subns\\func(); // 调用函数 My\\Full\\NSname\\subns\\func?&gt;\n导入操作是在编译执行的，但动态的类名称、函数名称或常量名称则不是。\n导入和动态名称：&lt;?phpuse My\\Full\\Classname as Another, My\\Full\\NSname;$obj = new Another; // 实例化一个 My\\Full\\Classname 对象$a = 'Another';$obj = new $a;      // 实际化一个 Another 对象?&gt;\n另外，导入操作只影响非限定名称和限定名称。完全限定名称由于是确定的，故不受导入的影响。\n导入和完全限定名称：&lt;?phpuse My\\Full\\Classname as Another, My\\Full\\NSname;$obj = new Another;         // instantiates object of class My\\Full\\Classname$obj = new \\Another;        // instantiates object of class Another$obj = new Another\\thing;   // instantiates object of class My\\Full\\Classname\\thing$obj = new \\Another\\thing;  // instantiates object of class Another\\thing?&gt;\n全局空间如果没有定义任何命名空间，所有的类与函数的定义都是在全局空间，与 PHP 引入命名空间概念前一样。在名称前加上前缀 \\ 表示该名称是全局空间中的名称，即使该名称位于其它的命名空间中时也是如此。\n&lt;?phpnamespace A\\B\\C;/* 这个函数是 A\\B\\C\\fopen */function fopen() &#123;      /* ... */     $f = \\fopen(...); // 调用全局的fopen函数     return $f;&#125; ?&gt;\n后备全局函数/常量在一个命名空间中，当 PHP 遇到一个非限定的类、函数或常量名称时，它使用不同的优先策略来解析该名称。类名称总是解析到当前命名空间中的名称。因此在访问系统内部或不包含在命名空间中的类名称时，必须使用完全限定名称，例如：\n&lt;?phpnamespace A\\B\\C;class Exception extends \\Exception &#123;&#125;$a = new Exception('hi'); // $a 是类 A\\B\\C\\Exception 的一个对象$b = new \\Exception('hi'); // $b 是类 Exception 的一个对象$c = new ArrayObject; // 致命错误, 找不到 A\\B\\C\\ArrayObject 类?&gt;\n对于函数和常量来说，如果当前命名空间中不存在该函数或常量，PHP 会退而使用全局空间中的函数或常量。\n&lt;?phpnamespace A\\B\\C;const E_ERROR = 45;function strlen($str) &#123;    return \\strlen($str) - 1;&#125;echo E_ERROR, \"\\n\"; // 输出 \"45\"echo INI_ALL, \"\\n\"; // 输出 \"7\" - 使用全局常量 INI_ALLecho strlen('hi'), \"\\n\"; // 输出 \"1\"if (is_array('hi')) &#123; // 输出 \"is not array\"    echo \"is array\\n\";&#125; else &#123;    echo \"is not array\\n\";&#125;?&gt;\n名称解析规则名称解析遵循下列规则：\n\n对完全限定名称的函数，类和常量的调用在编译时解析。例如 new \\A\\B 解析为类 A\\B。\n所有的非限定名称和限定名称（非完全限定名称）根据当前的导入规则在编译时进行转换。例如，如果命名空间 A\\B\\C 被导入为 C，那么对 C\\D\\e() 的调用就会被转换为 A\\B\\C\\D\\e()。\n在命名空间内部，所有的没有根据导入规则转换的限定名称均会在其前面加上当前的命名空间名称。例如，在命名空间 A\\B 内部调用 C\\D\\e()，则 C\\D\\e() 会被转换为 A\\B\\C\\D\\e() 。\n非限定类名根据当前的导入规则在编译时转换（用全名代替短的导入名称）。例如，如果命名空间 A\\B\\C 导入为C，则 new C() 被转换为 new A\\B\\C() 。\n在命名空间内部（例如A\\B），对非限定名称的函数调用是在运行时解析的。例如对函数 foo() 的调用是这样解析的：\n在当前命名空间中查找名为 A\\B\\foo() 的函数\n尝试查找并调用 全局(global) 空间中的函数 foo()。\n\n\n在命名空间（例如A\\B）内部对非限定名称或限定名称类（非完全限定名称）的调用是在运行时解析的。下面是调用 new C() 及 new D\\E() 的解析过程： new C()的解析:\n在当前命名空间中查找A\\B\\C类。\n尝试自动装载类A\\B\\C。\n\n\n\nnew D\\E()的解析:\n\n在类名称前面加上当前命名空间名称变成：A\\B\\D\\E，然后查找该类。\n尝试自动装载类 A\\B\\D\\E。\n\n为了引用全局命名空间中的全局类，必须使用完全限定名称 new \\C()。\nErrors错误基础可悲的是，不管我们在写代码时多么小心，错误始终是有的。PHP将会为许多常见的我文件和运行问题提供错误，警告和一些通知，同时让我们知道如何检测和处理这些错误，使得调试程序容易的多。\nPHP会报告与各种错误条件相对应的各种错误。\n如果没有设置错误处理程序，则PHP将根据其配置处理错误。哪些错误报告或者哪些错误忽略是通过error_reporting指令控制（php.ini）。或者在运行时调用error_reporting()，但是不推荐这样配置，因为在脚本执行之前可能也会发生一些错误。\n在开发环境，你应该配置error_reporting为E_ALL，因为你需要了解并解决PHP提出的问题。在生产环境，你可能希望将此设置的不太详细，比如 E_ALL, E_NOTICE, E_STRICT, E_DEPRECATED。但在许多情况下，E_ALL也是合适的，因为它可以提供潜在问题的早期预警。\nPHP对错误的处理取决于两个 php.ini 指令。display_errors 控制是否将错误显示为脚本输出的一部分。应该始终在生产环境中禁用它，因为它可以包含诸如数据库密码之类的机密信息，但是它常常在开发环境启用，因为它可以确保立即报告问题。\n除了显示错误，PHP也可以启用 log_errors 指令来记录错误日志。它将记录任何错误到错误日志文件，这在生产环境非常适用，你可以记录发生的错误，然后根据错误生成报告。\nPHP 7 错误处理PHP 7 改变了大多数错误的报告方式。不同于传统（PHP 5）的错误报告机制，现在大多数错误被作为 Error 异常抛出。\n这种 Error 异常可以像 Exception 异常一样被第一个匹配的 try / catch 块所捕获。如果没有匹配的 catch 块，则调用异常处理函数（事先通过 set_exception_handler() 注册）进行处理。 如果尚未注册异常处理函数，则按照传统方式处理：被报告为一个致命错误（Fatal Error）。\nError 类并非继承自 Exception 类，所以不能用 catch (Exception $e) { ... } 来捕获 Error。你可以用 catch (Error $e) { ... }，或者通过注册异常处理函数 set_exception_handler() 来捕获 Error。\n异常异常处理PHP 5 有一个类似于其他语言的异常处理模型。在PHP中可以主动抛出和捕获一个异常。代码被包含在 try 代码块中以便可以捕获，每一个 try 代码块都至少要有一个 catch 代码块或者 finally 代码块。\n可以使用多个 catch 块来捕获不同类别的异常，代码正常执行（try 代码块中没有抛出异常）则不会执行所有 catch 代码块的内容，异常也可以在 catch 代码块中重新抛出。当抛出异常时，将不会继续执行下面的代码，PHP将尝试查找第一个匹配的 catch 块，如果一个异常没有捕捉到，将发出一个未捕捉的异常的消息，除非处理程序已定义了 set_exception_handler()。\n在 PHP 5 和更高的版本，finally 代码块可以在最后一个 catch 块后指定，finally 块在 try 和 catch 执行完后总会执行的，不管是否抛出异常，finally 块的内容总会执行。\n除了代码运行产生的异常 还可以使用 throw 主动抛出一个异常，抛出的异常需要是一个异常的类的对象。\n示例：\n&lt;?phpfunction inverse($x) &#123;    if (!$x) &#123;        throw new Exception('Division by zero.&lt;/br&gt;');    &#125;    return 1/$x;&#125;try &#123;    echo inverse(5) . \"&lt;/br&gt;\";    echo inverse(0) . \"&lt;/br&gt;\";&#125; catch (Exception $e) &#123;    echo 'Caught exception: ',  $e-&gt;getMessage();&#125; finally &#123;    echo \"Second finally.&lt;/br&gt;\";&#125;// Continue executionecho \"Hello World&lt;/br&gt;\";?&gt;\n输出：\n0.2\nCaught exception: Division by zero.\nSecond finally.\nHello World\n自定义异常可以通过继承异常类来自定义异常，Exception 是所有异常的基类。\nException 类摘要：class Exception &#123;    /* 属性 */    protected string $message ;     // 异常消息内容    protected int $code ;           // 异常代码    protected string $file ;        // 抛出异常的文件名    protected int $line ;           // 抛出异常在该文件中的行号    /* 方法 */    public __construct ([ string $message = \"\" [, int $code = 0 [, Throwable $previous = NULL ]]] )    final public string getMessage ( void )    final public Throwable getPrevious ( void )    final public int getCode ( void )    final public string getFile ( void )    final public int getLine ( void )    final public array getTrace ( void )    final public string getTraceAsString ( void )    public string __toString ( void )    final private void __clone ( void )&#125;\n继承异常类：\n&lt;?phpclass MyException extends Exception &#123; &#125;try &#123;    throw new MyException(\"自定义异常\");&#125; catch (MyException $e) &#123;    echo $e . '&lt;/br&gt;';    echo \"捕捉到了自定义异常&lt;/br&gt;\";&#125;?&gt;\n输出：\nMyException: 自定义异常 in F:\\phpstudy\\src\\index.php:5 Stack trace: #0 {main}\n捕捉到了自定义异常\n生成器生成器总览生成器提供了一种更容易的方法来实现简单的对象迭代，相比较定义类实现 Iterator 接口的方式，性能开销和复杂性大大降低。\n生成器允许你在 foreach 代码块中写代码来迭代一组数据而不需要在内存中创建一个数组, 那会使你的内存达到上限，或者会占据可观的处理时间。相反，你可以写一个生成器函数，就像一个普通的自定义函数一样, 和普通函数只返回一次不同的是, 生成器可以根据需要 yield 多次，以便生成需要迭代的值。\n一个简单的例子就是使用生成器来重新实现 range() 函数。 标准的 range() 函数需要在内存中生成一个数组包含每一个在它范围内的值，然后返回该数组, 结果就是会产生多个很大的数组。 比如，调用 range(0, 1000000) 将导致内存占用超过 100 MB。\n做为一种替代方法, 我们可以实现一个 xrange() 生成器, 只需要足够的内存来创建 Iterator 对象并在内部跟踪生成器的当前状态，这样只需要不到1K字节的内存。\n将 range() 实现为生成器：\n&lt;?phpfunction xrange($start, $limit, $step = 1) &#123;    if ($start &lt; $limit) &#123;        if ($step &lt;= 0) &#123;            throw new LogicException('Step must be +ve');        &#125;        for ($i = $start; $i &lt;= $limit; $i += $step) &#123;            yield $i;        &#125;    &#125; else &#123;        if ($step &gt;= 0) &#123;            throw new LogicException('Step must be -ve');        &#125;        for ($i = $start; $i &gt;= $limit; $i += $step) &#123;            yield $i;        &#125;    &#125;&#125;// 注意下面range()和xrange()输出的结果是一样的。echo 'Single digit odd numbers from range():  ';foreach (range(0,10) as $number) &#123;    echo \"$number \";&#125;echo \"&lt;/br&gt;\";echo 'Single digit odd numbers from xrange(): ';foreach (xrange(0,10) as $number) &#123;    echo \"$number \";&#125;?&gt;\n生成器对象：当第一次调用生成器的时候，返回生成器类的一个对象。这个对象与迭代器对象使用相同的方式实现了迭代器接口，并提供可以调用的方法来处理生成器的状态，包括从它返回值或者向它发送值。\n生成器语法一个生成器函数看起来像一个普通的函数，不同的是普通函数返回一个值，而一个生成器可以yield生成许多它所需要的值。\n当一个生成器被调用的时候，它返回一个可以被遍历的对象.当你遍历这个对象的时候(例如通过一个foreach循环)，PHP 将会在每次需要值的时候调用生成器函数，并在产生一个值之后保存生成器的状态，这样它就可以在需要产生下一个值的时候恢复调用状态。\n一旦不再需要产生更多的值，生成器函数可以简单退出，而调用生成器的代码还可以继续执行，就像一个数组已经被遍历完了。\n在一个生成器函数中不可以存在 return ，否则将产生一个错误。\nyield 关键字生成器函数的核心是yield关键字。它最简单的调用形式看起来像一个return申明，不同之处在于普通return会返回值并终止函数的执行，而yield会返回一个值给循环调用此生成器的代码并且只是暂停执行生成器函数。\n示例：\n&lt;?phpfunction gen_one_to_three() &#123;    for ($i = 1; $i &lt;= 3; $i++) &#123;        //注意变量$i的值在不同的yield之间是保持传递的。        yield $i;    &#125;&#125;$generator = gen_one_to_three();foreach ($generator as $value) &#123;    echo \"$value&lt;/br&gt;\";&#125;?&gt;\n输出：\n1\n2\n3\n使用引用来生成值\n生成函数可以像使用值一样来使用引用生成。这个和从函数返回一个引用一样：通过在函数名前面加一个引用符号。\n&lt;?phpfunction &amp;gen_reference() &#123;    $value = 3;    while ($value &gt; 0) &#123;        yield $value;    &#125;&#125;// 我们可以在循环中修改$number的值，而生成器是使用的引用值来生成// 所以gen_reference()内部的$value值也会跟着变化。foreach (gen_reference() as &amp;$number) &#123;    echo (--$number).'... ';&#125;?&gt;\n输出：\n2... 1... 0... \n引用的解释引用是什么在 PHP 中引用意味着用不同的名字访问同一个变量内容。这并不像 C 的指针：例如你不能对他们做指针运算，他们并不是实际的内存地址…… 替代的是，引用是符号表别名。注意在PHP 中，变量名和变量内容是不一样的， 因此同样的内容可以有不同的名字。最接近的比喻是 Unix 的文件名和文件本身——变量名是目录条目，而变量内容则是文件本身。引用可以被看作是 Unix 文件系统中的硬链接。\n引用做什么PHP 的引用允许用两个变量来指向同一个内容。意思是，当这样做时：\n&lt;?php$a =&amp; $b;?&gt;\n这意味着 $a 和 $b 指向了同一个变量。\n同样的语法可以用在函数中，它返回引用，以及用在 new 运算符中\n&lt;?php$bar =&amp; new fooclass();$foo =&amp; find_var($bar);?&gt;\n自 PHP 5 起，new 自动返回引用，因此在此使用 =&amp; 已经过时了并且会产生 E_STRICT 级别的消息。\n引用做的第二件事是用引用传递变量。这是通过在函数内建立一个本地变量并且该变量在呼叫范围内引用了同一个内容来实现的。例如：\n&lt;?phpfunction foo(&amp;$var) &#123;    $var++;&#125;$a=5;foo($a);?&gt;\n将使 $a 变成 6。这是因为在 foo 函数中变量 $var 指向了和 $a 指向的同一个内容。\n引用不是什么如前所述，引用不是指针。这意味着下面的结构不会产生预期的效果：\n&lt;?phpfunction foo(&amp;$var)&#123;    $var =&amp; $GLOBALS[\"baz\"];&#125;foo($bar);?&gt;\n这将使 foo 函数中的 $var 变量在函数调用时和 $bar 绑定在一起，但接着又被重新绑定到了 $GLOBALS[“baz”] 上面。不可能通过引用机制将 $bar 在函数调用范围内绑定到别的变量上面，因为在函数 foo 中并没有变量 $bar（它被表示为 $var，但是 $var 只有变量内容而没有调用符号表中的名字到值的绑定）。可以使用引用返回来引用被函数选择的变量。\n引用传递可以将一个变量通过引用传递给函数，这样该函数就可以修改其参数的值。语法如下：\n&lt;?phpfunction foo(&amp;$var) &#123;    $var++;&#125;$a=5;foo($a);// $a is 6 here?&gt;\n以下内容可以通过引用传递：\n\n变量，例如 foo($a)\nNew 语句，例如 foo(new foobar())\n从函数中返回的引用，例如：\n\n&lt;?phpfunction &amp;bar() &#123;    $a = 5;    return $a;&#125;foo(bar());?&gt;\n任何其它表达式都不能通过引用传递。\n引用返回引用返回用在当想用函数找到引用应该被绑定在哪一个变量上面时。不要用返回引用来增加性能，引擎足够聪明来自己进行优化。仅在有合理的技术原因时才返回引用！要返回引用，使用此语法：\n&lt;?phpclass foo &#123;    public $value = 42;    public function &amp;getValue() &#123;        return $this-&gt;value;    &#125;&#125;$obj = new foo;$myValue = &amp;$obj-&gt;getValue(); // $myValue 是 $obj-&gt;value 的引用，现在值是 42$obj-&gt;value = 2;echo $myValue;                // 打印 $obj-&gt;value 的值, 现在是 2?&gt;\n取消引用当 unset 一个引用，只是断开了变量名和变量内容之间的绑定。这并不意味着变量内容被销毁了。例如：\n&lt;?php$a = 1;$b =&amp; $a;unset($a);?&gt;\n不会 unset $b，只是 $a。再拿这个和 Unix 的 unlink 调用来类比一下可能有助于理解。\n引用定位许多 PHP 的语法结构是通过引用机制实现的，所以上述有关引用绑定的一切也都适用于这些结构。一些结构，例如引用传递和返回，已经在上面提到了。其它使用引用的结构有：\n\nglobal 引用\n\n当用 global $var 声明一个变量时实际上建立了一个到全局变量的引用。也就是说和这样做是相同的：\n&lt;?php$var =&amp; $GLOBALS[\"var\"];?&gt;\n这意味着，例如，unset $var 不会 unset 全局变量。\n\n$this 在一个对象的方法中，$this 永远是调用它的对象的引用。\n\n预定义变量对于全部脚本而言，PHP 提供了大量的预定义变量。这些变量将所有的外部变量表示成内建环境变量，并且将错误信息表示成返回头。\n超全局变量超全局变量 — 超全局变量是在全部作用域中始终可用的内置变量\nPHP 中的许多预定义变量都是“超全局的”，这意味着它们在一个脚本的全部作用域中都可用。在函数或方法中无需执行 global $variable; 就可以访问它们。\n这些超全局变量是：\n\n$GLOBALS\n$_SERVER\n$_GET\n$_POST\n$_FILES\n$_COOKIE\n$_SESSION\n$_REQUEST\n$_ENV\n\n$GLOBALS$GLOBALS – 引用全局作用域中可用的全部变量，一个包含了全部变量的全局组合数组。变量的名字就是数组的键。\n示例：&lt;?phpfunction test() &#123;    $foo = \"local variable\";    echo '$foo in global scope: ' . $GLOBALS[\"foo\"] . \"\\n\";    echo '$foo in current scope: ' . $foo . \"\\n\";&#125;$foo = \"Example content\";test();?&gt;\n$_SERVER$_SERVER – 服务器和执行环境信息。$_SERVER 是一个包含了诸如头信息(header)、路径(path)、以及脚本位置(script locations)等等信息的数组。这个数组中的项目由 Web 服务器创建。不能保证每个服务器都提供全部项目；服务器可能会忽略一些，或者提供一些没有在这里列举出来的项目。\n\nPHP_SELF – 当前执行脚本的文件名，与 document root 有关。例如，在地址为 http://example.com/foo/bar.php 的脚本中使用 $_SERVER[&#39;PHP_SELF&#39;] 将得到 /foo/bar.php。__FILE__ 常量包含当前(例如包含)文件的完整路径和文件名。 从 PHP 4.3.0 版本开始，如果 PHP 以命令行模式运行，这个变量将包含脚本名。之前的版本该变量不可用。\n\nargv – 传递给该脚本的参数的数组。当脚本以命令行方式运行时，argv 变量传递给程序 C 语言样式的命令行参数。当通过 GET 方式调用时，该变量包含query string。\n\nargc – 包含命令行模式下传递给该脚本的参数的数目(如果运行在命令行模式下)。\n\nGATEWAY_INTERFACE – 服务器使用的 CGI 规范的版本；例如，”CGI/1.1”。\n\nSERVER_ADDR – 当前运行脚本所在的服务器的 IP 地址。\n\nSERVER_NAME – 当前运行脚本所在的服务器的主机名。如果脚本运行于虚拟主机中，该名称是由那个虚拟主机所设置的值决定。\n\nSERVER_SOFTWARE – 服务器标识字符串，在响应请求时的头信息中给出。\n\nSERVER_PROTOCOL – 请求页面时通信协议的名称和版本。例如，”HTTP/1.0”。\n\nREQUEST_METHOD – 访问页面使用的请求方法；例如，”GET”, “HEAD”，”POST”，”PUT”。\n\nREQUEST_TIME – 请求开始时的时间戳。从 PHP 5.1.0 起可用。\n\nREQUEST_TIME_FLOAT – 请求开始时的时间戳，微秒级别的精准度。 自 PHP 5.4.0 开始生效。\n\nQUERY_STRING – query string（查询字符串），如果有的话，通过它进行页面访问。\n\nDOCUMENT_ROOT – 当前运行脚本所在的文档根目录。在服务器配置文件中定义。\n\nHTTP_ACCEPT – 当前请求头中 Accept: 项的内容，如果存在的话。\n\nHTTP_ACCEPT_CHARSET – 当前请求头中 Accept-Charset: 项的内容，如果存在的话。例如：iso-8859-1,*,utf-8。\n\nHTTP_ACCEPT_ENCODING – 当前请求头中 Accept-Encoding: 项的内容，如果存在的话。例如：gzip。\n\nHTTP_ACCEPT_LANGUAGE – 当前请求头中 Accept-Language: 项的内容，如果存在的话。例如：en。\n\nHTTP_CONNECTION – 当前请求头中 Connection: 项的内容，如果存在的话。例如：Keep-Alive。\n\nHTTP_HOST – 当前请求头中 Host: 项的内容，如果存在的话。\n\nHTTP_REFERER – 引导用户代理到当前页的前一页的地址（如果存在）。由 user agent 设置决定。并不是所有的用户代理都会设置该项，有的还提供了修改 HTTP_REFERER 的功能。简言之，该值并不可信。\n\nHTTP_USER_AGENT – 当前请求头中 User-Agent: 项的内容，如果存在的话。该字符串表明了访问该页面的用户代理的信息。一个典型的例子是：Mozilla/4.5 [en] (X11; U; Linux 2.2.9 i586)。除此之外，你可以通过 get_browser() 来使用该值，从而定制页面输出以便适应用户代理的性能。\n\nHTTPS – 如果脚本是通过 HTTPS 协议被访问，则被设为一个非空的值。\n\nREMOTE_ADDR – 浏览当前页面的用户的 IP 地址。\n\nREMOTE_HOST – 浏览当前页面的用户的主机名。DNS 反向解析不依赖于用户的 REMOTE_ADDR。\n\nREMOTE_PORT – 用户机器上连接到 Web 服务器所使用的端口号。\n\nREMOTE_USER – 经验证的用户\n\nREDIRECT_REMOTE_USER – 验证的用户，如果请求已在内部重定向。\n\nSCRIPT_FILENAME – 当前执行脚本的绝对路径。\n\nSERVER_ADMIN – 该值指明了 Apache 服务器配置文件中的 SERVER_ADMIN 参数。如果脚本运行在一个虚拟主机上，则该值是那个虚拟主机的值。\n\nSERVER_PORT – Web 服务器使用的端口。默认值为 “80”。如果使用 SSL 安全连接，则这个值为用户设置的 HTTP 端口。\n\nSERVER_SIGNATURE – 包含了服务器版本和虚拟主机名的字符串。\n\nPATH_TRANSLATED – 当前脚本所在文件系统（非文档根目录）的基本路径。这是在服务器进行虚拟到真实路径的映像后的结果。\n\nSCRIPT_NAME – 包含当前脚本的路径。这在页面需要指向自己时非常有用。__FILE__ 常量包含当前脚本(例如包含文件)的完整路径和文件名。\n\nREQUEST_URI – URI 用来指定要访问的页面。例如 /index.html。\n\nPHP_AUTH_DIGEST – 当作为 Apache 模块运行时，进行 HTTP Digest 认证的过程中，此变量被设置成客户端发送的”Authorization” HTTP 头内容（以便作进一步的认证操作）。\n\nPHP_AUTH_USER – 当 PHP 运行在 Apache 或 IIS（PHP 5 是 ISAPI）模块方式下，并且正在使用 HTTP 认证功能，这个变量便是用户输入的用户名。\n\nPHP_AUTH_PW – 当 PHP 运行在 Apache 或 IIS（PHP 5 是 ISAPI）模块方式下，并且正在使用 HTTP 认证功能，这个变量便是用户输入的密码。\n\nAUTH_TYPE – 当 PHP 运行在 Apache 模块方式下，并且正在使用 HTTP 认证功能，这个变量便是认证的类型。\n\nPATH_INFO – 包含由客户端提供的、跟在真实脚本名称之后并且在查询语句（query string）之前的路径信息，如果存在的话。例如，如果当前脚本是通过 URL http://www.example.com/php/path_info.php/some/stuff?foo=bar 被访问，那么 $_SERVER[&#39;PATH_INFO&#39;] 将包含 /some/stuff。\n\nORIG_PATH_INFO – 在被 PHP 处理之前，PATH_INFO 的原始版本。\n\n\n示例：\n&lt;?phpecho '&lt;pre&gt;';echo $_SERVER['SERVER_NAME'];echo $_SERVER['HTTP_USER_AGENT'];?&gt;\n$_GET$_GET – HTTP GET 变量，通过 URL 参数传递给当前脚本的变量的数组。\n示例：\n&lt;?phpecho 'Hello ' . htmlspecialchars($_GET[\"name\"]) . '!';?&gt;\n浏览器访问：http://127.0.0.1:8088/?name=World\n$_POST$_POST HTTP POST 变量，当 HTTP POST 请求的 Content-Type 是 application/x-www-form-urlencoded 或 multipart/form-data 时，会将变量以关联数组形式传入当前脚本。\n示例：\npost.html&lt;html&gt;&lt;body&gt;    &lt;form action=\"post.php\" method=\"post\"&gt;        Name: &lt;input type=\"text\" name=\"name\"&gt;        &lt;input type=\"submit\"&gt;    &lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\npost.php&lt;?phpecho 'Hello ' . htmlspecialchars($_POST[\"name\"]) . '!';?&gt;\n浏览器访问：http://127.0.0.1:8088/post.html，输入内容后提交。\n$_FILES$_FILES – HTTP 文件上传变量，通过 HTTP POST 方式上传到当前脚本的项目的数组\n示例：\nfile.html&lt;html&gt;&lt;body&gt;    &lt;form action=\"file.php\" enctype=\"multipart/form-data\" method=\"post\"&gt;        File: &lt;input type=\"file\" name=\"name\"&gt;        &lt;input type=\"submit\"&gt;    &lt;/form&gt;&lt;/body&gt;&lt;/html&gt;\nfile.php&lt;?phpvar_dump($_FILES);?&gt;\n$_REQUEST$_REQUEST – HTTP Request 变量，默认情况下包含了 $_GET，$_POST 和 $_COOKIE 的数组。\n$_SESSION$_SESSION – Session 变量，当前脚本可用 SESSION 变量的数组。Session 是浏览器会话保持机制。\n示例：\n&lt;?phpsession_start();if (!isset($_SESSION['count'])) &#123;  $_SESSION['count'] = 0;&#125; else &#123;  $_SESSION['count']++;&#125;echo $_SESSION['count'];?&gt;\n然后不断的访问这个页面，可以看到数值不断增加。\n$_ENV$_ENV – 环境变量，通过环境方式传递给当前脚本的变量的数组。\n这些变量被从 PHP 解析器的运行环境导入到 PHP 的全局命名空间。很多是由支持 PHP 运行的 Shell 提供的，并且不同的系统很可能运行着不同种类的 Shell，所以不可能有一份确定的列表。请查看你的 Shell 文档来获取定义的环境变量列表。\n其他环境变量包含了 CGI 变量，而不管 PHP 是以服务器模块还是 CGI 处理器的方式运行。\n示例：\n&lt;?phpvar_dump($_ENV);?&gt;\n$_COOKIE$_COOKIE – HTTP Cookies，通过 HTTP Cookies 方式传递给当前脚本的变量的数组。Cookie 也是浏览器会话保持机制，与 Session 不同的是，Session 的内容保存在服务器端，而 Cookie 的内容保存在浏览器，所以安全性不如 Session 。\n示例：&lt;?phpif (!isset($_COOKIE['count'])) &#123;    $count = 0;    setcookie('count', $count, time()+3600);&#125; else &#123;    $count = ++$_COOKIE['count'];    setcookie('count', $count, time()+3600);&#125;echo $count;?&gt;\n然后不断的访问这个页面，可以看到数值不断增加。\n$http_response_header$http_response_header – HTTP 响应头，$http_response_header 将会被 HTTP 响应头信息填充。$http_response_header 将被创建于局部作用域中。\n示例：\n&lt;?phpfunction get_contents() &#123;  file_get_contents(\"http://www.baidu.com\");  var_dump($http_response_header);&#125;get_contents();echo '&lt;/br&gt;';var_dump($http_response_header);?&gt;\n可以看到 $http_response_header 只在 get_contents() 中被创建。\n$argc$argc – 传递给脚本的参数数目，仅在命令行执行有效。\n注意：脚本的文件名总是作为参数传递给当前脚本，因此 $argc 的最小值为 1。\nargc.php&lt;?phpecho $argc;echo \"\\r\\n\";?&gt;\n在终端里运行：php argc.php a a a a 输出：5\n$argv$argv – 传递给脚本的参数数组，仅在命令行执行有效。\nargv.php&lt;?phpvar_dump($argv);?&gt;\n在终端里运行：php argv.php a b c d输出：\narray(5) {\n[0]=&gt;\nstring(8) &quot;argv.php&quot;\n[1]=&gt;\nstring(1) &quot;a&quot;\n[2]=&gt;\nstring(1) &quot;b&quot;\n[3]=&gt;\nstring(1) &quot;c&quot;\n[4]=&gt;\nstring(1) &quot;d&quot;\n}\n预定义接口Traversable 接口Traversable（遍历）接口，检测一个类是否可以使用 foreach 进行遍历的接口。无法被单独实现的基本抽象接口。相反它必须由 IteratorAggregate 或 Iterator 接口实现。\n接口摘要：\nTraversable &#123; &#125;\n这个接口没有任何方法，它的作用仅仅是作为所有可遍历类的基本接口。\nIterator 接口Iterator（迭代器）接口，可在内部迭代自己的外部迭代器或类的接口。\n接口摘要：Iterator extends Traversable &#123;/* 方法 */    abstract public mixed current ( void )    abstract public scalar key ( void )    abstract public void next ( void )    abstract public void rewind ( void )    abstract public bool valid ( void )&#125;\n基本用法：\n&lt;?phpclass myIterator implements Iterator &#123;    private $position = 0;    private $array = array(        \"firstelement\",        \"secondelement\",        \"lastelement\",    );      public function __construct() &#123;        $this-&gt;position = 0;    &#125;    function rewind() &#123;        var_dump(__METHOD__);        $this-&gt;position = 0;    &#125;    function current() &#123;        var_dump(__METHOD__);        return $this-&gt;array[$this-&gt;position];    &#125;    function key() &#123;        var_dump(__METHOD__);        return $this-&gt;position;    &#125;    function next() &#123;        var_dump(__METHOD__);        ++$this-&gt;position;    &#125;    function valid() &#123;        var_dump(__METHOD__);        return isset($this-&gt;array[$this-&gt;position]);    &#125;&#125;$it = new myIterator;foreach($it as $key =&gt; $value) &#123;    var_dump($key, $value);    echo \"\\n\";&#125;?&gt;\n只要实现了 Iterator 这个接口的类，它的对象就可以使用 foreach 迭代了。\n其中要实现的方法：\n\nIterator::current — 返回当前元素，此函数没有参数，可返回任何类型。\nIterator::key — 返回当前元素的键，此函数没有参数，成功返回标量，失败则返回 NULL。\nIterator::next — 向前移动到下一个元素，此函数没有参数，任何返回都将被忽略。\nIterator::rewind — 返回到迭代器的第一个元素，此函数没有参数，任何返回都将被忽略。\nIterator::valid — 检查当前位置是否有效，此函数没有参数，返回将被转换为布尔型。成功时返回 TRUE， 或者在失败时返回 FALSE。\n\nIteratorAggregate 接口IteratorAggregate（聚合式迭代器）接口，创建外部迭代器的接口。\n接口摘要：IteratorAggregate extends Traversable &#123;    /* 方法 */    abstract public Traversable getIterator ( void )&#125;\n基本用法：&lt;?phpclass myData implements IteratorAggregate &#123;    public $property1 = \"Public property one\";    public $property2 = \"Public property two\";    public $property3 = \"Public property three\";    public function __construct() &#123;        $this-&gt;property4 = \"last property\";    &#125;    public function getIterator() &#123;        return new ArrayIterator($this);    &#125;&#125;$obj = new myData;foreach($obj as $key =&gt; $value) &#123;    var_dump($key, $value);    echo \"\\n\";&#125;?&gt;\n方法：IteratorAggregate::getIterator 返回一个外部迭代器，此函数没有参数，返回实现了 Iterator 或 Traversable 接口的类的一个实例。\nArrayAccess 接口ArrayAccess（数组式访问）接口，提供像访问数组一样访问对象的能力的接口。\n接口摘要：\nArrayAccess &#123;    /* 方法 */    abstract public boolean offsetExists ( mixed $offset )    abstract public mixed offsetGet ( mixed $offset )    abstract public void offsetSet ( mixed $offset , mixed $value )    abstract public void offsetUnset ( mixed $offset )&#125;\n示例：&lt;?phpclass obj implements arrayaccess &#123;    private $container = array();    public function __construct() &#123;        $this-&gt;container = array(            \"one\"   =&gt; 1,            \"two\"   =&gt; 2,            \"three\" =&gt; 3,        );    &#125;    public function offsetSet($offset, $value) &#123;        if (is_null($offset)) &#123;            $this-&gt;container[] = $value;        &#125; else &#123;            $this-&gt;container[$offset] = $value;        &#125;    &#125;    public function offsetExists($offset) &#123;        return isset($this-&gt;container[$offset]);    &#125;    public function offsetUnset($offset) &#123;        unset($this-&gt;container[$offset]);    &#125;    public function offsetGet($offset) &#123;        return isset($this-&gt;container[$offset]) ? $this-&gt;container[$offset] : null;    &#125;&#125;$obj = new obj;var_dump(isset($obj[\"two\"]));var_dump($obj[\"two\"]);unset($obj[\"two\"]);var_dump(isset($obj[\"two\"]));$obj[\"two\"] = \"A value\";var_dump($obj[\"two\"]);$obj[] = 'Append 1';$obj[] = 'Append 2';$obj[] = 'Append 3';print_r($obj);?&gt;\n\nArrayAccess::offsetExists – 检查一个偏移位置是否存在\nArrayAccess::offsetGet – 获取一个偏移位置的值\nArrayAccess::offsetSet – 设置一个偏移位置的值\nArrayAccess::offsetUnset – 复位一个偏移位置的值\n\n序列化接口Serializable 自定义序列化的接口。\n实现此接口的类将不再支持 sleep() 和 wakeup()。不论何时，只要有实例需要被序列化，serialize 方法都将被调用。它将不会调用 __destruct() 或有其他影响，除非程序化地调用此方法。当数据被反序列化时，类将被感知并且调用合适的 unserialize() 方法而不是调用 __construct()。如果需要执行标准的构造器，你应该在这个方法中进行处理。\n接口摘要：\nSerializable &#123;    /* 方法 */    abstract public string serialize ( void )    abstract public mixed unserialize ( string $serialized )&#125;\n示例：\n&lt;?phpclass obj implements Serializable &#123;    private $data;    public function __construct() &#123;        $this-&gt;data = \"My private data\";    &#125;    public function serialize() &#123;        return serialize($this-&gt;data);    &#125;    public function unserialize($data) &#123;        $this-&gt;data = unserialize($data);    &#125;    public function getData() &#123;        return $this-&gt;data;    &#125;&#125;$obj = new obj;$ser = serialize($obj);$newobj = unserialize($ser);var_dump($newobj-&gt;getData());?&gt;\n\nSerializable::serialize — 对象的字符串表示\nSerializable::unserialize — 构造对象\n\nClosure 类用于代表匿名函数的类。\n匿名函数会产生这个类型的对象。在过去，这个类被认为是一个实现细节，但现在可以依赖它做一些事情。自 PHP 5.4 起，这个类带有一些方法，允许在匿名函数创建后对其进行更多的控制。\n除了此处列出的方法，还有一个 __invoke 方法。这是为了与其他实现了 __invoke() 魔术方法 的对象保持一致性，但调用匿名函数的过程与它无关。\n类摘要：\nClosure &#123;    /* 方法 */    __construct ( void )    public static Closure bind ( Closure $closure , object $newthis [, mixed $newscope = 'static' ] )    public Closure bindTo ( object $newthis [, mixed $newscope = 'static' ] )&#125;\n\nClosure::__construct — 用于禁止实例化的构造函数\nClosure::bind — 复制一个闭包，绑定指定的$this对象和类作用域。\nClosure::bindTo — 复制当前闭包对象，绑定指定的$this对象和类作用域。\n\n生成器类Generator 对象是从 generators 返回的，Generator 对象不能通过 new 实例化。\n类摘要：\nGenerator implements Iterator &#123;    /* 方法 */    public mixed current ( void )    public mixed key ( void )    public void next ( void )    public void rewind ( void )    public mixed send ( mixed $value )    public void throw ( Exception $exception )    public bool valid ( void )    public void __wakeup ( void )&#125;\n\nGenerator::current — 返回当前产生的值\nGenerator::key — 返回当前产生的键\nGenerator::next — 生成器继续执行\nGenerator::rewind — 重置迭代器\nGenerator::send — 向生成器中传入一个值\nGenerator::throw — 向生成器中抛入一个异常\nGenerator::valid — 检查迭代器是否被关闭\nGenerator::__wakeup — 序列化回调\n\n附录到这里 PHP 的基础语法就结束了，想要用 PHP 去解决一些实际的事情就需要学习 PHP 如何应用了。\n本篇根据整理学习 PHP 官方手册 完成。\n","categories":["PHP"],"tags":["php"]}]