<?xml version="1.0" encoding="utf-8"?>
<search>
  <entry>
    <title><![CDATA[从零开始搭建Vue开发环境]]></title>
    <url>%2F2018%2F12%2F20%2F2018%2F%E4%BB%8E%E9%9B%B6%E5%BC%80%E5%A7%8B%E6%90%AD%E5%BB%BAVue%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[简介 Vue (读音 /vjuː/，类似于 view) 是一套用于构建用户界面的渐进式框架。与其它大型框架不同的是，Vue 被设计为可以自底向上逐层应用。Vue 的核心库只关注视图层，不仅易于上手，还便于与第三方库或既有项目整合。另一方面，当与现代化的工具链以及各种支持类库结合使用时，Vue 也完全能够为复杂的单页应用提供驱动。本篇文章记录不使用 vue-cli 的自动化功能，手动搭建一个 Vue 的开发环境。 环境 软件 版本 操作系统 Windows 10 Node.js v10.13.0 步骤初始化项目目录创建一个空的目录作为项目目录，并在目录内执行 npm init --yes D:\Workspace\webapp&gt;npm init --yes Wrote to D:\Workspace\webapp\package.json: { &quot;name&quot;: &quot;webapp&quot;, &quot;version&quot;: &quot;1.0.0&quot;, &quot;description&quot;: &quot;&quot;, &quot;main&quot;: &quot;index.js&quot;, &quot;scripts&quot;: { &quot;test&quot;: &quot;echo \&quot;Error: no test specified\&quot; &amp;&amp; exit 1&quot; }, &quot;keywords&quot;: [], &quot;author&quot;: &quot;&quot;, &quot;license&quot;: &quot;ISC&quot; } 并创建新目录 src 作为代码的存放目录。在 src 目录中创建 index.html 写入以下内容： 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 加速 npm 包下载默认的 npm 非常连接官方的 npm 源，下载速度非常慢，可以使用 cnpm 来加速下载。 首先全局安装 cnpm1npm install -g cnpm --registry=https://registry.npm.taobao.org 之后就可以使用 cnpm 来开心的下载 npm 包了，但是 cnpm 下载某些包会出现依赖无法完全解决的问题，导致包无法正常使用，这种情况就只好配合 npm 来使用了。 还有一种加速 npm 包下载的方法，就是让默认的 npm 命令使用国内的 npm 镜像站。可以注意到，上一条安装 cnpm 的命令中，就使用了 --registry=https://registry.npm.taobao.org 临时将下载源切换到 taobao 提供的 npm 镜像站。这里使用 nrm 工具来切换镜像站，nrm 工具也需要先使用 npm 来安装。 1npm install -g nrm --registry=https://registry.npm.taobao.org nrm ls 命令可以看到当前默认使用的是 npm 的官方源 D:\Workspace\webapp&gt;nrm ls * npm ---- https://registry.npmjs.org/ cnpm --- http://r.cnpmjs.org/ taobao - https://registry.npm.taobao.org/ nj ----- https://registry.nodejitsu.com/ rednpm - http://registry.mirror.cqupt.edu.cn/ npmMirror https://skimdb.npmjs.com/registry/ edunpm - http://registry.enpmjs.org/ 使用 nrm use taobao 将默认源切换到 taobao 提供的镜像站 D:\Workspace\webapp&gt;nrm use taobao Registry has been set to: https://registry.npm.taobao.org/ D:\Workspace\webapp&gt;nrm ls npm ---- https://registry.npmjs.org/ cnpm --- http://r.cnpmjs.org/ * taobao - https://registry.npm.taobao.org/ nj ----- https://registry.nodejitsu.com/ rednpm - http://registry.mirror.cqupt.edu.cn/ npmMirror https://skimdb.npmjs.com/registry/ edunpm - http://registry.enpmjs.org/ 搭建 webpack 开发环境安装 webpackVue 官方推荐的开发方式是配合 webpack 打包工具，那么首先把 webpack 环境搭建起来。 1cnpm install webpack webpack-cli --save-dev webpack3 中，webpack和它的命令行工具都包含在一个包中，但在 webpack4 中，官方将两者分开了，所以必须两个包都安装才可以使用 webpack 命令。官方推荐局部安装 webpack ，直接输入 webpack 命令是没法找到的，高版本的 node.js 可以使用 npx 命令来执行 webpack，或者直接使用相对路径执行 webpack。 D:\Workspace\webapp&gt;webpack -v &apos;webpack&apos; 不是内部或外部命令，也不是可运行的程序 或批处理文件。 D:\Workspace\webapp&gt;npx webpack -v 4.28.0 D:\Workspace\webapp&gt;node_modules\.bin\webpack -v 4.28.0 使用 webpack 打包接下来在 src 目录下编写一个 main.js，文件内容如下： 12let app = document.getElementById("app")app.innerHTML = "&lt;h1&gt;Hello webpack!&lt;h1&gt;" 将 main.js 打包为 bundle.js，我们一般将打包后的文件单独放到 dist 目录下： 1npx webpack src\main.js -o dist\bundle.js --mode development D:\Workspace\webapp&gt;npx webpack src\main.js -o dist\bundle.js --mode development Hash: 8a16b3a0c76c2b1d9f8a Version: webpack 4.28.0 Time: 94ms Built at: 2018-12-20 22:58:15 Asset Size Chunks Chunk Names bundle.js 3.85 KiB main [emitted] main Entrypoint main = bundle.js [./src/main.js] 82 bytes {main} [built] 如果不加上 --mode development，webpack 则默认使用 production 级别去打包，如果代码里有 console.log 等无关程序运行逻辑的代码都会被清理掉，这样不方便项目的调试。这时可以看到项目目录下多出来一个 dist 目录，目录中有一个打包好的 bundle.js。这个例子中并没有在 main.js 里引入第三方的文件，如果引入了，webpack 也会一并打包为一个 bundle.js。 在 index.html 里引入打包好的 bundle.js：1234&lt;body&gt; &lt;div id="app"&gt;&lt;/div&gt; &lt;script src="../dist/bundle.js"&gt;&lt;/script&gt;&lt;/body&gt; 浏览器查看效果： webpack 配置文件用命令行的方式是非常不方便，如果关闭了终端，下次使用 webpack 编译代码就还需要输入长长的一串代码，我们可以将代码写入到 webpack 的配置文件中，并配合 package.json 提供的自定义脚本命令功能来实现方便的编译。 与 package.json 同级的目录下创建 webpack.config.js 文件，当前项目目录下为： webpack.config.js 里写入如下内容： 12345678910const path = require('path')module.exports = &#123; entry: path.join(__dirname, './src/main.js'), output: &#123; path: path.join(__dirname, "./dist"), filename: "bundle.js" &#125;, mode: "development"&#125; 代码语法使用 node.js 的语法，并使用 module.exports 将配置暴露出去，其中 entry 表示入口文件，也就是我们的 main.js 所在的目录。output 提供一个输出的目录和打包后的文件名。mode 则是配置使用哪种模式进行打包。之后我们对 webpack 的配置也都是围绕这个文件进行。 这是在命令行只输入 npx webpack 命令，可以看到也编译成功了。 接着修改 package.json，在 scripts 项中添加 &quot;build&quot;: &quot;webpack&quot;，这里就不需要借助 npx 工具来执行 webpack 了，npm 会在合适的位置运行 webpack 命令。 当前 package.json 内容如下： 1234567891011121314151617&#123; "name": "webapp", "version": "1.0.0", "description": "", "main": "index.js", "scripts": &#123; "test": "echo \"Error: no test specified\" &amp;&amp; exit 1", "build": "webpack" &#125;, "keywords": [], "author": "", "license": "ISC", "devDependencies": &#123; "webpack": "^4.28.0", "webpack-cli": "^3.1.2" &#125;,&#125; 控制台运行 npm run build D:\Workspace\webapp&gt;npm run build &gt; webapp@1.0.0 build D:\Workspace\webapp &gt; webpack Hash: 8a16b3a0c76c2b1d9f8a Version: webpack 4.28.0 Time: 95ms Built at: 2018-12-20 23:25:53 Asset Size Chunks Chunk Names bundle.js 3.85 KiB main [emitted] main Entrypoint main = bundle.js [./src/main.js] 82 bytes {main} [built] 预设的命令执行成功了。 webpack-dev-server 配置每次更改了代码，每次都需要重新编译，并刷新浏览器页面，这样是非常浪费时间的。而且通过文件的方式在浏览器预览效果，后期可能会出现各种问题。webpack-dev-server 则提供了一个支持时时编译，并自动刷新浏览器的功能。 我们首先安装它： 1cnpm install webpack-dev-server --save-dev webpack-dev-server 也支持直接通过命令行参数启动，但是既然已经使用了 webpack.config.js 来管理配置，那么就不提倡命令行参数启动了。修改 webpack.config.js 内容如下： 12345678910111213141516171819const path = require('path')const webpack = require("webpack")module.exports = &#123; entry: path.join(__dirname, './src/main.js'), output: &#123; path: path.join(__dirname, "./dist"), filename: "bundle.js" &#125;, mode: "development", devServer: &#123; open: true, port: 3000, hot: true &#125;, plugins: [ new webpack.HotModuleReplacementPlugin(), ]&#125; 我们添加了 devServer 和 plugins 配置项，并导入了一个新的包 webpack。devServer 里配置的三个属性，open 表示自动帮我们打开浏览器，port 表示服务监听在 3000 端口，hot 表示开启热加载功能。热加载功能一个需要注意的地方就是需要在 plugins 里添加这个插件，否则热加载功能是关闭的，所以才有了 new webpack.HotModuleReplacementPlugin() 这段代码。 还有一个需要注意的地方是，使用 webpack-dev-server 时一定要将 mode 设置为 development，否则每次热更新都非常慢，因为编译为 production 是非常耗时且消耗 CPU 资源的，但是可以给打包后的代码带来更小的体积。 接着在 package.json 中添加命令，并修改 build 命令构建 production 级别的代码： 12345"scripts": &#123; "test": "echo \"Error: no test specified\" &amp;&amp; exit 1", "build": "webpack --mode production", "dev": "webpack-dev-server"&#125; 控制台输入 npm run dev 命令，可以看到 webpack-dev-server 开始执行了，片刻，浏览器也自动打开了项目的根目录的页面： index.html 在 src 目录下，点击 src 目录则打开了先前的页面。修改 main.js 里的内容为如下： 12let app = document.getElementById("app")app.innerHTML = "&lt;h1&gt;Hello Vue!&lt;h1&gt;" 可以看到每次对代码 Ctrl + S 保存一次，控制台就多输出一些内容，如果内容有 Compiled successfully. 则表示自动编译成功了，当我们兴高采烈的刷新浏览器时发现，怎么一点变化都没！这是因为 webpack-dev-server 并不是直接将编译后的代码保存在磁盘上，而且放在了内存中。而我们刚才的 index.html 引入的还是之前编译好的 bundle.js 文件。 修改 index.html 将引入 bundle.js 的代码改为 &lt;script src=&quot;/bundle.js&quot;&gt;&lt;/script&gt;，接着重启服务或者刷新浏览器试试： 而且每次修改了 main.js 后都会自动帮我们编译并刷新浏览器。还有个小问题，webpack-dev-server 每次打开浏览器能不能直接定位到 index.html 而不是我们手动进入 src 目录呢？答案是肯定的，修改 devServer 的属性如下： 123456devServer: &#123; open: true, port: 3000, hot: true, contentBase: "src",&#125;, contentBase 会告诉 webpack-dev-server 以哪个目录作为根目录，然后重启 webpack-dev-server 可以看到浏览器自动打开的就是我们希望看到的页面了。 但是。。。当我们自动修改了 main.js 的时候，webpack-dev-server 会自动编译并把它放入内存，而 index.html 依然在物理磁盘上，那么我们能不能把这个文件也放入内存？这时还需要借助一个 html-webpack-plugin 的插件，接下来安装并使用它： 1cnpm install html-webpack-plugin --save-dev 修改 webpack.config.js 为如下内容： 12345678910111213141516171819202122232425const path = require('path')const webpack = require("webpack")const htmlWebpackPlugin = require("html-webpack-plugin")module.exports = &#123; entry: path.join(__dirname, './src/main.js'), output: &#123; path: path.join(__dirname, "./dist"), filename: "bundle.js" &#125;, mode: "development", devServer: &#123; open: true, port: 3000, hot: true, // contentBase: "src", &#125;, plugins: [ new webpack.HotModuleReplacementPlugin(), new htmlWebpackPlugin(&#123; template: path.join(__dirname, "./src/index.html"), filename: "index.html" &#125;) ]&#125; 这里我们做了三处更改，首先引入了 html-webpack-plugin 这个插件，然后注释掉了 contentBase: &quot;src&quot;，接着初始化了 htmlWebpackPlugin 的对象，并将 index.html 的路径和文件名提供给插件。 还需要修改 index.html 将引入 bundle.js 的代码去掉： 123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; 然后重启 webpack-dev-server 可以看到，又打开了熟悉的页面。为什么我们没有引入 bundle.js 还可以正常显示页面呢？打开控制台可以看到，html-webpack-plugin 已经帮我们自动加入这句代码了。 其实这个插件最重要的一点是，我们执行 npm run build 编译项目的时候，html-webpack-plugin 还会帮我们把处理好的 index.html 文件放入 dist 目录中。 webpack 处理 csswebpack 会自动处理 main.js 中通过 import 引入的其他 JavaScript 代码，同样也可以处理通过 import 引入的 css 样式文件，不过需要使用专门的 css-loader 来进行处理。我们需要先安装打包处理 css 文件的两个包：style-loader 和 css-loader 1cnpm install style-loader css-loader --save-dev 现在 webpack 还不认识 css 文件，还需要修改 webpack.config.js 增加处理 css 文件的规则，修改后配置文件内容如下： 123456789101112131415161718192021222324252627282930const path = require('path')const webpack = require("webpack")const htmlWebpackPlugin = require("html-webpack-plugin")module.exports = &#123; entry: path.join(__dirname, './src/main.js'), output: &#123; path: path.join(__dirname, "./dist"), filename: "bundle.js" &#125;, mode: "development", devServer: &#123; open: true, port: 3000, hot: true, // contentBase: "src", &#125;, plugins: [ new webpack.HotModuleReplacementPlugin(), new htmlWebpackPlugin(&#123; template: path.join(__dirname, "./src/index.html"), filename: "index.html" &#125;) ], module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125; ] &#125;&#125; 其中新添了 module 配置项，并在其中添加了 rules。每一条规则都是一个对象格式，其中 test 是正则表达式，用于匹配以 .css 结尾的文件，use 配置了使用哪些加载器来处理匹配到的文件，加载器是从后往前处理的，css 文件先通过 css-loader 处理，然后才经过 style-loader 处理。 接着在 src 目录下新建 css 文件夹用于存放公共的 css 样式文件。css 目录中创建 base.css 文件来编写一些基础样式，文件内容如下： 12345678* &#123; margin: 0; padding: 0;&#125;div &#123; text-align: center;&#125; 接着在 main.js 里引入这个样式文件： 1234import './css/base.css'let app = document.getElementById("app")app.innerHTML = "&lt;h1&gt;Hello Vue!&lt;h1&gt;" 由于更改了 webpack 的配置文件，所以需要重启 webpack-dev-server，然后浏览器查看效果： 样式成功引入了。 webpack 中使用 less对于习惯用 less 的语法来写 css 的开发者，webpack 也提供了相应的加载器可以很方便的处理 less 代码。我们首先需要安装 less 的编译器以及 less 的加载器： 1cnpm install less less-loader --save-dev 然后 rules 规则中添加对 less 文件的处理： 123456module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125; ]&#125; css 目录中编写 base.less 文件：123456@baseColor: blue;div &#123; h1 &#123; color: @baseColor; &#125;&#125; 然后 main.js 中引入这个文件：12345import './css/base.css'import './css/base.less'let app = document.getElementById("app")app.innerHTML = "&lt;h1&gt;Hello Vue!&lt;h1&gt;" 重启 webpack-dev-server，浏览器查看效果： webpack 中使用 sasswebpack 处理 sass 语法编写的文件和 less 原理相同，不过由于 sass 是通过 ruby 写的编译器，通过 npm 安装会非常麻烦，而通过 cnpm 就非常容易了。同样先安装 sass 的编译器和加载器： 1cnpm install node-sass sass-loader --save-dev webpack 配置文件中添加处理 .scss 文件的规则： 1234567module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;, &#123;test: /\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125; ]&#125; css 目录中编写 base.scss 文件： 123456$baseColor: pink;div &#123; h1 &#123; background-color: $baseColor; &#125;&#125; main.js 引入这个文件： 123456import './css/base.css'import './css/base.less'import './css/base.scss'let app = document.getElementById("app")app.innerHTML = "&lt;h1&gt;Hello Vue!&lt;h1&gt;" 重启 webpack-dev-server，浏览器查看效果： webpack 处理其他资源css 中经常会引入一些背景图片、字体图标等文件，如果 webpack 不对这些文件也进行处理，那网页还是会出问题的。用 webpack 打包小图片和小图标还可以完美的解决客户端和浏览器因为传输小图片造成的 HTTP 资源浪费问题。之前我们解决这种问题通常是采用精灵图的方式。 处理这些资源我们需要安装 url-loader，它又依赖于 file-loader： 1cnpm install url-loader file-loader --save-dev 处理背景图片同处理 css 文件的过程，我们也需要在 webpack 配置文件中增加处理图片文件的规则： 12345678module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;, &#123;test: /\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;, &#123;test: /\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader']&#125; ]&#125; 在 src 目录下创建 images 目录 现在我们给网页增加一个背景图： 将背景图保存为 bg.png，并放入 src/images 目录中，然后修改 base.css 中引入这个图片作为背景： 12345678910111213* &#123; margin: 0; padding: 0;&#125;html &#123; background: url(../images/bg.png); background-repeat: repeat;&#125;div &#123; text-align: center;&#125; 重启 webpack-dev-server 后，页面背景图被成功加载了。 这些图片 webpack 是如何处理的呢？我们不妨 F12 开发者模式查看下： webpack 将图片以 Base64 的编码格式直接写入了 css 样式中，这样浏览器就不需要再次发起一次对图片的 HTTP 请求了。Base64 编码也有个不足的地方是，编码后的文件比源文件要增大三分之一，如果是小文件，Base64 的优势还是非常明显的，但是如果图片尺寸非常大，那带来的额外网络资源消耗就非常不划算了。我们可以通过给 url-loader 插件进行传参，来手动控制将多大尺寸的图片进行 Base64 编码。 修改 webpack 配置文件，我们用 get 请求传参的方式给 url-loader 传递参数： 12345678module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;, &#123;test: /\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;, &#123;test: /\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader?limit=8192']&#125; ]&#125; 这表示只有小于 8192 字节的图片，我们才需要进行 Base64 编码。图片的大小是 13.4K 明显超过了限制。重启 webpack-dev-server 查看效果： 现在文件名是一个32位的哈希值来表示，这样做的好处是可以避免如果项目中有内容完全相同的文件，就不需要处理两次了。当然这个名字的结构我们也是可以自定义的： 12345678910module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;, &#123;test: /\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;, &#123; test: /\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]'] &#125; ]&#125; 我们将文件的原名称放在第一位，后面紧跟8位的哈希值，后面带上原来的扩展名，修改 webpack 配置文件后并重启 webpack-dev-server： 处理字体图标文件一些 css 样式库自带了图标以及字体文件，比如 Bootstrap，如果我们不对这些资源进行处理的话，页面也是无法正常显示的，下面就使用 Bootstrap 试试图标字体该如何处理。 首先安装 bootstrap： 1cnpm install bootstrap@3 --save 由于我们只使用 Bootstrap 提供的样式，所以就不引入 jquery 等依赖了。 修改 webpack 配置文件，添加处理图标字体的规则： 1234567891011module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;, &#123;test: /\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;, &#123; test: /\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]'] &#125;, &#123;test: /\.(ttf|eot|svg|woff|woff2)$/, use: 'url-loader'&#125; ]&#125; 在 main.js 中引入 bootstrap.css 并向 div 元素中追加一个图标：1234567891011import './css/base.css'import './css/base.less'import './css/base.scss'import '../node_modules/bootstrap/dist/css/bootstrap.css'let app = document.getElementById("app")app.innerHTML = "&lt;h1&gt;Hello Vue!&lt;h1&gt;"let icon = document.createElement('i')icon.className = "glyphicon glyphicon-music"app.appendChild(icon) 重启 webpack-dev-server： 小小的图标出现了。 webpack 中 babel 配置webpack 虽然支持一部分 ES6 语法，但是我们还是无法放开了写 ES6 语法的。这时我们就需要一款工具，来自动帮我们把高版本的 JavaScript 语法转变为较低版本的，这样对于 webpack 和浏览器兼容性都比较好，而且我们也可以享受 ES6 甚至更高版本的语法带来的编程体验。这款工具就叫做 Babel。 安装 Babel 需要两套包：12cnpm install babel-core@6 babel-loader@7 babel-plugin-transform-runtime --save-devcnpm install babel-preset-env babel-preset-stage-0 --save-dev 接着修改 webpack 配置文件，让 .js 文件先通过 Babel 进行处理： 123456789101112module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;, &#123;test: /\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;, &#123; test: /\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]'] &#125;, &#123;test: /\.(ttf|eot|svg|woff|woff2)$/, use: 'url-loader'&#125;, &#123;test: /\.js$/, use: 'babel-loader', exclude: /node_modules/&#125; ]&#125; 这里通过 babel-loader 对 js 文件进行处理，并排除了 node_modules 中的 js 文件。如果不排除 node_modules，Babel 会将其中的所有 js 文件都打包编译，这样可能照成很多无法预料的结果，这显然不是我们希望的。 到这一步还没有结束，我们还需要给 Babel 提供一个配置文件，告诉 Babel 编译 js 文件的一些配置。配置文件名称是 .babelrc，文件内容格式是 JSON。 在项目主目录下创建 .babelrc 文件，并写入如下内容： 123456789&#123; "presets": [ "env", "stage-0" ], "plugins": [ "transform-runtime" ]&#125; 可以看到配置文件的内容和之前安装的几个包是相关的，其中 plugins 里放的就是之前安装的 babel-plugin-transform-runtime。而 presets 里的东西就更厉害了，如果我们要编译不同语法的 js 代码，比如 React 的 jsx 语法，ES6 甚至 ES7/8 的语法，就需要使用 babel-presets-* 相对应的包了。这些包里包含了不同标准代码的转码规则。 接下来修改 main.js 添加一些 ES6 才支持的语法： 12345678910111213141516171819import './css/base.css'import './css/base.less'import './css/base.scss'import '../node_modules/bootstrap/dist/css/bootstrap.css'let app = document.getElementById("app")app.innerHTML = "&lt;h1&gt;Hello Vue!&lt;h1&gt;"let icon = document.createElement('i')icon.className = "glyphicon glyphicon-music"app.appendChild(icon)class Person&#123; static info = &#123;name: "xiaoming", age: 20&#125; static show()&#123; console.log(Person.info.name, Person.info.age) &#125;&#125;Person.show() 重启 webpack-dev-server，打开浏览器开发者选项，可以看到我们用 class 定义的类，并调用类里静态方法的代码执行成功了。 文件总结现在的目录树是： webapp ├── dist │ ├── bundle.js │ └── index.html ├── node_modules ... ├── src │ ├── css │ │ ├── base.css │ │ ├── base.less │ │ └── base.scss │ ├── images │ │ └── bg.png │ ├── index.html │ └── main.js ├── .babelrc ├── package.json └── webpack.config.js 文件内容： base.css:12345678910111213* &#123; margin: 0; padding: 0;&#125;html &#123; background: url(../images/bg.png); background-repeat: repeat;&#125;div &#123; text-align: center;&#125; base.less:123456@baseColor: blue;div &#123; h1 &#123; color: @baseColor; &#125;&#125; base.scss:123456$baseColor: pink;div &#123; h1 &#123; background-color: $baseColor; &#125;&#125; index.html:123456789101112&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;Document&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="app"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt; main.js:12345678910111213141516171819import './css/base.css'import './css/base.less'import './css/base.scss'import '../node_modules/bootstrap/dist/css/bootstrap.css'let app = document.getElementById("app")app.innerHTML = "&lt;h1&gt;Hello Vue!&lt;h1&gt;"let icon = document.createElement('i')icon.className = "glyphicon glyphicon-music"app.appendChild(icon)class Person&#123; static info = &#123;name: "xiaoming", age: 20&#125; static show()&#123; console.log(Person.info.name, Person.info.age) &#125;&#125;Person.show() .babelrc:123456789&#123; "presets": [ "env", "stage-0" ], "plugins": [ "transform-runtime" ]&#125; package.json:123456789101112131415161718192021222324252627282930313233343536&#123; "name": "webapp", "version": "1.0.0", "description": "", "main": "index.js", "scripts": &#123; "test": "echo \"Error: no test specified\" &amp;&amp; exit 1", "build": "webpack --mode production", "dev": "webpack-dev-server" &#125;, "keywords": [], "author": "", "license": "ISC", "devDependencies": &#123; "babel-core": "^6.26.3", "babel-loader": "^7.1.5", "babel-plugin-transform-runtime": "^6.23.0", "babel-preset-env": "^1.7.0", "babel-preset-stage-0": "^6.24.1", "css-loader": "^2.0.1", "file-loader": "^3.0.1", "html-webpack-plugin": "^3.2.0", "less": "^3.9.0", "less-loader": "^4.1.0", "node-sass": "^4.11.0", "sass-loader": "^7.1.0", "style-loader": "^0.23.1", "url-loader": "^1.1.2", "webpack": "^4.28.0", "webpack-cli": "^3.1.2", "webpack-dev-server": "^3.1.10" &#125;, "dependencies": &#123; "bootstrap": "^3.4.0" &#125;&#125; webpack.config.js:12345678910111213141516171819202122232425262728293031323334353637const path = require('path')const webpack = require("webpack")const htmlWebpackPlugin = require("html-webpack-plugin")module.exports = &#123; entry: path.join(__dirname, './src/main.js'), output: &#123; path: path.join(__dirname, "./dist"), filename: "bundle.js" &#125;, mode: "development", devServer: &#123; open: true, port: 3000, hot: true, // contentBase: "src", &#125;, plugins: [ new webpack.HotModuleReplacementPlugin(), new htmlWebpackPlugin(&#123; template: path.join(__dirname, "./src/index.html"), filename: "index.html" &#125;) ], module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;, &#123;test: /\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;, &#123; test: /\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]'] &#125;, &#123;test: /\.(ttf|eot|svg|woff|woff2)$/, use: 'url-loader'&#125;, &#123;test: /\.js$/, use: 'babel-loader', exclude: /node_modules/&#125; ] &#125;&#125; webpack 与 Vue 的结合安装 vue这一步比较简单，直接用 cnpm 安装即可。 1cnpm install vue --save 编写 Vue 代码删除 main.js 原来的内容，新的内容如下： 12345678import Vue from "vue"let vm = new Vue(&#123; el: "#app", data:&#123; msg:"Hello Vue" &#125;&#125;) 并修改 index.html： 123&lt;body&gt; &lt;div id="app"&gt;&#123;&#123;msg&#125;&#125;&lt;/div&gt;&lt;/body&gt; 启动 webpack-dev-server 后，预料的 Hello Vue 并没有出现，打开浏览器控制台，这时出现了一个异常： Vue 中的一个坑为什么和我们直接在页面中通过 script 标签引入 vue.js 的结果不同呢？先来看 Vue 的警告是什么。 [Vue warn]: You are using the runtime-only build of Vue where the template compiler is not available. Either pre-compile the templates into render functions, or use the compiler-included build. (found in &lt;Root&gt;) 大致意思说，当前使用的是 Runtime Only 版本的 Vue，其中的模板编译器不可用，所以直接在 index.html 里写的模板字符串就没办法被编译了。解决方案也给了两个，要么预先将模板编译成 render 方法，要么使用包含编译器的 Vue.js 文件。 这是因为我们通过 import Vue from &quot;vue&quot; 导入的 Vue，是个精简版的 Vue…，把模板编译的功能给阉割了，所以模板字符串就没法被正常的替换了。可以查看 node_modules\vue\package.json 文件中 &quot;main&quot;: &quot;dist/vue.runtime.common.js&quot;，Vue 默认导出的是 dist/vue.runtime.common.js 这个文件。 我们可以在 main.js 中手动导入完整版的 vue.js 文件试试： 12345678import Vue from "vue/dist/vue.js"let vm = new Vue(&#123; el: "#app", data:&#123; msg:"Hello Vue" &#125;&#125;) 问题似乎是解决了： 但这并不是官方推荐的做法，否则 vue 的包不会默认导出不带编译器的 Runtime Only 版本了。在 vue 的包目录中，完整版的 vue.js 304K 的大小，而 vue.runtime.common.js 才 210K 大小。 Vue2 中的 template 模板会先经过模板编译器编译成 render 函数，最终都通过调用 render 函数将页面呈现出来。模板的编译功能可以离线进行，也可以在浏览器上进行。在浏览器上进行编译模板需要消耗更多的内存和CPU资源，所以离线编译模板会让页面的体验更佳。 如何使用 webpack 离线编译 Vue 模板，之后会讲到，下面先来看看如何使用 render 的方式渲染模板 使用 render 渲染模板修改 main.js 的内容为如下：1234567891011121314151617import Vue from "vue/dist/vue.js"let hello = &#123; template: "&lt;h1&gt;&#123;&#123;msg&#125;&#125;&lt;/h1&gt;", data()&#123; return &#123; msg:"Hello Render" &#125; &#125;&#125;let vm = new Vue(&#123; el: "#app", render: function(createElement)&#123; return createElement(hello) &#125;&#125;) 修改 index.html 去掉模板字符串：123&lt;body&gt; &lt;div id="app"&gt;&lt;/div&gt;&lt;/body&gt; 这里我们定义了一个新的 hello 模板，render 函数会接收一个方法，用这个方法可以将指定的模板渲染成 DOM 结构的对象（虚拟DOM），render 需要返回这个对象，然后这个对象被 Patch 到真实的 DOM 中(el: &quot;#app&quot;)。 查看浏览器，页面被成功的渲染出来了： 但结果似乎有个不太一样的地方，我们用模板字符串或者使用 components 申明的子组件，都包含在 &lt;div id=&quot;app&quot;&gt;&lt;/div&gt; 容器中，而使用 render 渲染的模板，却直接将 &lt;div id=&quot;app&quot;&gt;&lt;/div&gt; 替换了！ 使用 webpack 处理 vue 文件官方推荐的做法是将 Vue 的所有模板都定义为组件，单独写入以 .vue 结尾的文件，然后使用 vue-loader 和 vue-template-compiler 将 .vue 模板文件都离线编译处理成 JavaScript 代码。这样自然就不需要使用完整版 Vue 自带的模板编译功能了。 接下来安装这两个包：1cnpm install vue-loader vue-template-compiler --save-dev 修改 webpack 配置文件，引入 vue 插件，以及增加对 .vue 文件的处理规则： 12345678910111213141516171819202122232425262728293031323334353637383940const path = require('path')const webpack = require("webpack")const htmlWebpackPlugin = require("html-webpack-plugin")const VueLoaderPlugin = require('vue-loader/lib/plugin')module.exports = &#123; entry: path.join(__dirname, './src/main.js'), output: &#123; path: path.join(__dirname, "./dist"), filename: "bundle.js" &#125;, mode: "development", devServer: &#123; open: true, port: 3000, hot: true, // contentBase: "src", &#125;, plugins: [ new webpack.HotModuleReplacementPlugin(), new VueLoaderPlugin(), new htmlWebpackPlugin(&#123; template: path.join(__dirname, "./src/index.html"), filename: "index.html" &#125;) ], module: &#123; rules: [ &#123;test: /\.css$/, use: ['style-loader', 'css-loader']&#125;, &#123;test: /\.less$/, use: ['style-loader', 'css-loader','less-loader']&#125;, &#123;test: /\.scss$/, use: ['style-loader', 'css-loader','sass-loader']&#125;, &#123; test: /\.(jpg|png|gif|bmg|jpeg)$/, use: ['url-loader?limit=8192&amp;name=[name]-[hash:8].[ext]'] &#125;, &#123;test: /\.(ttf|eot|svg|woff|woff2)$/, use: 'url-loader'&#125;, &#123;test: /\.js$/, use: 'babel-loader', exclude: /node_modules/&#125;, &#123;test: /\.vue$/, use: 'vue-loader'&#125; ] &#125;&#125; src 目录下新建 App.vue 文件，然后写入如下内容： 123456789101112131415161718&lt;template&gt; &lt;div id="app"&gt; &#123;&#123;msg&#125;&#125; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;export default &#123; data()&#123; return &#123; msg: "Hello App!" &#125; &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; main.js 中引入并渲染这个组件：123456789import Vue from "vue"import App from "./App.vue"let vm = new Vue(&#123; el: "#app", render: function(createElement)&#123; return createElement(App) &#125;,&#125;) 重启 webpack-dev-server，Hello App! 成功的在页面显示了出来。 子组件使用我们接着在 src 目录创建一个 components 目录用来保存子组件。 在 components 目录中创建 Login.vue 文件，并写入如下内容： 1234567&lt;template&gt; &lt;div&gt; &lt;h3&gt;登陆&lt;/h3&gt; 账号：&lt;input type="text"&gt;&lt;br&gt; 密码：&lt;input type="password"&gt; &lt;/div&gt;&lt;/template&gt; 在 App.vue 中引入并使用这个组件：1234567891011121314151617181920212223&lt;template&gt; &lt;div id="app"&gt; &#123;&#123;msg&#125;&#125; &lt;login&gt;&lt;/login&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import login from './components/Login.vue'export default &#123; data()&#123; return &#123; msg: "Hello App!" &#125; &#125;, components:&#123; 'login': login &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 当前浏览器页面： 路由的使用接下来使用路由来导航到其他组件，需要先安装 Vue 的路由模块： 1cnpm install vue-router --save 在 components 目录中创建 Register.vue 文件，并写入如下内容：123456789&lt;template&gt; &lt;div&gt; &lt;h3&gt;注册&lt;/h3&gt; 账号：&lt;input type="text"&gt;&lt;br&gt; 密码：&lt;input type="password"&gt;&lt;br&gt; 确认密码：&lt;input type="password"&gt;&lt;br&gt; &lt;input type="submit" value="提交"&gt; &lt;/div&gt;&lt;/template&gt; 我们在 App.vue 中通过路由访问这两个组件： 12345678910111213141516171819202122232425262728&lt;template&gt; &lt;div id="app"&gt; &#123;&#123;msg&#125;&#125; &lt;br&gt; &lt;router-link to="/login"&gt;登陆&lt;/router-link&gt; &lt;router-link to="/register"&gt;注册&lt;/router-link&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import login from './components/Login.vue'import register from './components/Register.vue'export default &#123; data()&#123; return &#123; msg: "Hello App!" &#125; &#125;, components:&#123; 'login': login, 'register': register &#125;&#125;&lt;/script&gt;&lt;style&gt;&lt;/style&gt; 然后在 src 目录下创建一个单独的 router.js 文件来存放路由配置信息： 1234567891011121314import Vue from 'vue'import VueRouter from 'vue-router'Vue.use(VueRouter)import login from './components/Login.vue'import register from './components/Register.vue'export default new VueRouter(&#123; routes:[ &#123;path:"/login", component: login&#125;, &#123;path:"/register", component: register&#125;, ]&#125;) 在 main.js 中应用这个路由： 123456789101112import Vue from "vue"import App from "./App.vue"import router from "./router.js"let vm = new Vue(&#123; el: "#app", render: function(createElement)&#123; return createElement(App) &#125;, router: router&#125;) 浏览器查看效果： vue 中使用 lessVue 的样式写在模板文件的 style 标签中，并且可以给 style 标签使用 lang 属性来表明要使用的 css 语法。给 style 标签添加 scoped 属性可以让样式只对当前组件生效。 编辑 App.vue 的代码，内容如下： 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051&lt;template&gt; &lt;div id="app"&gt; &#123;&#123;msg&#125;&#125; &lt;br&gt; &lt;router-link to="/login"&gt;登陆&lt;/router-link&gt; &lt;router-link to="/register"&gt;注册&lt;/router-link&gt; &lt;router-view&gt;&lt;/router-view&gt; &lt;/div&gt;&lt;/template&gt;&lt;script&gt;import login from './components/Login.vue'import register from './components/Register.vue'export default &#123; data()&#123; return &#123; msg: "Hello App!" &#125; &#125;, components:&#123; 'login': login, 'register': register &#125;&#125;&lt;/script&gt;&lt;style lang="less" scoped&gt; #app &#123; @line: 30px; a &#123; display: inline-block; width: 80px; height: @line; text-decoration: none; border: 1px solid skyblue; text-align: center; line-height: @line; border-radius: 5px; color: #666666; transition: all 0.3s ease; &#125; a:hover &#123; background-color: skyblue; color: white; &#125; a:active &#123; background-color:rgb(0, 255, 157); &#125; &#125;&lt;/style&gt; 之前已经配置了 less 加载器，所以可以在页面上直接看到效果了： Vue 是如何保证加上 scoped 属性的 style 标签只作用于当前的组件而不会影响其他组件呢？可以看到，Vue 自动给当前组件的所有标签都加上了 data-v-7ba5bd90 这个属性，这个属性就相当于每个组件的唯一标识。只要在样式中选择只给带有这个标识的标签应用样式，这样就做到各组件互不影响了。 编译打包 Vue 项目当项目完成后，就可以将项目编译测试部署了，下面运行 npm run build 将项目打包测试，最终我们生成了一个 111KB 的 bundle.js 文件，浏览器里打开 index.html 也测试无误。 到这里 “从零开始搭建Vue开发环境” 就完成了。 当前项目目录树： webapp ├── dist │ ├── bundle.js │ └── index.html |── node_modules ... ├── src │ ├── App.vue │ ├── components │ │ ├── Login.vue │ │ └── Register.vue │ ├── css │ │ ├── base.css │ │ ├── base.less │ │ └── base.scss │ ├── images │ │ └── bg.png │ ├── index.html │ ├── main.js │ └── router.js ├── .babelrc ├── package.json └── webpack.config.js 附录Chrome Vue 拓展使用 Chrome 的 Vue 拓展插件，可以很方便的调试 Vue 项目，安装插件需要访问 Google 商店，安装地址：点击打开 使用效果： 项目文件打包下载点击下载 解压后进入 webapp 目录，执行 npm install 或者 cnpm install 安装依赖。]]></content>
      <categories>
        <category>Vue</category>
      </categories>
      <tags>
        <tag>web</tag>
        <tag>vue</tag>
        <tag>webpack</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Cordova混合开发环境搭建]]></title>
    <url>%2F2018%2F12%2F09%2F2018%2FCordova%E6%B7%B7%E5%90%88%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[简介 Cordova提供了一组设备相关的API，通过这组API，移动应用能够以JavaScript访问原生的设备功能，如摄像头、麦克风等。Cordova还提供了一组统一的JavaScript类库，以及为这些类库所用的设备相关的原生后台代码。Cordova支持如下移动操作系统：iOS, Android,ubuntu phone os, Blackberry, Windows Phone, Palm WebOS, Bada 和 Symbian。 环境 下面是在Windows平台编译安卓apk为例。如果是其他平台，本文档也有一定参考价值 安装应用 软件 版本要求 下载 Node.js 最新LTS版即可 下载地址 jdk 1.8 以上 下载地址 Android SDK 最新版即可 下载地址 gradle 最新版即可 下载地址 ant 最新版即可 下载地址 配置环境变量 根据实际软件的安装目录配置环境变量 变量名称 值 JAVA_HOME D:\Application\Java\jdk1.8.0_101 CLASSPATH .;%JAVA_HOME%\lib\dt.jar;%JAVA_HOME%\lib\tools.jar; ANDROID_HOME D:\Application\android\sdk Path环境变量中添加如下值 验证环境变量java &gt; java -version java version &quot;1.8.0_101&quot; Java(TM) SE Runtime Environment (build 1.8.0_101-b13) Java HotSpot(TM) 64-Bit Server VM (build 25.101-b13, mixed mode) gradle &gt; gradle -v ------------------------------------------------------------ Gradle 5.0 ------------------------------------------------------------ Build time: 2018-11-26 11:48:43 UTC Revision: 7fc6e5abf2fc5fe0824aec8a0f5462664dbcd987 Kotlin DSL: 1.0.4 Kotlin: 1.3.10 Groovy: 2.5.4 Ant: Apache Ant(TM) version 1.9.13 compiled on July 10 2018 JVM: 1.8.0_101 (Oracle Corporation 25.101-b13) OS: Windows 10 10.0 amd64 ant &gt; ant -v Apache Ant(TM) version 1.10.5 compiled on July 10 2018 Trying the default build file: build.xml Buildfile: build.xml does not exist! Build failed node.js &gt; node -v v10.13.0 安装 Android SDK进入 Android SDK 的安装目录，执行 SDK Manager.exe ，安装如下模块： 安装 Cordova node.js 默认会将全局安装的模块还有下载的缓存放在C盘，可以通过更改配置文件来改变安装的位置。 注意：根据 node.js 的实际安装位置或个人喜好酌情修改 &gt; npm config set prefix &quot;D:\Application\nodejs&quot; &gt; npm config set cache &quot;D:\Application\nodejs\node_cache&quot; 接下来就可以安装 Cordova 了，使用默认的仓库安装会比较慢，可以考虑使用淘宝的镜像站来安装 12npm config set registry &quot;https://registry.npm.taobao.org&quot;npm install -g cordova &gt; cordova -v 8.1.2 (cordova-lib@8.1.1) 如果没有报错，那么 cordova 就安装完了。 开发创建应用 接下来就用 Cordova 创建第一个应用程序，并打包为 Android APK。 &gt; cordova create myapp Creating a new cordova project. 这样一个初始项目目录就构建完成了，还需要添加相应的目标平台，比如 Android 还是 IOS。 &gt; cordova platform ls Installed platforms: Available platforms: android ~7.1.1 browser ~5.0.1 ios ~4.5.4 osx ~4.0.1 windows ~6.0.0 添加某个支持的平台使用 cordova platform add 命令，删除某个平台将 add 换成 rm 即可。 &gt; cordova platform add android Using cordova-fetch for cordova-android@~7.1.1 Adding android project... Creating Cordova project for the Android platform: Path: platforms\android Package: io.cordova.hellocordova Name: HelloCordova Activity: MainActivity Android target: android-27 Android project created with cordova-android@7.1.4 Android Studio project detected Android Studio project detected Discovered plugin &quot;cordova-plugin-whitelist&quot; in config.xml. Adding it to the project Installing &quot;cordova-plugin-whitelist&quot; for android This plugin is only applicable for versions of cordova-android greater than 4.0. If you have a previous platform version, you do *not* need this plugin since the whitelist will be built in. Adding cordova-plugin-whitelist to package.json Saved plugin info for &quot;cordova-plugin-whitelist&quot; to config.xml --save flag or autosave detected Saving android@~7.1.4 into config.xml file ... 编译项目执行：cordova build android，如果编译成功，最后会出现 BUILD SUCCESSFUL 以及 apk 安装包的位置。默认是 DEBUG 模式的编译，如果是发行版可以使用 cordova build android --release 注意：第一次编译的时候，Gradle 会下载一些依赖，这些依赖会安装在用户家目录下的 .gradle 目录中，这一步我也没有什么好的办法，只能祈祷网络好一点能赶紧下载完。编译后的 apk 都是没有签名的，如果是 release 模式编译的 apk，不签名的话是无法安装的。 如果通过USB连接了安卓手机，则可以直接使用 cordova run android 命令将 apk 部署到手机上测试，手机需要打开USB调试模式，并允许通过 USB 安装 apk 包。 打开效果如下： 调试项目可以通过 Chrome 浏览器调试页面，或者直接使用 Chrome 浏览器配合真机调试 使用浏览器调试首先安装浏览器平台的支持，然后使用浏览器调试页面。 &gt; cordova platform add browser Using cordova-fetch for cordova-browser@~5.0.1 Adding browser project... Creating Cordova project for cordova-browser: Path: D:\Workspace\myapp\platforms\browser Name: HelloCordova Installing &quot;cordova-plugin-whitelist&quot; for browser --save flag or autosave detected Saving browser@~5.0.4 into config.xml file ... 然后执行 cordova run browser 会直接打开浏览器显示页面，这时候可以使用 F12 打开控制台调试了。 使用浏览器调试真机将安卓手机通过USB连接电脑，并安装好驱动（Win10貌似自带驱动），然后打开USB调试模式并允许通过USB安装应用程序。执行 cordova run android 命令，这时手机上应该已经自动安装并打开了程序。 通过 Chrome 浏览器打开页面 chrome://inspect/#devices，Devices 中已经出现了自己的手机机型以及一个 cordova 的 WebView 条目，然后点击 inspect: 可以看到就跟调试普通页面一样，鼠标在不同的标签上划过，手机app上对应的标签也会高亮显示： 附录一个获取设备信息的demo首先安装获取设备信息的 cordova 插件 &gt; cordova plugin add cordova-plugin-device Installing &quot;cordova-plugin-device&quot; for android Android Studio project detected Installing &quot;cordova-plugin-device&quot; for browser Adding cordova-plugin-device to package.json Saved plugin info for &quot;cordova-plugin-device&quot; to config.xml cordova plugin add 命令会自动给已安装的所有平台都安装上指定的插件。 删除项目目录下 www 目录中的所有文件，然后重新创建 index.html，写入以下内容： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859&lt;!DOCTYPE html&gt;&lt;html lang="en"&gt;&lt;head&gt; &lt;meta charset="UTF-8"&gt; &lt;meta name="viewport" content="width=device-width, initial-scale=1.0"&gt; &lt;meta http-equiv="X-UA-Compatible" content="ie=edge"&gt; &lt;title&gt;设备信息&lt;/title&gt; &lt;style&gt; * &#123; margin: 0; padding: 0; &#125; #content &#123; position: fixed; height: 90%; width: 100%; background-color: #c7c7c7; text-align: center &#125; #btn &#123; position: fixed; bottom: 0; width: 100%; height: 10%; border: 1px solid skyblue; background-color: #fff; font-size: 18px; &#125; #btn:active &#123; background-color: skyblue; &#125; &lt;/style&gt;&lt;/head&gt;&lt;body&gt; &lt;div id="content"&gt; &lt;/div&gt; &lt;button id="btn"&gt;获取信息&lt;/button&gt; &lt;script src="cordova.js"&gt;&lt;/script&gt; &lt;script&gt; document.addEventListener("deviceready", onDeviceReady, false); function onDeviceReady() &#123; var btn = document.getElementById("btn") var content = document.getElementById("content") btn.onclick = function()&#123; content.innerHTML = "" for (let i of ['cordova','model','platform','uuid', 'version','manufacturer','serial'])&#123; let tmp = document.createElement("p") tmp.innerText = i + ': ' + device[i] content.appendChild(tmp) &#125; &#125; &#125; &lt;/script&gt;&lt;/body&gt;&lt;/html&gt; 运行：cordova run browser 在浏览器上点击获取信息的按钮，显示如下： 运行：cordova run android 在手机上点击获取信息的按钮，显示如下：]]></content>
      <categories>
        <category>Cordova</category>
      </categories>
      <tags>
        <tag>html5</tag>
        <tag>cordova</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Pyenv Python版本管理器]]></title>
    <url>%2F2018%2F10%2F08%2F2018%2FPyenv%20Python%E7%89%88%E6%9C%AC%E7%AE%A1%E7%90%86%E5%99%A8%2F</url>
    <content type="text"><![CDATA[简介 Node.js 有一个非常好用的版本管理器叫 nvm，可以很方便的安装和管理多种 node.js 的版本，于是开始寻找 Python 是否也存在类似的工具，这样可以方便的切换 Python2 和 Python3 的环境，以及 Python 发布新版本后可以迅速的体验一番，而且还不会对当前系统环境照成影响。所幸 遇到了 pyenv 这个工具。项目主页：https://github.com/pyenv/pyenv 安装这里在 ubuntu 16.04 上安装 pyenv，其他发行版上安装方法也都大同小异。 安装 pyenvpyenv 默认会安装在 ~/.pyenv，可以通过设置环境变量 PYENV_ROOT 来改变这个目录。如果是普通用户，就最好将 pyenv 安装到自己家目录了。 安装依赖12apt-get updateapt-get install curl git 使用自动化脚本安装pyenv12export PYENV_ROOT="/usr/local/pyenv"curl -L https://github.com/pyenv/pyenv-installer/raw/master/bin/pyenv-installer | bash 修改 .bashrc 使其自动加载 pyenv 12345echo 'export PYENV_ROOT="/usr/local/pyenv"' &gt;&gt; ~/.bashrcecho 'export PATH="/usr/local/pyenv/bin:$PATH"' &gt;&gt; ~/.bashrcecho 'eval "$(pyenv init -)"' &gt;&gt; ~/.bashrcecho 'eval "$(pyenv virtualenv-init -)"' &gt;&gt; ~/.bashrcexec bash 这时可以检查 pyenv 命令是否可用了。 root@localhost:~# pyenv pyenv 1.2.7 Usage: pyenv &lt;command&gt; [&lt;args&gt;] Some useful pyenv commands are: commands List all available pyenv commands local Set or show the local application-specific Python version global Set or show the global Python version shell Set or show the shell-specific Python version install Install a Python version using python-build uninstall Uninstall a specific Python version rehash Rehash pyenv shims (run this after installing executables) version Show the current Python version and its origin versions List all Python versions available to pyenv which Display the full path to an executable whence List all Python versions that contain the given executable See `pyenv help &lt;command&gt;&apos; for information on a specific command. For full documentation, see: https://github.com/pyenv/pyenv#readme 使用查看可以安装的 Python 环境命令： pyenv install --list 这条命令会列出当前可用的所有Python环境，可以看到可选的环境官方的加上第三方的是非常多的 安装目标 Python 环境命令： pyenv install ${version} 只需要将 ${version} 写成上面列出的所有可选的 Python 环境即可，Python 的源码包会存放到 ${PYENV_ROOT} 目录下的 cache 目录下(如果没有需要手动创建)，默认从官方镜像站下载，如果速度比较慢，可以选择手动从国内镜像站下载，手动将源码包放入这个目录，然后再执行安装命令。 123456789101112# 首先安装编译Python需要的开发包和开发工具apt-get install zlib1g-dev libbz2-dev libssl-dev libncurses5-dev \libsqlite3-dev libreadline-dev tk-dev libgdbm-dev libdb-dev \libpcap-dev xz-utils libexpat-dev gcc make# 手动放置源码包的方式# mkdir $&#123;PYENV_ROOT&#125;/cache# cd $&#123;PYENV_ROOT&#125;/cache# wget https://www.python.org/ftp/python/3.6.6/Python-3.6.6.tar.xz# 执行编译安装pyenv install 3.6.6 如果需要将 Python 编译为动态共享库的方式，则需要将编译参数通过环境变量传给 pyenv 1env PYTHON_CONFIGURE_OPTS="--enable-shared" pyenv install 3.6.6 安装完成 root@localhost:~# env PYTHON_CONFIGURE_OPTS=&quot;--enable-shared&quot; pyenv install 3.6.6 Installing Python-3.6.6... Installed Python-3.6.6 to /usr/local/pyenv/versions/3.6.6 列出当前版本命令： pyenv version 查看当前版本 root@localhost:~# pyenv version system (set by /usr/local/pyenv/version) 命令： pyenv versions 查看当前可用版本 root@localhost:~# pyenv versions * system (set by /usr/local/pyenv/version) 3.6.6 切换当前 shell 会话的 Python 版本命令： pyenv shell 3.6.6 root@localhost:~# python -V Python 2.7.12 root@localhost:~# pyenv shell 3.6.6 root@localhost:~# python -V Python 3.6.6 这个命令并不会影响其他会话里的 Python 版本，而且在关闭这个 shell 会话后，设置就消失了，所以只是临时的。 指定全局的 Python 版本命令： pyenv global 3.6.6 这时全局的 Python 版本都变成了指定的 3.6.6，如果想设置回系统默认的版本可以使用 pyenv global system 设置某个目录使用的 Python 版本命令： pyenv local 3.6.6 这个目录就比较有意思了，当进入某个目录后，然后在这个目录下执行这个命令，那么以后只要切换到这个目录，那么使用的 Python 版本就是指定的这个版本了。 如果想取消这个设置，可以删除这个目录下的 .python-version 文件 卸载已安装的 Python 版本命令： pyenv uninstall 3.6.6 辛辛苦苦安装上，我就不测试执行了。 附录再配合上 Python 的虚拟环境，简直强无敌啊，更重要的是，非 root 用户也可以随意的安装配置不同的 Python 版本了。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Bottle 轻量级Web框架]]></title>
    <url>%2F2018%2F07%2F12%2F2018%2FBottle%20%E8%BD%BB%E9%87%8F%E7%BA%A7Web%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[简介 Bottle 是一个快速、简单、轻量级的 Python Web 框架，Bottle 作为一个单独的文件模块分发，而且除了标准库没有任何第三方依赖，但是麻雀虽小五脏俱全，所以非常适合第一次接触 Python Web 开发的新手入门学习使用。Bottle 支持URL映射、模板引擎、访问表单、文件上传等功能。内建 HTTP 开发服务器，而且还支持 Paste, Gevent, gunicorn 等高性能 WSGI 服务器。本文通过阅读官方文档 并结合自己的实际测试编写而成。 使用快速安装体验Bottle 的安装非常简单，可以通过 easy_install bottle 或者使用 pip install bottle 来安装，甚至可以直接下载 Bottle.py (最新版，非稳定版) 放到程序目录下来使用。Bottle 可以运行在 Python2.5+ 和 Python3.x 上。 目前 Bottle 稳定版为 0.12.13，开发版为 0.13-dev。点此打开Github地址 看一个简单的例子：123456789import bottleapp = bottle.Bottle()@app.route('/hello/&lt;name&gt;')def index(name): return bottle.template('&lt;b&gt;Hello &#123;&#123;name&#125;&#125;&lt;/b&gt;!', name=name)app.run(host="localhost", port=8080) 启动脚本： (python3) root@ubuntu:~# python demo.py Bottle v0.12.13 server starting up (using WSGIRefServer())... Listening on http://localhost:8080/ Hit Ctrl-C to quit. 使用浏览器或者 curl 测试： root@ubuntu:~# curl http://127.0.0.1:8080/hello/yunfwe &lt;b&gt;Hello yunfwe&lt;/b&gt;! 如果学过 Flask 框架，可以发现它们的语法非常相似。 教程安装Bottle 不依赖任何第三方库，所以可以直接将 bottle.py 下载到项目目录中使用，但这通常下载的是最新开发版。 $ wget https://github.com/defnull/bottle/raw/master/bottle.py 如果更喜欢稳定版，可以在 PyPi 上获取，推荐使用 pip 包管理器来安装，或者使用 easy_install 也可以。 $ sudo pip install bottle $ sudo easy_install bottle Bottle 支持 Python2.5 或者更高版本才能正常运行，如果你没有权限在系统范围内安装，可以使用 Python虚拟环境 virtualenv。 Hello World安装成功后，从最简单的 “Hello World” 示例开始吧！ 12345678910import bottleapp = bottle.Bottle()@app.route('/hello')def hello(): return 'Hello World!'if __name__ == '__main__': app.run(host='localhost', port=8080, debug=True, reloader=True) 运行此代码，访问 http://localhost:8080/hello，将在浏览器中看到 “Hello World!”，下面是它的工作原理： 使用 app.route() 装饰器装饰的函数 hello()，与 app.route() 传入的路径参数 /hello 做绑定，当浏览器请求 URL 时，如果匹配了这个路径，将调用这个路径所绑定的函数，并将函数的返回值发送回浏览器，就是这么简单。路由是这个框架最重要的概念，你可以根据需求定义任何数量的路由。 最后一行的 app.run() 会启动一个内置的开发服务器，它根据传递的参数在 localhost 上的 8080 端口启动服务，直到你通过 Ctrl-C 停止这个服务。debug=True 会以调试模式启动服务，在开发过程中是非常有用，但是在程序发布后应该是关闭的。reloader=True 也是在开发时非常有用的一个小技巧，Bottle 会自动检测当前脚本是否更新，如果有更新会自动帮你重新运行程序，这样就免去每次改了代码，需要手动停止程序再重新启动程序的过程，这个配置在生产环境也应该是关闭的。 请求路由上一章中，我们只构建了一个只有一条路由，而且非常简单的 Web 应用程序。多个 app.route() 都可以绑定到通一个回调函数上，看下面的例子： 1234@app.route('/')@app.route('/hello/&lt;name&gt;')def hello(name='yunfwe'): return bottle.template('Hello &#123;&#123;name&#125;&#125;!\n', name=name) 浏览器访问： root@ubuntu:~# curl http://127.0.0.1:8080/ Hello yunfwe! root@ubuntu:~# curl http://127.0.0.1:8080/hello/bottle Hello bottle! 这个示例告诉我们两件事：可以将多个路由绑定到同一个函数上，并且可以向URL添加通配符，并通过关键字参数访问它们。 动态路由包含通配符的路由称为动态路由，并且可以匹配满足条件的所有URL。简单的通配符由尖括号中的名称组成，例如：&lt;name&gt;。路由 /hello/&lt;name&gt; 会匹配 /hello/alice 以及 /hello/bob 等，如果遇到了下一个斜杆 / 则不会匹配，例如：/hello/mr/smith。 每个通配符都将匹配到的部分作为关键字参数传递给路由绑定的回调函数，所以回调函数应该提供参数接收它们，否则将会抛出异常。通过动态路由，可以设计出漂亮而且有意义的URL，下面是一些示例： 1234567@app.route('/wiki/&lt;pagename&gt;')def show_wiki_page(pagename): pass@app.route('/&lt;action&gt;/&lt;user&gt;')def user_api(action, user): pass 过滤器还可以使用过滤器来定义更具体的通配符，在将URL匹配到的部分传递给回调函数前通过过滤器来转换它们。 当前内置的几个过滤器： :int 仅匹配正整数，并将值转为整数后传递给回调 :float 类似于 :int，将值转为浮点数后传递给回调 :path 以非贪婪的方式匹配包含斜杠字符在内的所有字符，并且可以用于匹配多个路径段 :re[:exp] 允许使用自定义的正则表达式匹配，匹配的值不会被修改或者转换。 示例：123456789101112131415@app.route('/int/&lt;val:int&gt;')def test_int(val): return str(val) + '\n'@app.route('/float/&lt;val:float&gt;')def test_float(val): return str(val) + '\n'@app.route('/path/&lt;val:path&gt;')def test_path(val): return str(val) + '\n'@app.route('/re/&lt;val:re:[a-z]+&gt;')def test_re(val): return str(val) + '\n' 结果： root@ubuntu:~# curl http://127.0.0.1:8080/int/123 123 root@ubuntu:~# curl http://127.0.0.1:8080/float/1.1 1.1 root@ubuntu:~# curl http://127.0.0.1:8080/path/usr/local/ usr/local/ root@ubuntu:~# curl http://127.0.0.1:8080/re/abcdef abcdef HTTP请求方法HTTP协议为不同的任务定义了几种请求方法，GET 方法是 Bottle 路由的默认方法，如果需要处理其他方法，比如 POST, PUT, DELETE 等方法，需要添加一个 method 参数到 app.route() 装饰器上，或者使用 app.get(), app.post(), app.put(), app.delete() 这四个备选装饰器。 POST 方法常用于 HTML 表单提交，下面示例演示如何使用 POST 处理登陆表单。 123456789101112131415161718192021222324252627import bottleapp = bottle.Bottle()# 或者使用 @app.route('/login')@app.get('/login') def login(): return ''' &lt;form action="/login" method="post"&gt; Username: &lt;input name="username" type="text" /&gt; Password: &lt;input name="password" type="password" /&gt; &lt;input value="Login" type="submit" /&gt; &lt;/form&gt;'''# 或者使用 @app.route('/login', method='POST')@app.post('/login') def do_login(): username = bottle.request.forms.get('username') password = bottle.request.forms.get('password') if username == 'root' and password == '123456': return "&lt;p&gt;Your login information was correct.&lt;/p&gt;\n" else: return "&lt;p&gt;Login failed.&lt;/p&gt;\n"if __name__ == '__main__': app.run(host='localhost', port=8080, debug=True, reloader=True) 使用浏览器或者 curl 验证结果： root@ubuntu:~# curl http://127.0.0.1:8080/login -X GET &lt;form action=&quot;/login&quot; method=&quot;post&quot;&gt; Username: &lt;input name=&quot;username&quot; type=&quot;text&quot; /&gt; Password: &lt;input name=&quot;password&quot; type=&quot;password&quot; /&gt; &lt;input value=&quot;Login&quot; type=&quot;submit&quot; /&gt; &lt;/form&gt; root@ubuntu:~# curl http://127.0.0.1:8080/login -X POST --data &apos;username=root&amp;password=654321&apos; &lt;p&gt;Login failed.&lt;/p&gt; root@ubuntu:~# curl http://127.0.0.1:8080/login -X POST --data &apos;username=root&amp;password=123456&apos; &lt;p&gt;Your login information was correct.&lt;/p&gt; 或者还可以在一个回调函数里同时处理 GET 和 POST 请求，需要传给 method 参数一个列表，将需要的 HTTP 方法加入到列表中 例如：method=[&#39;GET&#39;, &#39;POST&#39;]，然后在回调函数中通过 bottle.request.method 来判断当前请求的方法： 123456789101112131415161718192021222324import bottleapp = bottle.Bottle()@app.route('/login', method=['GET', 'POST'])def login(): if bottle.request.method == 'GET': return ''' &lt;form action="/login" method="post"&gt; Username: &lt;input name="username" type="text" /&gt; Password: &lt;input name="password" type="password" /&gt; &lt;input value="Login" type="submit" /&gt; &lt;/form&gt;''' if bottle.request.method == 'POST': username = bottle.request.forms.get('username') password = bottle.request.forms.get('password') if username == 'root' and password == '123456': return "&lt;p&gt;Your login information was correct.&lt;/p&gt;\n" else: return "&lt;p&gt;Login failed.&lt;/p&gt;\n"if __name__ == '__main__': app.run(host='localhost', port=8080, debug=True, reloader=True) 特殊方法：HEAD 和 ANY HEAD 方法和 GET 方法类似，但是 HEAD 方法并不返回消息体，只返回 HTTP 协议头部信息。HEAD 方法常用来测试链接的有效性。当对 Bottle 的 GET 路由使用 HEAD 方法访问时，Bottle 会正常按照 GET 请求处理，但是并不会返回消息体（回调函数的返回结果）。 ANY 方法会匹配所有请求方法，但也只会在没有定义其他更具体的路由时。这对于将请求重定向到更具体的子应用程序的代理路由很有用。 显式路由配置如果不想使用装饰器的方式来定义路由，可以显式的将某个函数传递给某个路由，下面看一个简单的例子： 12345678import bottleapp = bottle.Bottle()def hello(): return 'Hello World!'app.route('/', 'GET', hello) 或者使用一个工厂函数： 123456789101112131415import bottledef hello(): return 'Hello World!'def setup_routing(app, urls): for u in urls: app.route(*u)urls = [ ('/', 'GET', hello),]app = bottle.Bottle()setup_routing(app, urls) 错误页面如果出现任何问题，Bottle 会显示一个包含错误信息但非常简单的错误页面，可以通过 app.error() 装饰器来覆盖特定 HTTP 状态码的默认页面： 123@app.error(404)def error404(error): return 'Nothing here, Sorry!\nError Message: %s\n' % str(error) 当访问一个未定义的页面时： root@ubuntu:~# curl http://127.0.0.1:8080/abc Nothing here, Sorry! Error Message: (404, &quot;Not found: &apos;/abc&apos;&quot;) 还可以捕捉 abort() 主动抛出的错误： 1234567@app.route('/abort')def test_abort(): bottle.abort(500, ' Server error')@app.error(500)def error500(error): return 'Error Message: %s\n' % str(error) root@ubuntu:~# curl http://127.0.0.1:8080/abort Error Message: (500, &apos; Server error&apos;) 生成响应在存 WSGI 中，一个标准的 WSGI 应用必须返回可迭代的字符串。而 Bottle 更灵活，支持多种类型，并且会自动添加一个合适的 Content-Type 头部。下面是路由绑定的回调函数允许返回的类型列表： dict：返回字典类型的数据会自动转换为 JSON 字符串，并设置 Content-Type 类型为 application/json。 空字符串，False，None或其他非真值：会产生一个空输出，并将 Content-Length 设置为 0。 Unicode：会使用 Content-Type 中指定的编码（默认UTF-8）自动编码，然后将其视为普通字符串。 Byte：字节类型，Bottle 将整个字节串作为一个整体返回，并且根据长度设置 Content-Length。 HTTPError或HTTPResponse：返回一个 HTTPError 或 HTTPResponse 的实例，如果是 HTTPError，则会运行错误处理程序 文件对象：具有 .read() 方法的所有内容都被视为文件对象，并传递给定义在 WSGI 服务框架中的 wsgi.file_wrapper 可调用对象。一些 WSGI 服务器可以利用更优的系统调用(sendfile) 来高效的传输文件。Content-Length 或 Content-Type 都不会自动设置。 迭代器和生成器：只要是可以产生或迭代 Unicode, Byte, HTTPError, HTTPResponse 类型，就可以在回调函数中使用。 下面看一些示例： 12345678910111213141516171819202122232425262728@app.route('/dict')def test_dict(): return &#123;'msg':'hello bottle'&#125;@app.route('/false')def test_false(): return False@app.route('/unicode')def test_unicode(): return u'喵喵喵'@app.route('/byte')def test_byte(): return b'abcabc'@app.route('/response')def test_response(): return bottle.HTTPResponse(body='hello bottle', status=200)@app.route('/file')def test_file(): return open('/etc/issue','rb')@app.route('/generators')def test_generators(): for i in range(10): yield str(i) 结果： root@ubuntu:~# curl http://127.0.0.1:8080/dict {&quot;msg&quot;: &quot;hello bottle&quot;} root@ubuntu:~# curl http://127.0.0.1:8080/false root@ubuntu:~# curl http://127.0.0.1:8080/unicode 喵喵喵 root@ubuntu:~# curl http://127.0.0.1:8080/byte abcabc abcabcroot@ubuntu:~# curl http://127.0.0.1:8080/response hello bottle root@ubuntu:~# curl http://127.0.0.1:8080/file Ubuntu 16.04.5 LTS \n \l root@ubuntu:~# curl http://127.0.0.1:8080/generators 0123456789 更改默认编码Bottle 使用 Content-Type 标头的字符集参数来决定如何对 Unicode 字符串进行编码。此标头默认为 text/html;charset=UTF8，并且可以使用 bottle.response.content_type 来进行修改。例如： 1234@app.route('/gbk')def get_latin(): bottle.response.content_type = 'text/html; charset=gbk' return u'这些文字将使用gbk编码' 处理静态文件Bottle 没有像 Flask 一样默认提供了静态文件路由，必须手动添加路由和回调来控制要提供的文件。虽然你可以直接返回一个文件对象，Bottle 提供的 static_file() 以一种安全和方便的方式提供文件访问，默认会自动检测文件拓展类型，并提供合适的 mimetype。浏览器对于文本文件，图像文件等可能会直接浏览而不是下载，这时可以使用 download=True 来使浏览器强制下载文件。如果想指定客户端拿到的文件名，可以使用 download=filename，客户端将自动将文件保存为传给 download 的文件名。 123@app.route('/static/filepath:path')def server_static(filepath): return bottle.static_file(filepath, root='/your/static/files/path') 指定静态文件的根目录时一定要小心，如果使用了相对路径，很有可能并不是你想象得那样。可以试试使用 os.path.dirname(os.path.abspath(__file__)) 巧妙的获取脚本所在目录。 HTTP错误和重定向调用 bottle.abort() 函数是生成 HTTP 错误页面的快捷方法。 123@app.route('/restricted')def restricted(): bottle.abort(401, "Sorry, access denied.") 如果将客户端重定向到其他URL，可以使用 bottle.redirect()，它会发送 303 See Other，并且添加 Location 头部来告诉客户端新的地址在哪。你还可以提供不同的 HTTP 状态码作为重定向函数的第二个参数。 1234567@app.route('/old')def old(): bottle.redirect("/new")@app.route('/new')def new(): return 'New page.' root@ubuntu:~# curl http://127.0.0.1:8080/old -L New page. response 对象响应的元数据，比如 HTTP 状态码、响应标头 还有 Cookie 存储在 bottle.response 对象中。你可以直接或使用预定义的方法操作这些元数据，直到它们被传输到浏览器。这里介绍最常见的用例和功能。 状态码HTTP 状态码控制浏览器的行为，默认值为 200 OK。可以通过设置 bottle.response.status 来更改状态吗，在大多数情况下不需要手动设置，但使用 abort() 或者返回 HTTPResponse 实例时需要提供状态码。 响应头 修改响应头，比如添加 Cache-Control 或者修改 Content-Type 可以通过 bottle.response.set_header() 和 bottle.response.add_header() 来修改。它们接受两个参数，一个标头名，一个值。这两个方法的区别是，set_header() 会覆盖已有的标头名，而 add_header() 则会继续添加一个即使已存在的标头。 CookieCookie 是一种用户客户端跟踪技术，Bottle 中可以通过 bottle.request.get_cookie() 和 bottle.response.set_cookie() 获取和设置 Cookie。 1234567@app.route('/cookie')def test_cookie(): if bottle.request.get_cookie("visited"): return "Welcome back! Nice to see you again\n" else: bottle.response.set_cookie("visited", "yes") return "Hello there! Nice to meet you\n" 使用 curl 测试访问，第一次将 Cookie 保存到文件，第二次带上 Cookie 去访问： root@ubuntu:~# curl http://127.0.0.1:8080/cookie -c cookie.txt Hello there! Nice to meet you root@ubuntu:~# curl http://127.0.0.1:8080/cookie -b cookie.txt Welcome back! Nice to see you again set_cookie() 方法接受许多其他关键字参数来控制 Cookie 的生存期和行为，这里介绍一些常用的设置： max_age：表示 Cookie 创建后多久过期，单位为秒。如果为 0，表示立即过期，为 -1 表示关闭窗口后 Cookie 就过期。 expires：指定一个 Cookie 的过期时间点，值是 UNIX 时间戳，现在已被 max_age 取代。 domain：允许读取 Cookie 的域，可以使多个web服务器共享 Cookie。 path：指定与 Cookie 关联在一起的网页。默认情况下 Cookie 会与创建它的页面，以及该页面下的子页面关联。 secure：限制 Cookie 使用 HTTPS 连接，默认不限制。 httponly：限制客户端 JavaScript 读取 Cookie。 如果没有设置 Cookie 有效期，则默认在页面会话结束后立即过期，在使用 Cookie 时应该考虑下面这些问题： 在大多数浏览器中，Cookie 的大小限制为 4K 的文本 有些用户将浏览器设置为不接受 Cookie。 Cookie 存储在客户端，不以任何方式加密，攻击者可能通过 XSS 漏洞窃取用户的 Cookie。 Cookie 很容易伪造，不要过于相信 Cookie。 Cookie 签名 如上所述，恶意客户很容易伪造 Cookie，Bottle 可以对 Cookie 进行签名加密，以防止这种伪造。你只需在 set_cookie() 和 get_cookie() 时通过 secret 参数提供密钥签名。如果 cookie 未签名，或者签名不匹配，get_cookie() 将返回 None： 1234567@app.route('/cookie')def test_cookie(): if bottle.request.get_cookie("visited", secret='qweasd'): return "Welcome back! Nice to see you again\n" else: bottle.response.set_cookie("visited", "yes", secret='qweasd') return "Hello there! Nice to meet you\n" 接下来用 curl 验证结果 root@ubuntu:~# cat cookie.txt # Netscape HTTP Cookie File # http://curl.haxx.se/docs/http-cookies.html # This file was generated by libcurl! Edit at your own risk. 127.0.0.1 FALSE / FALSE 0 visited yes root@ubuntu:~# curl http://127.0.0.1:8080/cookie -b cookie.txt Hello there! Nice to meet you root@ubuntu:~# curl http://127.0.0.1:8080/cookie -c cookie.txt Hello there! Nice to meet you root@ubuntu:~# curl http://127.0.0.1:8080/cookie -b cookie.txt Welcome back! Nice to see you again root@ubuntu:~# cat cookie.txt # Netscape HTTP Cookie File # http://curl.haxx.se/docs/http-cookies.html # This file was generated by libcurl! Edit at your own risk. 127.0.0.1 FALSE / FALSE 0 visited &quot;!7Bk4nXY6kRKp8QWKVN4ZWQ==?gASVEwAAAAAAAACMB3Zpc2l0ZWSUjAN5ZXOUhpQu&quot; 可以看到，之前的 cookie.txt 文件里，visited 字段的值是明文的，带着旧的 Cookie 访问服务，服务已经不承认旧的 Cookie 了。之后重新保存新的 Cookie，才可以继续使用。而新的 cookie.txt 文件里，visited 字段的值已经是加密后的。 Cookie 将所有信息都保存到了客户端，这样是极不安全的，对应的有比较安全的 Session 技术，将用户信息保存在服务端，通过在 Cookie 中保存一个 SessionID，然后使用 SessionID 来获取用户信息。可惜 Bottle 并没有实现 Session，想在 Bottle 中使用 Session 技术，还需要利用第三方实现。 请求数据Cookie, HTTP 标头, HTML &lt;form&gt; 字段和其他请求数据可以通过全局的 request 对象获取。即使在多线程多客户端连接的环境，这个特殊的对象也始终引用当前请求。 该对象是 BaseRequest 的子类，它有丰富的访问数据的 API，我们这里介绍最常用的。 FormsDictBottle 使用一种特殊类型的字典来存储表单数据和 Cookie。FormsDict 的行为就像一个普通字典，但是有一些额外的功能，使你使用的更方便。 属性访问：字典中的所有值都可以作为属性访问，这些虚拟属性返回 Unicode 字符串，即使该值丢失或者 Unicode 解码失败。这种情况下，字符串为空，但仍存在： 123456name = bottle.request.cookies.namename = bottle.request.cookies.getunicode('name') # encoding='utf-8' (default)try: name = bottle.request.cookies.get('name', '').decode('utf-8')except UnicodeError: name = u'' 每个键多个值：FormsDict 是 MultiDict 的子类，可以为每个键存储多个值。标准字典访问方法只能返回单个值，但 getall() 方法返回指定键的所有值的列表。 12for choice in request.forms.getall('multiple_choice'): do_something(choice) WTForms支持：一些库（例如WTForms）希望将 Unicode 字典作为输入，FormsDict.decode() 会自动解码所有值并返回自身的副本，同时保留每个键的所有值和功能。 Cookie前面已经讲到使用 set_cookie() 和 get_cookie() 来设置和获取 Cookie，客户端发送的所有 Cookie 还可以通过 FormsDict 获取，下面看一个简单的例子： 123456@app.route('/count')def counter(): count = int(bottle.request.cookies.get('counter','0')) count += 1 bottle.response.set_cookie('counter', str(count)) return 'Count: %d\n' % count 使用 curl 或者浏览器不停的刷新页面，可以看到计数器一直在增加： root@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt Count: 1 root@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt Count: 2 root@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt Count: 3 root@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt Count: 4 root@ubuntu:~# curl http://127.0.0.1:8080/count -b cookie.txt -c cookie.txt Count: 5 HTTP 标头客户端发送的所有 HTTP 标头都存储在 WSGIHeaderDict 中，可以通过 BaseRequest.headers 属性访问。WSGIHeaderDict 的键基本上都是不区分大小写的。 123@app.route('/headers')def headers(): return bottle.request.headers.get('User-Agent') + '\n' 打印出客户端标识： root@ubuntu:~# curl http://127.0.0.1:8080/headers curl/7.47.0 HTML 表单处理在 HTML 中，典型的 &lt;form&gt; 看起来像这样： 12345&lt;form action="/login" method="post"&gt; Username: &lt;input name="username" type="text" /&gt; Password: &lt;input name="password" type="password" /&gt; &lt;input value="Login" type="submit" /&gt;&lt;/form&gt; action 属性指定将接收表单数据的 URL，method 定义要使用的 HTTP 方法。用 method=&quot;get&quot; 返回的表单，可以使用 BaseRequest.query 来接收，但 GET 请求并不是安全的，所以在返回用户名和密码用 POST 方法。通过 POST 返回的表单存储在 BaseRequest.forms。服务端代码可能如下所示： 12345678@app.post('/login') def do_login(): username = bottle.request.forms.get('username') password = bottle.request.forms.get('password') if username == 'root' and password == '123456': return "&lt;p&gt;Your login information was correct.&lt;/p&gt;\n" else: return "&lt;p&gt;Login failed.&lt;/p&gt;\n" 还有其他几个属性可以用于访问表单数据，下面给出一个整体概述： 属性 GET 表单字段 POST 表单字段 文件上传 BaseRequest.query yes no no BaseRequest.forms no yes no BaseRequest.files no no yes BaseRequest.params yes yes no BaseRequest.GET yes no no BaseRequest.POST no yes yes 文件上传为了支持文件上传，我们需要修改 &lt;form&gt; 标签。首先需要添加标签 enctype=&quot;multipart/form-data&quot; 来告诉浏览器如何编码，然后添加 &lt;input type=&quot;file&quot; /&gt; 来让用户选择文件： 1234&lt;form action="/upload" method="post" enctype="multipart/form-data"&gt; Select a file: &lt;input type="file" name="upload" /&gt; &lt;input type="submit" value="Start upload" /&gt;&lt;/form&gt; Bottle 使用 BaseRequest.files 存储上传的文件以及一些有关上传的元数据，它是 FileUpload 的实例。下面是个服务端保存上传的文件的示例： 1234567@app.route('/upload', method='POST')def do_upload(): upload = bottle.request.files.get('upload') filename = upload.filename upload_root = "/tmp" upload.save(upload_root) return filename + '\n' 使用 curl 测试上传文件 root@ubuntu:~# curl http://127.0.0.1:8080/upload -F &quot;upload=@/etc/issue&quot; issue root@ubuntu:~# cat /tmp/issue Ubuntu 16.04.5 LTS \n \l FileUpload.filename 会对文件名清理和规范化，以防止文件名中出现不支持的字符或路径导致错误。如果想访问未经修改的文件名，可以通过访问 FileUpload.raw_filename。 FileUpload.save 将文件安全高效的存储到硬盘，如果想手动操作文件数据流，可以访问 FileUpload.file： 1234@app.route('/upload', method='POST')def do_upload(): upload = bottle.request.files.get('upload') return upload.file.read() root@ubuntu:~# curl http://127.0.0.1:8080/upload -F &quot;upload=@/etc/issue&quot; Ubuntu 16.04.5 LTS \n \l 这里使用了最危险的读取文件的方法，如果文件非常大，可能系统内存会耗尽，所以最好不要这样做。 JSON 内容如果客户端将 Content-Type: application/json 的内容发送到服务器，BaseRequest.json 属性会包含已解析的数据（数据结构正常的情况下）。 123@app.route('/json', method='POST')def test_json(): return bottle.request.json root@ubuntu:~# curl http://127.0.0.1:8080/json -X POST -H &apos;content-type: application/json&apos; -d &apos;{&quot;msg&quot;:&quot;hello world&quot;}&apos; {&quot;msg&quot;: &quot;hello world&quot;} 原始请求体你可以通过原始数据作为类文件对象访问 BaseRequest.body。这是 BytesIO 缓冲区或临时文件，具体取决于内容长度和 BaseRequest.MEMFILE_MAX 的设置（默认1M大小）。可以通过 bottle.request[&#39;wsgi.input&#39;] 来访问它。 上传的内容非常大的情况下（比如上传一个巨大的JSON内容），可以在程序开始提供给 bottle.BaseRequest.MEMFILE_MAX 一个合适的值。否则将抛出 413 Request Entity Too Large。 WSGI 环境每个 BaseRequest 实例都包含一个 WSGI 环境字典，如果想直接访问它，可以通过 BaseRequest.environ 来直接访问： 123@app.route('/getip')def getip(): return bottle.request.environ.get('REMOTE_ADDR') root@ubuntu:~# curl http://127.0.0.1:8080/getip 127.0.0.1 模板引擎Bottle 附带了一个快速而强大的内置模板引擎，名为 Simple Template Engine，要渲染模板，可以使用 template() 函数或者 view() 装饰器。需要做的就是将模板名称和关键字参数传递给模板： 1234@app.route('/hello')@app.route('/hello/&lt;name&gt;')def test_template(name='World'): return bottle.template('hello', name=name) 这里传递的模板名为 hello，Bottle 会在脚本所在目录和所在目录中的 views 目录下寻找模板文件，可以通过将路径添加到 bottle.TEMPLATE_PATH列表中来增加 Bottle 的搜索路径。模板文件的拓展名为 tpl，接着在脚本目录下创建 views 目录，然后在这个目录下新建 hello.tpl 文件，写入如下内容： 1234567%if name == &apos;World&apos;: &lt;h1&gt;Hello &#123;&#123;name&#125;&#125;!&lt;/h1&gt; &lt;p&gt;This is a test.&lt;/p&gt;%else: &lt;h1&gt;Hello &#123;&#123;name.title()&#125;&#125;!&lt;/h1&gt; &lt;p&gt;How are you?&lt;/p&gt;%end 测试访问，可以看到模板中根据 name 的值进行了逻辑处理 root@ubuntu:~# curl http://127.0.0.1:8080/hello &lt;h1&gt;Hello World!&lt;/h1&gt; &lt;p&gt;This is a test.&lt;/p&gt; root@ubuntu:~# curl http://127.0.0.1:8080/hello/abc &lt;h1&gt;Hello Abc!&lt;/h1&gt; &lt;p&gt;How are you?&lt;/p&gt; 也可以直接将模板字符串传递给 template() 函数，但是并不推荐这样做 例如： 1234567891011@app.route('/hello')@app.route('/hello/&lt;name&gt;')def test_template(name='World'): hello = """%if name == 'World': &lt;h1&gt;Hello &#123;&#123;name&#125;&#125;!&lt;/h1&gt; &lt;p&gt;This is a test.&lt;/p&gt;%else: &lt;h1&gt;Hello &#123;&#123;name.title()&#125;&#125;!&lt;/h1&gt; &lt;p&gt;How are you?&lt;/p&gt;%end""" return bottle.template(hello, name=name) 模板使用 % 开始编写 Python 的代码，使用 %end 结束代码块，更详细的语法规则 下面会讲到。模板在编译后，将缓存在内存中，在清楚缓存之前，对模板的任何改动都不会立即生效，可以通过调用 bottle.TEMPLATES.clear() 来清理缓存，如果在调试模式下将禁用缓存。 插件Bottle 的核心功能涵盖了最常见的用例，但作为一个微框架，它有其局限性，插件为框架添加缺少的功能，这就是插件发挥作用的地方。 体验插件这里看看 SQLitePlugin 插件的简单用法，首先通过pip安装这个插件：pip install bottle-sqlite，然后看下面示例： 12345678910111213141516171819202122232425262728293031import bottlefrom bottle_sqlite import SQLitePluginapp = bottle.Bottle()sqlite_plugin = SQLitePlugin(dbfile='/tmp/test.db')app.install(sqlite_plugin)@app.route('/createdb')def create(db): db.execute('create table data (key varchar, value varchar)') db.commit() return 'True\n'@app.route('/set')def db_set(db): key = bottle.request.params.get('k') value = bottle.request.params.get('v') db.execute('insert into data values (?,?)', (key, value)) db.commit() return 'True\n'@app.route('/get')def db_get(db): key = bottle.request.params.get('k') c = db.execute('select value from data where key=?', (key,)) row = c.fetchone() print(row) return row[0] + '\n'if __name__ == '__main__': app.run(host='localhost', port=8080, debug=True, reloader=True) 对接口进行测试： root@ubuntu:~# curl http://127.0.0.1:8080/createdb True root@ubuntu:~# curl &quot;http://127.0.0.1:8080/set?k=a&amp;v=qwe&quot; True root@ubuntu:~# curl &quot;http://127.0.0.1:8080/get?k=a&quot; qwe 对 app 对象安装 SQLitePlugin 插件，接着在需要使用数据库的地方，给回调函数添加 db 关键字即可，关键字的位置无所谓。插件检测到添加了 db 的关键字后，会将一个打开的 sqlite3.Connection 对象传递给 db 关键字，这样就可以在回掉函数中操作数据库了。 卸载插件卸载插件非常简单，调用 app.uninstall() 函数即可： 1234app.uninstall(sqlite_plugin) # 卸载指定的插件app.uninstall(SQLitePlugin) # 卸载这个类型的所有插件app.uninstall('sqlite') # 卸载以这个名称开头的所有插件app.uninstall(True) # 一次性卸载所有插件 将插件安装到指定的路由有时候并不想全局安装某个插件，可以单独将这个插件安装到某个路由上： 1234sqlite_plugin = SQLitePlugin(dbfile='/tmp/test.db')@app.route('/create', apply=[sqlite_plugin])def create(db): pass 将需要应用到这个路由的插件添加到 apply 参数的列表中就可以了。 黑名单插件有时候不想让某个函数应用某个插件，可以使用 skip 来跳过这些插件： 12345sqlite_plugin = SQLitePlugin(dbfile='/tmp/test.db')app.install(sqlite_plugin)@app.route('/create', skip=[sqlite_plugin])def create(): pass 如果设置 skip=True 将跳过所有插件。 插件与子程序将一个 Bottle 程序挂挂载到另一个 Bottle 程序上，相当于在主程序上创建一个代理路由，访问该代理路由的请求都转发到相应的子程序。此类代理路由是禁用插件的，安装在主程序上的插件并不会影响到子程序 例如： 123456789101112131415161718192021import bottlefrom bottle_sqlite import SQLitePluginapp = bottle.Bottle()blog = bottle.Bottle()sqlite_plugin = SQLitePlugin(dbfile='/tmp/test.db')app.install(sqlite_plugin)@blog.route('/db')def blog_db(db='Not sqlite db\n'): return str(db)@app.route('/db')def app_db(db='Not sqlite db\n'): return str(db)app.mount('/blog', blog)if __name__ == '__main__': app.run(host='localhost', port=8080, debug=True, reloader=True) 访问这几个路由： root@ubuntu:~# curl http://127.0.0.1:8080/db &lt;sqlite3.Connection object at 0x7fad044429d0&gt; root@ubuntu:~# curl http://127.0.0.1:8080/blog/db Not sqlite db 使用 app.mount() 函数将 blog 的所有路由挂载到 app 的 /blog 路由下。 实际开发现在已经可以使用Bottle开发简单的应用了，下面这些知识可以帮助你提高工作效率。 默认应用Bottle 维护一个全局堆栈的 Bottle 实例，并使用堆栈顶部作为某些模块级函数和装饰器的默认值，例如 bottle.route() 装饰器，是调用默认应用程序的快捷方式： 12345from bottle import route@route('/')def hello(): return 'hello world' 对于小型应用程序会非常方便，但是只要导入模块，就会将路由安装到全局应用程序中。为了避免这种导入，Bottle 提供了更明确的方法： 123456from bottle import Bottleapp = Bottle()@app.route('/')def hello(): return 'hello world' 分离应用程序对象可以大大提高可重用性，其他开发人员也可以安全的从你的模块中导入对象并使用 Bottle.mount() 将应用程序合并在一起。另外还可以使用应用程序堆栈来隔离路由： 12345678from bottle import route, default_appdefault_app.push()@route('/')def hello(): return 'Hello World'app = default_app.pop() 调试模式在开发早期，调试模式非常有用，可以在有错误发生时显示更详细的错误信息，并且模板不会缓存，插件也会立即应用。 可以通过调用 bottle.debug(True) 或者在 app.run() 中设置 debug 参数为 True。 自动加载运行在开发过程中，修改了代码必须手动重启服务才可以测试更改，自动重新加载器可以帮你完成这些工作： 123import bottleapp = bottle.Bottle()app.run(reloader=True) 命令行界面从版本 0.10 开始，就可以使用 Bottle 作为命令行工具： root@ubuntu:~# python -m bottle Usage: bottle.py [options] package.module:app Options: -h, --help show this help message and exit --version show version number. -b ADDRESS, --bind=ADDRESS bind socket to ADDRESS. -s SERVER, --server=SERVER use SERVER as backend. -p PLUGIN, --plugin=PLUGIN install additional plugin/s. --debug start server in debug mode. --reload auto-reload on file changes. Error: No application specified. 只用指定应用模块启动即可： 1234567import bottleapp = bottle.Bottle()@app.route('/')def hello(): return 'Hello World' 将代码保存为 hello.py，然后通过命令行启动：python -m bottle --debug --reload hello:app，hello 是模块名，app 是应用对象。 配置Bottle 应用程序的配置存储在 Bottle.config 这个类似于字典的对象里，可以用与通过配置告诉插件需要做什么，也可以存储自己的配置。 基础配置Bottle.config 的行为看起来很想普通字典，所有常见的字典方法都能按照预期工作，让我们看看一些例子： 1234567891011121314151617181920212223242526import bottleapp = bottle.Bottle()app.config['autojson'] = False # 关闭JSON自动转换的特性app.config['sqlite.db'] = ':memory:' # 告诉SQLite插件使用哪个数据库app.config['myapp.param'] = 'value' # 自定义配置值# 一次性配置多个值app.config.update(&#123; 'autojson': False, 'sqlite.db': ':memory:', 'myapp.param': 'value'&#125;)# 添加默认值app.config.setdefault('myapp.param2', 'some default')# 获取值param = app.config['myapp.param']param2 = app.config.get('myapp.param2', 'fallback value')# 在路由中从配置获取数据的例子@app.route('/about', view='about.rst')def about(): email = app.config.get('my.email', 'nomail@example.com') return &#123;'email': email&#125; app 对象并不是总是可用的，但是你可以在请求上下文中，使用 request 对象获取当前应用程序对象和它的配置 123from bottle import requestdef is_admin(user): return user == request.app.config['myapp.admin_user'] 命名约定为了更好的开发，插件和应用程序应遵守一些简单的命名规则： 所有的键名都应该是小写字符串，不能有特殊字符，但下划线除外。 命名空间由 “.” 分隔，比如 namespace.field。 Bottle 使用根命名空间进行自己的配置，插件应将所有变量存储在自己的命名空间中，例如 sqlite.db。 自定义的配置也应该有单独的命名空间，比如 myapp.* 从文件加载配置如果想使非程序员也能够配置程序，或想给程序带来高的可配置性，那么配置文件很有用。这里提供了配置文件的一种非常常见的语法： 123456789[bottle]debug = True[sqlite]db = /tmp/test.dbcommit = auto[myapp]admin_user = defnull 现在可以通过 load_config() 方法加载这些配置文件： 1app.config.load_config('/etc/myapp.conf') 从嵌套的字典加载配置另一个常用的方法使 load_dict()。这个方法将嵌套的字典转换为具有命名空间键和值的平面字典。 123456789101112131415# 从字典中加载配置app.config.load_dict(&#123; 'autojson': False, 'sqlite': &#123; 'db': ':memory:' &#125;, 'myapp': &#123; 'param': 'value', 'param2': 'value2' &#125;&#125;)assert app.config['myapp.param'] == 'value'# 从json文件中加载配置with open('/etc/myapp.json') as fp: app.config.load_dict(json.load(fp)) 监听配置更改每次更改 Bottle 中的值时，都将触发应用程序对象上的 config 钩子。此钩子可用于在运行时对配置更改做出反应，例如重新连接到新数据库、更改后端服务上的调试设置 或者调整工作线程池的大小。钩子的回调函数接收两个参数(键, 新值)，并在字典中实际值更改之前调用，如果回调函数引发异常将取消更改，并保留原值。 1234@app.hook('config')def on_config_change(key, value): if key == 'debug': switch_own_debug_mode_to(value) 钩子的回调函数不能改变要存储到字典中的值，只能有过滤器的用处。 过滤器和其他元数据ConfigDict 允许你存储元数据和配置键，目前定义了两个源字段： help: 帮助或说明字符串，可由调试、内省或管理工具去帮助站点管理员配置应用程序。 filter: 接收和返回单个值的可调用对象，如果你为键定义了过滤器，那么存储到该键的所有值都先通过过滤器。过滤器可以对值进行检查和修改，或者抛出异常。下面看个例子： 1234567891011121314151617class SomePlugin(object): def setup(app): app.config.meta_set('some.int', 'filter', int) app.config.meta_set('some.list', 'filter', lambda val: str(val).split(';')) app.config.meta_set('some.list', 'help', 'A semicolon separated list.') def apply(self, callback, route): ...import bottleapp = bottle.default_app()app.install(SomePlugin())app.config['some.list'] = 'a;b;c' # 自动转为列表app.config['some.int'] = 'not an int' # 抛出异常 简单模板引擎Bottle 附带一个快速、功能强大且易学的内置模板引擎，简称 SimpleTemplate。 view() 和 template() 函数帮助用户使用这个引擎。这里解释模板语法，并提供几个常用的示例。 基本 API 使用 1234from bottle import SimpleTemplatetpl = SimpleTemplate('Hello &#123;&#123;name&#125;&#125;!')tpl.render(name='World')# 结果：u'Hello World!' 使用 template() 函数可以简化这个过程 12from bottle import templatetemplate('Hello &#123;&#123;name&#125;&#125;!', name='World') SimpleTemplate 语法Python 是一种非常强大的语言，但它严格的缩进使它很难用于模板语言。SimpleTemplate 取消了这些限制，允许你编写干净，可读和可维护的模板，同时保留 Python 语言的功能。 内联表达式上面已经学习了两个大括号这样的语法，实际上可以在大括号中使用任何 Python 表达式： &gt;&gt;&gt; template(&apos;Hello {{name}}!&apos;, name=&apos;World&apos;) &apos;Hello World!&apos; &gt;&gt;&gt; template(&apos;Hello {{name.title() if name else "stranger"}}!&apos;, name=None) &apos;Hello stranger!&apos; &gt;&gt;&gt; template(&apos;Hello {{name.title() if name else "stranger"}}!&apos;, name=&apos;mArC&apos;) &apos;Hello Marc!&apos; 如果传入的字符串包含 HTML 字符，则会自动转义来防止 XSS 攻击，但是你可以使用 ! 来表示禁止转义： &gt;&gt;&gt; template(&apos;Hello {{name}}&apos;, name=&apos;&lt;b&gt;World&lt;/b&gt;&apos;) &apos;Hello &amp;lt;b&amp;gt;World&amp;lt;/b&amp;gt;&apos; &gt;&gt;&gt; template(&apos;Hello {{!name}}&apos;, name=&apos;&lt;b&gt;World&lt;/b&gt;&apos;) &apos;Hello &lt;b&gt;World&lt;/b&gt;&apos; 嵌入 Python 代码模板引擎允许你在模板中嵌入 Python 代码行或块。代码行以 % 开头，代码快由 &lt;% 和 %&gt; 包围： 1234567% name = "Bob" # 行级别的 Python 代码&lt;p&gt;Some plain text in between&lt;/p&gt;&lt;% # 块级别的 Python 代码 name = name.title().strip()%&gt;&lt;p&gt;More plain text&lt;/p&gt; 嵌入的 Python 代码遵循常规 Python 语法，但有两个额外的语法规则： 缩进被忽略，你可以根据需要在语句前尽可能多的放置空格，这样可以与周围的代码对其，提高可读性。 缩进的块现在必须用 %end 显式关闭，比如： 12345&lt;ul&gt; % for item in basket: &lt;li&gt;&#123;&#123;item&#125;&#125;&lt;/li&gt; % end&lt;/ul&gt; 空白符控制代码块和代码行在模板中总是跨行的，在模板被渲染后，代码段会被删除，但是模板中并不会出现悬空的空白行，例如： 12345&lt;div&gt; % if True: &lt;span&gt;content&lt;/span&gt; % end&lt;/div&gt; 被渲染后成为： 123&lt;div&gt; &lt;span&gt;content&lt;/span&gt;&lt;/div&gt; 如果想跳过代码段前面的换行符，可以使用双反斜杠结束文本： 12345&lt;div&gt;\\ %if True:&lt;span&gt;content&lt;/span&gt;\\ %end&lt;/div&gt; 渲染后的效果是： 1&lt;div&gt;&lt;span&gt;content&lt;/span&gt;&lt;/div&gt; 模板功能每个模板都预置了一些函数，可以帮助处理一些常见的功能。这些函数直接可用，无需安装或导入。 注意：在 0.12 版本之前，include() 和 rebase() 是语法关键字，而不是函数。 includeinclude(sub_template, variables)** 使用指定的变量渲染子模版，并将生成的文本插入到当前模板。该函数返回包含在子模板中传递或定义的局部变量的字典: 123% include('header.tpl', title='Page Title')Page Content% include('footer.tpl') rebaserebase(name, variables)** 将当前模板标记为稍后包含在不同的模板中，呈现当前模板后，其将生成的文本存储在一个名为 base 的变量中，并传递给基本模板，然后呈现该模板： 12% rebase('base.tpl', title='Page Title')&lt;p&gt;Page Content ...&lt;/p&gt; 以下是 base.tpl 的内容： 12345678&lt;html&gt;&lt;head&gt; &lt;title&gt;&#123;&#123;title or 'No title'&#125;&#125;&lt;/title&gt;&lt;/head&gt;&lt;body&gt; &#123;&#123;!base&#125;&#125;&lt;/body&gt;&lt;/html&gt; 渲染的最终结果： &gt;&gt;&gt; from bottle import template &gt;&gt;&gt; t = &apos;&apos;&apos;% rebase(&apos;base.tpl&apos;, title=&apos;Page Title&apos;) ... &lt;p&gt;Page Content ...&lt;/p&gt;&apos;&apos;&apos; &gt;&gt;&gt; print(template(t)) &lt;html&gt; &lt;head&gt; &lt;title&gt;Page Title&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;p&gt;Page Content ...&lt;/p&gt; &lt;/body&gt; &lt;/html&gt; defineddefined(name) 测试一个变量名是否定义： &gt;&gt;&gt; t = &apos;&apos;&apos;% if defined(&quot;title&quot;): ... &lt;p&gt;defined title&lt;/&gt; ... % else: ... &lt;p&gt;not defined title&lt;/p&gt; ... % end&apos;&apos;&apos; &gt;&gt;&gt; template(t) &apos;&lt;p&gt;not defined title&lt;/p&gt;\n&apos; &gt;&gt;&gt; template(t, title=&apos;test&apos;) &apos;&lt;p&gt;defined title&lt;/&gt;\n&apos; getget(name, default=None) 和字典的 get 方法相似： &gt;&gt;&gt; t = &apos;&apos;&apos;% print(get(&apos;title&apos;))&apos;&apos;&apos; &gt;&gt;&gt; template(t) None &apos;&apos; &gt;&gt;&gt; template(t, title=&apos;abc&apos;) abc &apos;&apos; setdefaultsetdefault(name, default) 如果变量没有定义，创建它并提供一个默认值，否则返回它的值： &gt;&gt;&gt; t = &apos;&apos;&apos;% setdefault(&quot;title&quot;, &quot;abc&quot;) ... {{title}}&apos;&apos;&apos; &gt;&gt;&gt; template(t) &apos;abc&apos; &gt;&gt;&gt; template(t, title=&apos;title&apos;) &apos;title&apos; 部署目前我最喜欢的部署方式是使用 gunicorn，如果想通过协程的方式提高程序的并发，还会搭配 gevent。它们都可以很方便的通过 pip 安装 gunicorn安装pip install gunicorn 配置文件gunicorn 最好通过配置文件的方式启动，配置文件可以是普通的键值对的文本，也可以是一个可执行的 Python 文件，采用 Python 文件的方式更灵活，所以我更喜欢这个。下面看一个配置文件的例子： 1234567891011121314151617181920212223242526272829import osimport sysimport multiprocessingDEBUG = os.environ.get('DEBUG','FALSE').upper() in ['TRUE','1']# gunicorn configpath_of_current_file = os.path.abspath(__file__)path_of_current_dir = os.path.dirname(path_of_current_file)sys.path.insert(0, path_of_current_dir)worker_class = 'gevent'workers = multiprocessing.cpu_count()chdir = path_of_current_dirworker_connections = 1000timeout = 30max_requests = 2000loglevel = 'info'bind = "0.0.0.0:8000"pidfile = '%s/run/gunicorn.pid' % path_of_current_dirif DEBUG: reload = True debug = True errorlog = "-" accesslog = "-"else: reload = False debug = False errorlog = '%s/logs/error.log' % path_of_current_dir accesslog = '%s/logs/access.log' % path_of_current_dir 配置文件的代码很简单，会自动根据当前系统CPU核数来配置生成多少个工作进程，还可以采用多进程配合多线程的方式，但这里选择了使用协程用以更好的支持并发。 并且配置文件编写了通过环境变量获取是否进入DEBUG模式的代码，让程序的配置更灵活。更多 gunicron 的配置说明可以查看官方文档：点此打开 配合Gevent使用 Gevent 可以在几乎不修改任何代码的情况下让 Web 性能获取飙升，安装也非常简单 pip install gevent。在上面的配置文件中，worker_class 已经指定了要使用 gevent 启动程序gunicorn 的启动方式也非常简单，直接使用命令行将应用程序对象和配置文件传递给 gunicorn: hello.py 1234567import bottleapp = bottle.Bottle()@app.route('/')def hello(): return 'Hello World' 启动: root@ubuntu: # gunicorn hello:app -c config.py [2018-10-16 11:42:45 +0000] [46823] [INFO] Starting gunicorn 19.6.0 [2018-10-16 11:42:45 +0000] [46823] [INFO] Listening at: http://0.0.0.0:8000 (46823) [2018-10-16 11:42:45 +0000] [46823] [INFO] Using worker: gevent [2018-10-16 11:42:45 +0000] [46827] [INFO] Booting worker with pid: 46827 [2018-10-16 11:42:45 +0000] [46828] [INFO] Booting worker with pid: 46828 [2018-10-16 11:42:45 +0000] [46829] [INFO] Booting worker with pid: 46829 [2018-10-16 11:42:45 +0000] [46830] [INFO] Booting worker with pid: 46830 但是默认是前台启动的，如果想启动后就放入后台执行，可以将 daemon=True 写入配置文件，或者直接在命令行添加 -D 参数。 使用 Nginx 做静态资源服务器gunicorn 是 WSGI 服务器，并不擅长处理静态资源，可以将静态文件交给 Nginx 处理。使用 Nginx 配置动静分离，将动态的请求转发到 gunicorn ，将静态资源直接返回给客户端，这样又可以提升不少的性能。 附录可用插件列表官网列出的 Bottle 现在可用的插件：点击打开]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>bottle</tag>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[WebSocket 协议分析]]></title>
    <url>%2F2018%2F06%2F22%2F2018%2FWebSocket%E5%8D%8F%E8%AE%AE%E5%88%86%E6%9E%90%2F</url>
    <content type="text"><![CDATA[简介 WebSocket协议是基于TCP的一种新的网络协议。它实现了浏览器与服务器全双工(full-duplex)通信——允许服务器主动发送信息给客户端。它弥补了 HTTP 协议只能只能由客户端，而无法实现服务器主动推送消息。在此之前，浏览器想了解服务端有没有更新数据只能每隔一段时间就发送一个HTTP请求去询问，这样的效率是非常低下的。而通过 WebSocket，服务器和客户端可以建立一条稳定的连接，并且可以双向通信。 协议分析WebSocket 协议的规范可以翻阅 RFC 6455 WebSocket协议有两部分：握手和数据传输。由客户端主动发送连接请求，握手信息是标准的HTTP协议，并通过 Upgrade 字段来表示升级为 WebSocket 协议，因此 WebSocket 的请求也很容易的可以穿过HTTP代理等服务。 握手阶段客户端发起的握手请求： GET /chat HTTP/1.1 Host: server.example.com Upgrade: WebSocket Connection: Upgrade Sec-WebSocket-Key: dGhlIHNhbXBsZSBub25jZQ== Origin: http://example.com Sec-WebSocket-Protocol: chat, superchat Sec-WebSocket-Version: 13 来自服务端的响应： HTTP/1.1 101 Switching Protocols Upgrade: WebSocket Connection: Upgrade Sec-WebSocket-Accept:s3pPLMBiTxaQ9kYGzzhZRbK+xOo= Sec-WebSocket-Protocol: chat 接下来看各字段具体作用 Upgrade: WebSocket：这是一个特殊的HTTP请求，目的是将客户端和服务端的通信协议从HTTP协议升级到 WebSocket 协议。 Sec-WebSocket-Key：这是一段Base64加密的密钥。 Sec-WebSocket-Accept：服务端收到客户端发来的密钥后追加一段魔法字符串，并将结果进行SHA-1散列签名后再经过Base64加密返回客户端。 Sec-WebSocket-Protocol：表示客户端提供的可供选择的自协议，及服务端选中的支持的子协议。 Origin：服务器端用于区分未授权的 websocket 浏览器。 HTTP/1.1 101 Switching Protocols：其中101为服务器返回的状态码，所有非101的状态码都表示握手并未完成。 在对 Sec-WebSocket-Accept 的解释中，有一个魔法字符串，这个魔法字符串是 WebSocket 标准中规定的一个常量：258EAFA5-E914-47DA-95CA-C5AB0DC85B11。这个常量只是定制标准时随机生成的一个标识符而已。 传输阶段Websocket协议通过序列化的数据帧传输数据。数据封包协议中定义了opcode、payload length、Payload data等字段。其中要求：客户端向服务器传输的数据帧必须进行掩码处理，服务器若接收到未经过掩码处理的数据帧，则必须主动关闭连接。服务器向客户端传输的数据帧一定不能进行掩码处理，客户端若接收到经过掩码处理的数据帧，则必须主动关闭连接。 具体数据帧格式如下所示： 0 1 2 3 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 +-+-+-+-+-------+-+-------------+-------------------------------+ |F|R|R|R| opcode|M| Payload len | Extended payload length | |I|S|S|S| (4) |A| (7) | (16/64) | |N|V|V|V| |S| | (if payload len==126/127) | | |1|2|3| |K| | | +-+-+-+-+-------+-+-------------+ - - - - - - - - - - - - - - - + | Extended payload length continued, if payload len == 127 | + - - - - - - - - - - - - - - - +-------------------------------+ | |Masking-key, if MASK set to 1 | +-------------------------------+-------------------------------+ | Masking-key (continued) | Payload Data | +-------------------------------- - - - - - - - - - - - - - - - + : Payload Data continued ... : + - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - + | Payload Data continued ... | +---------------------------------------------------------------+ 00010001 FIN：标识是否为此消息的最后一个数据包，占 1 bitRSV1, RSV2, RSV3： 用于扩展协议，一般为0，各占1bitOpcode：数据包类型（frame type），占4bits 0x0：标识一个中间数据包 0x1：标识一个text类型数据包 0x2：标识一个binary类型数据包 0x3-7：保留 0x8：标识一个断开连接类型数据包 0x9：标识一个ping类型数据包 0xA：表示一个pong类型数据包 0xB-F：保留 MASK：占1bits 用于标识PayloadData是否经过掩码处理。如果是1，Masking-key域的数据即是掩码密钥，用于解码PayloadData。客户端发出的数据帧需要进行掩码处理，所以此位是1。Payload length：Payload data的长度，占7bits，7+16bits，7+64bits。如果其值在0-125，则是payload的真实长度。如果值是126，则后面2个字节形成的16bits无符号整型数的值是payload的真实长度。如果值是127，则后面8个字节形成的64bits无符号整型数的值是payload的真实长度。Masking-key：如果是客户端发送的数据，长度信息之后的4个字节是掩码，Payload data：应用层数据，客户端发往服务端需要将数据的每一位和掩码的第 N%4 位进行异或运算。 而服务端返回的数据则不需要掩码和加密数据。 实现服务端接下来使用 Python3 来实现一个简单的 WebSocket 回声服务器，并每个比特的分析 WebSocket 协议的头部。 编写代码12345678910111213141516import structimport socketimport base64import hashlibHOST = '0.0.0.0'PORT = 2000MAGIC_STRING = '258EAFA5-E914-47DA-95CA-C5AB0DC85B11'HTTP_RESPONSE = ( 'HTTP/1.1 101 Switching Protocols\r\n' "Upgrade: websocket\r\n" "Connection: Upgrade\r\n" "Sec-WebSocket-Accept: &#123;KEY&#125;\r\n" "WebSocket-Location: ws://&#123;HOST&#125;/echo\r\n\r\n") 这里定义监听在 TCP 2000 端口，还有 WebSocket 标准定义的魔法字符串，以及通过 HTTP 协议建立 WebSocket 连接的响应模板字符串。 123456789101112131415def handshake(conn): headers = &#123;&#125; raw_headers = conn.recv(4096) if not len(raw_headers): return False header, data = raw_headers.split(b'\r\n\r\n', 1) for line in header.split(b'\r\n')[1:]: key, val = line.split(b': ', 1) headers[key] = val try: sec_key = headers[b'Sec-WebSocket-Key'] except: return False res_key = base64.b64encode(hashlib.sha1(sec_key + MAGIC_STRING.encode()).digest()) http_response = HTTP_RESPONSE.format(KEY=res_key.decode(), HOST=HOST) conn.send(http_response.encode()) return True 解析客户端发来的 WebSocket 握手请求，请求头中的 Sec-WebSocket-Key 和魔法字符串拼接后的SHA1的值经过Base64编码返回客户端，这一步握手就成功了，接下来的数据传输就是通过 WebSocket 协议进行了。 123456789101112131415161718192021def parseData(package): fin = package[0] &gt;&gt; 7 # 第一个字节(8 bit)右移7位获得FIN的比特位。 opcode = package[0] &amp; 0b1111 # 与运算获取最后四个比特位(opcode)的值 mask_flag = package[1] &gt;&gt; 7 # 客户端必须将MASK设置为1（必须将数据进行掩码处理） data_length = package[1] &amp; 0b1111111 # 计算数据长度 if data_length == 126: # 如果数据长度126，则之后的2个字节也是长度信息 masks = package[4:8] # 所以掩码值就在第 4,5,6,7 这四个字节 raw_data = package[8:] # 实际的数据所在字节 elif data_length == 127: # 如果数据长度127，则之后的8个字节也是长度信息 masks = package[10:14] # 所以掩码值就在第 10,11,12,13 这四个字节 raw_data = package[14:] else: masks = package[2:6] # 如果长度在0-125，则 2,3,4,5 就是掩码的值 raw_data = package[6:] data = b"" i = 0 for B in raw_data: tmp = B ^ masks[i % 4] # 将数据的每个字节与掩码进行异或运算 data += struct.pack('B', tmp) # 然后将值打包为二进制 i += 1 return data 解析接收到的 WebSocket 数据帧，并返回解密后的数据部分。 1234def packData(data): finAndOpcode = struct.pack('B', 0b10000001) maskAndLength = struct.pack('B', len(data)) return finAndOpcode+maskAndLength+data 构建服务端返回客户端的数据帧，因为不需要对数据按字节异或加密，所以代码比较简单。 12345678910111213141516171819202122def startServer(): sock = socket.socket(socket.AF_INET, socket.SOCK_STREAM) sock.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) sock.bind((HOST, PORT)) sock.listen(5) print('Server listen on %s:%s ...' % (HOST,PORT)) while True: conn, addr = sock.accept() if not handshake(conn): print("Client %s:%s handshake failed!" % addr) print("Client %s:%s handshake success!" % addr) data = conn.recv(4096) print('Raw data: ', data, sep='') print('Fact data: '+parseData(data).decode()) conn.send(packData(parseData(data))) conn.close()if __name__ == '__main__': try: startServer() except KeyboardInterrupt: print("Server exit...") 创建套接字监听，并启动服务，当有客户端握手成功后，将客户端发来的数据原样返回并关闭连接。运行脚本，然后看看效果吧！ 浏览器测试这里在 Chrome 浏览器中做演示，F12 进入开发者模式，然后点击 Console，现在就打开 JavaScript 的交互界面了。然后输入如下代码： 123var ws = new WebSocket("ws://127.0.0.1:2000/echo")ws.onmessage = data =&gt; &#123;console.log("Recv: "+data.data)&#125;ws.send("Hi! 喵喵喵") 可以看到，发送给服务端的字符串又被原样返回了。 服务端也可以看到终端上的输出： yunfwe@zhzz:/mnt/c/Users/yunfwe/Desktop$ python3 server.py Server listen on 0.0.0.0:2000 ... Client 127.0.0.1:53117 handshake success! Raw data: b&apos;\x81\x8d7\x91\xc6\x8b\x7f\xf8\xe7\xab\xd2\x07sn\xa1$#\x1d\x82&apos; Fact data: Hi! 喵喵喵 附录客户端一般都是浏览器等程序，如果感兴趣的话也可以试试用 Python 实现一个简单的 WebSocket 客户端。]]></content>
      <categories>
        <category>WebSocket</category>
      </categories>
      <tags>
        <tag>websocket</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一步步搭建PXE网络装机]]></title>
    <url>%2F2018%2F06%2F03%2F2018%2F%E4%B8%80%E6%AD%A5%E6%AD%A5%E6%90%AD%E5%BB%BAPXE%E7%BD%91%E7%BB%9C%E8%A3%85%E6%9C%BA%2F</url>
    <content type="text"><![CDATA[简介 PXE (preboot execute environment，预启动执行环境) 是由 Intel 公司设计的协议，它可以使计算机通过网络启动。当计算机引导时，BIOS 把 PXE client 调入内存执行，并显示出命令菜单，经用户选择后，PXE client将放置在远端的操作系统通过网络下载到本地运行。除了可以通过网络直接运行操作系统外，也可以用于通过网络来将系统安装到本地。在运维中工作中，通过 PXE 来为机房服务器批量部署系统是非常方便的。 环境PXE 对运行环境没有什么需求，只需能提供 tftp, dhcp, http 等服务的系统即可。这里使用 Linux 环境来搭建PXE服务。使用 dnsmasq 这个小巧玲珑的软件提供 tftp 和 dhcp 服务，使用 Nginx 来提供 http 服务。 步骤PXE 的启动原理是 PXE client 在网卡的 ROM 中，可以在计算机开机的时候选择通过硬盘引导还是 PXE 等引导方式，比如 DELL 的服务器在出现开机 LOGO 画面后通过键入 F12 来进入 PXE 引导，Vmware 新创建的虚拟机在第一次启动的时候如果没有装载光驱或者ISO镜像，则会尝试通过网络引导。如果是笔记本或者台式机可以在开机的时候进入引导菜单，然后选择通过网卡设备启动。 当进入 PXE 引导界面后，PXE client 会向网络中的 dhcp 服务器请求IP地址，dhcp 服务器发现是个 PXE client 的请求会将分配好的IP和引导程序的访问地址返回给 PXE client。这个引导程序一般是名为 pxelinux.0 的文件，这个文件是通过 tftp 协议发送给 PXE client 的。当客户端成功获取到引导文件和引导文件的相关配置文件后就成功加载出引导菜单。这个菜单则是我们通过更改 pxelinux.0 的配置文件来的。下面是通过Vmware引导的效果： 如果在30秒内没做任何选择则默认从本地磁盘启动，这样就避免了某些将PXE启动作为第一启动项的服务器重启后误重装系统。当选择了某个项目的时候，比如 Install CentOS6.8 for vmware 则向服务器获取根据配置文件中指定的 CentOS 内核文件和启动参数。当需要的数据都准备好后，系统则开始启动 Linux 内核，接下来的操作就跟普通的安装系统没两样了，只不过需要的数据都是通过网络获取的。比如安装 CentOS 过程中需要的所有 rpm 包都是通过 http 服务提供的 CentOS 镜像站提供的了。 但是如何通过 PXE 来同时安装成百上千台服务器呢？在安装系统的过程中，总会遇到各种需要交互的地方，比如给硬盘分区，选择语言，创建用户等地方，幸好大部分的系统安装镜像都支持通过 Kickstart 自动应答在安装过程中免人工干预的进行系统安装。就像是你的所有问题的回答我先写成一个文件，然后你需要问的时候先从文件中找答案一样。自动应答文件通常是 ks.cfg 文件，此文件的位置大多通过在启动 Linux 内核的时候通过启动参数的方式告诉内核。 接下来就看看 PXE 启动该如何配置。 服务配置安装 dnsmasq可以首先从Linux发行版的官方仓库中找找有没有 dnsmasq 的软件包，如果没有可以下载编译。 编译方法：12345cd /usr/local/src/wget http://www.thekelleys.org.uk/dnsmasq/dnsmasq-2.79.tar.xztar xf dnsmasq-2.79.tar.xzcd dnsmasq-2.79 &amp;&amp; makecp src/dnsmasq /usr/local/bin/ 只需要将 dnsmasq 的二进制文件放到系统环境变量就可以了，接下来给它提供一个配置文件来告诉它要启动哪些服务。源码目录下有一个官方提供的配置文件模板，不过我们并不需要这么多的配置。 123mkdir -p /data/pxeboot # PXE启动所需要的文件就都放到这里了cd /data/pxebootvim dnsmasq.conf 然后写入以下内容： # enable dhcp dhcp-range=192.168.4.10,192.168.4.200,12h dhcp-option=3,192.168.4.254 dhcp-option=option:dns-server,114.114.114.114,119.29.29.29 #dhcp-boot=pxelinux.0 dhcp-boot=undionly.kpxe # disable dns port=0 # enable tftp enable-tftp tftp-root=/data/pxeboot 一定要注意，dhcp-range 给客户端分配的IP地址池一定要是自己网段的。根据前面讲解的 PXE 启动的原理，可能大家会比较好奇，为什么这里 dhcp 推送的是 undionly.kpxe 这个文件呢？这个会在下面讲到，接下来就可以先启动 dnsmasq 了。 1dnsmasq -C dnsmasq.conf -d # 如果不加 -d 参数，dnsmasq 则进入后台运行 [root@localhost pxeboot]# dnsmasq -C dnsmasq.conf -d dnsmasq: started, version 2.79 DNS disabled dnsmasq: compile time options: IPv6 GNU-getopt no-DBus no-i18n no-IDN ...... dnsmasq-dhcp: DHCP, IP range 192.168.4.10 -- 192.168.4.200, lease time 12h dnsmasq-tftp: TFTP root is /data/pxeboot 现在基础的 dhcp 和 tftp 服务已经搭建完成了，dhcp 监听在 udp 67 端口，tftp 监听在 udp 69，使用前最好关闭服务器的 selinux 和 iptables。 安装 Nginx也不一定非要使用 Nginx，只要是能提供通过 HTTP 协议对文件进行访问服务的程序都可以，只不过感觉 Nginx 用起来更得心应手一些。同样，如果可以从发行版的官方仓库安装就非常省事了，或者手动编译也可以。 编译方法： 123456cd /usr/local/src/wget http://nginx.org/download/nginx-1.14.0.tar.gztar xf nginx-1.14.0.tar.gzcd nginx-1.14.0./configure --prefix=/usr/local/nginx --without-http_rewrite_modulemake -j4 &amp;&amp; make install 因为用不到 Nginx 的 rewrite 规则，而且这个模块依赖 pcre 库，所以就去掉了，接下来简单的配置下 Nginx。 12mkdir -p /data/wwwroot/pxefiles # /data/wwwroot 作为HTTP根目录vim /usr/local/nginx/conf/nginx.conf 然后写入以下内容： worker_processes 4; events { worker_connections 1024; } http { include mime.types; default_type application/octet-stream; sendfile on; autoindex on; keepalive_timeout 65; server { listen 80; server_name localhost; location / { root /data/wwwroot; index index.html index.htm; } error_page 500 502 503 504 /50x.html; location = /50x.html { root html; } } } 1/usr/local/nginx/sbin/nginx # 启动Nginx服务 安装 ipxe 引导文件为什么这里又出现了 ipxe 引导文件呢？理论上来说，只是用 pxelinux.0 确实也可以引导各种系统，但是 pxelinux.0 只支持使用 tftp 协议来加载需要的文件。 tftp 在使用 UDP 传输数据，为了保证文件的完整性，tftp 自己实现了一套数据校验机制，但是却大大降低了文件传输效率。而且某些未知情况下 tftp 在局域网内居然只有 KB 级别的传输速率。于是，一些支持 http 、ftp、nfs 等文件传输协议的引导程序诞生了，ipxe 就是其中一种。 ipxe 提供的引导文件针对不同使用场合又分好几种，比如 .pxe，.kpxe，.kkpxe 格式的引导文件。比较常见的是 .pxe，.kpxe，其中的区别可以看这里：点此打开，这里使用 undionly.kpxe 引导文件，采用链式加载的方法加载 pxelinux.0。这样就可以实现既使用 ipxe 提供的网络协议支持，还可以使用 pxelinux.0 提供的引导界面了。 编译 undionly.kpxe： 1234cd /usr/local/src/git clone git://git.ipxe.org/ipxe.gitcd ipxe/srcvim embed.ipxe 写入如下内容： #!ipxe dhcp chain tftp://${next-server}/menu.ipxe 其中 ${next-server} 会自动解析为 dhcp 服务器的地址，tftp 也搭建在这个地址上。当通过 dhcp 获取到IP地址后，通过 tftp 协议请求 menu.ipxe 文件，然后 ipxe 会解析和执行文件里的内容，这个文件可以说就是 ipxe 的配置文件了。接着编译出 undionly.kpxe，这样 undionly.kpxe 才会默认就加载同目录下的 menu.ipxe 文件了。 12make bin/undionly.kpxe EMBED=embed.ipxecp bin/undionly.kpxe /data/pxeboot/ 其中编译步骤需要 lzma.h 这个头文件，需要安装你的发行版上提供这个头文件的软件包。编译好的 undionly.kpxe 可以保存下来下次搭建环境的时候直接用，如果服务是搭建在 Windows 系统上也可以使用这个编译好的文件。 然后编辑 menu.ipxe 文件，配置接下来的文件都通过 http 协议来访问，并且链接到 pxelinux.0。 1vim /data/pxeboot/menu.ipxe 写入如下内容： #!ipxe set 210:string http://192.168.4.6/pxefiles/ set 209:string pxelinux.cfg/default chain ${210:string}pxelinux.0 其中 set 210:string 定义了请求的文件的主目录，因为之前创建的 /data/wwwroot/ 为 http 的根目录，/data/wwwroot/pxefiles/ 目录中存放 pxelinux.0 相关的数据文件。其中的服务器IP地址需要替换为你实际的服务器IP。set 209:string 则定义了 pxelinux.0 直接加载 pxelinux.cfg/default 这个配置文件，否则 pxelinux.0 会阶梯性的查找配置文件，如果都没找到最后默认才加载 pxelinux.cfg/default。 安装 pxelinux.0 引导文件接下来的操作就是在 /data/wwwroot/pxefiles/ 目录下进行了，因为 ipxe 启动后剩下的文件都是通过 http 协议访问的。 pxelinux.0 可以通过发行版的 syslinux 包来获取，或者自己从官方下载也可，这里采用从官方下载的方式。 1234567cd /usr/local/src/wget https://mirrors.edge.kernel.org/pub/linux/utils/boot/syslinux/Testing/3.86/syslinux-3.86-pre4.tar.xztar xf syslinux-3.86-pre4.tar.xzcd syslinux-3.86-pre4cp com32/menu/vesamenu.c32 /data/wwwroot/pxefiles/cp core/pxelinux.0 /data/wwwroot/pxefiles/cp memdisk/memdisk /data/wwwroot/pxefiles/ syslinux 最新版是16年发布的 6.04，但是使用中发现无法引导 ESXI，而且 pxelinux.0 引导后还要加载好几个 .c32 文件，所以采用老一点的 3.86 版本。 接着给 pxelinux.0 提供配置文件 123cd /data/wwwroot/pxefiles/mkdir pxelinux.cfgvim pxelinux.cfg/default 写入以下内容： default vesamenu.c32 timeout 300 menu title Welcome to PXE server! menu background splash.jpg menu color border 0 #ffffffff #00000000 menu color sel 7 #ffffffff #ff000000 menu color title 0 #ffffffff #00000000 menu color tabmsg 0 #ffffffff #00000000 menu color unsel 0 #ffffffff #00000000 menu color hotsel 0 #ff000000 #ffffffff menu color hotkey 7 #ffffffff #ff000000 menu color scrollbar 0 #ffffffff #00000000 label local menu label Boot from local drive menu default localboot 0xffff 这里为了界面美观使用了一张背景图片: splash.jpg，图片需要是一张 640*480 像素的 jpg 图片，并根据图片的主题颜色调整下页面边框、文字等颜色，如果不需要使用背景图片的话可以将 menu background 和 menu color 的配置项都删掉或者注释掉。 其中 timeout 300 会在引导界面30秒无操作就就启动下面 label 中定义为 menu default 的条目。到这一步已经可以尝试将虚拟机或者主机通过 PXE 启动，看看是否可以加载出引导界面了。 接下来，试试通过 PXE 实际启动或安装一些系统吧！ 网络启动 即使是通过网络安装，也是需要系统的镜像包的。最好先将需要安装的系统的镜像下载到本地，当然如果对自己网速很自信的话是可以直接通过公网来安装系统的（方法见附录）。 安装 CentOS下载系统镜像下载最新的CentOS镜像可以去官网或者国内的镜像站找，旧版本的可以在官网里找到。或者一个简单的方法，http://mirror.nsc.liu.se/centos-store/6.8/isos/x86_64/ 把其中的6.8改为相应的版本号就可以了。 这里使用和机房服务器系统版本一致的 CentOS 6.8 镜像，如果只是想安装一个最小化的 CentOS 系统的话，选择 minimal.iso，而如果想安装带桌面的甚至想搭建一个本地的yum源，就使用 bin-DVD1.iso 和 bin-DVD2.iso 这两个镜像。其中 bin-DVD2.iso 不可用于系统安装，因为里面只是额外的RPM包，搭建 yum源的话可以将两个镜像的内容合并到一个目录中。还有个是 LiveCD.iso 或者 LiveDVD.iso 的镜像，这种镜像可以直接刻录到光盘并从光盘启动系统。 这里直接使用 bin-DVD 的镜像。 配置安装源首先将 bin-DVD1.iso 和 bin-DVD2.iso 的内容合并到一个目录中12345678mkdir -p /data/wwwroot/yum/CentOS6.8/ mount -o loop CentOS-6.8-x86_64-bin-DVD1.iso /mnt/cp -rf /mnt/* /data/wwwroot/yum/CentOS6.8/umount /mnt/mount -o loop CentOS-6.8-x86_64-bin-DVD2.iso /mnt/cp -rf /mnt/* /data/wwwroot/yum/CentOS6.8/ # 所有同名文件都覆盖掉umount /mnt/ln -s /data/wwwroot/yum/ /data/wwwroot/pxefiles/yum 这里创建了一个软链接的原因是 menu.ipxe 中定义为pxe主目录在 /data/wwwroot/pxefiles/ 中。 准备自动应答文件每次安装完 CentOS 的系统后不知道大家是否有留意root用户家目录下的三个文本文件 anaconda-ks.cfg，install.log，install.log.syslog。其中 anaconda-ks.cfg 就是系统安装过程中的所有问答产生的 ks.cfg 自动应答文件，这个是可以直接拿来用的。 如果这个文件被删除了，那么也可以通过软件包 system-config-kickstart 来定制，此工具需要在图形化界面下或者配置好了X11转移的环境中使用。使用 yum -y install system-config-kickstart 安装后使用 system-config-kickstart 运行程序。 配置好后使用 Ctrl+S 保存并退出，将制作好的 ks.cfg 文件或者 anaconda-ks.cfg 复制到刚才创建的yum源中。因为不同的主机类型可能对应着不同的自动应答文件，所以可以保存为针对不同安装类型或平台的自动应答文件。 1cp /root/anaconda-ks.cfg /data/wwwroot/yum/CentOS6.8/ks-minimal-vmware.cfg ks-minimal-vmware.cfg 文件内容为： install reboot text url --url=http://192.168.4.6/yum/CentOS6.8 lang zh_CN.UTF-8 keyboard us network --onboot yes --device eth0 --mtu=1500 --bootproto dhcp --noipv6 # root passwd : 123456 rootpw --iscrypted $6$5dCFp4Me$YkPWb8h0M/wRUPH3puKXcmbhsErJxfFPCXTtIzfglpfHriMBJsRtqjS5Ewh6Vj/h3mnRdXfsAGcadD3TpRAlk1 firewall --service=ssh authconfig --enableshadow --passalgo=sha512 selinux --disabled timezone --utc Asia/Shanghai bootloader --location=mbr --driveorder=sda --append=&quot;crashkernel=auto rhgb rhgb quiet quiet&quot; zerombr clearpart --all --drives=sda part /boot --fstype=ext4 --size=500 part swap --size=2048 part / --fstype=ext4 --grow --size=1 repo --name=&quot;CentOS&quot; --baseurl=http://192.168.4.6/yum/CentOS6.8 --cost=100 %packages @Base @Core %post cd /etc/yum.repos.d/ mkdir bak mv * bak cat &gt;&gt; CentOS-Base.repo &lt;&lt;END [base] name=CentOS-$releasever Base baseurl=http://192.168.4.6/yum/CentOS6.8 enabled=1 gpgcheck=0 END yum update yum -y install lrzsz 其中配置了 root 密码为 123456，只安装了最基础的软件包。在安装完之后自动配置系统的yum源到本地服务器上，并且安装 lrzsz 工具包。这里密码是通过加密后的，也可以直接使用 rootpw 123456 这种方式。其中 reboot 会在安装完成后自动重启。 添加PXE启动项该为 pxelinux.0 添加 CentOS6.8 的启动项了，编辑 pxelinux.cfg/default，在 label local 前添加如下配置块： label centos6.8 menu label Install CentOS6.8 for vmware (minimal install) kernel /yum/CentOS6.8/images/pxeboot/vmlinuz append initrd=/yum/CentOS6.8/images/pxeboot/initrd.img ks=http://192.168.4.6/yum/CentOS6.8/ks-minimal-vmware.cfg ksdevice=eth0 kernel 和 initrd 可以使用文件对于URL的相对路径，加载的内核也是 CentOS 镜像中提供的支持PXE启动的内核文件。ks 是传给内核的参数，制定了自动应答文件的位置。内核启动后就不是由PXE控制网卡了，就无法使用相对路径的方式获取文件，所以自动应答文件要使用全路径。ksdevice 在单网卡的情况下可以不指定，如果是多网卡的服务器不指定 ksdevice 的话，安装过程则会停在让你手动选择要使用的网卡界面。 开始安装再次进入PXE引导界面，可以看到刚才新加的启动项生效了，接着选择它并回车。 可以看到剩下的过程根本没有人工干预就安装完成了。 安装完成后会自动重启。 安装 Ubuntu下载系统镜像镜像可以从Ubuntu官网下载，也可以在中科大或其他的国内开源镜像站中下载。点此打开 这里使用 ubuntu-16.04.4-server-amd64.iso 这个镜像，最新的 ubuntu-18.04 并没有经过测试，不知道是否还能用此方法进行安装。 配置安装源同理将镜像解压到web目录。 12345mkdir -p /data/wwwroot/apt/ubuntu16.04mount -o loop ubuntu-16.04.4-server-amd64.iso /mnt/cp -rf /mnt/* /data/wwwroot/apt/ubuntu16.04umount /mnt/ln -s /data/wwwroot/apt/ /data/wwwroot/pxefiles/apt 准备自动应答文件也可以在 ubuntu 上使用 system-config-kickstart 工具来制作自动应答文件，使用前先安装：apt install system-config-kickstart。ubuntu 的自动应答文件不可以和 CentOS 的通用。 1vim /data/wwwroot/apt/ubuntu16.04/ks-server-vmware.cfg 文件内容如下： lang en_US langsupport en_US keyboard us mouse timezone Asia/Shanghai rootpw --disabled # ubuntu password: 123456 user ubuntu --fullname &quot;ubuntu&quot; --iscrypted --password $1$4C9x9TxO$PfPaSIUWQwN80J0MtEyQ3. reboot text install url --url http://192.168.4.6/apt/ubuntu16.04/ bootloader --location=mbr zerombr yes clearpart --all --initlabel part / --fstype ext4 --size 1 --grow part swap --size 2048 auth --useshadow --enablemd5 network --bootproto=dhcp --device=eth0 firewall --disabled skipx %packages @^minimal @core openssh-server 其中新建了一个叫 ubuntu 的用户，用户密码是 123456。默认没有配置root用户的密码，可以使用普通用户登陆后使用 sudo 来切换到 root 用户。ubuntu 默认是不允许 root 用户登陆的，需要修改 /etc/ssh/sshd_config 中的 PermitRootLogin 为 yes。 添加PXE启动项编辑 pxelinux.cfg/default 添加如下 label 块： label ubuntu server 16.04 menu label Install Ubuntu server 16.04.4 (minimal install) kernel /apt/ubuntu16.04/install/netboot/ubuntu-installer/amd64/linux append initrd=apt/ubuntu16.04/install/netboot/ubuntu-installer/amd64/initrd.gz ks=http://192.168.4.6/apt/ubuntu16.04/ks-server-vmware.cfg --- live-installer/net-image=http://192.168.4.6/apt/ubuntu16.04/install/filesystem.squashfs 开始安装 安装完成后会自动重启。 安装 ESXI下载系统镜像在官网下载需要登陆，官方下载地址。如果是用于服务器安装，那最好找找有没有服务器官方提供的针对服务器硬件的 ESXI 版本，比如戴尔官方提供的定制版 ESXI 戴尔官方下载地址 这里使用戴尔官方提供的 VMware ESXi 5.5 Update 3 点此下载 配置安装源ESXI 的镜像比较特殊，需要做些调整才可以通过 PXE 安装。12345mkdir -p /data/wwwroot/esxi/5.5mount -o loop VMware-VMvisor-Installer-5.5.0.update03-3029944.x86_64-Dell_Customized-A00.iso /mntcp -rf /mnt/* /data/wwwroot/esxi/5.5/umount /mntln -s /data/wwwroot/esxi/ /data/wwwroot/pxefiles/esxi 修改 exsi/5.5 目录中的 boot.cfg 123sed -i '1a\prefix=/esxi/5.5/' /data/wwwroot/esxi/5.5/boot.cfgsed -i '6s/\///g' /data/wwwroot/esxi/5.5/boot.cfgsed -i 's/^kernel=.*$/kernel=tboot.b00/g' /data/wwwroot/esxi/5.5/boot.cfg 准备自动应答文件编辑 /data/wwwroot/esxi/5.5/ks.cfg，写入如下内容： accepteula rootpw 12345678 clearpart --firstdisk=local --overwritevmfs install --firstdisk=local --overwritevmfs network --bootproto=dhcp --device=vmnic0 reboot root 用户的密码是 12345678 添加PXE启动项编辑 pxelinux.cfg/default 添加如下 label 块： label Install ESXI 5.5 for dell menu label Install ESXI 5.5 for dell kernel /esxi/5.5/mboot.c32 append -c /esxi/5.5/boot.cfg ks=http://192.168.4.6/esxi/5.5/ks.cfg 开始安装虽然下载的是针对服务器的，但是为了方便截图依然使用虚拟机测试。需要注意的是，虚拟机安装 ESXI 需要将操作系统设置为 VMware EXS(X) 然后正常进入PXE引导菜单 安装完成后会自动重启。 安装 WindowsWindows 系统的安装就比较特殊了，因为不像 Linux 可以通过内核引导启动，虽然也可以实现无人应答安装，但是研究的成本高于工作中的实际成本，所以这里只实现了可以通过网络手动安装 Windows 系统。 Windows 系统的安装需要一个 WinPE 的安装环境，先通过网络引导启动 WinPE，然后在 WinPE 环境中安装 Windows 镜像。 下载系统镜像除了可以在微软官方下载镜像，也可以在国内好心人制作的 MSDN I Tell You 里下载。 这里使用 windows_server_2008_R2_standard_enterprise_and_datacenter_x64_dvd_x15-59777.iso 这个镜像。 配置镜像站首先需要一个带网络功能的 WinPE，如果不嫌麻烦的话可以百度如何制作 WinPE 镜像，如果采用第三方提供做好的 WinPE 就需要保证镜像是否是干净安全的，而且还需要集成了网卡驱动，如果是用于服务器安装，可能还需要集成 Raid 卡的驱动。 这里使用无垠PE制作的 Win8PE64网络版.iso 点此打开网盘分享 密码：sees。其中有一个 win8pe_x64_raid_network.iso 的镜像据说是集成了 Raid 卡驱动适用于服务器的 WinPE，实际还并未测试过。 PXE环境对中文的支持能力几乎没有，所以下载后需要将文件名中的中文去掉，然后放到相应目录。然后将 Windows 系统安装镜像解压。 123456mkdir -p /data/wwwroot/windows/windows_server_2008_x64mv Win8PE64网络版.iso /data/wwwroot/windows/win8pe.isoln -s /data/wwwroot/windows/ /data/wwwroot/pxefiles/windowsmount -o loop windows_server_2008_R2_standard_enterprise_and_datacenter_x64_dvd_x15-59777.iso /mntcp -rf /mnt/* /data/wwwroot/windows/windows_server_2008_x64/umount /mnt 接下来就是另一个比较麻烦的地方了，因为在 WinPE 中通过网络安装 Windows 系统最简单方便的方法就是在 Linux 上创建 Samba 共享，然后 WinPE 中挂载使用。Samba 软件也可以从发行版的官方仓库中获得，或者手动编译安装。 编译安装 Samba： 12345wget https://download.samba.org/pub/samba/stable/samba-4.8.2.tar.gztar xf samba-4.8.2.tar.gzcd samba-4.8.2./configure --prefix=/usr/local/sambamake -j4 &amp;&amp; make install 配置过程中如果出现了什么错误，就根据提示自行解决依赖。接着配置 Samba 共享目录并启动服务。 1vim /usr/local/samba/etc/smb.conf 写入如下内容： [global] workgroup = MYGROUP server string = Samba Server server role = standalone server log file = /dev/stdout max log size = 50 dns proxy = no pam password change = yes map to guest = bad user usershare allow guests = yes create mask = 0664 force create mode = 0664 directory mask = 0775 force directory mode = 0775 force user = root force group = root follow symlinks = yes load printers = no printing = bsd printcap name = /dev/null disable spoolss = yes socket options = TCP_NODELAY strict locking = no vfs objects = recycle recycle:keeptree = yes recycle:versions = yes min protocol = SMB2 [public] path = /data/wwwroot/windows/ browsable = yes read only = yes guest ok = yes veto files = /._*/.apdisk/.AppleDouble/.DS_Store/.TemporaryItems/.Trashes/desktop.ini/ehthumbs.db/Network Trash Folder/Temporary Items/Thumbs.db/ delete veto files = yes 启动 Samba 服务后可以在 Windows 上连接试试 1/usr/local/samba/sbin/smbd -D 在 Windows 资源管理器中输入 \\192.168.4.6 就可以打开共享的目录了。 添加PXE启动项还记得之前和 pxelinux.0 同一目录的 memdisk 文件吧，这通过这个文件可以将 iso 镜像加载到内存中启动，就利用这个方式来启动 WinPE 镜像。 编辑 pxelinux.cfg/default 添加如下 label 块： label Install windows for vmware (WinPE) menu label Install Windows for vmware (WinPE) kernel memdisk append initrd=/windows/win8pe.iso ksdevice=bootif raw iso 开始安装选择启动 WinPE 进入 WinPE 桌面环境后连接到服务端的 Samba 共享目录，然后执行 Windows 系统安装镜像中的 setup.exe 剩下的步骤就是 Windows 系统的普遍安装方式了。 Ubuntu LiveCDLiveCD 是个比较有意思的模式，用于直接通过光盘或者镜像启动 Linux，相当于直接将光盘作为根文件系统，在不安装到硬盘的情况下就可以体验到当前发行版了。而且稍加修改就可以通过网络来启动，由于不依赖硬盘启动，个人认为还可以将 LiveCD 模式当作救援模式使用，因为 LiveCD 模式下相当于正常启动了 Linux 系统，因此也可以正常使用包管理器来安装软件，以及挂载和卸载硬盘。 LiveCD 需要通过 NFS 来加载镜像内容，因此还需要搭建一个 NFS 目录共享。 下载系统镜像由于 Ubuntu Server 的镜像不支持 LiveCD 模式，所以这里使用桌面版的 Ubuntu-16.04 镜像。镜像名为：ubuntu-16.04.3-desktop-amd64.iso 配置 NFS 共享各发行版的 NFS 使用的软件包名称都不太一样，可以借助搜索引擎获取你所使用的发行版是如何安装 NFS 共享软件包的，这里就使用 CentOS 6.8 的 NFS 共享为例。 123456mkdir /data/wwwroot/apt/ubuntu16.04-desktop/mount -o loop ubuntu-16.04.3-desktop-amd64.iso /mnt/cp -rf /mnt/* /data/wwwroot/apt/ubuntu16.04-desktop/umount /mntyum install -y rpcbind nfs-utilsvim /etc/exports 写入如下内容： /data/wwwroot/apt/ubuntu16.04-desktop/ * (ro,sync,no_root_squash) 启动 NFS 服务 12service rpcbind restartservice nfs restart 共享成功后可以在其他主机上看到自己的共享： [root@localhost ~]# showmount -e 192.168.4.6 Export list for 192.168.4.6: /data/wwwroot/apt/ubuntu16.04-desktop * [root@localhost ~]# 添加PXE启动项编辑 pxelinux.cfg/default 添加如下 label 块： label Ubuntu 16.04 amd64 menu label Ubuntu 16.04 amd64 LiveCD kernel /apt/ubuntu16.04-desktop/casper/vmlinuz.efi append initrd=/apt/ubuntu16.04-desktop/casper/initrd.lz boot=casper netboot=nfs nfsroot=192.168.4.133:/data/wwwroot/apt/ubuntu16.04-desktop/ splash locale=zh_CN url=http://192.168.4.133/apt/ubuntu16.04-desktop/preseed/ubuntu.seed 进入 LiveCD 模式 加载过程可能会比较慢，但最后还是成功进入了 Ubuntu 桌面。 附录附件：点击下载压缩包里包含了所有的配置文件和dnsmasq, pxelinux.0, undionly.kpxe 这些就可以免去编译安装了。 再介绍一个好玩的，通过中科大网络启动服务来安装系统 点此访问 如果觉得手动配置PXE启动的每一个环节非常麻烦，可以试试自动化装机神器 Cobbler。]]></content>
      <categories>
        <category>PXE</category>
      </categories>
      <tags>
        <tag>pxe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[一起动手写一个VPN]]></title>
    <url>%2F2018%2F05%2F24%2F2018%2F%E4%B8%80%E8%B5%B7%E5%8A%A8%E6%89%8B%E5%86%99%E4%B8%80%E4%B8%AAVPN%2F</url>
    <content type="text"><![CDATA[简介 了解了OpenVPN之后，发现通过一个UDP隧道来打通NAT网络非常有意思，于是就萌发出使用Python来实现一个类似于OpenVPN的隧道，OpenVPN不仅支持UDP协议还支持TCP协议，但是这里并不会像OpenVPN设计的这么复杂完善，只使用简单的UDP协议和密码认证。也通过这个小程序来更深入的学习下Linux网络相关的知识。 环境VPN隧道的实现依赖于Linux内核提供的 tun/tap 虚拟网络接口，只要不是太古董级别的Linux系统，或者其他类Unix系统就都可以支持。可以查看是否存在设备文件 /dev/net/tun，如果存在则表示支持 tun/tap 功能，对于早些的Linux内核，设备文件还可能是 /dev/tun。 其中 tun 是模拟的三层网络设备，只支持三层以上的协议，只能做到点对点隧道，而 tap 则可以模拟二层网络设备，arp 协议等二层协议也是支持的，可以实现多机组成的虚拟局域网。tun 也可以通过数据转发的方式实现互通。 服务端代码为了更高的性能和不依赖第三方库使用Python3完成，客户端就尽量兼容更多版本的Python。网络使用常用的 tun 虚拟网卡。 编程先来理解一下使用 tun 的VPN是如何实现的呢？简单来说 就是 /dev/net/tun 设备实现了应用层直接处理网络数据包的能力。当使用 /dev/net/tun 创建了虚拟网卡设备后，发到这个网卡的数据包会被 /dev/net/tun 拦截并返回给打开它上上层程序，上层程序可以通过 udp、tcp 甚至 icmp 协议将原始的数据包发送到目标主机。当目标主机通过网络接受到数据包后再写入到 /dev/net/tun 设备中，/dev/net/tun 再将数据包注入到内核的网络协议栈按照正常到达的数据包来处理。VPN大部分采用的是通过 udp 协议发送到对端的，如果是通过 tcp 协议传输，tcp 包内部包裹着另一个 tcp 包，如果发生了丢包重传现象，内部的 tcp 包和外部的 tcp 包可能发生混乱。 服务端程序 服务端程序使用 Python3 开发，只使用了标准库 导入需要的模块123456789import osimport sysimport timeimport structimport socketfrom fcntl import ioctlfrom select import selectfrom threading import Threadfrom ipaddress import ip_network 可能大多数人都熟悉 os, sys, time 这些模块，而对其他的就不太了解了。其中 struct 是一个将Python的数据类型转换为C语言中的数据类型的字节流的模块。fnctl.ioctl 用来对设备的一些特性进行控制，比如这里来设定要启用的虚拟网卡的类型和网卡名称。select 是 I/O多路复用 的一个实现，用来在单线程中高效的利用网络I/O。ipaddress 模块是Python3新增的模块，用来解析IP地址的。 定义一些常量1234567891011121314DEBUG = TruePASSWORD = b'4fb88ca224e'BIND_ADDRESS = '0.0.0.0',2003NETWORK = '10.0.0.0/24'BUFFER_SIZE = 4096MTU = 1400IPRANGE = list(map(str,ip_network(NETWORK)))[1:]LOCAL_IP = IPRANGE.pop(0)TUNSETIFF = 0x400454caIFF_TUN = 0x0001IFF_TAP = 0x0002 在这里定义了一些常量，比如认证的密码，服务监听的地址，以及整个网络段。其中不太好理解的可能是 TUNSETIFF, IFF_TUN 和 IFF_TAP 这三个常量。这三个常量实际上是定义在 linux/if_tun.h 这个头文件中，因为用Python来实现 tun 隧道 所以也需要使用这三个常量。TUNSETIFF 这个常量是告诉 ioctl 要完成虚拟网卡的注册，而IFF_TUN 和 IFF_TAP 则表示是要使用 tun 类型还是 tap 类型的虚拟网卡。 创建和启动虚拟网卡1234567891011def createTunnel(tunName='tun%d',tunMode=IFF_TUN): tunfd = os.open("/dev/net/tun", os.O_RDWR) ifn = ioctl(tunfd, TUNSETIFF, struct.pack(b"16sH", tunName.encode(), tunMode)) tunName = ifn[:16].decode().strip("\x00") return tunfd,tunName def startTunnel(tunName,peerIP): os.popen('ifconfig %s %s dstaddr %s mtu %s up' % (tunName, LOCAL_IP, peerIP, MTU)).read() now = lambda :time.strftime('[%Y/%m/%d %H:%M:%S] ') 先看 createTunnel 函数，默认是使用 tun 类型的虚拟网卡，os.open 是更底层的文件读写方式，事实上，常用的 open(&#39;filename&#39;) 方法就是对 os.open 的高级封装，os.O_RDWR 标志以读写模式打开 tun 的设备文件。然后使用 ioctl 来创建一个虚拟网卡，并返回创建成功后的网卡名称，默认是按照 tun0，tun1 依次增加的。 startTunnel 就是用 ifconfig 命令为这个虚拟网卡配置IP地址。MTU 之所以设置为 1400 因为Linux默认网卡的 MTU 是 1500，但是隧道来的数据包还要包裹一层 udp 封装发往对端，如果隧道的 MTU 也设置为 1500 的话，那最终通过 udp 封装后肯定会超出物理网卡的界限，最终会被拆分为两个数据包发送二照成不必要的浪费。 now 是一个 lambda 表达式，给下面的打印调试信息使用。 VPN的核心实现123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354555657585960616263646566676869707172737475767778798081828384858687888990919293949596979899100101102103104class Server(): def __init__(self): self.sessions = [] self.readables = [] self.udp = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) self.udp.bind(BIND_ADDRESS) self.readables.append(self.udp) self.tunInfo = &#123; 'tunName':None, 'tunfd':None, 'addr':None, 'tunAddr':None, 'lastTime':None &#125; print('Server listen on %s:%s...' % BIND_ADDRESS) def getTunByAddr(self, addr): for i in self.sessions: if i['addr'] == addr: return i['tunfd'] return -1 def getAddrByTun(self,tunfd): for i in self.sessions: if i['tunfd'] == tunfd: return i['addr'] return -1 def createSession(self, addr): tunfd,tunName = createTunnel() tunAddr = IPRANGE.pop(0) startTunnel(tunName,tunAddr) self.sessions.append( &#123; 'tunName':tunName, 'tunfd':tunfd, 'addr':addr, 'tunAddr':tunAddr, 'lastTime':time.time() &#125; ) self.readables.append(tunfd) reply = '%s;%s' % (tunAddr,LOCAL_IP) self.udp.sendto(reply.encode(), addr) def delSessionByTun(self, tunfd): if tunfd == -1: return False for i in self.sessions: if i['tunfd'] == tunfd: self.sessions.remove(i) IPRANGE.append(i['tunAddr']) self.readables.remove(tunfd) os.close(tunfd) return True def updateLastTime(self, tunfd): for i in self.sessions: if i['tunfd'] == tunfd: i['lastTime'] = time.time() def cleanExpireTun(self): while True: for i in self.sessions: if (time.time() - i['lastTime']) &gt; 60: self.delSessionByTun(i['tunfd']) if DEBUG: print('Session: %s:%s expired!' % i['addr']) time.sleep(1) def auth(self,addr,data,tunfd): if data == b'\x00': if tunfd == -1: self.udp.sendto(b'r', addr) else: self.updateLastTime(tunfd) return False if data == b'e': if self.delSessionByTun(tunfd): if DEBUG: print("Client %s:%s is disconnect" % addr) return False if data == PASSWORD: return True else: if DEBUG: print('Clinet %s:%s connect failed' % addr) return False def run_forever(self): cleanThread = Thread(target=self.cleanExpireTun) cleanThread.setDaemon(True) cleanThread.start() while True: readab = select(self.readables, [], [], 1)[0] for r in readab: if r == self.udp: data, addr = self.udp.recvfrom(BUFFER_SIZE) if DEBUG: print(now()+'from (%s:%s)' % addr, data[:10]) try: tunfd = self.getTunByAddr(addr) try: os.write(tunfd,data) except OSError: if not self.auth(addr,data,tunfd):continue self.createSession(addr) if DEBUG: print('Clinet %s:%s connect successful' % addr) except OSError: continue else: try: addr = self.getAddrByTun(r) data = os.read(r, BUFFER_SIZE) self.udp.sendto(data,addr) if DEBUG: print(now()+'to (%s:%s)' % addr, data[:10]) except Exception: continue 一步一步的来看，首先定义了一个 Server 的类。在初始化方法 __init__ 中，self.sessions = [] 用来保存连接的用户会话，self.readables = [] 用来保存为每个会话创建的隧道的文件描述符，接着创建了一个 udp 的网络套接字，并将这个套接字加入到 self.readables 中。self.tunInfo 定义了每个会话保存的隧道信息。 接下来的 getTunByAddr 是通过接受到的 udp 数据包的来源信息找到需要注入到哪条隧道中，getAddrByTun 正好相反，根据从隧道来的数据找到是要通过 udp 发往哪个主机。 createSession 则是客户端连接成功后为它创建一个会话和相应的虚拟网卡，并且将客户端的网卡配置信息通过 udp 发送过去。 delSessionByTun 是用来清理用户会话和虚拟网卡。 updateLastTime 用来在客户端发送来心跳包后更新用户最后一次发送心跳包的时间戳，cleanExpireTun 用来清理已经超过一分钟没有发来心跳包的客户端，认为这个客户端已经失去了连接，但是可能因为网络故障等原因没有正常关闭隧道。 auth 则是对客户端发来的数据进行处理，如何客户端发来 b&#39;\x00&#39; 则表明这是一个心跳包，但是如果并不存在这个心跳包源主机的会话，可能因为网络原因服务端清理了这个客户端的会话，就发送 b&#39;r&#39; 告诉客户端重新认证。否则就更新这个会话的最后心跳包的时间戳。客户端在退出的时候会发送 b&#39;e&#39; 到服务端，然后服务端会主动清理这个客户端的会话。最后会匹配数据包是否是认证密码，如果认证成功了就返回 True 程序会继续处理。 run_forever 是整个服务运转的核心了，首先使用一个新线程启动会话清理方法，然后进入事件循环，使用 select 监听 udp 网络套接字和隧道套接字的可读事件，一旦某个套接字有数据过来了 select 则会返回这个套接字对象，然后判断这个套接字是网络套接字还是隧道套接字，如果是网络套接字则首先尝试将数据写入到客户端所在的隧道中，如果数据内容不是一个正确的网络数据包格式或者没有找到这个客户端地址相关联的隧道，就进入异常处理模式，因为新客户端的连接和心跳包导致进入异常处理的频率是比较小的 所以并不会对整体性能照成很大的影响，如果在一开始就进行数据内容判断的话 就非常影响程序的性能了，因为毕竟接收到的大多都是合法的能写入到隧道的数据包。 接着如果可读对象是一个隧道文件描述符的话，就找到客户端的网络地址，通过 udp 将读取到的数据包发送给客户端，并且如果出现了任何异常的话 就跳过。 程序执行入口12345if __name__ == '__main__': try: Server().run_forever() except KeyboardInterrupt: print('Closing vpn server ...') 创建一个匿名对象并且启动 run_forever 方法。 客户端程序 客户端就比较简单了，只需要将网络来的数据写入隧道，隧道来的数据通过网络发送出去 导入需要的模块1234567891011from __future__ import print_functionfrom __future__ import unicode_literalsimport osimport sysimport timeimport structimport socketfrom fcntl import ioctlfrom select import selectfrom threading import Thread 因为需要尽可能的支持更多的Python版本，所以需要使用一些兼容性相关的小技巧。 定义一些常量123456789PASSWORD = b'4fb88ca224e'MTU = 1400BUFFER_SIZE = 4096KEEPALIVE = 10TUNSETIFF = 0x400454caIFF_TUN = 0x0001IFF_TAP = 0x0002 同服务端，客户端也需要配置隧道，客户端多了一个 KEEPALIVE 的常量，用来定义多久向服务端发送心跳包。 创建和启动虚拟网卡123456789def createTunnel(tunName='tun%d',tunMode=IFF_TUN): tunfd = os.open("/dev/net/tun", os.O_RDWR) ifn = ioctl(tunfd, TUNSETIFF, struct.pack(b"16sH", tunName.encode(), tunMode)) tunName = ifn[:16].decode().strip("\x00") return tunfd,tunName def startTunnel(tunName, localIP, peerIP): os.popen('ifconfig %s %s dstaddr %s mtu %s up' % (tunName, localIP, peerIP, MTU)).read() startTunnel 有个不同的地方是还需要知道对端（服务端）的隧道IP。 VPN的核心实现12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758class Client(): def __init__(self): self.udp = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) self.udp.settimeout(5) self.to = SERVER_ADDRESS def keepalive(self): def _keepalive(udp, to): while True: time.sleep(KEEPALIVE) udp.sendto(b'\x00', to) k = Thread(target=_keepalive, args=(self.udp, self.to), name='keepalive') k.setDaemon(True) k.start() def login(self): self.udp.sendto(PASSWORD,self.to) try: data,addr = self.udp.recvfrom(BUFFER_SIZE) tunfd,tunName = createTunnel() localIP,peerIP = data.decode().split(';') print('Local ip: %s\tPeer ip: %s' % (localIP,peerIP)) startTunnel(tunName,localIP,peerIP) return tunfd except socket.timeout: return False def run_forever(self): print('Start connect to server...') tunfd = self.login() if not tunfd: print("Connect failed!") sys.exit(0) print('Connect to server successful') self.keepalive() readables = [self.udp, tunfd] while True: try: readab = select(readables, [], [], 10)[0] except KeyboardInterrupt: self.udp.sendto(b'e', self.to) raise KeyboardInterrupt for r in readab: if r == self.udp: data, addr = self.udp.recvfrom(BUFFER_SIZE) try: os.write(tunfd, data) except OSError: if data == b'r': os.close(tunfd) readables.remove(tunfd) print('Reconnecting...') tunfd = self.login() readables.append(tunfd) continue else: data = os.read(tunfd, BUFFER_SIZE) self.udp.sendto(data, self.to) 和服务端的比较类似，不同的是客户端需要处理的是登陆、从服务端接收到隧道配置信息然后创建和启动隧道和处理服务端发来的 b&#39;r&#39; 重连命令。还会启动一个定期发送心跳包的线程，这个主要是因为在传统的 NAT 模型中，UDP会话可能在短短的几分钟甚至几十秒钟就会被网关设备清理掉，导致VPN隧道断开。而不断地发送心跳包则可以保持网关设备上客户端和服务端的UDP会话。 程序执行入口12345678if __name__ == '__main__': try: SERVER_ADDRESS = (sys.argv[1], int(sys.argv[2])) Client().run_forever() except IndexError: print('Usage: %s [remote_ip] [remote_port]' % sys.argv[0]) except KeyboardInterrupt: print('Closing vpn client ...') 这里通过命令行获取客户端要连接的服务端IP和端口，如果参数出错并给出相应的提示信息。 运行结果在服务端使用Python3运行服务端程序： root@ubuntu:~# python3 vpnserver.py Server listen on 0.0.0.0:2003... 服务正常监听，然后客户端启动客户端程序： [root@localhost ~]# python vpnclient.py 192.168.4.233 2003 Start connect to server... Local ip: 10.0.0.2 Peer ip: 10.0.0.1 Connect to server successful [root@localhost ~]# ifconfig tun0 tun0 Link encap:UNSPEC HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 inet addr:10.0.0.2 P-t-P:10.0.0.1 Mask:255.255.255.255 UP POINTOPOINT RUNNING NOARP MULTICAST MTU:1400 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:500 RX bytes:0 (0.0 b) TX bytes:0 (0.0 b) 客户端连接成功后打印出连接信息，并且可以看到多出来一块 tun0 的虚拟网卡。 root@ubuntu:~# python3 vpnserver.py Server listen on 0.0.0.0:2003... [2018/05/26 13:47:13] from (192.168.4.6:58502) b&apos;4fb88ca224&apos; Clinet 192.168.4.6:58502 connect successful [2018/05/26 13:47:23] from (192.168.4.6:58502) b&apos;\x00&apos; [2018/05/26 13:47:33] from (192.168.4.6:58502) b&apos;\x00&apos; [2018/05/26 13:47:43] from (192.168.4.6:58502) b&apos;\x00&apos; [2018/05/26 13:47:53] from (192.168.4.6:58502) b&apos;\x00&apos; [2018/05/26 13:48:03] from (192.168.4.6:58502) b&apos;\x00&apos; [2018/05/26 13:48:13] from (192.168.4.6:58502) b&apos;\x00&apos; [2018/05/26 13:48:23] from (192.168.4.6:58502) b&apos;\x00&apos; [2018/05/26 13:48:33] from (192.168.4.6:58502) b&apos;\x00&apos; [2018/05/26 13:48:43] from (192.168.4.6:58502) b&apos;\x00&apos; root@ubuntu:~# ifconfig tun0 tun0 Link encap:UNSPEC HWaddr 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 inet addr:10.0.0.1 P-t-P:10.0.0.2 Mask:255.255.255.255 UP POINTOPOINT RUNNING NOARP MULTICAST MTU:1400 Metric:1 RX packets:0 errors:0 dropped:0 overruns:0 frame:0 TX packets:0 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:500 RX bytes:0 (0.0 B) TX bytes:0 (0.0 B) 可以看到服务端也打印出客户端连接成功的消息，以及打印出每次从客户端发来的数据包信息。同样也有一条到客户端的虚拟网卡。接着尝试服务端是否可以直接PING通客户端了。 root@ubuntu:~# ping 10.0.0.2 -c 2 PING 10.0.0.2 (10.0.0.2) 56(84) bytes of data. 64 bytes from 10.0.0.2: icmp_seq=1 ttl=64 time=0.814 ms 64 bytes from 10.0.0.2: icmp_seq=2 ttl=64 time=0.569 ms --- 10.0.0.2 ping statistics --- 2 packets transmitted, 2 received, 0% packet loss, time 999ms rtt min/avg/max/mdev = 0.569/0.691/0.814/0.125 ms [2018/05/26 13:51:40] to (192.168.4.6:58502) b&apos;\x00\x00\x08\x00E\x00\x00T\x19\xdd&apos; [2018/05/26 13:51:40] from (192.168.4.6:58502) b&apos;\x00\x00\x08\x00E\x00\x00T\x99V&apos; [2018/05/26 13:51:41] to (192.168.4.6:58502) b&apos;\x00\x00\x08\x00E\x00\x00T\x19\xe4&apos; [2018/05/26 13:51:41] from (192.168.4.6:58502) b&apos;\x00\x00\x08\x00E\x00\x00T\x99W&apos; 可以看到隧道是正常的，并且服务端打印出了去的两个ICMP包和回来的两个ICMP包，接着关闭客户端程序。 [2018/05/26 13:54:45] from (192.168.4.6:58502) b&apos;e&apos; Client 192.168.4.6:58502 is disconnect 服务端接收到了 b&#39;e&#39; 后打印客户端断开连接的消息，接着发现 tun0 这块虚拟网卡也消失了。 附录服务端程序就完成了，但是还是存在非常多的问题，比如用户认证的安全性，select 的性能和支持的最大客户端数量可以使用更好的 epoll 方式，但是 select 的平台兼容性比较强，如果考虑把程序移植到 Windows 的话可以继续使用（不考虑移植到Windows，但是Windows的tap驱动软件是否提供了这种可能？）。客户端断开后重连IP就会改变，如果能给客户端固定IP就好了，以及没法监控每个客户端的流量和控制客户端的速率。服务端应该采用配置文件的方式来更改运行的参数，并且应该能够使用守护进程的方式运行并处理 kill 命令发送的信号，这样这个程序就比较完善了。 注意：程序中多次出现的 b&#39;e&#39;, b&#39;r&#39; 这样的字符，这只是表示Python中 Byte 类型的数据。]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>vpn</tag>
        <tag>udp</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[愉快的用 Vim 写代码]]></title>
    <url>%2F2018%2F05%2F11%2F2018%2F%E6%84%89%E5%BF%AB%E7%9A%84%E7%94%A8Vim%E5%86%99%E4%BB%A3%E7%A0%81%2F</url>
    <content type="text"><![CDATA[简介 Vim 是一款高可定制的文本编辑器软件，而大多数人使用 vim 应该是从 Linux 的教科书里得知的吧。vim 来自于 vi 编辑器，而 vi 在1976年就发布了，经过如此多年的进化，可以说是非常成熟和强大了。但是 vim 的学习曲线比较陡，但是对 vim 学习的越深入，使用 vim 提升的效率就越高。这里是这几天对 vim 的学习，打造出的一款比较得心应手的编程工具。 环境在 Ubuntu 16.04 和 Ubuntu 18.04 上测试成功，理论上比较高的 Vim 版本都可以。Mac 没测试环境 ╮(╯▽╰)╭ ，Windows 就用 IDE 了，不想用 IDE 还可以使用 Notepad++ 或者 VScode。Vim 胜在是安装在服务器上的，这样需要远程连接服务器来写代码调试的话就非常方便了。先秀几张效果截图。 代码补全 文件分屏 文件操作 安装自己写的配置已经开源在了 Github 上 点击浏览 因为安装过程中需要联网安装插件，所以务必保证网络正常，并且已经安装 git 命令行工具。 输入以下命令安装：1source &lt;(curl -s https://raw.githubusercontent.com/yunfwe/vimconf/master/install.sh) Vim 的配置被安装到了家目录下的 .vimrc 文件和 .vim 目录，如果安装之前存在着两个目录，脚本将自动备份。如果想卸载也非常简单，手动删除家目录下的 .vimrc 和 .vim 即可，或者执行提供好的卸载脚本也可以：1source &lt;(curl -s https://raw.githubusercontent.com/yunfwe/vimconf/master/uninstall.sh) 配置Vim 的配置文件非常强大，是一种专门的 Vim Script 的语言编写，大部分的 Vim 插件也都是用这个语言写的 这里看看配置文件的内容，以及各内容的说明 &quot; curl -fLo ~/.vim/autoload/plug.vim --create-dirs https://raw.githubusercontent.com/junegunn/vim-plug/master/plug.vim &quot; vim -c &quot;PlugInstall&quot; -c &quot;q&quot; -c &quot;q&quot; &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 使用plug &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; call plug#begin(&apos;~/.vim/plugged&apos;) Plug &apos;scrooloose/nerdtree&apos; &quot; 目录树插件 Plug &apos;vim-airline/vim-airline&apos; &quot; 状态栏插件 Plug &apos;vim-airline/vim-airline-themes&apos; &quot; 状态栏主题插件 Plug &apos;joshdick/onedark.vim&apos; &quot; 状态栏主题使用的颜色 Plug &apos;jiangmiao/auto-pairs&apos; &quot; 自动补全引号括号 Plug &apos;vim-scripts/SuperTab&apos; &quot; 提高Tab键能力的插件 &quot;Plug &apos;vim-scripts/c.vim&apos; &quot; 官方C语言插件 Plug &apos;rkulla/pydiction&apos; &quot; 轻量级的Python补全插件 Plug &apos;luochen1990/rainbow&apos; &quot; 为不同的括号添加颜色的插件 call plug#end() &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; Vim 的配置文件中，用双引号开头表示注释，是被 Vim 忽略的，Vim 安装插件最简单的方法就是使用插件管理器，但是插件管理器也是 Vim 的一个插件，所以这个插件就需要手动安装了，因此安装脚本的开头就是从 Github 上获取这个插件管理器，然后放到相应的目录中后 先用一个简单的只包含需要安装其他插件指令的配置文件启动 Vim 并安装其他插件。 插件大多数人都选择直接从 github 上获取，所以插件名就可以不用写 github 的全路径，只需要用户名和仓库名就可以了，Vim 的插件管理器还有非常多的种类，但是 vim-plug 可以并发下载安装插件，比其他种类的更轻，更快。 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 实用设置 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;当打开vim且没有文件时自动打开NERDTree autocmd vimenter * if !argc() | NERDTree | endif &quot; 只剩 NERDTree时自动关闭 autocmd bufenter * if (winnr(&quot;$&quot;) == 1 &amp;&amp; exists(&quot;b:NERDTreeType&quot;) &amp;&amp; b:NERDTreeType == &quot;primary&quot;) | q | endif set autoread &quot; 设置当文件被改动时自动载入 if has(&quot;autocmd&quot;) au BufReadPost * if line(&quot;&apos;\&quot;&quot;) &gt; 1 &amp;&amp; line(&quot;&apos;\&quot;&quot;) &lt;= line(&quot;$&quot;) | exe &quot;normal! g&apos;\&quot;&quot; | endif endif &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 编码设置 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; set langmenu=zh_CN.UTF-8 set helplang=cn set termencoding=utf-8 set encoding=utf8 set fileencodings=utf8,ucs-bom,gbk,cp936,gb2312,gb18030 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 通用设置 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; let mapleader = &quot;,&quot; &quot; 定义&lt;leader&gt;键 set nocompatible &quot; 设置不兼容原始vi模式 filetype on &quot; 设置开启文件类型侦测 filetype plugin on &quot; 设置加载对应文件类型的插件 set noeb &quot; 关闭错误的提示 syntax enable &quot; 开启语法高亮功能 syntax on &quot; 自动语法高亮 set t_Co=256 &quot; 开启256色支持 set cmdheight=1 &quot; 设置命令行的高度 set showcmd &quot; select模式下显示选中的行数 set scrolloff=3 &quot; 光标移动到buffer的顶部和底部时保持3行距离 set ruler &quot; 总是显示光标位置 set laststatus=2 &quot; 总是显示状态栏 set number &quot; 开启行号显示 set cursorline &quot; 高亮显示当前行 set whichwrap+=&lt;,&gt;,h,l &quot; 设置光标键跨行 set virtualedit=block,onemore &quot; 允许光标出现在最后一个字符的后面 set incsearch &quot; 实时搜索 set mouse-=a &quot; 不允许使用鼠标操作 set noeb vb t_vb= &quot; 关闭终端响铃 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 代码缩进和排版 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; set autoindent &quot; 设置自动缩进 set cindent &quot; 设置使用C/C++语言的自动缩进方式 set cinoptions=g0,:0,N-s,(0 &quot; 设置C/C++语言的具体缩进方式 set smartindent &quot; 智能的选择对其方式 filetype indent on &quot; 自适应不同语言的智能缩进 set expandtab &quot; 将制表符扩展为空格 set tabstop=4 &quot; 设置编辑时制表符占用空格数 set shiftwidth=4 &quot; 设置格式化时制表符占用空格数 set softtabstop=4 &quot; 设置4个空格为制表符 set smarttab &quot; 在行和段开始处使用制表符 &quot;set nowrap &quot; 禁止折行 set wrap &quot; 自动折行 set iskeyword+=_,$,@,%,#,- &quot; 带有如下符号的单词不要被换行分割 set backspace=2 &quot; 使用回车键正常处理indent,eol,start等 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 代码补全 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; set wildmenu &quot; vim自身命名行模式智能补全 set completeopt-=preview &quot; 补全时不显示窗口，只显示补全列表 set matchtime=1 &quot; 匹配括号高亮的时间（单位是十分之一秒） &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 代码折叠 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; set foldmethod=syntax &quot; 设置基于语法进行代码折叠 set nofoldenable &quot; 关闭折叠代码 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 缓存设置 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; set nobackup &quot; 设置不备份 set noswapfile &quot; 禁止生成临时文件 set autoread &quot; 文件在vim之外修改过，自动重新读入 set autowrite &quot; 设置自动保存 set confirm &quot; 在处理未保存或只读文件的时候，弹出确认 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; 正如每个配置项的注释所言，这个是对 Vim 编辑器的一些配置。 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 新文件标题 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot;新建.c,.h,.sh,.java文件，自动插入文件头 autocmd BufNewFile *.cpp,*.[ch],*.sh,*.rb,*.java,*.py exec &quot;:call SetTitle()&quot; &quot;&quot;定义函数SetTitle，自动插入文件头 func SetTitle() &quot;如果文件类型为.sh文件 if &amp;filetype == &apos;sh&apos; call setline(1,&quot;\#!/bin/bash&quot;) call append(line(&quot;.&quot;), &quot;&quot;) elseif &amp;filetype == &apos;python&apos; call setline(1,&quot;#!/usr/bin/env python&quot;) call append(line(&quot;.&quot;),&quot;# -*- coding:utf-8 -*-&quot;) call append(line(&quot;.&quot;)+1,&quot;# Author: root date: &quot;.strftime(&quot;%Y-%m-%d&quot;)) call append(line(&quot;.&quot;)+2, &quot;&quot;) call append(line(&quot;.&quot;)+3, &quot;&quot;) elseif &amp;filetype == &apos;ruby&apos; call setline(1,&quot;#!/usr/bin/env ruby&quot;) call append(line(&quot;.&quot;),&quot;# encoding: utf-8&quot;) call append(line(&quot;.&quot;)+1, &quot;&quot;) call append(line(&quot;.&quot;)+2, &quot;&quot;) &quot; elseif &amp;filetype == &apos;mkd&apos; &quot; call setline(1,&quot;&lt;head&gt;&lt;meta charset=\&quot;UTF-8\&quot;&gt;&lt;/head&gt;&quot;) else call setline(1, &quot;/*************************************************************************&quot;) call append(line(&quot;.&quot;), &quot; &gt; File Name: &quot;.expand(&quot;%&quot;)) call append(line(&quot;.&quot;)+1, &quot; &gt; Author: root&quot;) call append(line(&quot;.&quot;)+2, &quot; &gt; Mail: root@localhost.com&quot;) call append(line(&quot;.&quot;)+3, &quot; &gt; Created Time: &quot;.strftime(&quot;%Y-%m-%d&quot;)) call append(line(&quot;.&quot;)+4, &quot; ************************************************************************/&quot;) call append(line(&quot;.&quot;)+5, &quot;&quot;) endif if expand(&quot;%:e&quot;) == &apos;cpp&apos; call append(line(&quot;.&quot;)+6, &quot;#include &lt;iostream&gt;&quot;) call append(line(&quot;.&quot;)+7, &quot;using namespace std;&quot;) call append(line(&quot;.&quot;)+8, &quot;&quot;) call append(line(&quot;.&quot;)+9, &quot;&quot;) endif if &amp;filetype == &apos;c&apos; call append(line(&quot;.&quot;)+6, &quot;#include &lt;stdio.h&gt;&quot;) call append(line(&quot;.&quot;)+7, &quot;&quot;) call append(line(&quot;.&quot;)+8, &quot;&quot;) endif if expand(&quot;%:e&quot;) == &apos;h&apos; call append(line(&quot;.&quot;)+6, &quot;#ifndef _&quot;.toupper(expand(&quot;%:r&quot;)).&quot;_H&quot;) call append(line(&quot;.&quot;)+7, &quot;#define _&quot;.toupper(expand(&quot;%:r&quot;)).&quot;_H&quot;) call append(line(&quot;.&quot;)+8, &quot;#endif&quot;) call append(line(&quot;.&quot;)+9, &quot;&quot;) endif if &amp;filetype == &apos;java&apos; call append(line(&quot;.&quot;)+6,&quot;public class &quot;.expand(&quot;%:r&quot;)) call append(line(&quot;.&quot;)+7,&quot;&quot;) endif &quot;新建文件后，自动定位到文件末尾 endfunc autocmd BufNewFile * normal G &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; 这段配置就用到了定义函数，逻辑判断等语法，作用是在 Vim 编辑新文件的时候，根据文件名来自动生成不同的文件头部信息，为了方便，可以把代码中的 Author 和 Mail 配置为自己的信息，这样就不用每次创建了文件之后再修改了。 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 键盘命令 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; nnoremap &lt;C-N&gt; :bn&lt;CR&gt; nnoremap &lt;C-P&gt; :bp&lt;CR&gt; nmap &lt;Esc&gt;&lt;Esc&gt;&lt;Esc&gt; :qa!&lt;CR&gt; &quot; 连续三个Esc不保存退出全部 &quot; 切换NERDTree map &lt;F3&gt; :NERDTreeToggle&lt;CR&gt; :autocmd BufRead,BufNewFile *.dot map &lt;F5&gt; :w&lt;CR&gt;:!dot -Tjpg -o %&lt;.jpg % &amp;&amp; eog %&lt;.jpg &lt;CR&gt;&lt;CR&gt; &amp;&amp; exec &quot;redr!&quot; &quot;C，C++ 按F5编译运行 map &lt;F5&gt; :call CompileRunGcc()&lt;CR&gt; func! CompileRunGcc() exec &quot;w&quot; if &amp;filetype == &apos;c&apos; &quot;exec &quot;!g++ % -o %&lt;&quot; &quot;exec &quot;!time ./%&lt;&quot; exec &quot;!g++ % -o %&lt; &amp;&amp; time ./%&lt;&quot; elseif &amp;filetype == &apos;cpp&apos; &quot;exec &quot;!g++ % -std=c++11 -o %&lt;&quot; &quot;exec &quot;!time ./%&lt;&quot; exec &quot;!g++ % -std=c++11 -o %&lt; &amp;&amp; time ./%&lt;&quot; elseif &amp;filetype == &apos;java&apos; &quot;exec &quot;!javac %&quot; &quot;exec &quot;!time java %&lt;&quot; exec &quot;!javac % &amp;&amp; time java %&lt;&quot; elseif &amp;filetype == &apos;sh&apos; :!time bash % elseif &amp;filetype == &apos;python&apos; exec &quot;!time python %&quot; elseif &amp;filetype == &apos;html&apos; exec &quot;!firefox % &amp;&quot; elseif &amp;filetype == &apos;go&apos; &quot; exec &quot;!go build %&lt;&quot; exec &quot;!time go run %&quot; elseif &amp;filetype == &apos;mkd&apos; exec &quot;!~/.vim/markdown.pl % &gt; %.html &amp;&quot; exec &quot;!firefox %.html &amp;&quot; endif endfunc &quot;代码调试 map &lt;F8&gt; :call Rungdb()&lt;CR&gt; func! Rungdb() exec &quot;w&quot; if &amp;filetype == &apos;cpp&apos; &quot;exec &quot;!g++ % -std=c++11 -g -o %&lt;&quot; &quot;exec &quot;!gdb ./%&lt;&quot; exec &quot;!g++ % -std=c++11 -g -o %&lt; &amp;&amp; gdb ./%&lt;&quot; elseif &amp;filetype == &apos;c&apos; &quot;exec &quot;!gcc % -g -o %&lt;&quot; &quot;exec &quot;!gdb ./%&lt;&quot; exec &quot;!gcc % -g -o %&lt; &amp;&amp; gdb ./%&lt;&quot; elseif &amp;filetype == &apos;python&apos; exec &quot;!python -m pdb %&quot; elseif &amp;filetype == &apos;go&apos; &quot;exec &quot;!go build -o %&lt; %&quot; &quot;exec &quot;!gdb ./%&lt;&quot; exec &quot;!go build -o %&lt; % &amp;&amp; gdb ./%&lt;&quot; endif endfunc &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; 定义了一些快捷键，比如在同时编辑多个文件时 Ctrl + p 和 Ctrl + n 可以切换到上一个或下一个，连击三次 Esc 会不保存退出全部文件， F3 会切换是否显示文件目录树，F5 编译运行和 F8 调试。还有就是插件自己的快捷键，比如使用 Ctrl + w + w 可以切换窗口，使用 s 或者 i 可以分割窗口。使用 m 可以显示文件操作菜单，这些都是 NERDTree 目录树插件的快捷键，还可以自己按照 Vim 的规则定义一些方便的快捷键。 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 主题 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; set background=dark let g:onedark_termcolors=256 colorscheme onedark 这里就是应用了下载的第一个插件的那个主题，感觉非常养眼，不 是没那么毁眼。其中有几个特殊的字符需要特殊的几种字体才能看到，我喜欢用的 Consolas 字体是没问题的。 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; 插件配置 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; airline let g:airline_theme=&quot;onedark&quot; let g:airline_powerline_fonts = 1 let g:airline#extensions#tabline#enabled = 1 if !exists(&apos;g:airline_symbols&apos;) let g:airline_symbols = {} endif let g:airline_left_sep = &apos;&apos; let g:airline_left_alt_sep = &apos;&apos; let g:airline_right_sep = &apos;&apos; let g:airline_right_alt_sep = &apos;&apos; &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; nerdtree &quot;let g:NERDTreeFileExtensionHighlightFullName = 1 &quot;let g:NERDTreeExactMatchHighlightFullName = 1 &quot;let g:NERDTreePatternMatchHighlightFullName = 1 &quot;let g:NERDTreeHighlightFolders = 1 &quot;let g:NERDTreeHighlightFoldersFullName = 1 &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; pydiction let g:pydiction_location = &apos;~/.vim/plugged/pydiction/complete-dict&apos; &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; &quot; rainbow let g:rainbow_active = 1 &quot;0 if you want to enable it later via :RainbowToggle &quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot;&quot; 顾名思义，就是针对安装的插件的配置了，不同的插件会读取其中不同的值来产生不同的行为。 附录如果体验了和平常不同的 Vim 后对它产生了浓厚的兴趣，那么对 Vim 的使用进行一次深入的学习那就最好不过了。 官方中文文档在线 官方中文文档下载]]></content>
      <categories>
        <category>Vim</category>
      </categories>
      <tags>
        <tag>vim</tag>
        <tag>linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[OpenVPN 穿越NAT网络]]></title>
    <url>%2F2018%2F05%2F03%2F2018%2FOpenVPN%20%E7%A9%BF%E8%B6%8ANAT%E7%BD%91%E7%BB%9C%2F</url>
    <content type="text"><![CDATA[简介 想和朋友联机打局域网游戏，在家需要连接到公司办公，如果是机密信息还要保证数据的加密传输，而且还要简单稳定好用，那么OpenVPN绝对是不二之选，OpenVPN是一个基于OpenSSL库的应用层VPN实现，完全开源免费，而且支持的平台众多，Linux平台，Windows平台，Android和IOS平台也都支持。 环境想要连通两个NAT后的网络，比如家里的局域网和公司的局域网就必须存在一个公网IP来做数据中转。这里使用阿里云的一台主机来做数据中转。 系统使用的是 Ubuntu 16.04.03 64位OpenVPN 使用最新的稳定版 2.3.18 点此下载 如果下载不了，可能需要自备梯子或者从其他地方下载。如果使用的 CentOS 系列安装可能需要先关闭 SElinux。 安装也可以选择直接从官方仓库中下载安装使用。 解决依赖1apt-get install make gcc g++ libssl-dev liblzo2-dev libpam-dev unzip 这里只适用于 Ubuntu 系统 编译安装1234567tar xf openvpn-2.3.18.tar.xzcd openvpn-2.3.18./configure --prefix=/usr/local/openvpnmake -j4 &amp;&amp; make installmkdir /etc/openvpncp -rf sample/ /etc/openvpn/ # 拷贝配置文件模块cp /etc/openvpn/sample/sample-config-files/server.conf /etc/openvpn/ 由于系统环境的复杂，配置过程中可能会缺少某些库的头文件，只需要找到这些头文件所在的包然后安装下就好了。 配置证书服务端证书配置easy-rsa123cd /etc/openvpngit clone -b release/2.x https://github.com/OpenVPN/easy-rsa.gitcd /etc/openvpn/easy-rsa/easy-rsa/2.0 然后编辑 vars 文件，修改下列内容的值为随意内容。需要注意的是，值不可以是空的。 export KEY_COUNTRY=&quot;US&quot; export KEY_PROVINCE=&quot;California&quot; export KEY_CITY=&quot;SanFrancisco&quot; export KEY_ORG=&quot;Fort-Funston&quot; export KEY_EMAIL=&quot;me@myhost.mydomain&quot; export KEY_OU=&quot;MyOrganizationalUnit&quot; 我这里修改为了如下内容 export KEY_COUNTRY=&quot;CN&quot; export KEY_PROVINCE=&quot;BeiJing&quot; export KEY_CITY=&quot;BeiJing&quot; export KEY_ORG=&quot;wu&quot; export KEY_EMAIL=&quot;admin@localhost.com&quot; export KEY_OU=&quot;openvpn&quot; 接着修改 export KEY_NAME=&quot;EasyRSA&quot; 这句话，将 EasyRSA 改为自己喜欢的名字，这里就简单的使用 server，修改后就可以保存退出了。 创建根证书123source vars./clean-all./build-ca 这一步一路的回车就好，因为已经在 vars 文件中配置过了。 root@ubuntu:/etc/openvpn/easy-rsa/easy-rsa/2.0# ./build-ca Generating a 2048 bit RSA private key ............................................................+++ ..........................+++ writing new private key to &apos;ca.key&apos; ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter &apos;.&apos;, the field will be left blank. ----- Country Name (2 letter code) [CN]: State or Province Name (full name) [BeiJing]: Locality Name (eg, city) [BeiJing]: Organization Name (eg, company) [wu]: Organizational Unit Name (eg, section) [openvpn]: Common Name (eg, your name or your server&apos;s hostname) [wu CA]: Name [server]: Email Address [admin@localhost.com]: 颁发服务端证书1./build-key-server server 这个 server 就是刚才 export KEY_NAME=&quot;EasyRSA&quot; 中指定的名字。之后就是一路的回车，当遇到两个问答的时候都回答 y 就可以了。 root@ubuntu:/etc/openvpn/easy-rsa/easy-rsa/2.0# ./build-key-server server Generating a 2048 bit RSA private key .......................+++ ..............+++ writing new private key to &apos;server.key&apos; ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter &apos;.&apos;, the field will be left blank. ----- Country Name (2 letter code) [CN]: State or Province Name (full name) [BeiJing]: Locality Name (eg, city) [BeiJing]: Organization Name (eg, company) [wu]: Organizational Unit Name (eg, section) [openvpn]: Common Name (eg, your name or your server&apos;s hostname) [server]: Name [server]: Email Address [admin@localhost.com]: Please enter the following &apos;extra&apos; attributes to be sent with your certificate request A challenge password []: An optional company name []: Using configuration from /etc/openvpn/easy-rsa/easy-rsa/2.0/openssl-1.0.0.cnf Check that the request matches the signature Signature ok The Subject&apos;s Distinguished Name is as follows countryName :PRINTABLE:&apos;CN&apos; stateOrProvinceName :PRINTABLE:&apos;BeiJing&apos; localityName :PRINTABLE:&apos;BeiJing&apos; organizationName :PRINTABLE:&apos;wu&apos; organizationalUnitName:PRINTABLE:&apos;openvpn&apos; commonName :PRINTABLE:&apos;server&apos; name :PRINTABLE:&apos;server&apos; emailAddress :IA5STRING:&apos;admin@localhost.com&apos; Certificate is to be certified until Apr 30 07:50:21 2028 GMT (3650 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Data Base Updated 生成Diffie-Hellman文件 Diffie-Hellman是一种确保共享KEY安全穿越不安全网络的方法 12./build-dh/usr/local/openvpn/sbin/openvpn --genkey --secret keys/ta.key 这一步需要的时间会长一些。 客户端证书颁发客户端证书使用 build-key 命令可以颁发一个不带密码的证书，如果需要带密码保护的证书，可以使用 build-key-pass 命令。这里使用不带密码的凭证，证书名为 client1 1./build-key client1 同理 一路回车后最后两个问答输入 y root@ubuntu:/etc/openvpn/easy-rsa/easy-rsa/2.0# ./build-key client1 Generating a 2048 bit RSA private key ....................+++ ..............................+++ writing new private key to &apos;client1.key&apos; ----- You are about to be asked to enter information that will be incorporated into your certificate request. What you are about to enter is what is called a Distinguished Name or a DN. There are quite a few fields but you can leave some blank For some fields there will be a default value, If you enter &apos;.&apos;, the field will be left blank. ----- Country Name (2 letter code) [CN]: State or Province Name (full name) [BeiJing]: Locality Name (eg, city) [BeiJing]: Organization Name (eg, company) [wu]: Organizational Unit Name (eg, section) [openvpn]: Common Name (eg, your name or your server&apos;s hostname) [client1]: Name [server]: Email Address [admin@localhost.com]: Please enter the following &apos;extra&apos; attributes to be sent with your certificate request A challenge password []: An optional company name []: Using configuration from /etc/openvpn/easy-rsa/easy-rsa/2.0/openssl-1.0.0.cnf Check that the request matches the signature Signature ok The Subject&apos;s Distinguished Name is as follows countryName :PRINTABLE:&apos;CN&apos; stateOrProvinceName :PRINTABLE:&apos;BeiJing&apos; localityName :PRINTABLE:&apos;BeiJing&apos; organizationName :PRINTABLE:&apos;wu&apos; organizationalUnitName:PRINTABLE:&apos;openvpn&apos; commonName :PRINTABLE:&apos;client1&apos; name :PRINTABLE:&apos;server&apos; emailAddress :IA5STRING:&apos;admin@localhost.com&apos; Certificate is to be certified until Apr 30 07:58:09 2028 GMT (3650 days) Sign the certificate? [y/n]:y 1 out of 1 certificate requests certified, commit? [y/n]y Write out database with 1 new entries Data Base Updated 安置证书现在所有的证书都在 keys 目录中，为了方便使用，将 keys 目录直接软链到 /etc/openvpn/ 下 1ln -s /etc/openvpn/easy-rsa/easy-rsa/2.0/keys/ /etc/openvpn/keys 到这里，安装的部分就结束了。 使用服务端配置配置文件编辑服务端配置文件：/etc/openvpn/server.conf 修改内容如下： port 2001 proto udp dev tun ca keys/ca.crt cert keys/server.crt key keys/server.key dh keys/dh2048.pem server 10.0.0.0 255.255.255.0 ifconfig-pool-persist ipp.txt push &quot;route 10.0.0.0 255.255.255.0&quot; client-to-client keepalive 10 120 tls-auth keys/ta.key 0 cipher AES-256-CBC auth SHA256 key-direction 0 user nobody group nogroup persist-key persist-tun status openvpn-status.log verb 3 需要注意的是，这里使用 udp 的 2001 端口，在阿里云等环境，还需要配置相应的安全组策略来开放这个端口的流量。 Linux配置开启 Linux 的内核转发功能，编辑 /etc/sysctl.conf 文件，取消掉 #net.ipv4.ip_forward=1 之前的注释。然后执行 sysctl -p 命令。 root@ubuntu:/etc/openvpn# sysctl -p net.ipv4.ip_forward = 1 vm.swappiness = 0 net.ipv4.neigh.default.gc_stale_time = 120 net.ipv4.conf.all.rp_filter = 0 net.ipv4.conf.default.rp_filter = 0 net.ipv4.conf.default.arp_announce = 2 net.ipv4.conf.lo.arp_announce = 2 net.ipv4.conf.all.arp_announce = 2 net.ipv4.tcp_max_tw_buckets = 5000 net.ipv4.tcp_syncookies = 1 net.ipv4.tcp_max_syn_backlog = 1024 net.ipv4.tcp_synack_retries = 2 net.ipv6.conf.all.disable_ipv6 = 1 net.ipv6.conf.default.disable_ipv6 = 1 net.ipv6.conf.lo.disable_ipv6 = 1 还需要确保 iptable 的 FORWARD 链允许数据转发 1iptables -P FORWARD ACCEPT 启动OpenVPN1/usr/local/openvpn/sbin/openvpn --cd /etc/openvpn/ --config /etc/openvpn/server.conf 以调试模式启动 OpenVPN，如果启动过程中有什么错误的话会显示在输出里，确定没有问题了，可以添加 --daemon 参数在后台运行 OpenVPN root@ubuntu:/etc/openvpn# /usr/local/openvpn/sbin/openvpn --cd /etc/openvpn/ --config /etc/openvpn/server.conf Thu May 3 16:32:55 2018 OpenVPN 2.3.18 x86_64-unknown-linux-gnu [SSL (OpenSSL)] [LZO] [EPOLL] [MH] [IPv6] built on May 3 2018 Thu May 3 16:32:55 2018 library versions: OpenSSL 1.0.2g 1 Mar 2016, LZO 2.08 Thu May 3 16:32:55 2018 Diffie-Hellman initialized with 2048 bit key Thu May 3 16:32:55 2018 Control Channel Authentication: using &apos;keys/ta.key&apos; as a OpenVPN static key file Thu May 3 16:32:55 2018 Outgoing Control Channel Authentication: Using 160 bit message hash &apos;SHA1&apos; for HMAC authentication Thu May 3 16:32:55 2018 Incoming Control Channel Authentication: Using 160 bit message hash &apos;SHA1&apos; for HMAC authentication Thu May 3 16:32:55 2018 Socket Buffers: R=[212992-&gt;212992] S=[212992-&gt;212992] Thu May 3 16:32:55 2018 ROUTE_GATEWAY 172.31.143.253/255.255.240.0 IFACE=eth0 HWADDR=00:16:3e:08:fb:5f Thu May 3 16:32:55 2018 TUN/TAP device tun0 opened Thu May 3 16:32:55 2018 TUN/TAP TX queue length set to 100 Thu May 3 16:32:55 2018 do_ifconfig, tt-&gt;ipv6=0, tt-&gt;did_ifconfig_ipv6_setup=0 Thu May 3 16:32:55 2018 /sbin/ifconfig tun0 10.0.0.1 pointopoint 10.0.0.2 mtu 1500 Thu May 3 16:32:55 2018 /sbin/route add -net 10.0.0.0 netmask 255.255.255.0 gw 10.0.0.2 Thu May 3 16:32:55 2018 GID set to nogroup Thu May 3 16:32:55 2018 UID set to nobody Thu May 3 16:32:55 2018 UDPv4 link local (bound): [undef] Thu May 3 16:32:55 2018 UDPv4 link remote: [undef] Thu May 3 16:32:55 2018 MULTI: multi_init called, r=256 v=256 Thu May 3 16:32:55 2018 IFCONFIG POOL: base=10.0.0.4 size=62, ipv6=0 Thu May 3 16:32:55 2018 IFCONFIG POOL LIST Thu May 3 16:32:55 2018 Initialization Sequence Completed 使用 ifconfig 命令，应该可以看到多出来了一块 tun0 的网卡。 制作客户端ovpn文件为了方便客户端的连接，可以在服务端制作好客户端的配置文件，只需将文件下发给客户端，就可以直接使用了。这个文件的拓展名是 ovpn 1234cd /etc/openvpn/mkdir make_clientscp sample/sample-config-files/client.conf make_clients/cd make_clients 然后编辑 client.conf 为以下内容，其中连接服务器的 IP 需要修改为自己的。 client dev tun proto udp remote 47.xxx.xxx.155 2001 resolv-retry infinite nobind user nobody group nogroup persist-key persist-tun remote-cert-tls server cipher AES-256-CBC auth SHA256 key-direction 1 verb 3 explicit-exit-notify 1 还记得刚才颁发的客户端证书 client1 吧，先为这个证书生成一份配置文件。使用一个自动化脚本来完成配置文件的创建。新建 make_config.sh 脚本，然后写入如下内容 123456789101112131415161718#!/bin/bash# First argument: Client identifierKEY_DIR=/etc/openvpn/keysOUTPUT_DIR=./filesBASE_CONFIG=./client.confcat $&#123;BASE_CONFIG&#125; \ &lt;(echo -e '&lt;ca&gt;') \ $&#123;KEY_DIR&#125;/ca.crt \ &lt;(echo -e '&lt;/ca&gt;\n&lt;cert&gt;') \ $&#123;KEY_DIR&#125;/$&#123;1&#125;.crt \ &lt;(echo -e '&lt;/cert&gt;\n&lt;key&gt;') \ $&#123;KEY_DIR&#125;/$&#123;1&#125;.key \ &lt;(echo -e '&lt;/key&gt;\n&lt;tls-auth&gt;') \ $&#123;KEY_DIR&#125;/ta.key \ &lt;(echo -e '&lt;/tls-auth&gt;') \ &gt; $&#123;OUTPUT_DIR&#125;/$&#123;1&#125;.ovpn 开始创建 123chmod +x make_config.shmkdir files./make_config.sh client1 这个 client1 就是用户证书的名字，也只有存在才可以创建成功。脚本正常执行后可以在 files 目录中看到 client1.ovpn 文件，这个文件中已经包含了客户端所需要的密钥以及连接信息，所以只需要将这个文件发给用户，然后在客户端上导入就可以直接连接了。不过要注意，基于密钥的认证方式，每个密钥只允许同时一台机器连接使用。 客户端连接首先需要将生成的 ovpn 文件发送给用户的机器上，然后还需要安装适合当前平台的客户端。 在 Linux 上登陆 OpenVPNLinux上编译出的 openvpn 程序既可以是服务端，也可以是客户端，所以只需要再下载下来源码包编译一次就可以了。连接也非常方便，直接使用 openvpn --config client1.ovpn 即可。如果想后台运行，也只需要添加 --daemon 参数。 当连接成功后，可以看到多出来一块 tun0 的网卡 tun0: flags=4305&lt;UP,POINTOPOINT,RUNNING,NOARP,MULTICAST&gt; mtu 1500 inet 10.0.0.6 netmask 255.255.255.255 destination 10.0.0.5 inet6 fe80::bf9f:2316:1d8c:83d1 prefixlen 64 scopeid 0x20&lt;link&gt; unspec 00-00-00-00-00-00-00-00-00-00-00-00-00-00-00-00 txqueuelen 100 (UNSPEC) RX packets 1 bytes 84 (84.0 B) RX errors 0 dropped 0 overruns 0 frame 0 TX packets 5 bytes 276 (276.0 B) TX errors 0 dropped 0 overruns 0 carrier 0 collisions 0 服务端IP为 10.0.0.1，可以看看能不能PING通 root@raspberrypi:~# ping 10.0.0.1 -c 4 PING 10.0.0.1 (10.0.0.1) 56(84) bytes of data. 64 bytes from 10.0.0.1: icmp_seq=1 ttl=64 time=62.2 ms 64 bytes from 10.0.0.1: icmp_seq=2 ttl=64 time=61.7 ms 64 bytes from 10.0.0.1: icmp_seq=3 ttl=64 time=68.1 ms 64 bytes from 10.0.0.1: icmp_seq=4 ttl=64 time=68.1 ms --- 10.0.0.1 ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3005ms rtt min/avg/max/mdev = 61.782/65.097/68.185/3.103 ms 在 Windows 上登陆 OpenVPNWindows 客户端需要在官方下载，下载时可能需要自备梯子，下载地址：点此打开 下载安装成功后，第一次打开会弹出一个窗口，说没有可以读取的配置文件，这时候只需右击系统状态栏里OpenVPN的小图标，然后选择 Import file... 打开刚才生成的 client1.ovpn 就可以了。然后再次右击小图标，点击 Connect，等弹出的窗口自动退出口，系统也会通知 OpenVPN 是否连接成功。 在 Windows 上也是可以PING通服务器的 C:\Users\yunfwe\Desktop&gt;ping 10.0.0.1 正在 Ping 10.0.0.1 具有 32 字节的数据: 来自 10.0.0.1 的回复: 字节=32 时间=68ms TTL=64 来自 10.0.0.1 的回复: 字节=32 时间=71ms TTL=64 来自 10.0.0.1 的回复: 字节=32 时间=62ms TTL=64 来自 10.0.0.1 的回复: 字节=32 时间=60ms TTL=64 10.0.0.1 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)， 往返行程的估计时间(以毫秒为单位): 最短 = 60ms，最长 = 71ms，平均 = 65ms 在 Android 上登陆 OpenVPN在谷歌应用商店里可以找到一款名为 openvpn-connect 的apk，使用这个软件也可以通过导入ovpn文件的方式连接到服务器。 附录]]></content>
      <categories>
        <category>OpenVPN</category>
      </categories>
      <tags>
        <tag>openvpn</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[ESP8266 WiFi开发板]]></title>
    <url>%2F2018%2F04%2F29%2F2018%2FESP8266%20WiFi%E5%BC%80%E5%8F%91%E6%9D%BF%2F</url>
    <content type="text"><![CDATA[简介 ESP8266串口WIFI模块，超低成本（只需10RMB左右）的物联网开发板，而且有非常丰富的引脚，超低的功耗。ESP8266内部有一个完整的 32bit MCU 核心，主频支持80Mz和160Mz。这个模块支持 IEEE802.11 b/g/n 协议，完整的 TCP/IP 协议栈，可以为现有的设备添加联网功能。而且除了C语言，还可以使用 Python, JavaScript, Lua脚本语言来为ESP8266写程序，极大降低了学习ESP8266的门槛。 环境在 Win10 下进行开发，因为更熟悉 Python 所以使用 MicroPython 来进行开发。 硬件 ESP8266开发板 这里使用基于 ESP8266-12F 的 D1 WiFi UNO R3 开发板。 数据线 普通安卓的数据线就可以，D1 开发板集成了 CH340 USB转TTL芯片。 如果是其他系统的话，需要确保 CH340 的驱动有安装。 D1 WiFi UNO R3 开发板： 软件 esptool 固件烧录工具 PuTTY 串口连接工具 esp8266 MicroPython固件 点此下载 烧录固件esptool 需要Python运行环境的支持，所以需要提前安装 Python 然后配置好环境变量，或者也可以下载其他的固件烧写工具。 1pip install esptool 装好之后从设备管理器中查看端口，如果是linux环境，应该是 /dev/ttyUSB*，然后先使用 esptool.py 命令擦除固件数据。 1esptool.py --port COM4 erase_flash esptool.py v2.3.1 Connecting.... Detecting chip type... ESP8266 Chip is ESP8266EX Features: WiFi Uploading stub... Running stub... Stub running... Erasing flash (this may take a while)... Chip erase completed successfully in 9.7s Hard resetting via RTS pin... 接着就可以将下载好的固件文件烧录到板子里了，固件的bin文件要选择实际的文件。 1esptool.py --port COM4 --baud 460800 write_flash --flash_size=detect 0 esp8266.bin esptool.py v2.3.1 Connecting.... Detecting chip type... ESP8266 Chip is ESP8266EX Features: WiFi Uploading stub... Running stub... Stub running... Changing baud rate to 460800 Changed. Configuring flash size... Auto-detected Flash size: 4MB Flash params set to 0x0040 Compressed 600888 bytes to 392073... Wrote 600888 bytes (392073 compressed) at 0x00000000 in 8.8 seconds (effective 546.1 kbit/s)... Hash of data verified. Leaving... Hard resetting via RTS pin... 烧录成功后就可以打开PuTTY，设置好COM口，波特率 115200 然后连接了。 [开头这里乱码正常]#4 ets_task(40100130, 3, 3fff837c, 4) OSError: [Errno 2] ENOENT MicroPython v1.9.3-8-g63826ac5c on 2017-11-01; ESP module with ESP8266 Type &quot;help()&quot; for more information. &gt;&gt;&gt; 使用MicroPython 通过 MicroPython 的使用一些代码来认识下 ESP8266 的硬件 MicroPython 简单认识MicroPython 使用Python3的语法，使用 help(&#39;modules&#39;) 命令可以看到支持的所有模块， &gt;&gt;&gt; help(&apos;modules&apos;) __main__ http_client_ssl sys urandom _boot http_server time ure _onewire http_server_ssl uasyncio/__init__ urequests _webrepl inisetup uasyncio/core urllib/urequest apa102 json ubinascii uselect array lwip ucollections usocket btree machine uctypes ussl builtins math uerrno ustruct dht micropython uhashlib utime ds18x20 neopixel uheapq utimeq errno network uio uzlib esp ntptime ujson webrepl example_pub_button onewire umqtt/robust webrepl_setup example_sub_led os umqtt/simple websocket flashbdev port_diag uos websocket_helper framebuf select upip gc socket upip_utarfile http_client ssd1306 upysh Plus any modules on the filesystem &gt;&gt;&gt; 其中跟板子硬件相关的模块主要是 esp 和 machine，其他大多就是与网络有关的模块了，可以看出来还是比较丰富的。简单的测试了下，对Python3的语法支持还是比较完善的，除了基本的数据类型和语法甚至 lambda表达式、列表解析、装饰器、生成器也都支持。 具体使用查看 MicroPython官方文档 查看资源信息内存信息可以使用 micropython.mem_info() 获取 &gt;&gt;&gt; import micropython &gt;&gt;&gt; micropython.mem_info() stack: 2112 out of 8192 GC: total: 35968, used: 9744, free: 26224 No. of 1-blocks: 48, 2-blocks: 24, max blk sz: 264, max free sz: 1132 8K的栈，35K的堆。。。不过这资源对于它也是够了。 Flash大小可以使用 esp.flash_size() 获取 &gt;&gt;&gt; import esp &gt;&gt;&gt; str(esp.flash_size()/1024/1024) + &apos; MB&apos; &apos;4.0 MB&apos; 4MB的存储空间，除去系统占用的只是存放一些简单的程序脚本也完全够用了。 测试MCU的速度ESP8266内置的MCU主频支持80MHz和160MHz，那么测试下这样的速度到底有多快呢。 在终端使用 Ctrl + e 进入代码粘贴模式，然后 Ctrl + d 提交或者 Ctrl + c 取消，然后键入以下代码。 12345678910111213141516171819202122232425262728import timeimport machineimport micropythondef toTime(tus): ts = [' us', ' ms', ' s'] for t in ts: if tus &lt; 1000:return str(tus)+t tus = tus / 1000 @micropython.nativedef loop(count): t1 = time.ticks_us() for i in range(count): pass t2 = time.ticks_us()-t1 print('Loop %s times for %s'%(count, toTime(t2)))def loop_start(count=10000): cur_freq = machine.freq() machine.freq(80000000) freq = lambda :str(int(machine.freq()/1000000)) print('Present freq: %sMHz' % freq()) loop(count) machine.freq(160000000) print('Present freq: %sMHz' % freq()) loop(count) machine.freq(cur_freq) &gt;&gt;&gt; loop_start() Present freq: 80MHz Loop 10000 times for 30.567 ms Present freq: 160MHz Loop 10000 times for 15.299 ms &gt;&gt;&gt; 代码提交后调用 loop_start() 方法，可以看到在默认的 80MHz 下和调节到 160MHz 下的空循环10000次需要多长时间，差不多每次循环使用不到16微妙。其中 micropython.native 装饰器能让代码以机器码的速度运行，如果好奇的话可以试试没有这个装饰器的执行速度。 将板子重启后，修改代码去掉那个加速的装饰器，然后重新提交代码执行测试（重启后可能得退出PuTTY后重连才能操作），可以看到速度慢了十几倍。 &gt;&gt;&gt; loop_start() Present freq: 80MHz Loop 10000 times for 460.035 ms Present freq: 160MHz Loop 10000 times for 230.091 ms &gt;&gt;&gt; 网络功能 既然它是WiFi开发板，那么最大的特点应该是可以接入WiFi网络，并且通过网络和其他设备交换数据。 连接WiFi终端执行 help() 函数会显示一个基础的连接WiFi的方法，现在就来连接到一个WiFi试试。这里为了测试方便，用笔记本开了个热点给开发板用。 ESP8266跟连接WiFi相关的库是 network 库，先来看看这个库的使用 123456789import networkwlan = network.WLAN(network.STA_IF) # 创建一个WiFi对象wlan.active(True) # 激活接口wlan.scan() # 扫描目标wlan.isconnected() # 检查是否已经连接wlan.connect('zhzz', '12365470') # 连接到WiFiwlan.config('mac') # 获取接口的mac地址wlan.ifconfig() # 获取接口的IP/掩码/网关/DNS信息 ESP8266如果断线会自动重连，ifconfig() 方法不仅可以查看当前IP，还可以配置静态IP，只需要将 IP/netmask/gw/DNS 作为一个元组或列表传入即可。比如: 1wlan.ifconfig((&apos;192.168.137.2&apos;,&apos;255.255.255.0&apos;,&apos;192.168.137.1&apos;,&apos;119.29.29.29&apos;)) 修改后会立即生效，如果在 wlan.connect() 之前就配置好了静态IP，这样就不会再向路由器发起DHCP请求了。 C:\Users\yunfwe\Desktop&gt;ping 192.168.137.2 正在 Ping 192.168.137.2 具有 32 字节的数据: 来自 192.168.137.2 的回复: 字节=32 时间=1ms TTL=255 来自 192.168.137.2 的回复: 字节=32 时间=3ms TTL=255 来自 192.168.137.2 的回复: 字节=32 时间=1ms TTL=255 来自 192.168.137.2 的回复: 字节=32 时间=1ms TTL=255 192.168.137.2 的 Ping 统计信息: 数据包: 已发送 = 4，已接收 = 4，丢失 = 0 (0% 丢失)， 往返行程的估计时间(以毫秒为单位): 最短 = 1ms，最长 = 3ms，平均 = 1ms 只要连接WiFi成功后，再次重启开发板也会自动连接，不过配置的静态IP就丢失了，需要重新配置。如果不想让开发板在启动的时候自动连接WiFi，可以在使用后执行 wlan.active(False)。但是开发板还是保存了WiFi的连接信息，想彻底清除这个连接信息可以执行 wlan.connect(&#39;&#39;,&#39;&#39;)。 如果想看到更多的连接细节，可以启用系统的调式功能 123import espesp.osdebug(0) # 将调试信息重定向到UART(0)esp.osdebug(None) # 关闭调试信息 AP模式ESP8266除了可以连接WiFi外，还可以作为一个AP来使用 1234567wlan.disconnect() # 先断开先前的连接wlan.active(False) # 取消激活接口ap = network.WLAN(network.AP_IF) # 创建AP对象ap.active(True) # 激活APap.config(essid='esp8266',password='12345678', authmode=network.AUTH_WPA2_PSK) # AP的SSID和密码，认证方式使用wpa2# ap.config(essid='esp8266',authmode=network.AUTH_OPEN) # 或者创建没有密码的WiFi 如果想更改AP模式分配的网段，也可以使用 ap.ifconfig() 来设置。这个时候用手机或者电脑就可以连接到此设备了。 同时，ESP8266还支持 AP+STA 模式，这样就可以充当一个无线中继器了。还有 SmartConfig 技术，可以实现不连接开发板的情况下自动配置开发板连接WiFi，可惜比较遗憾的是，MicroPython 上并没有实现或者找到如何实现这样的功能。。。 WebREPLESP8266 还提供了一个在浏览器上远程打开 MicroPython 提示符的功能就是 WebREPL，而且在这个页面上还可以实现上传文件等功能，把自己写好的代码上传到开发板，然后让它开机运行。 打开这个功能非常简单，首先配置这个服务 1import webrepl_setup 执行后会询问你是否开机自启，输入 E 允许开机自启后需要配置一个连接密码来提高安全性，之后问你是否重启，输入 y 重启后可以看到提示符多了一行信息 WebREPL daemon started on ws://0.0.0.0:8266 Started webrepl in normal mode OSError: [Errno 2] ENOENT MicroPython v1.9.3-8-g63826ac5c on 2017-11-01; ESP module with ESP8266 Type &quot;help()&quot; for more information. &gt;&gt;&gt; 这个时候 可以打开官方提供的连接页面：点此打开，输入IP和端口，连接成功后如下 还记得刚才写的测试MCU速度的脚本吗，现在把这个脚本也加入到系统里吧，这样每次开机后都可以使用这个测试的功能了。 把刚才的程序代码写入到一个名叫 mcu.py 的文件，在终端执行如下代码12import osos.listdir('/') 可以看到，一共有两个文件，一个是 boot.py，一个是 webrepl.cfg.py，其中 boot.py 会在开机的时候自动运行，webrepl.cfg.py 里面记录的就是Web上连接的时候需要的密码了。现在将 boot.py 下载下来，然后修改这个文件，在最后一行添加 from mcu import loop_start，然后将 mcu.py 和 boot.py 上传回去，然后重启板子。 &gt;&gt;&gt; os.listdir(&apos;/&apos;) [&apos;boot.py&apos;, &apos;webrepl_cfg.py&apos;, &apos;mcu.py&apos;] &gt;&gt;&gt; loop_start() Present freq: 80MHz Loop 10000 times for 30.56 ms Present freq: 160MHz Loop 10000 times for 15.296 ms &gt;&gt;&gt; 可以看到，loop_start() 函数在启动的时候就会自动导入了，也就是说 mcu.py 被自动运行了，利用 boot.py 这样就可以实现开机的时候自动为WiFi配置静态IP了。 UDP/TCP能使用UDP/TCP进行通讯，这才是物联网的第一步，MicroPython 上的 socket 模块提供了对网络套接字的支持。下面用几个例子来看看如何使用。 广播自己的IP地址开发板连接上WiFi了，但是你并不知道板子的IP怎么办，除了登陆路由器来查看它的IP，还可以让它主动告诉你啊。 下面看代码：123456789101112import timeimport socketimport networkdef broadcast_ip(): wlan = network.WLAN(network.STA_IF) while not wlan.isconnected(): time.sleep(1) s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM) for i in range(3): s.sendto(b'Hi! i am ESP8266!', ('255.255.255.255',2001)) time.sleep(1) 将此代码保存为 ip.py 然后修改 boot.py 文件末尾添加：12from ip import broadcast_ipbroadcast_ip() 这里选择了向整个局域网内的2001端口发送UDP广播，也可以定点向某台主机发送，但是如果自己的IP也是DHCP获取的，那么可能下一次就又得该代码了。 然后编写接收端的代码，接收端的代码在自己的电脑上运行。 1234567import sockets = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)s.bind(('',2001))print('Start listen on: 0.0.0.0:2001')while True: d, a = s.recvfrom(1024) print("From: %s:%s\tMessage: %s" % (a[0], a[1], d.decode())) 然后保存为 find_esp8266.py 并启动脚本，接着重启开发板，几秒钟后可以看到收到开发板发来的消息了。 C:\Users\yunfwe\Desktop&gt;python find_esp8266.py Start listen on: 0.0.0.0:2001 From: 192.168.137.197:4097 Message: Hi! i am ESP8266! From: 192.168.137.197:4097 Message: Hi! i am ESP8266! From: 192.168.137.197:4097 Message: Hi! i am ESP8266! 获取NAT出口的公网IP局域网内的主机都是通过NAT方式共享一个公网IP来访问互联网的，那么怎么获取自己出口的这个IP呢？如果自己有台公网上的服务器，让ESP8266向它发个包就知道了，可是大多数人都是没有公网上的服务器的，这样还可以利用第三方提供的查询服务。 这里使用搜狐的查询接口: 点此打开，通过原始TCP套接字手动构建一个 HTTP 请求来访问数据 1234567891011121314151617import jsonimport socketdef get_nat_ip(): s = socket.socket(socket.AF_INET, socket.SOCK_STREAM) ip = socket.getaddrinfo('pv.sohu.com',0)[0][-1][0] s.connect((ip,80)) request = b'GET /cityjson?ie=utf-8 HTTP/1.1\r\n' request += b'Host: pv.sohu.com\r\n\r\n' size = s.send(request) header, data = s.recv(1024).decode().split('\r\n\r\n') data = data.split('=')[1][1:-1] data = json.loads(data) s.close() print('NAT IP: %s' % data['cip'])get_nat_ip() 在板子上执行看看吧！ 硬件IO通过网络来控制硬件，这样才能构建出各种智能硬件，先看看这块板子的引脚说明 引脚说明IC 内部引脚D0(RX)串口接收GPIO3D1(TX)串口发送GPIO1D2I/O，不支持中断、PWM、I2C、以及1-wireGPIO16D3/SCL/D15I/O，默认模式下I2C的SCLGPIO5D4/SDA/D14I/O，默认模式下I2C的SDAGPIO4D5/SCK/D13I/O，SPI的时钟GPIO14D6/MISO/D11I/O，SPI的MISOGPIO12D7/MOSI/D11I/O，SPI的MOSIGPIO13D8I/O，上拉，低电平时进入FLASH模式GPIO0D9/TX1I/O，上拉GPIO2D10/SSI/O，下拉，SPI时默认的片选(SS)GPIO15A0AD输入，0-3.3VADC 所有的IO工作电平为 3.3V，可瞬间承受 5V 除D2外，所有 I/O 都支持中断，PWM，I2C，和 1-wire GPIOESP8266-12F 板载了一颗蓝光的LED灯，就试试用代码控制这个灯吧。这颗灯会在 GPIO2 输出为高电平的时候灭掉，输出为低电平的时候亮起来，这样通过控制 GPIO2 口的电平高低就可以控制这颗LED的亮灭了。 ESP8266 跟硬件控制相关的库是 machine，下面看看用 MicroPython 如何控制 GPIO 12345678from machine import Pinled = Pin(2, Pin.OUT) # 将GPIO的2号引脚设置为输出led.value(1) # 将这个引脚设置为输出高电平led.value(0) # 将这个引脚设置为输出低电平led.on() # 相当于led.value(1)led.off() # 相当于led.value(0)led.value() # 获取当前的电平值 可以看到，执行 led = Pin(2, Pin.OUT) 的时候，本来灭着的LED灯突然亮了，接着执行 led.value(1) 的时候，LED灯灭了，这个时候 GPIO2 引脚输出的是高电平，如果在这个引脚上接一个LED灯或者其他设备，这个设备就开始工作了。 D1 WiFi UNO R3 这块板子上还板载了一颗接在 GPIO 14号引脚的LED灯，也可以通过 GPIO 直接控制这颗灯的亮灭，利用这个灯做一个 Blink LED 吧。 123456789import timefrom machine import Pinled = Pin(14,Pin.OUT, value=1) # 创建时初始值为1while True: led.on() time.sleep(0.5) led.off() time.sleep(1) 这颗LED灯已经开始以亮 0.5 秒，灭 1 秒的频率无限的闪下去了。 PWM通过设置 GPIO 口的输出电平，只能控制灯的亮灭，那有没有什么办法可以调节灯的亮度呢，那就是 PWM。那什么是 PWM 呢？还记得刚才让 LED 灯闪烁的例子吗，亮 0.5 秒，灭 1 秒，这样的频率肉眼很容易就观察出来了。那么如果减少这个休眠的时间，亮 1 毫秒，灭 2 毫秒，这样的频率，人的肉眼几乎就观察不出来了，而且看到的就是LED只有原来的 1/3 的亮度了。这里就引出了一个概念：占空比 通电时间占总时间的比例。而 PWM 就是调节这个的。 下面使用PWM测试下 GPIO14 上的这颗LED灯 12345678910from machine import Pin, PWMled = PWM(Pin(14)) # 对 GPIO14 进行PWM控制led.freq() # 获取当前的频率led.freq(1000) # 调整当前的频率led.duty() # 获取当前的占空比led.duty(1000) # 现在LED应该是满亮led.duty(500) # 现在LED应该是半亮led.duty(10) # 现在LED应该是微亮led.deinit() # 关闭对 GPIO14 的PWM控制 利用这个性质可以做出一个好看的呼吸灯特效，下面看代码 123456789101112from time import sleep_msfrom machine import Pin, PWMled = PWM(Pin(2), freq=1000, duty=0)while True: for i in range(0,1001,10): led.duty(i) sleep_ms(20) for i in range(1000,0,-10): led.duty(i) sleep_ms(10)led.deinit() TimerESP8266的内存实在太小了，因此 MicroPython 并没有为ESP8266实现多线程的功能，那么如果想通过网络来控制呼吸灯应该怎么做到呢？可以试试用定时器。 定时器类似于 JavaScript 的 setTimeout 和 setInterval，因为它们实现的功能是一摸一样的。MicroPython 的 machine.Timer() 会在给定的时间段执行一次或者周期性的执行这个回掉函数，下面看看具体是如何使用的。 123456from machine import Timert1 = Timer(-1) # 传给构造器一个ID，如果这个ID是-1，会初始化一个虚拟定时器t1.init(period=5000, mode=Timer.ONE_SHOT, callback=lambda t:print(1))t2 = Timer(0)t2.init(period=2000, mode=Timer.PERIODIC, callback=lambda t:print(2))t2.deinit() # 取消定时器。 参数 period 是每个周期的时间，单位是毫秒。mode 是运行模式，是只运行一次还是周期性运行。callback 则是到了这个时间周期然后执行的函数。如果这个 period 时间非常短的话，而且周期性的运行一个函数，这个函数将自己的数据保存在全局环境中，等到下个运行周期到了再继续处理数据，如果存在多个不同回掉函数的定时器，切换速度非常快的情况下，不就相当于多个函数在同时运行了吗。定时器每次调用回掉函数的时候，还会将自己本身作为参数传给回掉函数。 下面看代码，运用上面所学的网络套接字，呼吸灯，还有定时器的知识来完成一个可以在局域网甚至公网来控制的呼吸灯。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162import timeimport socketimport machineimport networkwlan = network.WLAN(network.STA_IF)wlan.active(True)wlan.ifconfig(('192.168.1.10', '255.255.255.0', '192.168.1.1', '119.29.29.29'))wlan.connect('SSID', 'PASSWORD')ap = network.WLAN(network.AP_IF)ap.active(False)led_timer = machine.Timer(1)keep_alive_timer = machine.Timer(2)net_control_timer = machine.Timer(3)led = machine.PWM(machine.Pin(2), freq=1000, duty=0)up = 1count = 0def breathing_light(t): global led, up, count if up == 1: count += 3 led.duty(count) if count &gt; 1000: up = 0 if up == 0: count -= 3 led.duty(count) if count == 3: up = 1def keep_alive(t): global s s.sendto(b'ESP8266-msg: live',('1.1.1.1',2002))def net_control(t): global s,led_timer,led try: data,addr = s.recvfrom(5) except: return print('From: %s:%s\tRecv: %s' % (addr[0],addr[1],data.decode())) if data in [b'on',b'start']: led_timer.init(period=10, mode=machine.Timer.PERIODIC, callback=breathing_light) elif data == b'stop': led_timer.deinit() elif data == b'off': led_timer.deinit() led.duty(0)while wlan.isconnected(): time.sleep_ms(200)s = socket.socket(socket.AF_INET, socket.SOCK_DGRAM)s.setblocking(0)s.bind(('0.0.0.0',2002))keep_alive_timer.init(period=10000, mode=machine.Timer.PERIODIC, callback=keep_alive)net_control_timer.init(period=10, mode=machine.Timer.PERIODIC, callback=net_control)print('Running...') 将代码中的连接 WiFi 的SSID和PASSWORD换成实际的，keep_alive 函数主要是保持一条与公网主机的UDP通道，如果没有公网主机可以注释掉下面 keep_alive_timer 定时器的语句。程序启动了一个UDP端口，接受来自局域网主机的控制，如果存在公网主机，也可以在公网主机上向开发板发送数据。UDP套接字设置为了非阻塞模式，然后定时器每10毫秒会询问一次是否收到UDP数据，如果收到了 on 或者 start 数据，就启动呼吸灯的定时器，呼吸灯定时器的回掉函数将当前的状态保存在了全局变量中，执行一次更改亮度的操作后就退出了，等待下个10毫秒继续执行。这样多个定时器如果存在互相调用，就不会因为发生阻塞而影响其他定时器的运行了。 当ESP8266和公网建立通信后，那么可以玩的地方更多了，比如接收温湿度传感器的数据，然后监控环境温度并定期将温度上传到服务器，或者接入微信公众平台用微信来控制单片机，这些就又是一个很大的话题了。 附录板子还在继续折腾中。。。等折腾出其他好玩的了继续更新]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>esp8266</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[玩转树莓派]]></title>
    <url>%2F2018%2F04%2F24%2F2018%2F%E7%8E%A9%E8%BD%AC%E6%A0%91%E8%8E%93%E6%B4%BE%2F</url>
    <content type="text"><![CDATA[简介 Raspberry Pi 中文名为树莓派，原本是为学习计算机编程教育而设计的只有卡片大小的微型电脑，上面可以运行 Linux 甚至 Windows 10 loT 系统。树莓派虽小，却五脏俱全，而且拥有丰富的拓展接口，是学习Linux、嵌入式、物联网的利器。 开始使用准备工具 树莓派，当前最新版本是 这里使用的是树莓派3B 读卡器，给树莓派烧录系统用，因为树莓派的系统安装在内存卡。 最好 8G 或以上的 Micro SD 卡，但是也不用太大，否则可能不稳定甚至不支持。 最好 5V 2.5A 电源（普通安卓充电器也可以），如果需要为树莓派扩展硬件的话，电源需要比较给力。 鼠标、键盘、HDMI转VGA线还有显示器，不过这些并不是必须的，看情况使用。 安装系统下载镜像包镜像包可以选择官方的镜像，或者第三方的镜像 官方下载：https://www.raspberrypi.org/downloads/Ubuntu：https://wiki.ubuntu.com/ARM/RaspberryPi 这里下载官方系统的Lite版，点此下载。 解压和烧录可以在Linux下和Windows下进行烧录，Windows下需要下载 Win32 Disk IMager 工具进行烧录，linux下可以直接使用dd命令。 Linux下烧录将内存卡插入到读卡器，然后读卡器插入电脑，读卡器设备被系统映射为了 /dev/sdc。 注意：Linux需要看看读卡器被系统映射为了哪个设备文件，如果指定错了设备文件，后果可能不堪设想。 1234# 先卸载一下 确保系统没有主动挂载这个设备，如果存在多个分区，需要卸载多个umount /dev/sdc1 unzip 2018-04-18-raspbian-stretch-lite.zipsudo dd if=2018-04-18-raspbian-stretch-lite.img of=/dev/sdc bs=4M Windows下烧录先将下载的xz镜像解压为img文件，然后使用 Win32 Disk IMager 工具烧录到内存卡。 需要注意的是，选择SD卡的设备，然后选择好解压后的img镜像后点击 write 开始写入。 启动树莓派正常来说，插入内存卡，插入网线就可以开机了，树莓派默认会DHCP获取IP地址，但是如果局域网不存在DHCP服务，那启动后会在获取DHCP地址过程中等待五六分钟，而且这种情况没有显示器就没法操作树莓派了。 配置静态IP但是对于不存在DHCP服务的局域网，可以在启动树莓派之前就配置好树莓派的IP地址，这样启动后就会自动应用配置的IP，连显示器和键盘也不需要了。 以下操作在 Linux 上进行。 12mount /dev/sdc2 /mnt # 烧录后树莓派的rootfs在sdc的第二个分区上vim /mnt/etc/network/interfaces # 编辑这个文件为下面内容，将IP信息替换为合适的信息 # This file describes the network interfaces available on your system # and how to activate them. For more information, see interfaces(5). # The loopback network interface auto lo iface lo inet loopback # Source interfaces # Please check /etc/network/interfaces.d before changing this file # as interfaces may have been defined in /etc/network/interfaces.d # See LP: #1262951 # source /etc/network/interfaces.d/*.cfg auto eth0 iface eth0 inet static address 192.168.2.220 netmask 255.255.255.0 network 192.168.2.0 broadcast 192.168.2.255 gateway 192.168.2.254 # dns-* options are implemented by the resolvconf package, if installed dns-nameservers 119.29.29.29 dns-nameservers 223.5.5.5 自动启动SSH服务系统默认启动是不启动SSH服务的，所以还要修改下 rc.local 文件，将 SSH服务 在系统启动后也跟着起来。 编辑 /mnt/etc/rc.local 添加内容：systemctl start ssh.servic 开机启动插入内存卡，连接网线，连接电源的那一刻树莓派就自动启动了。默认用户名：pi 默认密码：raspberry，ssh连接下试试吧。 系统定制 定制只能在 Linux 环境下进行，这里使用 ubuntu 16.04 64位系统。 对原始的img镜像文件进行修改定制，这样如果以后需要频繁重装系统，或者用于商业目的时，可能就有这种需求了。 安装需要的包12apt-get updateapt-get install qemu qemu-user qemu-user-static kpartx 将镜像挂在到系统目录需要先将系统镜像映射到loop设备文件，才能正常挂载镜像文件中的分区 123losetup /dev/loop0 2018-04-18-raspbian-stretch-lite.imgkpartx -av /dev/loop0mount /dev/mapper/loop0p2 /mnt/ 这样就将镜像的 rootfs 挂载到了 /mnt 下，系统镜像有两个分区，分别被映射为了 /dev/mapper/loop0p1 和 loop0p2， 其中loop0p1是内核存放分区，暂时是不需要的。 修改镜像中的数据qemu 提供了一个非常有意思的功能，可以 chroot 到异构CPU的二进制组成的根文件系统中，这样就可以在 x86 上对 ARM 的根文件系统的程序做调式了。 1234modprobe binfmt_miscecho &apos;:arm:M::\x7fELF\x01\x01\x01\x00\x00\x00\x00\x00\x00\x00\x00\x00\x02\x00\x28\x00:\xff\xff\xff\xff\xff\xff\xff\x00\xff\xff\xff\xff\xff\xff\xff\xff\xfe\xff\xff\xff:/usr/bin/qemu-static-arm-binfmt:P&apos; &gt; /proc/sys/fs/binfmt_misc/registercp /usr/bin/qemu-arm-static /mnt/usr/bin/ # 将此文件拷贝到ARM的根中chroot /mnt/ bash 执行了 chroot 之后，如果没有报错就切换到树莓派的根文件系统了，可以看看当前根的二进制文件是不是 ARM 架构的了 file /bin/bash，或者执行 uname -a 可以看到 内核也被模拟成了 ARM 架构的。 接下来就可以进行一些安装配置和修改文件等操作了，比如修改网卡的配置文件配置一个静态的IP地址，这样启动树莓派后就可以直接连接了。接下来修改 apt 源为阿里云源，加快软件下载速度。 修改：/etc/apt/sources.list deb http://mirrors.aliyun.com/raspbian/raspbian stretch main contrib non-free rpi 之后可以 apt-get update 然后安装需要的软件了。这时候就可以执行 systemctl enable ssh.service 命令，将SSH服务加入开机自启了。 修改完后退出了 chroot 环境，然后对 /mnt 目录进行卸载。 1234exit # 执行exit命令或者 Ctrl + d 就可以退出了umount /mnt # 如果卸载不掉，使用 fuser -ka /mnt 强制卸载kpartx -d /dev/loop0 # 卸载loop0中的分区映射losetup -d /dev/loop0 # 卸载img文件和loop0的映射 刷入内存卡进行开机验证一些不当的修改可能导致无法开机，而且一些特殊的软件包会对内核进行更改，这种情况下就无法使用这种方式定制了。建议每次修改完系统镜像后都进行一次归档保存，并且记录每次归档的修改信息，这样如果某次修改出现了问题导致无法开机，就可以回退到上一次归档的镜像而不是重头再来了。 功能和拓展连接WiFi树莓派3B默认是包含了WiFi和蓝牙模块的，配置连接WiFi路由器也很简单。 首先安装连接WiFi使用的程序1apt install wpasupplicant 连接WPA加密的WiFi创建配置文件: /etc/wpa_supplicant/wpa_supplicant.conf network={ ssid=&quot;SSID&quot; key_mgmt=WPA-PSK psk=&quot;PASSWORD&quot; } 将 SSID 和 PASSWORD 替换成要连接的用户名和密码就可以了。 然后执行 wpa_supplicant 命令手动连接到WiFi 1wpa_supplicant -i wlan0 -c /etc/wpa_supplicant/wpa_supplicant.conf 这种方式连接WiFi 如果有错误会打印错误信息，适合手动调试WiFi，等连接无误后，ifconfig 命令可以看到 wlan0 这块网卡。这个时候还是没有IP地址的，需要手动配置一个IP地址或者使用 dhclient wlan0 命令来自动获取IP地址。 还可以让系统 networking 服务来开机自动连接，修改网卡配置文件：/etc/network/interfaces 添加以下内容 auto wlan0 iface wlan0 inet dhcp wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf 或者配置为静态IP地址 auto wlan0 iface wlan0 inet static address 192.168.0.2 netmask 255.255.255.0 gateway 192.168.0.1 dns-nameservers 119.29.29.29 dns-nameservers 114.114.114.114 wpa-conf /etc/wpa_supplicant/wpa_supplicant.conf 注意: 使用 systemctl restart networking.service 时，如果长时间没有反应，千万不要强行停止，否则可能会各种问题 连接隐藏的WiFi修改配置文件：/etc/wpa_supplicant/wpa_supplicant.conf 为以下内容 network={ ssid=&quot;SSID&quot; scan_ssid=1 psk=&quot;PASSWORD&quot; } 同理，将 SSID 和 PASSWORD 替换为自己实际的，其他步骤和上面的一致。 连接没密码的WiFi修改配置文件：/etc/wpa_supplicant/wpa_supplicant.conf 为以下内容 network={ ssid=&quot;SSID&quot; key_mgmt=NONE } 添加多个WiFi可以在配置文件中添加多个 network 配置块来添加多个WiFi配置，wpa_supplicant 将会自动连接可以连接的WiFi，也可以手动配置优先级来偏重连接某个WiFi。 network={ ssid=&quot;SSID1&quot; psk=&quot;PASSWORD1&quot; priority=1 id_str=&quot;homeOne&quot; } network={ ssid=&quot;SSID2&quot; psk=&quot;PASSWORD2&quot; priority=2 id_str=&quot;homeTwo&quot; } 使用4G上网由于树莓派3B并没有自带4G模块，所以想使用SIM卡拨号上网就需要另外买一个4G模块。树莓派3B也没有适用于4G模块的 Mini PCI-e 接口，所以还需要买一个 Mini PCI-e 转 USB 的4G模块专用开发板。 这里4G模块使用 华为ME909s-821，SIM卡使用联通实名制的4G卡，需要先保证4G卡可以正常上网。 安装4G拨号软件1apt install wvdial 修改配置文件：/etc/wvdial.conf 添加如下内容 [Dialer wcdma] Init1 = ATZ Init2 = ATQ0 V1 E1 S0=0 Init3 = AT+CGDCONT=1,&quot;IP&quot;,&quot;3gnet&quot; Modem Type = Analog Modem Baud = 9600 New PPPD = yes Modem = /dev/ttyUSB0 ISDN = 0 Phone = *99# Password = guest Username = guest 需要注意的地方是 Modem = /dev/ttyUSB0 ，需要找到4G模块的设备文件，如果不确定4G模块的设备文件是啥，可以先记录下 /dev/ 目录下的所有文件名，然后插上后看看多出来了哪些，4G模块会多出来5个设备文件，一般第一个 ttyUSB* 设备文件是 Modem 的设备文件，也就是 /dev/ttyUSB0，但是如果已经存在了其它的 ttyUSB* 文件，则4G模块的设备文件会依次往后排。 将4G模块插入 Mini PCI-e 接口将SIM卡插入到卡槽，天线最好接上，否则信号可能太差导致拨号失败。 使用 wvdial wcdma 命令开始拨号，当出现如下信息时，则拨号成功了 --&gt; local IP address 10.90.80.32 --&gt; pppd: XE[01] --&gt; remote IP address 10.64.64.64 --&gt; pppd: XE[01] --&gt; primary DNS address 123.123.123.123 --&gt; pppd: XE[01] --&gt; secondary DNS address 123.123.123.124 --&gt; pppd: XE[01] 这时候使用 ifconfig 可以看到 ppp0 接口已经连接 ppp0 Link encap:Point-to-Point Protocol inet addr:10.90.80.32 P-t-P:10.64.64.64 Mask:255.255.255.255 UP POINTOPOINT RUNNING NOARP MULTICAST MTU:1500 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:7 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:3 RX bytes:66 (66.0 B) TX bytes:129 (129.0 B) 然后替换默认路由到点对点拨号的对端IP就可以使用4G上网了 12ip ro replace default via 10.64.64.6ping www.baidu.com -c 4 root@raspberrypi:~# ip ro replace default via 10.64.64.64 root@raspberrypi:~# ping www.baidu.com -c 4 PING www.a.shifen.com (61.135.169.121) 56(84) bytes of data. 64 bytes from 61.135.169.121: icmp_seq=1 ttl=54 time=36.2 ms 64 bytes from 61.135.169.121: icmp_seq=2 ttl=54 time=25.9 ms 64 bytes from 61.135.169.121: icmp_seq=3 ttl=54 time=21.9 ms 64 bytes from 61.135.169.121: icmp_seq=4 ttl=54 time=19.8 ms --- www.a.shifen.com ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3003ms rtt min/avg/max/mdev = 19.859/25.984/36.220/6.300 ms root@raspberrypi:~# 还有一些需要注意的地方，如果使用物联网卡，需要确保物联网卡是否支持4G，是否支持数据业务，以及4G模块支持的网络和运营商。 将 wvdial 程序 Ctrl + c 后4G就自动断开了。 使用GPS模块如果想用树莓派做行车记录仪之类的东西，GPS模块就必不可少了，这里使用 NEO-7N-0-002 GPS模块。这款GPS模块支持通过USB连接到树莓派，也支持和树莓派直接进行串口连接。 USB连接直接使用普通的数据线连接，自带陶瓷天线，但是最好外接天线。使用自带的陶瓷天线定位时最好将GPS模块放到靠窗的位置，户外效果最佳，否则将无法定位。 连接如下，通过USB连接后设备被映射为 /dev/ttyACM0 当橘红色的灯按频率闪灭，而不是常亮时就定位成功了，使用 cat /dev/ttyACM0 命令查看GPS模块的输出只需要关心 $GPGGA 的内容就可以，定位成功的信息是这样子的 root@raspberrypi:~# cat /dev/ttyACM0 |grep GPGGA $GPGGA,025456.00,?955.49947,N,?1619.28218,E,2,08,1.52,98.4,M,-8.7,M,,0000*74 $GPGGA,025457.00,?955.49948,N,?1619.28211,E,2,08,1.52,98.5,M,-8.7,M,,0000*72 $GPGGA,025458.00,?955.49960,N,?1619.28209,E,2,08,1.52,98.4,M,-8.7,M,,0000*7F $GPGGA,025459.00,?955.49967,N,?1619.28204,E,2,08,1.52,98.3,M,-8.7,M,,0000*73 其中 ?955.49947,N,?1619.28218,E N前面的浮点数表示北纬，E前面的浮点数表示东经，为了防止位置信息泄露，所以其中有一位数字用 ? 代替了，想了解 $GPGGA 的更多详细信息，可以翻阅 GPGGA 卫星数据格式。 串口连接由于树莓派3B自带的串口被用于蓝牙了，所以最省事的方法就是使用USB转TTL线，将TTL线的 +5V 接到GPS模块的 VCC 引脚， GND 接到GPS模块的 GND，TXD 接到GPS模块的 RXD，RXD 接到GPS模块的 TXD，也就是说TTL线的输入输出要和GPS模块的输入输出交叉接。 但是不知道是不是这款GPS模块板子上印刷错了，导致TTL线的 RXD 必须和 GPS模块上印刷的 RXD 引脚相接才能正常接收数据，由于只需要从GPS模块上接收数据，所以TTL线的 TXD 也可以不和GPS模块相接。 接线图如下 使用 minicom -D /dev/ttyUSB0 -b 9600 命令就可以获取GPS数据了。如果要处理GPS数据，可以用程序直连串口获取。摁下 Ctrl + a 松开后摁 x 然后敲下回车就退出 minicom 了。 设备和设备文件绑定前面的4G模块使用的是 /dev/ttyUSB0 设备文件，TTL线使用的也是 /dev/ttyUSB0，如果同时使用这两个模块，重启后谁也无法确定当前的 /dev/ttyUSB0 是哪个模块，这种情况可以使用 udev 规则来绑定设备和设备文件。 使用 udevadm info --attribute-walk --name=/dev/ttyUSB0 可以查看当前 /dev/ttyUSB0 设备的详细信息，然后通过这些信息匹配来为设备文件建立一个软连接，这样每次可以通过软连接来访问设备了。 添加文件：/etc/udev/rules.d/mydevice.rules KERNEL==&quot;ttyUSB*&quot;, ATTRS{idVendor}==&quot;1a86&quot;, ATTRS{idProduct}==&quot;7523&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;, SYMLINK+=&quot;ttl0&quot; KERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;02&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;, SYMLINK+=&quot;hw4g0&quot; KERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;03&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;, SYMLINK+=&quot;hw4g1&quot; KERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;04&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;, SYMLINK+=&quot;hw4g2&quot; KERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;05&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;, SYMLINK+=&quot;hw4g3&quot; KERNEL==&quot;ttyUSB*&quot;, ATTRS{bInterfaceNumber}==&quot;06&quot;, MODE:=&quot;0666&quot;, GROUP:=&quot;dialout&quot;, SYMLINK+=&quot;hw4g4&quot; 这样同时使用GPS和4G模块就可以通过访问 /dev/ttl0 和 /dev/hw4g0 来实现了。udev 规则的编写可以执行 man udev 获取。 附录资料参考： 树莓派命令行配置WiFi网络 树莓派调试华为4G模块 华为LTE模块AT拨号上网 树莓派调试GPS模块 udev绑定USB串口的方式]]></content>
      <categories>
        <category>IoT</category>
      </categories>
      <tags>
        <tag>ubuntu</tag>
        <tag>raspberry</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python进阶指南]]></title>
    <url>%2F2018%2F04%2F04%2F2018%2FPython%E8%BF%9B%E9%98%B6%E6%8C%87%E5%8D%97%2F</url>
    <content type="text"><![CDATA[简介 记录了关于Python编程中的一些小技巧和黑科技，包括一些非常好用的官方库和第三方库（堪称神器）用于解决工作学习中遇到的各种问题。本文档并不详细解释所有提到的知识点和库，只提供解决某种类型问题的一种思路，详细的用法还需要进一步翻阅官方文档或者借助搜索引擎。由于 Python2.7 将会在2020年官方停止，Python3 才是未来，所以本文档的例子都在 Python3.6 上测试通过。本文档长期更新。 编程技巧高级语法解压序列解压序列赋值给多个变量，先看一个简单的例子 &gt;&gt;&gt; a,b,c = (1,2,3) &gt;&gt;&gt; print(a,b,c,sep=&apos; &apos;) 1 2 3 &gt;&gt;&gt; a,b = (1,2,3) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; ValueError: too many values to unpack (expected 2) &gt;&gt;&gt; a,b,c,d = (1,2,3) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; ValueError: not enough values to unpack (expected 4, got 3) 元组(1,2,3)解压并分别赋值给了a,b,c，如果接收的变量太少或者太多都会抛出异常。这时可以使用 * 来将多余的元素都赋值给这个变量。 &gt;&gt;&gt; a,*b,c = (1,2,3,4) &gt;&gt;&gt; print(&apos;a=%s b=%s c=%s&apos; % (a,b,c)) a=1 b=[2, 3] c=4 这种解压赋值可以用在任何可迭代对象上，也就是说字符串、列表、生成器、字典甚至文件对象都适用，不过字典会将 key 进行赋值。 &gt;&gt;&gt; a,b,c = {&apos;d&apos;:1,&apos;e&apos;:2,&apos;f&apos;:3} &gt;&gt;&gt; print(a,b,c,sep=&apos; &apos;) d e f &gt;&gt;&gt; f = open(&apos;/etc/passwd&apos;) &gt;&gt;&gt; a,b,*_ = f &gt;&gt;&gt; print(a,b,sep=&apos;&apos;) root:x:0:0:root:/root:/bin/bash daemon:x:1:1:daemon:/usr/sbin:/usr/sbin/nologin 利用这个知识点还可以实现不借助第三方变量来交换两个变量的值 &gt;&gt;&gt; x,y = 1,2 &gt;&gt;&gt; print(x,y,sep=&apos; &apos;) 1 2 &gt;&gt;&gt; x,y = y,x &gt;&gt;&gt; print(x,y,sep=&apos; &apos;) 2 1 三目运算符像 C 和 Java 等都有一种叫三目运算符的东西 (expr) ? value1 : value2;，根据判断表达式的结果来从两个选择中取一个值，Python 中也有类似的东西，但是语法却完全不同的。 语法： value1 if expr else value2。当表达式的结果为真时，取 value1，为假时取 value2。 示例： &gt;&gt;&gt; b = 1 &gt;&gt;&gt; a = 2 if b != 1 else 3 &gt;&gt;&gt; print(a) 3 还有一个小技巧，Python 如果对 True 和 False 进行数学运算的时候，会把 True 当作 1，False 当作 0，所以还可以采用对迭代器进行切片的方式取值： &gt;&gt;&gt; True+1 2 &gt;&gt;&gt; True + False 1 &gt;&gt;&gt; (&apos;a&apos;,&apos;b&apos;)[1&gt;2] &apos;a&apos; &gt;&gt;&gt; (&apos;a&apos;,&apos;b&apos;)[1&lt;2] &apos;b&apos; 列表解析列表解析是根据已有的可迭代对象，高效的创建新列表的方法。 语法： [expression for iter_val in iterable] [expression for iter_val in iterable if cond_expr] 示例： 将所有的小写字母转为大写 &gt;&gt;&gt; L = [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;] &gt;&gt;&gt; [x.upper() for x in L] [&apos;A&apos;, &apos;B&apos;, &apos;C&apos;] 将所有的小写字母转为大写并排除掉列表中的数字 &gt;&gt;&gt; L = [1, &apos;a&apos;, 2, &apos;c&apos;] &gt;&gt;&gt; [x.upper() for x in L if type(x) == type(str())] [&apos;A&apos;, &apos;C&apos;] 可以看到，对于一些简单的处理，用列表解析更简洁，而且因为Python的内部优化，其运行速度会比普通处理方法更快。 字典解析字典解析就是利用可迭代对象创建新的字典。 语法： {expression:expression for iter_val in iterable} {expression:expression for iter_val in iterable if cond_expr} 示例： 计算字符的 ASCII 码，然后以键值的形式保存在字典中 &gt;&gt;&gt; L = [&apos;a&apos;, &apos;b&apos;, &apos;C&apos;, &apos;D&apos;] &gt;&gt;&gt; {x:ord(x) for x in L} {&apos;a&apos;: 97, &apos;b&apos;: 98, &apos;C&apos;: 67, &apos;D&apos;: 68} 过滤掉刚才字典中小写字母的键 &gt;&gt;&gt; D = {&apos;a&apos;: 97, &apos;b&apos;: 98, &apos;C&apos;: 67, &apos;D&apos;: 68} &gt;&gt;&gt; {x:y for x,y in D.items() if y &gt;= 65 and y &lt; 97} {&apos;C&apos;: 67, &apos;D&apos;: 68} 集合解析集合解析和列表解析用法一致，只不过使用和字典解析一样的大括号，并且返回的是一个集合。 语法： {expression for iter_val in iterable} {expression for iter_val in iterable if cond_expr} 示例： 将所有的小写字母转为大写，并且去掉重复的字母 &gt;&gt;&gt; L = [&apos;a&apos;, &apos;a&apos;, &apos;b&apos;, &apos;c&apos;] &gt;&gt;&gt; {x.upper() for x in L} {&apos;B&apos;, &apos;A&apos;, &apos;C&apos;} 生成器表达式生成器表达式的用法和列表解析也非常相似，但是生成器表达式不同于列表解析的地方是它返回的是一个生成器。生成器表达式使用了惰性计算的机制。 语法： (expression for iter_val in iterable) (expression for iter_val in iterable if cond_expr) 示例： 将所有的小写字母转为大写并排除掉列表中的数字 &gt;&gt;&gt; L = [1, &apos;a&apos;, 2, &apos;c&apos;] &gt;&gt;&gt; g = (x.upper() for x in L if type(x) == type(str())) &gt;&gt;&gt; g &lt;generator object &lt;genexpr&gt; at 0x7f8e1fa79468&gt; &gt;&gt;&gt; next(g) &apos;A&apos; &gt;&gt;&gt; next(g) &apos;C&apos; &gt;&gt;&gt; next(g) Traceback (most recent call last): File &quot;&lt;stdin&gt;&quot;, line 1, in &lt;module&gt; StopIteration 函数式编程lambda先来看看 lambda 的一个简单例子： &gt;&gt;&gt; func = lambda x: x**2 &gt;&gt;&gt; func(2) 4 &gt;&gt;&gt; func(4) 16 可以这样理解，lambda 作为一个表达式，定义了一个匿名函数。lambda 的主体只能是一个表达式，而不是一个代码块，所以 lambda 只能封装有限的逻辑进去。表达式的结果就是 lambda 的返回值。 语法：lambda [arg1 [,arg2,.....argn]]:expression map语法：map(function, iterable, ...) map() 函数的第一个参数是一个方法，第二个参数开始是一个迭代器。如果同时存在多个迭代器，map() 会同时遍历所有的迭代器，遍历次数以最短的迭代器为准，每个迭代器的值都将作为参数传给 function。下面看看 map() 应该怎么用。 示例： 把列表中所有是数字的元素乘 2 &gt;&gt;&gt; L = [1, &apos;a&apos;, 2, &apos;c&apos;] &gt;&gt;&gt; list(map(lambda x: x*2 if type(x) == type(int()) else x, L)) [2, &apos;a&apos;, 4, &apos;c&apos;] Python3 的 map() 函数默认返回生成器，所以需要用 list() 函数将它转化为列表。这里传给 map() 函数的处理方法，使用的是 lambda 表达式生成的匿名函数，也可以将一个普通函数或者方法传给 map() 使用，比如： &gt;&gt;&gt; list(map(chr,[68,69,88])) [&apos;D&apos;, &apos;E&apos;, &apos;X&apos;] filter语法：filter(function, iterable) filter() 函数用于过滤序列，过滤掉不符合条件的元素，返回由符合条件元素组成的新列表。Python3 的 filter() 也是返回一个生成器。 示例： 过滤掉列表中的偶数，只保留奇数 &gt;&gt;&gt; list(filter(lambda x: x%2,range(10))) [1, 3, 5, 7, 9] 当处理函数返回 True 时，列表元素会留下，返回 False 时，列表元素会被丢弃。1 会被作为 True，0 会被作为 False。 reduce语法：reduce(function, iterable[, initializer]) reduce() 函数会对参数序列中元素进行累积。reduce() 函数默认会先将迭代器的第一个和第二个元素传入 function 中来求值，之后将得到的新值和迭代器的第三个元素传入 function 中继续求值，直到迭代器遍历完毕后汇总结果。initializer 参数是一个可选参数，如果提供了此参数，则 reduce() 函数会直接将它的值作为运算的初始值与迭代器的第一个元素传入 function 中。 Python3 的 reduce() 不再是默认全局空间的了，用的时候需要先导入。 示例： 计算 1 到 100 的和 &gt;&gt;&gt; from functools import reduce &gt;&gt;&gt; reduce(lambda x,y: x+y, range(1,101)) 5050 &gt;&gt;&gt; reduce(lambda x,y: x+y, range(1,101),100) 5150 题外话：理解了 Python 中的 map() 和 reduce() 函数，也很容易理解 Hadoop 中的 MapReduce 计算模型了。 对字符串进行操作使用正则来分割字符串对字符串的分割通常是使用字符串的 split() 方法，但是这个方法有个局限就是每次只能按照一种分隔符来进行分割，而使用 re.split() 则可以使用正则表达式来进行分割。 &gt;&gt;&gt; import re &gt;&gt;&gt; s = &apos;abc 123;def,oe2&apos; &gt;&gt;&gt; re.split(r&apos;\s|;|,&apos;, s) [&apos;abc&apos;, &apos;123&apos;, &apos;def&apos;, &apos;oe2&apos;] 字符串开头或结尾匹配可能经常需要对一个url的协议头进行检测，或者对一个文件名的后缀进行检测，最简单的方法就是使用 str.startswith() 和 str.endswith() 方法了。 &gt;&gt;&gt; url = [&apos;http://127.0.0.1/&apos;,&apos;ftp://127.0.0.1/&apos;] &gt;&gt;&gt; fname = [&apos;hello.py&apos;, &apos;hi.c&apos;, &apos;hi.py&apos;, &apos;hi.js&apos;] &gt;&gt;&gt; [s for s in url if s.startswith(&apos;http:&apos;)] [&apos;http://127.0.0.1/&apos;] &gt;&gt;&gt; [s for s in fname if s.endswith((&apos;c&apos;,&apos;js&apos;))] [&apos;hi.c&apos;, &apos;hi.js&apos;] 需要注意的是，如果想匹配多个字符串开头或结尾，必须将多个匹配项放到元组内。 字符串匹配和搜索如果只是简单的匹配或者搜索字符串中特定的字符串，使用 str 类型的 find() 方法就可以了，但是如果想要完成更复杂的搜索，就要使用正则表达式了，Python的 re 模块提供了对正则表达式的支持 &gt;&gt;&gt; import re, os &gt;&gt;&gt; reg = re.compile(r&apos;inet addr:(.*?)\s&apos;, re.S) &gt;&gt;&gt; re.findall(reg, os.popen(&apos;ifconfig em1&apos;).read()) [&apos;192.168.4.6&apos;] 字符串搜索和替换对于简单的字符串替换，可以使用 str.replace() 方法。 &gt;&gt;&gt; text = &apos;yeah, but no, but yeah, but no, but yeah&apos; &gt;&gt;&gt; text.replace(&apos;yeah&apos;, &apos;yep&apos;) &apos;yep, but no, but yep, but no, but yep&apos; 对于复杂的替换可以使用 re.sub() 函数。 &gt;&gt;&gt; text = &apos;Today is 11/27/2012. PyCon starts 3/13/2013.&apos; &gt;&gt;&gt; import re &gt;&gt;&gt; re.sub(r&apos;(\d+)/(\d+)/(\d+)&apos;, r&apos;\3-\1-\2&apos;, text) &apos;Today is 2012-11-27. PyCon starts 2013-3-13.&apos; 如果想要忽略大小写的替换，可以在使用 re 模块的时候给这些操作提供 re.IGNORECASE 标志参数。 &gt;&gt;&gt; text = &apos;UPPER PYTHON, lower python, Mixed Python&apos; &gt;&gt;&gt; re.findall(&apos;python&apos;, text, flags=re.IGNORECASE) [&apos;PYTHON&apos;, &apos;python&apos;, &apos;Python&apos;] &gt;&gt;&gt; re.sub(&apos;python&apos;, &apos;snake&apos;, text, flags=re.IGNORECASE) &apos;UPPER snake, lower snake, Mixed snake&apos; 对于文本搜索，难点在于正则表达式的编写。 删除字符串头尾部不需要的字符strip() 方法能用于删除开始或结尾的字符。 lstrip() 和 rstrip() 分别从左和从右执行删除操作。 默认情况下，这些方法会去除空白字符，但是也可以指定其他字符。 &gt;&gt;&gt; s = &apos; hello world \n&apos; &gt;&gt;&gt; s.strip() &apos;hello world&apos; &gt;&gt;&gt; s.lstrip() &apos;hello world \n&apos; &gt;&gt;&gt; s.rstrip() &apos; hello world&apos; &gt;&gt;&gt; &gt;&gt;&gt; t = &apos;-----hello=====&apos; &gt;&gt;&gt; t.lstrip(&apos;-&apos;) &apos;hello=====&apos; &gt;&gt;&gt; t.strip(&apos;-=&apos;) &apos;hello&apos; 字符串对齐在终端上打印长短不一的字符串时这个可能非常有用，对字符串的对其方法，可以使用字符串的 ljust() , rjust() 和 center() 方法 12345print('id'.ljust(10),'name'.ljust(10),'age'.ljust(10),sep='')print('-'*23)print('1'.ljust(10),'Tom'.ljust(10),'20'.ljust(10),sep='')print('2'.ljust(10),'Jack'.ljust(10),'21'.ljust(10),sep='')print('3'.ljust(10),'Alan'.ljust(10),'19'.ljust(10),sep='') 输出： [root@localhost ~]# python3 test.py id name age ----------------------- 1 Tom 20 2 Jack 21 3 Alan 19 这些方法都能接受一个可选的填充字符参数 &gt;&gt;&gt; a = &apos;Tom&apos; &gt;&gt;&gt; a.center(10,&apos;*&apos;) &apos;***Tom****&apos; 或者还可以使用更强大的内建函数 format()。 字符串拼接字符串拼接除了使用 + 号连接两个字符串，还有效率更高更快的 join() 方法， join() 适用于要拼接的字符串在一个可迭代对象中。 &gt;&gt;&gt; parts = [&apos;Is&apos;, &apos;Chicago&apos;, &apos;Not&apos;, &apos;Chicago?&apos;] &gt;&gt;&gt; &apos; &apos;.join(parts) &apos;Is Chicago Not Chicago?&apos; &gt;&gt;&gt; &apos;,&apos;.join(parts) &apos;Is,Chicago,Not,Chicago?&apos; &gt;&gt;&gt; &apos;&apos;.join(parts) &apos;IsChicagoNotChicago?&apos; 字符串插入变量可能经常会遇到动态生成字符串的场景，Python 提供了多种方式来实现这种需求 使用字符串拼接： &gt;&gt;&gt; s = &apos;Monday&apos; &gt;&gt;&gt; &apos;Today is &apos; + s &apos;Today is Monday&apos; 使用占位符： &gt;&gt;&gt; s = &apos;Hi, %s is %s&apos; &gt;&gt;&gt; s % (&apos;Today&apos;, &apos;Monday&apos;) &apos;Hi, Today is Monday&apos; 使用 str.format() 函数： &gt;&gt;&gt; info = &apos;Name: {name}, Age: {age}&apos; &gt;&gt;&gt; info.format(name=&apos;Tom&apos;, age=20) &apos;Name: Tom, Age: 20&apos; 使用格式化字符串（Python 3.6 +） &gt;&gt;&gt; name,age = &apos;Tom&apos;,20 &gt;&gt;&gt; f&apos;Name: {name}, Age: {age}&apos; &apos;Name: Tom, Age: 20&apos; 像操作文件一样操作字符串使用 io.StringIO() 和 io.BytesIO() 类来创建类文件对象操作字符串数据 &gt;&gt;&gt; s = io.StringIO() &gt;&gt;&gt; s.write(&apos;Hello World\n&apos;) 12 &gt;&gt;&gt; print(&apos;This is a test&apos;, file=s) 15 &gt;&gt;&gt; # Get all of the data written so far &gt;&gt;&gt; s.getvalue() &apos;Hello World\nThis is a test\n&apos; &gt;&gt;&gt; # Wrap a file interface around an existing string &gt;&gt;&gt; s = io.StringIO(&apos;Hello\nWorld\n&apos;) &gt;&gt;&gt; s.read(4) &apos;Hell&apos; &gt;&gt;&gt; s.read() &apos;o\nWorld\n&apos; &gt;&gt;&gt; io.StringIO 只能用于文本。如果你要操作二进制数据，要使用 io.BytesIO 类来代替 对列表/字典等操作对字典的值进行排序内置函数 sorted() 支持对可迭代对象的元素进行排序，并将结果作为列表返回。如果排序的元素也是一个可迭代对象，则可以指定使用这个元素的某个项进行排序。 &gt;&gt;&gt; d = {&apos;a&apos;:10,&apos;b&apos;:8,&apos;c&apos;:11} &gt;&gt;&gt; sorted(d.items(), key=lambda x:x[1]) [(&apos;b&apos;, 8), (&apos;a&apos;, 10), (&apos;c&apos;, 11)] 或者下面这样也可以，只不过只返回了键 &gt;&gt;&gt; sorted(d, key=lambda k:d[k]) [&apos;b&apos;, &apos;a&apos;, &apos;c&apos;] 同理，使用这个方法也可以找出字典的最小值和最大值，但是还有更好的方法。 字典的最大值和最小值 min() 和 max() 函数可以快速得出一个可迭代对象的最小值和最大值，如果只是想简单的知道字典中的最大值或者最小值，调用字典的 values() 方法，然后通过 min() 或者 max() 进行计算就解决了，但是显然就无法得出这个最大值的键了。 min() 和 max() 函数也提供有 key 参数，使用上和 sorted 相同。 &gt;&gt;&gt; d = {&apos;a&apos;:10,&apos;b&apos;:8,&apos;c&apos;:11} &gt;&gt;&gt; min(d, key=lambda k:d[k]) &apos;b&apos; &gt;&gt;&gt; max(d, key=lambda k:d[k]) &apos;c&apos; &gt;&gt;&gt; max(d.items(), key=lambda d:d[1]) (&apos;c&apos;, 11) 去除列表/字典中的重复元素/值去除列表重复元素可以使用 set() 函数将列表转换为集合，其中重复的值就去掉了，但是这样也将丢失列表元素的顺序，而且也并不适合字典类型的数据。我们可以模仿 sorted() 函数来自己写一个完成需求的函数。 1234567def dedupe(items, key=None): seen = set() for item in items: val = item if key is None else key(item) if val not in seen: yield item seen.add(val) &gt;&gt;&gt; d = {&apos;a&apos;:10,&apos;b&apos;:8,&apos;c&apos;:11,&apos;d&apos;:8} &gt;&gt;&gt; l = [2,1,3,1,2] &gt;&gt;&gt; list(dedupe(d, lambda x:d[x])) [&apos;a&apos;, &apos;b&apos;, &apos;c&apos;] &gt;&gt;&gt; list(dedupe(l)) [2, 1, 3] 快速找到字典公共键可以利用集合的特性，计算多个字典键的交集即可。 &gt;&gt;&gt; d1 = {&apos;a&apos;:1,&apos;c&apos;:2,&apos;f&apos;:3} &gt;&gt;&gt; d2 = {&apos;a&apos;:2,&apos;c&apos;:4,&apos;d&apos;:3} &gt;&gt;&gt; d3 = {&apos;b&apos;:2,&apos;e&apos;:4,&apos;c&apos;:3} &gt;&gt;&gt; set(d1.keys()) &amp; set(d2.keys()) &amp; set(d3.keys()) {&apos;c&apos;} &gt;&gt;&gt; d1.keys() &amp; d2.keys() &amp; d3.keys() {&apos;c&apos;} 集合之间可以进行 -（差集），&amp;（交集），|（并集）计算。 如果字典比较多，还可以使用 map() 和 reduce() 来处理 &gt;&gt;&gt; from functools import reduce &gt;&gt;&gt; reduce(lambda x,y:x&amp;y, map(dict.keys, [d1,d2,d3])) {&apos;c&apos;} 给切片一个名字如果程序里需要用到大量的切片，这样会很严重的降低程序的可读性。但是如果给切片范围起一个名字，代码就更清晰可读了。 使用 slice() 函数创建一个切片对象，可以被用在任何切片允许的地方 &gt;&gt;&gt; INFO = &quot;00:50:56:C0:00:08-192.168.198.1&quot; &gt;&gt;&gt; mac = slice(None,17) &gt;&gt;&gt; ip = slice(18,None) &gt;&gt;&gt; INFO[mac] &apos;00:50:56:C0:00:08&apos; &gt;&gt;&gt; INFO[ip] &apos;192.168.198.1&apos; 标准库数据结构处理collections 数据类型容器collections.namedtuplePython中普通的 tuple 数据类型的元素是不可修改的，而且 tuple 的长度是不可变的，因此 tuple 的资源消耗少于 list。tuple 的元素访问只能通过索引，而在程序中通过索引访问元素的代码可读性太差，而 collections.namedtuple 则拓展了 tuple 的能力，允许以面向对象的方式访问其中的元素，而且资源消耗却跟 tuple 差不多。 示例： &gt;&gt;&gt; from collections import namedtuple &gt;&gt;&gt; Student = namedtuple(&apos;Student&apos;,[&apos;name&apos;,&apos;age&apos;,&apos;sex&apos;]) &gt;&gt;&gt; s = Student(name=&apos;Tom&apos;,age=16,sex=&apos;boy&apos;) &gt;&gt;&gt; s Student(name=&apos;Tom&apos;, age=16, sex=&apos;boy&apos;) &gt;&gt;&gt; s[0] &apos;Tom&apos; &gt;&gt;&gt; s.name &apos;Tom&apos; &gt;&gt;&gt; isinstance(s, tuple) True 可以看到 namedtuple 类型是 tuple 类型的子类。任何可以使用 tuple 的地方就可以使用 namedtuple collections.OrderedDictPython的默认 dict 类型是无序的，使用 OrderedDict 则可以实现有序的字典。 注意：Python3.6 换了种 dict 类型的实现方式，所以 Python3.6 的字典变成有序的了，但是使用 OrderedDict 可以确保在之前支持 OrderedDict 的版本中创建有序字典。 &gt;&gt;&gt; from collections import OrderedDict &gt;&gt;&gt; d = OrderedDict(c=1,b=2,a=3) &gt;&gt;&gt; d.keys() odict_keys([&apos;c&apos;, &apos;b&apos;, &apos;a&apos;]) &gt;&gt;&gt; isinstance(d,dict) True OrderedDict 是 dict 类型的子类，使用 dict 类型的地方也完全可以使用 OrderedDict collections.dequecollections.deque 是一个双端队列。顾名思义 deque 提供了在队列两端插入和删除的操作，如果创建 deque 对象的时候指定了队列长度，当队列满了从一端继续插入元素的时候，另一端的元素就会被移除。如果没有指定队列长度，就可以在两端无限插入元素了，当然前提是内存够用。 &gt;&gt;&gt; import collections &gt;&gt;&gt; d = collections.deque(maxlen=3) &gt;&gt;&gt; d.append(1) &gt;&gt;&gt; d.append(2) &gt;&gt;&gt; d.append(3) &gt;&gt;&gt; d deque([1, 2, 3], maxlen=3) &gt;&gt;&gt; d.append(4) &gt;&gt;&gt; d deque([2, 3, 4], maxlen=3) deque 对象的 rotate 方法比较有意思，相当于从队列右边弹出几个元素插入到左边来。下面看一个有趣的小例子，模拟一个无限循环的进度条。 123456789import sysimport timefrom collections import dequeloading = deque('&gt;--------------------')while True: sys.stdout.write('\r[%s]' % ''.join(loading)) loading.rotate(1) sys.stdout.flush() time.sleep(0.1) Python的 list（列表）对象不也提供了两端插入或者删除元素的方法吗，但是 deque 在两端插入或删除的时间复杂度是 O(1)，而 list 是 O(N)。 collections.CounterCounter 工具用于支持便捷和快速地统计可迭代对象中每个元素出现的次数，而且速度非常快。 快速的统计一个文本中，出现次数最多的三个字符 &gt;&gt;&gt; from collections import Counter &gt;&gt;&gt; c = Counter(open(&apos;abc.txt&apos;).read()) &gt;&gt;&gt; c.most_common(3) [(&apos;，&apos;, 312256), (&apos; &apos;, 296920), (&apos;的&apos;, 180567)] Counter 是 dict 类型的子类，以迭代器的每个元素为键，元素出现的次数为值。 collections.ChainMap当需要从多个字典中执行某些操作，比如检测某些键或值是否存在，使用 ChainMap 函数可以将多个字典逻辑上合并为一个字典。 &gt;&gt;&gt; from collections import ChainMap &gt;&gt;&gt; a = {&apos;x&apos;: 1, &apos;z&apos;: 3 } &gt;&gt;&gt; b = {&apos;y&apos;: 2, &apos;z&apos;: 4 } &gt;&gt;&gt; c = ChainMap(a,b) &gt;&gt;&gt; print(c[&apos;x&apos;],c[&apos;y&apos;],c[&apos;z&apos;]) 1 2 3 &gt;&gt;&gt; del c[&apos;z&apos;] &gt;&gt;&gt; c[&apos;z&apos;] 4 &gt;&gt;&gt; a {&apos;x&apos;: 1} 如果出现重复键，第一次找到的键被返回，如果对新产生的字典做操作，更改也会映射到原来的字典上去。如果只考虑合并两个字典，可以使用字典的 update 方法。 heapq 堆队列算法实现排序堆是一个二叉树，其中每个父节点的值都小于或者等于其所有子节点的值。整个堆的最小元素总是位于二叉树的根节点。Python 的 heapq 模块提供了对堆的支持。 如何获取一个无序列表最大的十个元素和最小的十个元素呢，这里试试使用 list 数据类型的实现和使用 heapq 的实现。 list 的实现12345678import timeimport randomL = [random.randint(1,10000000) for x in range(5000000)]now = time.time()L.sort()print('Max: %s' % L[-10:])print('Min: %s' % L[:10])print('Used time: %s sec' % str(time.time()-now)) 结果： Max: [9999984, 9999989, ...... , 9999998, 9999999] Min: [2, 2, 3, 5, 5, 7, 10, 12, 14, 16] Used time: 5.01489806175 sec heapq 的实现12345678import timeimport heapqimport randomL = [random.randint(1,10000000) for x in range(5000000)]now = time.time()print('Max: %s' % heapq.nlargest(10, L))print('Min: %s' % heapq.nsmallest(10, L))print('Used time: %s sec' % str(time.time()-now)) 结果： Max: [10000000, 9999999, ...... , 9999989, 9999988] Min: [2, 6, 7, 7, 8, 8, 8, 10, 11, 13] Used time: 1.21054005623 sec 实现一个优先级队列先看这样一个例子： &gt;&gt;&gt; a = [] &gt;&gt;&gt; heapq.heappush(a,[-2,2,&apos;a&apos;]) &gt;&gt;&gt; heapq.heappush(a,[-1,5,&apos;b&apos;]) &gt;&gt;&gt; heapq.heappush(a,[-1,3,&apos;c&apos;]) &gt;&gt;&gt; a [[-2, 2, &apos;a&apos;], [-1, 5, &apos;b&apos;], [-1, 3, &apos;c&apos;]] &gt;&gt;&gt; heapq.heappop(a) [-2, 2, &apos;a&apos;] &gt;&gt;&gt; heapq.heappop(a) [-1, 3, &apos;c&apos;] &gt;&gt;&gt; heapq.heappop(a) [-1, 5, &apos;b&apos;] 使用 heappush 向一个队列中插入一个列表元素，先使用列表的第一个元素来排序，如果第一个元素相同，则使用第二个元素排序，如果只有一个字母的话，将使用 ASCII 码进行排序。 利用这个特性，可以使用 heapq 来实现一个优先级队列，下面看代码： 12345678910111213import heapqclass PriorityQueue: def __init__(self): self._queue = [] self._index = 0 def push(self, item, priority): heapq.heappush(self._queue, (-priority, self._index, item)) self._index += 1 def pop(self): return heapq.heappop(self._queue)[-1] push 方法中传入元素和它的优先级，因为 heapq 中值越小的就越在队列开头，所以插入到队列的时候要将优先级取负数。而 _index 的作用就是如果出现优先级相同的元素，就根据这个值来排序，而每插入一个元素，_index 的值都会增加1，所以后面插入的元素优先级就小于之前插入的元素了。 接下来看看效果如何： &gt;&gt;&gt; q = PriorityQueue() &gt;&gt;&gt; q.push(&apos;Bob&apos;, 2) &gt;&gt;&gt; q.push(&apos;Tom&apos;, 8) &gt;&gt;&gt; q.push(&apos;Jack&apos;, -5) &gt;&gt;&gt; q.pop() &apos;Tom&apos; &gt;&gt;&gt; q.pop() &apos;Bob&apos; &gt;&gt;&gt; q.pop() &apos;Jack&apos; Tom 的优先级最高，所以 Tom 被最先弹出了，一个简单的优先级队列就完成了。如果需要在多个线程中使用同一个队列，可以加入锁和信号量机制。 operator 内置操作符的函数接口operator.itemgetter如果有一个字典列表，想根据某个或某几个字典字段来排序这个列表。通过使用 operator 模块的 itemgetter 函数，可以非常容易的排序这样的数据结构。 &gt;&gt;&gt; from operator import itemgetter &gt;&gt;&gt; rows = [ ... {&apos;id&apos;:1000, &apos;name&apos;:&apos;Tom&apos;, &apos;age&apos;: 18}, ... {&apos;id&apos;:1001, &apos;name&apos;:&apos;Jack&apos;, &apos;age&apos;: 20}, ... {&apos;id&apos;:1003, &apos;name&apos;:&apos;Mei&apos;, &apos;age&apos;: 17}, ... {&apos;id&apos;:1002, &apos;name&apos;:&apos;Li&apos;, &apos;age&apos;: 17}, ... ] &gt;&gt;&gt; sorted(rows, key=itemgetter(&apos;name&apos;)) [{&apos;id&apos;: 1001, &apos;name&apos;: &apos;Jack&apos;, &apos;age&apos;: 20}, {&apos;id&apos;: 1002, &apos;name&apos;: &apos;Li&apos;, &apos;age&apos;: 17}, {&apos;id&apos;: 1003, &apos;name&apos;: &apos;Mei&apos;, &apos;age&apos;: 17}, {&apos;id&apos;: 1000, &apos;name&apos;: &apos;Tom&apos;, &apos;age&apos;: 18}] &gt;&gt;&gt; sorted(rows, key=itemgetter(&apos;id&apos;)) [{&apos;id&apos;: 1000, &apos;name&apos;: &apos;Tom&apos;, &apos;age&apos;: 18}, {&apos;id&apos;: 1001, &apos;name&apos;: &apos;Jack&apos;, &apos;age&apos;: 20}, {&apos;id&apos;: 1002, &apos;name&apos;: &apos;Li&apos;, &apos;age&apos;: 17}, {&apos;id&apos;: 1003, &apos;name&apos;: &apos;Mei&apos;, &apos;age&apos;: 17}] itemgetter 函数也支持多个 keys，比如下面的代码，如果 age 相同的情况下，则按照 id 来排序 &gt;&gt;&gt; sorted(rows, key=itemgetter(&apos;age&apos;,&apos;id&apos;)) [{&apos;id&apos;: 1002, &apos;name&apos;: &apos;Li&apos;, &apos;age&apos;: 17}, {&apos;id&apos;: 1003, &apos;name&apos;: &apos;Mei&apos;, &apos;age&apos;: 17}, {&apos;id&apos;: 1000, &apos;name&apos;: &apos;Tom&apos;, &apos;age&apos;: 18}, {&apos;id&apos;: 1001, &apos;name&apos;: &apos;Jack&apos;, &apos;age&apos;: 20}] 也可以使用 sorted() 和 lambda 表达式实现上面的效果，比如 &gt;&gt;&gt; sorted(rows, key=lambda r:(r[&apos;age&apos;],r[&apos;id&apos;])) [{&apos;id&apos;: 1002, &apos;name&apos;: &apos;Li&apos;, &apos;age&apos;: 17}, {&apos;id&apos;: 1003, &apos;name&apos;: &apos;Mei&apos;, &apos;age&apos;: 17}, {&apos;id&apos;: 1000, &apos;name&apos;: &apos;Tom&apos;, &apos;age&apos;: 18}, {&apos;id&apos;: 1001, &apos;name&apos;: &apos;Jack&apos;, &apos;age&apos;: 20}] 但是效率可能要比 itemgetter 慢一些。 operator.attrgetteritemgetter 是获取字典的每一项，如果是将数据保存在对象实例的属性中，则可以使用 attrgetter 来获取 1234567891011from operator import attrgetterclass User(): def __init__(self,id,name,age): self.id,self.name,self.age = id,name,age def __repr__(self): return 'User(id=%s, name=%s, age=%s)' % (self.id,self.name,self.age)users = [User(1000,'Tom',18),User(1001,'Jack',20), User(1003,'Mei',17),User(1002,'Li',17)]sorted(users, key=attrgetter('id'))sorted(users, key=attrgetter('age','id')) 输出： &gt;&gt;&gt; sorted(users, key=attrgetter(&apos;id&apos;)) [User(id=1000, name=Tom, age=18), User(id=1001, name=Jack, age=20), User(id=1002, name=Li, age=17), User(id=1003, name=Mei, age=17)] &gt;&gt;&gt; sorted(users, key=attrgetter(&apos;age&apos;,&apos;id&apos;)) [User(id=1002, name=Li, age=17), User(id=1003, name=Mei, age=17), User(id=1000, name=Tom, age=18), User(id=1001, name=Jack, age=20)] 同理，如果不想用 attrgetter 也可以自己用 lambda 实现功能。 itertools 操作迭代对象的库itertools.groupby如果有一个包含字典或者对象实例的列表，想根据某个字段进行分组迭代访问，可以使用 groupby 函数。 1234567rows = [ &#123;'id':1000, 'name':'Tom', 'age': 18&#125;, &#123;'id':1001, 'name':'Jack', 'age': 20&#125;, &#123;'id':1003, 'name':'Mei', 'age': 17&#125;, &#123;'id':1002, 'name':'Li', 'age': 17&#125;, &#123;'id':1004, 'name':'Ani', 'age': 20&#125;] 首先需要排序，然后才可以分组 1234567from operator import itemgetterfrom itertools import groupbyrows.sort(key=itemgetter('age'))for age,items in groupby(rows, key=itemgetter('age')): print('age = %s:' % age) for i in items: print(' ',i) 输出： age = 17: {&apos;id&apos;: 1003, &apos;name&apos;: &apos;Mei&apos;, &apos;age&apos;: 17} {&apos;id&apos;: 1002, &apos;name&apos;: &apos;Li&apos;, &apos;age&apos;: 17} age = 18: {&apos;id&apos;: 1000, &apos;name&apos;: &apos;Tom&apos;, &apos;age&apos;: 18} age = 20: {&apos;id&apos;: 1001, &apos;name&apos;: &apos;Jack&apos;, &apos;age&apos;: 20} {&apos;id&apos;: 1004, &apos;name&apos;: &apos;Ani&apos;, &apos;age&apos;: 20} 文件处理固定大小的文件迭代如果有个文本文件，迭代文件对象最好是按行读取，但如果是二进制文件，则最好是每次读取固定大小的字节。 iter() 函数有个不常用的用法是如果传入了两个参数，第一个参数必须是一个可调用对象，第二个参数是结束标志，如果迭代过程中遇到了这个结束标志，迭代就结束了。可以利用这个性质来实现文件按固定字节读取。 &gt;&gt;&gt; f = open(&apos;/bin/bash&apos;,&apos;rb&apos;) &gt;&gt;&gt; i = iter(lambda :f.read(10), b&apos;&apos;) &gt;&gt;&gt; next(i) b&apos;\x7fELF\x02\x01\x01\x00\x00\x00&apos; &gt;&gt;&gt; next(i) b&apos;\x00\x00\x00\x00\x00\x00\x02\x00&gt;\x00&apos; &gt;&gt;&gt; next(i) b&apos;\x01\x00\x00\x00`\x05B\x00\x00\x00&apos; gzip/bz2 文件解压缩gzip 和 bz2 为Python提供了对文件进行 gz 和 bz2 格式的解压缩。 文件压缩： &gt;&gt;&gt; import gzip &gt;&gt;&gt; f = gzip.open(&apos;/tmp/test.gz&apos;,&apos;wt&apos;) &gt;&gt;&gt; f.write(&apos;Hello gzip&apos;) 10 &gt;&gt;&gt; f.close() gzip.open() 和 open() 函数一样，根据文件模式来判断对文件的读写方式，如果对文本文件压缩，使用 wt 文件模式，读取压缩文件使用 rt 文件模式。 文件解压： &gt;&gt;&gt; import gzip &gt;&gt;&gt; f = gzip.open(&apos;/tmp/test.gz&apos;,&apos;rt&apos;) &gt;&gt;&gt; f.read() &apos;Hello gzip&apos; bz2 和 gzip 的使用方式一致。压缩文件的时候还可以传入一个压缩等级的参数 默认是 compresslevel=9，打开的文件可以是一个文件名，也可以是一个类文件对象上，比如一个套接字对象、一个管道等。 mmap 内存映射文件对文件修改的场景还是经常遇到的，但是如果要修改一个非常大的文件，传统的读取文件，修改文件，写回文件的方式就非常不合适了。 第三方库chatdetpyinstallergeventbottlegunicorn附录参考资料： Python3-cookbook Python3.6 官方文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Peewee 轻量级ORM框架]]></title>
    <url>%2F2018%2F03%2F20%2F2018%2FPeewee%20%E8%BD%BB%E9%87%8F%E7%BA%A7ORM%E6%A1%86%E6%9E%B6%2F</url>
    <content type="text"><![CDATA[简介 Peewee 是Python的一款轻量级ORM框架。ORM 是对象-关系映射（Object-Relational Mapping），是一种为了解决面向对象与关系数据库存在的互不匹配的现象的技术。简单的说，ORM是通过使用描述对象和数据库之间映射的元数据，将程序中的对象自动持久化到关系数据库中。ORM 屏蔽了底层数据库操作的细节，使代码几乎不用修改即可支持不同的底层数据库存储。支持Python2.7和3.4以上的版本，内置对SQLite, MySQL和Postgresql的支持。本文通过阅读官方文档翻译而来。 环境这里使用 Windows 版的 Python 3.6 和当前最新版的 peewee 3.1.3。 Github地址：https://github.com/coleifer/peewee 使用安装这里使用 pip 命令安装 1pip install peewee 也可以将代码 git 下来 使用 setup 安装 123git clone https://github.com/coleifer/peewee.git cd peewee python setup.py install 如果底层想要使用 MySQL 数据库需要安装 MySQL 的连接驱动：pip install pymysql，并且配置好一个可用的 MySQL 数据库。Postgres 同理，Postgres 的连接驱动：pip install psycopg2。 SQLite 是 Python 标准库的模块，不需要额外安装和配置，也更简单方便，所以这里就以 SQLite 为例。 快速体验先来体验一下 peewee 对数据交互带来的方便吧。 创建数据模型先理解下什么 ORM ，ORM 是将编程语言中的对象映射为数据库中的数据，比如说 可以将编程语言中的一个类，映射为数据库的一个表，这个类被称为模型类（Model class）。模型类的字段实例（Field instance），映射为数据库中表的字段。模型实例（Model instance）映射为数据库中表的每一行数据。 建议在命令行中执行下面的代码，这样就更直观的知道每一步都发生了什么。 在项目中使用 peewee 时，刚开始最好创建一个模型类，peewee 会自动根据这个模型类在数据库中创建好表。下面看看模型类如何定义的： 1234567891011from peewee import *db = SqliteDatabase('people.db')class Person(Model): name = CharField() birthday = DateField() is_relative = BooleanField() class Meta: database = db # This model uses the "people.db" database. 当我们使用外键建立模型之间的关系时，peewee 可以很容易的做到这一点。 1234567class Pet(Model): owner = ForeignKeyField(Person, backref='pets') name = CharField() animal_type = CharField() class Meta: database = db # this model uses the "people.db" database 现在创建好了模型，让我们连接到数据库。虽然在执行第一条查询的时候会自动连接数据库，但是手动连接可以立即显示数据库连接的任何错误，在使用完后手动关闭数据库连接也是个很好的习惯。 1db.connect() 首先在数据库中创建存储数据的表。这将创建具有适当列，索引，序列和外键约束的表： 1db.create_tables([Person, Pet]) 可以看到 当前目录 已经出现了一个 people.db 的 SQLite 数据库文件。 存储数据现在开始存储一些数据，我们将使用 save() 和 create() 方法添加和修改表中的记录 123from datetime import dateuncle_bob = Person(name='Bob', birthday=date(1960, 1, 15), is_relative=True)uncle_bob.save() # bob is now stored in the database. Returns: 1 调用 save() 将返回修改的行数。也可使用 create() 方法来添加一个人： 12grandma = Person.create(name='Grandma', birthday=date(1935, 3, 1), is_relative=True)herb = Person.create(name='Herb', birthday=date(1950, 5, 5), is_relative=False) 如果想更改某行，修改模型实例的属性，然后调用 save() 方法就会同步到数据库了。 12grandma.name = 'Grandma L.'grandma.save() 现在已经在数据库中存储了三个人，让我们给他们一些宠物。奶奶不喜欢宠物，但Herb是宠物的爱好者。 1234bob_kitty = Pet.create(owner=uncle_bob, name='Kitty', animal_type='cat')herb_fido = Pet.create(owner=herb, name='Fido', animal_type='dog')herb_mittens = Pet.create(owner=herb, name='Mittens', animal_type='cat')herb_mittens_jr = Pet.create(owner=herb, name='Mittens Jr', animal_type='cat') 经过漫长的时间后，Mittens 生病死亡了，现在从数据库中删的它。 1herb_mittens.delete_instance() delete_instance() 方法也会返回删除的行数。 叔叔 Bob 觉得在 Herb 的房间死了太多动物，所以收养了他的狗 Fido。 123herb_fido.owner = uncle_bobherb_fido.save()bob_fido = herb_fido # rename our variable for clarity 检索数据数据库的优势在于可以通过SQL语句来检索数据，现在看看 peewee 中是如何检索数据的。 查询一条记录让我们从数据库中获取奶奶的记录，从数据库获取单条记录使用 select.get() 1grandma = Person.select().where(Person.name == 'Grandma L.').get() 我们也可以使用等效的缩写 Model.get() 1grandma = Person.get(Person.name == 'Grandma L.') 列出记录让我们列出所有人的记录 12for person in Person.select(): print(person.name, person.is_relative) 输出： Bob True Grandma L. True Herb False 让我们列出所有的猫和它们主人的名字 123query = Pet.select().where(Pet.animal_type == 'cat')for pet in query: print(pet.name, pet.owner.name) 输出： Kitty Bob Mittens Jr Herb 但是这样的查询有一个很大的问题，因为我们想要知道宠物主人的名字，但是 Pet 表中并没有这一个字段，所以当访问 pet.owner.name 的时候，peewee 不得不执行额外的查询来检索宠物的所有者，这样的情况通常应该是避免的。 我们应当使用 join 进行关联查询来避免额外的开销 1234567query = (Pet .select(Pet, Person) .join(Person) .where(Pet.animal_type == 'cat'))for pet in query: print(pet.name, pet.owner.name) 输出： Kitty Bob Mittens Jr Herb 让我们看看 Bob 有哪些宠物 12for pet in Pet.select().join(Person).where(Person.name == 'Bob'): print(pet.name) 输出： Kitty Fido 我们还有一个很酷的方法获取 Bob 的宠物，因为我们已经有一个表示 Bob 的对象，所以我们可以这样做 12for pet in Pet.select().where(Pet.owner == uncle_bob): print(pet.name) 排序让我们添加一个 order_by() 方法来让它们按照字母顺序排序 12for pet in Pet.select().where(Pet.owner == uncle_bob).order_by(Pet.name): print(pet.name) 输出： Fido Kitty 让我们按照年纪 从年轻到年老列出人们 12for person in Person.select().order_by(Person.birthday.desc()): print(person.name, person.birthday) 输出： Bob 1960-01-15 Herb 1950-05-05 Grandma L. 1935-03-01 结合过滤器表达式Peewee 支持任意嵌套的表达式。让我们得到所有生日不一的人 1940之前的人（Grandma）1959年之后的人（Bob） 12345678d1940 = date(1940, 1, 1)d1960 = date(1960, 1, 1)query = (Person .select() .where((Person.birthday &lt; d1940) | (Person.birthday &gt; d1960)))for person in query: print(person.name, person.birthday) 输出： Bob 1960-01-15 Grandma L. 1935-03-01 现在看看生日在1940年至1960年之间的人 123456query = (Person .select() .where(Person.birthday.between(d1940, d1960)))for person in query: print(person.name, person.birthday) 输出： Herb 1950-05-05 聚合和预获取现在让我们列出所有的人和他们有多少宠物 12for person in Person.select(): print(person.name, person.pets.count(), 'pets') 输出： Bob 2 pets Grandma L. 0 pets Herb 1 pets 在这种情况下，我们又为返回的每个人执行了附加查询！我们可以通过执行join并使用sql函数来聚合结果来避免这种情况。 12345678query = (Person .select(Person, fn.COUNT(Pet.id).alias('pet_count')) .join(Pet, JOIN.LEFT_OUTER) # include people without pets. .group_by(Person) .order_by(Person.name))for person in query: # "pet_count" becomes an attribute on the returned model instances. print(person.name, person.pet_count, 'pets') 输出： Bob 2 pets Grandma L. 0 pets Herb 1 pets 一只宠物只能有一个主人，所以当进行从 Pet 到 Person 的 join 操作时，它们通常都会进行一次匹配。当我们从 Person 到 Pet 的 join 时，情况会不同，因为一个人可能没有宠物，或者他们可能有几只宠物。因为我们使用关系数据库，当我们从 Person 到 Pet 的 join 时，那么每个宠物都会重复每个拥有多个宠物的人。 它看起来像这样：1234567891011query = (Person .select(Person, Pet) .join(Pet, JOIN.LEFT_OUTER) .order_by(Person.name, Pet.name))for person in query: # We need to check if they have a pet instance attached, since not all # people have pets. if hasattr(person, 'pet'): print(person.name, person.pet.name) else: print(person.name, 'no pets') 输出： Bob Fido Bob Kitty Grandma L. no pets Herb Mittens Jr 通常这种类型的重复是不可取的，我们可以使用一种 prefetch() 的特殊方法 12345query = Person.select().order_by(Person.name).prefetch(Pet)for person in query: print(person.name) for pet in person.pets: print(' *', pet.name) SQL 函数这将使用一个 SQL 方法来查找名字以大写或者小写 g 开头的人 123expression = fn.Lower(fn.Substr(Person.name, 1, 1)) == 'g'for person in Person.select().where(expression): print(person.name) 输出： Grandma L. 这只是 peewee 的基础，你还可以使查询更复杂，其他的 SQL 子句也可以使用，比如 group_by(), having(), limit(), offset() 关闭数据库当使用完数据库，我们应该关闭它 1db.close() 从数据库导出模型如果已经存在的数据库，可以使用模型生成器 pwiz 自动生成 peewee 模型 比如将刚才 people.db 的数据再导出模型 1python -m pwiz -e sqlite people.db 如果想导出 MySQL 库的数据 可以这样做：1python -m pwiz -e mysql -H localhost -p3306 -uuser -Ppassword dbname &gt; db.py 数据库连接数据库Peewee 的 Database 对象表示到数据库的连接。Database 类将实例化打开的数据库连接所需的所有信息，这些信息可用于： 打开和关闭连接 执行查询请求 事务管理 内省表，列，索引和约束 模型整合 peewee支持 SQLite, MySQL 和 Postgres。每个数据库类都提供了一些基本的数据库特定的配置选项 1234567891011121314from peewee import *# SQLite database using WAL journal mode and 64MB cache.sqlite_db = SqliteDatabase('/path/to/app.db', pragmas=( ('journal_mode', 'wal'), ('cache_size', -1024 * 64)))# Connect to a MySQL database on network.mysql_db = MySQLDatabase('dbname', user='root', password='db_password', host='10.1.0.8', port=3306)# Connect to a Postgres database.pg_db = PostgresqlDatabase('my_app', user='postgres', password='secret', host='10.1.0.9', port=5432) Peewee 通过特定的扩展模块提供了对 SQLite 和 Postgres 的高级支持。要使用扩展功能，需要导入特殊数据库模块的 Database 类 123456789from playhouse.sqlite_ext import SqliteExtDatabase# Use SQLite (will register a REGEXP function and set busy timeout to 3s).db = SqliteExtDatabase('/path/to/app.db', regexp_function=True, timeout=3, pragmas=(('journal_mode', 'wal'),))from playhouse.postgres_ext import PostgresqlExtDatabase# Use Postgres (and register hstore extension).db = PostgresqlExtDatabase('dbname', user='postgres', register_hstore=True) Database 类的初始化方法第一个参数是期望的数据库名称，剩下的参数将传给建立连接的底层数据库驱动程序 使用URL连接数据库playhouse 模块提供了一个 connect() 函数，它接受数据库URL 并返回一个数据库实例 示例：12345678910import osfrom peewee import *from playhouse.db_url import connect# Connect to the database URL defined in the environment, falling# back to a local Sqlite database if no database URL is specified.db = connect(os.environ.get('DATABASE') or 'sqlite:///default.db')class BaseModel(Model): class Meta: database = db 数据库URL示例： sqlite:///my_database.db 将为 my_database.db 在当前目录创建 SqliteDatabase 实例。 sqlite:///:memory 将要创建在内存中的 SqliteDatabase 实例。 postgresql://postgres:my_password@localhost:5432/my_database 将创建一个 PostgresqlDatabase 实例。并提供用户名和密码以及连接的主机和端口 mysql://user:passwd@ip:port/my_db 将为本地 MySQL 数据库创建 MySQLDatabase 的实例。 数据库运行时配置有时候直到运行时数据库配置才会直到，这些值可以从配置文件或者环境变量获取。在这种情况下可以通过将 None 指定为数据库名来推迟数据库的初始化。 12345database = SqliteDatabase(None) # Un-initialized database.class SomeModel(Model): class Meta: database = database 这时候尝试连接数据库时会抛出一个异常 12database.connect()Exception: Error, database not properly initialized before opening connection 可以手动调用 init() 方法来初始化数据库 12database_name = raw_input('What is the name of the db? ')database.init(database_name, host='localhost', user='postgres') 动态定义数据库为了更好地控制数据库的定义/初始化方式，可以使用 Proxy() 方法，Proxy() 方法充当占位符，然后在运行时您可以将其交换出一个不同的对象。 12345678910111213141516171819database_proxy = Proxy() # Create a proxy for our db.class BaseModel(Model): class Meta: database = database_proxy # Use proxy for our DB.class User(BaseModel): username = CharField()# Based on configuration, use a different database.if app.config['DEBUG']: database = SqliteDatabase('local.db')elif app.config['TESTING']: database = SqliteDatabase(':memory:')else: database = PostgresqlDatabase('mega_production_db')# Configure our proxy to use the db we specified in config.database_proxy.initialize(database) 连接管理打开一个数据库连接，使用 Database.connect() 方法 12db = SqliteDatabase(':memory:') db.connect() 如果尝试再次调用 connect() 将会得到一个 OperationalError 123456db.connect()Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "/home/charles/pypath/peewee.py", line 2390, in connect raise OperationalError('Connection already opened.')peewee.OperationalError: Connection already opened. 为了阻止这个异常，可以添加参数 reuse_if_open = True 12db.connect()db.connect(reuse_if_open = True) 注意：如果数据库连接已打开，则返回 False 调用 close() 将关闭已打开的数据库连接，再次调用 close() 则只会返回 False 小提示：虽然在使用之前没必要显式连接到数据库，但时最好明确连接。这样如果连接失败，在打开的时候就可以捕获该异常，而不是执行数据库操作的时候。如果在使用数据库连接池。则需要调用 connect() 和 close() 以确保连接正确回收。 Peewee 使用线程本地存储跟踪连接状态，使得 Peewee 数据库对象可以安全的用于多个线程，每个线程都拥有自己的连接。 数据库对象本身可以使用 with 上下文管理器，在上下文管理器中打开一个连接，在连接关闭之前提交，如果错误发生，这种情况下事务将回滚。 12345db.is_closed() # Truewith db: print(db.is_closed()) # Falsedb.is_closed() # True connection_context() 方法也可用于装饰器 123456@db.connection_context()def prepare_database(): # DB connection will be managed by the decorator, which opens # a connection, calls function, and closes upon returning. db.create_tables(MODELS) # Create schema. load_fixture_data(db) 使用 Database.connection() 方法可以获取底层数据库驱动的原始对象。 12db.connection()# &lt;sqlite3.Connection object at 0x0574DF20&gt; 连接池连接池由 Playhouse 扩展库中包含的池模块提供 超时后的连接收回 最大连接数上限 1234567891011121314from playhouse.pool import PooledMySQLDatabasedb = PooledMySQLDatabase( 'my_database', max_connections=8, stale_timeout=300, time_out=60, user='root', password='db_password', host='10.1.0.8')class BaseModel(Model): class Meta: database = db 以下数据库连接池类可用： PooledPostgresqlDatabase PooledPostgresqlExtDatabase PooledMySQLDatabase PooledSqliteDatabase PooledSqliteExtDatabase 执行查询如果想直接执行 SQL 语句，可以使用 Database.execute_sql() 方法。 1234567891011db = SqliteDatabase('my_app.db')db.connect()# Example of executing a simple query and ignoring the results.db.execute_sql("ATTACH DATABASE ':memory:' AS cache;")# Example of iterating over the results of a query using the cursor.cursor = db.execute_sql('SELECT * FROM users WHERE status = ?', (ACTIVE,))for row in cursor.fetchall(): # Do something with row, which is a tuple containing column data. pass 事务管理Peewee 提供了几个用于处理事务的接口，最常用的是 Database.atomic() 方法，它也支持嵌套事务。如果包装块中发生异常，则当前事务将回滚，否则将提交。 而在 atomic() 上下文管理器包装的代码块内部时，可以通过调用 Transaction.rollback() 或者 Transaction.commit() 显性的回滚或提交事务。 1234567891011121314with db.atomic() as transaction: # Opens new transaction. try: save_some_objects() except ErrorSavingData: # Because this block of code is wrapped with "atomic", a # new transaction will begin automatically after the call # to rollback(). transaction.rollback() error_saving = True create_report(error_saving=error_saving) # Note: no need to call commit. Since this marks the end of the # wrapped block of code, the `atomic` context manager will # automatically call commit for us. atomic() 不仅可以用作上下文管理器，还可用做装饰器 用作装饰器：12345678910111213db = SqliteDatabase(':memory:')with db.atomic() as txn: # This is the outer-most level, so this block corresponds to # a transaction. User.create(username='charlie') with db.atomic() as nested_txn: # This block corresponds to a savepoint. User.create(username='huey') # This will roll back the above create() query. nested_txn.rollback() User.create(username='mickey')# When the block ends, the transaction is committed (assuming no error# occurs). At that point there will be two users, "charlie" and "mickey". 还可使用 atomic() 方法来获取或创建数据：123456try: with db.atomic(): user = User.create(username=username) return 'Success'except peewee.IntegrityError: return 'Failure: %s is already in use.' % username 用作装饰器：123456@db.atomic()def create_user(username): # This statement will run in a transaction. If the caller is already # running in an `atomic` block, then a savepoint will be used instead. return User.create(username=username)create_user('charlie') 保存点： 可以像显式创建事务一样，也可以使用 savepoint() 方法显式创建保存点。保存点必须发生在一个事务中，但可以任意嵌套。 1234567with db.transaction() as txn: with db.savepoint() as sp: User.create(username='mickey') with db.savepoint() as sp2: User.create(username='zaizee') sp2.rollback() # "zaizee" will not be saved, but "mickey" will be. 如果手动提交或回滚保存点，则不会自动创建新的保存点。这与事务的行为不同，它会在手动提交/回滚之后自动打开新的事务。 日志记录所有查询都使用标准库 logging 模块记录到 peewee 命名空间。查询使用 DEBUG 级别。如果你对查询有兴趣，你可以简单地注册一个处理程序。 12345# Print all queries to stderr.import logginglogger = logging.getLogger('peewee')logger.setLevel(logging.DEBUG)logger.addHandler(logging.StreamHandler()) 模型和字段模型类、字段实例和模型实例都映射到了数据库 项 对应于 模型类 数据库 字段实例 表中的列 模型实例 表中的行 下面的例子演示了定义数据库连接和模型类的方法 1234567891011121314151617181920from peewee import *# 创建一个数据库的实例db = SqliteDatabase('my_app.db')# 创建一个指定数据库的基础模型类class BaseModel(Model): class Meta: database = db# 定义模型类class User(BaseModel): username = CharField(unique=True)# 定义模型类class Tweet(BaseModel): user = ForeignKeyField(User, backref='tweets') message = TextField() created_date = DateTimeField(default=datetime.datetime.now) is_published = BooleanField(default=True) 字段字段类用于描述模型属性到数据库字段的映射，每一个字段类型都有一个相应的 SQL 存储类型，如 varchar, int。并且python的数据类型和 SQL 存储类型之间的转换是透明的。 在创建模型类时，字段被定义为类属性。有一种特殊类型的字段 ForeignKeyField，可以以更直观的方式表示模型之间的外键关系。 1234class Message(Model): user = ForeignKeyField(User, backref='messages') body = TextField() send_date = DateTimeField() 这允许你编写如下的代码： 123print(some_message.user.username)for message in some_user.messages: print(message.body) 字段类型表 字段类型 Sqlite Postgresql MySQL IntegerField integer integer integer BigIntegerField integer bigint bigint SmallIntegerField integer smallint smallint AutoField integer serial integer FloatField real real real DoubleField real double precision double precision DecimalField decimal numeric numeric CharField varchar varchar varchar FixedCharField char char char TextField text text longtext BlobField blob bytea blob BitField integer bigint bigint BigBitField blob bytea blob UUIDField text uuid varchar(40) DateTimeField datetime timestamp datetime DateField date date date TimeField time time time TimestampField integer integer integer IPField integer bigint bigint BooleanField integer boolean bool BareField untyped 不支持 不支持 ForeignKeyField integer integer integer 字段初始参数所有字段类型接受的参数与默认值 null = False – 布尔值，表示是否允许存储空值 index = False – 布尔值，表示是否在此列上创建索引 unique = False – 布尔值，表示是否在此列上创建唯一索引 column_name = None – 如果和属性名不同，底层的数据库字段使用这个值 default = None – 字段默认值，可以是一个函数，将使用函数返回的值 primary_key = False – 布尔值，此字段是否是主键 constraints = None - 一个或多个约束的列表 例如：[Check(&#39;price &gt; 0&#39;)] sequence = None – 序列填充字段（如果后端数据库支持） collation = None – 用于排序字段/索引的排序规则 unindexed = False – 表示虚拟表上的字段应该是未索引的（仅用于sqlite） choices = None – 一个可选的迭代器，包含两元数组（value, display） help_text = None – 表示字段的帮助文本 verbose_name = None – 表示用户友好的字段名 一些字段的特殊参数 字段类型 特殊参数 CharField max_length FixedCharField max_length DateTimeField formats DateField formats TimeField formats TimestampField resolution, utc DecimalField max_digits, decimal_places, auto_round, rounding ForeignKeyField model, field, backref, on_delete, on_update, extra BareField coerce 字段默认值创建对象时，peewee 可以为字段提供默认值，例如将字段的默认值null设置为0123class Message(Model): context = TextField() read_count = IntegerField(default=0) 如果想提供一个动态值，比如当前时间，可以传入一个函数 123class Message(Model): context = TextField() timestamp = DateTimeField(default=datetime.datetime.now) 数据库还可以提供字段的默认值。虽然 peewee 没有明确提供设置服务器端默认值的 API，但您可以使用 constraints 参数来指定服务器默认值： 123class Message(Model): context = TextField() timestamp = DateTimeField(constraints=[SQL('DEFAULT CURRENT_TIMESTAMP')]) 外键字段foreignkeyfield 是一种特殊的字段类型，允许一个模型引用另一个模型。通常外键将包含与其相关的模型的主键（但您可以通过指定一个字段来指定特定的列）。 可以通过追加 _id 的外键字段名称来访问原始外键值 12345tweets = Tweet.select()for tweet in tweets: # Instead of "tweet.user", we will just get the raw ID value stored # in the column. print(tweet.user_id, tweet.message) ForeignKeyField 允许将反向引用属性绑定到目标模型。隐含地，这个属性将被命名为 classname_set，其中 classname 是类的小写名称，但可以通过参数覆盖 backref： 123456789101112class Message(Model): from_user = ForeignKeyField(User) to_user = ForeignKeyField(User, backref='received_messages') text = TextField()for message in some_user.message_set: # We are iterating over all Messages whose from_user is some_user. print(message)for message in some_user.received_messages: # We are iterating over all Messages whose to_user is some_user print(message) 日期字段DateField TimeField 和 DateTimeField 字段 DateField 包含 year month dayTimeField 包含 hour minute secondDateTimeField 包含以上所有 创建模型表为了开始使用模型，它需要打开一个到数据库的连接并创建表。Peewee 将运行必要的 CREATE TABLE 查询，另外创建约束和索引。 12345# Connect to our database.db.connect()# Create the tables.db.create_tables([User, Tweet]) 默认情况下，Peewee 将确定表是否已经存在，并有条件地创建它们。如果你想禁用它，指定 safe=False。 模型选项和表格元数据为了不污染模型空间，模型的配置被放置在名为 Meta 的特殊类中 123456from peewee import *contacts_db = SqliteDatabase('contacts.db')class Person(Model): name = CharField() class Meta: database = contacts_db 模型一旦定义，访问元数据应该访问 ModelClass._meta 123Person._meta.fieldsPerson._meta.primary_keyPerson._meta.database 有几个选项可以指定为Meta属性。虽然大多数选项都是可继承的，但有些选项是特定于表的，不会被子类继承。 选项 含义 是否可继承 database 模型的数据库 是 table_name 用于存储数据的表的名称 否 table_function 函数动态生成表名 是 indexes 要索引的字段列表 是 primary_key 一个 CompositeKey 实例 是 constraints 表约束列表 是 schema 模型的数据库概要 是 only_save_dirty 当调用 model.save() 时，只保存脏字段 是 options 用于创建表扩展选项的字典 是 table_alias 用于查询中的表的别名 否 depends_on 此表依赖于另一个表的创建 否 without_rowid 指示表不应该有rowid（仅限SQLite） 否 不可被继承的例子 &gt;&gt;&gt; db = SqliteDatabase(&apos;:memory:&apos;) &gt;&gt;&gt; class ModelOne(Model): ... class Meta: ... database = db ... table_name = &apos;model_one_tbl&apos; ... &gt;&gt;&gt; class ModelTwo(ModelOne): ... pass ... &gt;&gt;&gt; ModelOne._meta.database is ModelTwo._meta.database True &gt;&gt;&gt; ModelOne._meta.table_name == ModelTwo._meta.table_name False 自定义主键或者没有主键可以用 CompositeKey 或者将主键设置为 False 1234567891011class BlogToTag(Model): """A simple "through" table for many-to-many relationship.""" blog = ForeignKeyField(Blog) tag = ForeignKeyField(Tag) class Meta: primary_key = CompositeKey('blog', 'tag')class NoPrimaryKey(Model): data = IntegerField() class Meta: primary_key = False 索引和约束Peewee 可以在单列或多列上创建索引，可以包含 UNIQUE 约束。Peewee 还在模型和字段上支持用户定义的约束。 单列索引和约束单列索引是使用字段初始化参数定义的。以下示例在用户名字段上添加唯一索引，并在电子邮件字段上添加常规索引： 123class User （Model ）： username = CharField （unique = True ） email = CharField （index = True ） 要在列上添加用户定义的约束，可以使用constraints参数传递它 。您可能希望将默认值指定为架构的一部分，或者添加一个 CHECK 约束，例如： 12345class Product(Model): name = CharField(unique=True) price = DecimalField(constraints=[Check('price &lt; 10000')]) created = DateTimeField( constraints=[SQL("DEFAULT (datetime('now'))")]) 多列索引多列索引可以使用嵌套元组定义为元属性。每个数据库索引都是一个两个元素的元组，第一部分是字段名称的元组，第二部分是布尔值，指示索引是否应该是唯一的。 12345678910111213class Transaction(Model): from_acct = CharField() to_acct = CharField() amount = DecimalField() date = DateTimeField() class Meta: indexes = ( # create a unique on from/to/date (('from_acct', 'to_acct', 'date'), True), # create a non-unique on from/to (('from_acct', 'to_acct'), False), ) 创建高级索引Peewee 支持更结构化的 API，以便使用该 Model.add_index() 方法在模型上声明索引，或直接使用 ModelIndexhelper 类。 12345678910111213141516class Article(Model): name = TextField() timestamp = TimestampField() status = IntegerField() flags = IntegerField()# Add an index on "name" and "timestamp" columns.Article.add_index(Article.name, Article.timestamp)# Add a partial index on name and timestamp where status = 1.Article.add_index(Article.name, Article.timestamp, where=(Article.status == 1))# Create a unique index on timestamp desc, status &amp; 4.idx = Article.index( Article.timestamp.desc(), Article.flags.bin_and(4), unique=True)Article.add_index(idx) 表约束Peewee允许您为您添加任意约束Model，这将在创建模式时成为表定义的一部分。 例如，假设您有一个具有两列组合主键的人员表格，即人员的姓名。您希望将另一个表与人员表相关联，为此，您需要定义一个外键约束： 12345678910111213class Person(Model): first = CharField() last = CharField() class Meta: primary_key = CompositeKey('first', 'last')class Pet(Model): owner_first = CharField() owner_last = CharField() pet_name = CharField() class Meta: constraints = [SQL('FOREIGN KEY(owner_first, owner_last) ' 'REFERENCES person(first, last)')] 也可以使用 CHECK 在表级别实施约束： 12345class Product(Model): name = CharField(unique=True) price = DecimalField() class Meta: constraints = [Check('price &lt; 10000')] 其他主键非整数主键如果想使用非整数主键，可以在创建字段时指定 primary_key=True。当希望使用非自动增量主键为模型创建新实例时，您需要确保 save() 指定 force_insert=True。 123from peewee import *class UUIDModel(Model): id = UUIDField(primary_key=True) 自动递增ID在新行插入数据库时​​会自动生成，当调用 save() 时 peewee 会根据主键值的存在性来确定是否执行 insert 和 update。由于在上一个例子中，数据库驱动程序不会生成新的ID，所以需要手动指定它。在第一次调用 save() 时，传入：force_insert = True 123456789import uuid# This works because .create() will specify `force_insert=True`.obj1 = UUIDModel.create(id=uuid.uuid4())# This will not work, however. Peewee will attempt to do an update:obj2 = UUIDModel(id=uuid.uuid4())obj2.save() # WRONGobj2.save(force_insert=True) # CORRECT# Once the object has been created, you can call save() normally.obj2.save() 复合主键Peewee 对复合键有基本的支持。为了使用组合键，必须将 primary_key 模型选项的属性设置为一个 CompositeKey 实例： 123456class BlogToTag(Model): """A simple "through" table for many-to-many relationship.""" blog = ForeignKeyField(Blog) tag = ForeignKeyField(Tag) class Meta: primary_key = CompositeKey('blog', 'tag') 手动指定主键有时不希望数据库自动为主键生成值，例如在批量加载关系数据时。要一次性处理这个问题，您可以简单地告诉 peewee auto_increment 在导入期间关闭： 123456789data = load_user_csv() # load up a bunch of dataUser._meta.auto_increment = False # turn off auto incrementing IDswith db.transaction(): for row in data: u = User(id=row[0], username=row[1]) u.save(force_insert=True) # &lt;-- force peewee to insert rowUser._meta.auto_increment = True 如果想要始终控制主键，则不要使用 PrimaryKeyField 字段类型，而要使用正常 IntegerField（或其他列类型）： class User(BaseModel): id = IntegerField(primary_key=True) username = CharField() &gt;&gt;&gt; u = User.create(id=999, username=&apos;somebody&apos;) &gt;&gt;&gt; u.id 999 &gt;&gt;&gt; User.get(User.username == &apos;somebody&apos;).id 999 没有主键的模型如果你想创建一个没有主键的模型，你可以在内部类 Meta 中指定 ：primary_key = False 123456class MyData(BaseModel): timestamp = DateTimeField() value = IntegerField() class Meta: primary_key = False 更改和查询本章将介绍在关系型数据库上执行 CRUD 操作 Model.create()，用于执行 INSERT 请求。 Model.save() 和 Model.update() 执行 UPDATE 请求。 Model.delete_instance() 和 Model.delete() 执行 DELETE 请求。 Model.select()，用于执行 SELECT 请求。 创建一条新记录可以使用 Model.create() 创建一个新的模型实例。此方法接受关键字参数，其中键与模型字段的名称相对应。返回一个新实例并将一行添加到表中。 1User.create(username='Charlie') 这将插入一行新数据到数据库中，主键将自动检索并存储在模型实例中。或者还可以先创建模型实例，然后调用 save() &gt;&gt;&gt; user = User(username=&apos;Charlie&apos;) &gt;&gt;&gt; user.save() # save() returns the number of rows modified. 1 &gt;&gt;&gt; user.id 1 &gt;&gt;&gt; huey = User() &gt;&gt;&gt; huey.username = &apos;Huey&apos; &gt;&gt;&gt; huey.save() 1 &gt;&gt;&gt; huey.id 2 当模型有外键时，可以在创建新记录时直接将模型实例分配给外键字段。 &gt;&gt;&gt; tweet = Tweet.create(user=huey, message=&apos;Hello!&apos;) 也可以使用相关对象主键的值： &gt;&gt;&gt; tweet = Tweet.create(user=2, message=&apos;Hello again!&apos;) 如果只是想插入数据而不需要创建模型实例，则可以使用 Model.insert()： &gt;&gt;&gt; User.insert(username=&apos;Mickey&apos;).execute() 3 批量插入可以通过调用 insert_many() 高效率的插入大量数据 12345678910111213141516171819data_source = [ &#123;'field1': 'val1-1', 'field2': 'val1-2'&#125;, &#123;'field1': 'val2-1', 'field2': 'val2-2'&#125;, # ...]# 最快的方法MyModel.insert_many(data_source).execute()# 也可以使用元组 并指定插入的字段fields = [MyModel.field1, MyModel.field2]data = [('val1-1', 'val1-2'), ('val2-1', 'val2-2'), ('val3-1', 'val3-2')]MyModel.insert_many(data, fields=fields)# 也可以包含在一个事务中with db.atomic(): MyModel.insert_many(data, fields=fields) 如果要批量加载的数据存储在另一个表中，则还可以创建其源为 SELECT 请求的 INSERT 请求。使用 方法：Model.insert_from() 12345query = (TweetArchive .insert_from( Tweet.select(Tweet.user, Tweet.message), fields=[Tweet.user, Tweet.message]) .execute()) 更新数据一旦模型具有主键，后续的任何 save() 都将导致 UPDATE 而不是 INSERT，该模型的主键不会改变。 &gt;&gt;&gt; user.save() 1 &gt;&gt;&gt; user.id 2 &gt;&gt;&gt; user.username = &apos;Tom&apos; &gt;&gt;&gt; user.save() 1 &gt;&gt;&gt; user.id 2 如果想更新多条记录，使用 Model.update() &gt;&gt;&gt; today = datetime.today() &gt;&gt;&gt; query = Tweet.update(is_published=True).where(Tweet.creation_date &lt; today) &gt;&gt;&gt; query.execute() # Returns the number of rows that were updated. 4 原子更新peewee 允许执行原子更新。假设需要更新计数器，天真的方法是这样写的： &gt;&gt;&gt; for stat in Stat.select().where(Stat.url == request.url): ... stat.counter += 1 ... stat.save() 这样速度不仅特别慢，如果多进程同时更新计数器，还会受到竞争条件的影响。可以使用 update() 自动更新计数器。 12query = Stat.update(counter=Stat.counter + 1).where(Stat.url == request.url)query.execute() 还可以使这些更新语句更复杂些。让我们给所有员工一个奖金，等于他们以前的奖金加上他们工资的10％： 12query = Employee.update(bonus=(Employee.bonus + (Employee.salary * .1)))query.execute() 还可以使用子查询来更新值： 123subquery = Tweet.select(fn.COUNT(Tweet.id)).where(Tweet.user == User.id)update = User.update(num_tweets=subquery)update.execute() 删除记录要删除单个模型实例，可以使用 Model.delete_instance()，delete_instance() 方法将删除给定的模型实例，并可以递归删除任何依赖对象（指定 recursive=True） 12user = User.get(User.id == 1)user.delete_instance() 要删除多行，可以使用删除命令： 12query = Tweet.delete().where(Tweet.creation_date &lt; one_year_ago)query.execute() 查询一条记录可以使用 Model.get() 方法来检索查询匹配到的单个实例。对于主键查找，还可以使用快捷方式 Model.get_by_id()。如果没有查询到结果，将返回一个异常 &gt;&gt;&gt; User.get(User.id == 1) &lt;__main__.User object at 0x25294d0&gt; &gt;&gt;&gt; User.get_by_id(1) # Same as above. &lt;__main__.User object at 0x252df10&gt; &gt;&gt;&gt; User[1] # Also same as above. &lt;__main__.User object at 0x252dd10&gt; &gt;&gt;&gt; User.get(User.id == 1).username u&apos;Charlie&apos; &gt;&gt;&gt; User.get(User.username == &apos;Charlie&apos;) &lt;__main__.User object at 0x2529410&gt; &gt;&gt;&gt; User.get(User.username == &apos;nobody&apos;) UserDoesNotExist: instance matching query does not exist: SQL: SELECT t1.&quot;id&quot;, t1.&quot;username&quot; FROM &quot;user&quot; AS t1 WHERE t1.&quot;username&quot; = ? PARAMS: [&apos;nobody&apos;] 对于更高级的查询，可以使用 SelectBase.get()。 &gt;&gt;&gt; (Tweet ... .select() ... .join(User) ... .where(User.username == &apos;charlie&apos;) ... .order_by(Tweet.created_date.desc()) ... .get()) &lt;__main__.Tweet object at 0x2623410&gt; 获取或创建Peewee 有一个用于执行获取或者创建类型操作的方法 Model.get_or_create()，它首先尝试检索匹配的行，否则将创建一个新行 1user, created = User.get_or_create(username=username) 选择多行可以使用 Model.select() 从表中检索多行，peewee 允许迭代以及检索和切片这些行 &gt;&gt;&gt; query = User.select() &gt;&gt;&gt; [user.username for user in query] [&apos;Charlie&apos;, &apos;Huey&apos;, &apos;Peewee&apos;] &gt;&gt;&gt; query[1] &lt;__main__.User at 0x7f83e80f5550&gt; &gt;&gt;&gt; query[1].username &apos;Huey&apos; &gt;&gt;&gt; query[:2] [&lt;__main__.User at 0x7f83e80f53a8&gt;, &lt;__main__.User at 0x7f83e80f5550&gt;] 除了返回模型实例之外，选择查询还可以返回字典，元组和命名集。 &gt;&gt;&gt; query = User.select().dicts() &gt;&gt;&gt; for row in query: ... print(row) {&apos;id&apos;: 1, &apos;username&apos;: &apos;Charlie&apos;} {&apos;id&apos;: 2, &apos;username&apos;: &apos;Huey&apos;} {&apos;id&apos;: 3, &apos;username&apos;: &apos;Peewee&apos;} 过滤可以使用普通的Python操作符来过滤特定的记录。 Peewee 支持多种查询操作符。 &gt;&gt;&gt; user = User.get(User.username == &apos;Charlie&apos;) &gt;&gt;&gt; for tweet in Tweet.select().where(Tweet.user == user, Tweet.is_published == True): ... print(tweet.user.username, &apos;-&gt;&apos;, tweet.message) ... Charlie -&gt; hello world Charlie -&gt; this is fun &gt;&gt;&gt; for tweet in Tweet.select().where(Tweet.created_date &lt; datetime.datetime(2011, 1, 1)): ... print(tweet.message, tweet.created_date) ... Really old tweet 2010-01-01 00:00:00 还可以使用 join 后过滤 &gt;&gt;&gt; for tweet in Tweet.select().join(User).where(User.username == &apos;Charlie&apos;): ... print(tweet.message) hello world this is fun look at this picture of my food 如果想表达复杂的逻辑，还可以使用 | 或者 &amp; 操作符 &gt;&gt;&gt; Tweet.select().join(User).where( ... (User.username == &apos;Charlie&apos;) | ... (User.username == &apos;Peewee Herman&apos;)) 排序要按顺序返回行，要使用 order_by() 方法 &gt;&gt;&gt; for t in Tweet.select().order_by(Tweet.created_date): ... print(t.pub_date) ... 2010-01-01 00:00:00 2011-06-07 14:08:48 2011-06-07 14:12:57 &gt;&gt;&gt; for t in Tweet.select().order_by(Tweet.created_date.desc()): ... print(t.pub_date) ... 2011-06-07 14:12:57 2011-06-07 14:08:48 2010-01-01 00:00:00 还可以使用 + 和 - 前缀来指示排序： 12345678# The following queries are equivalent:Tweet.select().order_by(Tweet.created_date.desc())Tweet.select().order_by(-Tweet.created_date) # Note the "-" prefix.# Similarly you can use "+" to indicate ascending order, though ascending# is the default when no ordering is otherwise specified.User.select().order_by(+User.username) 还可以使用 join 连接后排序 1234query = (Tweet .select() .join(User) .order_by(User.username, Tweet.created_date.desc())) 当对计算值进行排序时，可以包含必需的 sql 表达式，或者分配给该值别名。 1234567# Let's start with our base query. We want to get all usernames and the number of# tweets they've made. We wish to sort this list from users with most tweets to# users with fewest tweets.query = (User .select(User.username, fn.COUNT(Tweet.id).alias('num_tweets')) .join(Tweet, JOIN.LEFT_OUTER) .group_by(User.username)) 还可以在 select 中使用 COUNT 表达式来排序 12345query = (User .select(User.username, fn.COUNT(Tweet.id).alias('num_tweets')) .join(Tweet, JOIN.LEFT_OUTER) .group_by(User.username) .order_by(fn.COUNT(Tweet.id).desc())) 获取随机记录偶尔可能想从数据库中提取一条随机记录，可以通过 random 或 rand（取决于你的数据库）来完成这个任务： 1234567# Postgresql and Sqlite use the Random function# Pick 5 lucky winners:LotteryNumber.select().order_by(fn.Random()).limit(5)# MySQL uses Rand:# Pick 5 lucky winners:LotterNumber.select().order_by(fn.Rand()).limit(5) 分页paginate() 方法可以轻松对记录进行分页，paginate() 方法需要两个参数，page_number, 和 items_per_page。 &gt;&gt;&gt; for tweet in Tweet.select().order_by(Tweet.id).paginate(2, 10): ... print(tweet.message) ... tweet 10 tweet 11 tweet 12 tweet 13 tweet 14 tweet 15 tweet 16 tweet 17 tweet 18 tweet 19 计数可以计算任何查询中选择的行数 1234&gt;&gt;&gt; Tweet.select().count()100&gt;&gt;&gt; Tweet.select().where(Tweet.id &gt; 50).count()50 汇总假设你有一些用户，并希望得到他们的列表以及每个人的推文数量。 1234query = (User .select(User, fn.Count(Tweet.id).alias('count')) .join(Tweet, JOIN.LEFT_OUTER) .group_by(User)) 返回标量值可以通过调用 Query.scalar() 来返回标量值： &gt;&gt;&gt; PageView.select(fn.Count(fn.Distinct(PageView.url))).scalar() 100 您可以通过传递 as_tuple=true 来返回多个标量值： &gt;&gt;&gt; Employee.select( ... fn.Min(Employee.salary), fn.Max(Employee.salary) ... ).scalar(as_tuple=True) (30000, 50000) SQL函数，子查询和原始表达式要使用特殊的 SQL 函数，需要使用 fn 的对象来构造请求假设要获取所有以字母 a 开头的用户列表： 123456789# Select the user's id, username and the first letter of their username, lower-casedfirst_letter = fn.LOWER(fn.SUBSTR(User.username, 1, 1))query = User.select(User, first_letter.alias('first_letter'))# Alternatively we could select only users whose username begins with 'a'a_users = User.select().where(first_letter == 'a')for user in a_users: print(user.username) 有时候想传入一些任意的 SQL ，可以使用特殊的 SQL 类来做到这点 123456789101112# We'll query the user table and annotate it with a count of tweets for# the given userquery = (User .select(User, fn.Count(Tweet.id).alias('ct')) .join(Tweet) .group_by(User))# Now we will order by the count, which was aliased to "ct"query = query.order_by(SQL('ct'))# You could, of course, also write this as:query = query.order_by(fn.COUNT(Tweet.id)) 有两种方法可以用 peewee 执行手动编写的 SQL 语句： Database.execute_sql() 用户执行任意类型的查询 用于执行 SELECT 查询和返回模型实例的 RawQuery 安全和SQL注入默认情况下，peewee会参数化查询，所以用户传入的参数将被转义。这条规则唯一的例外是，如果你正在编写一个原始的 sql 查询或传入一个可能包含不可信数据的 sql 对象。为了减轻这一点，请确保任何用户定义的数据都作为查询参数传入，而不是实际的 sql 查询的一部分： 1234567891011# Bad! DO NOT DO THIS!query = MyModel.raw('SELECT * FROM my_table WHERE data = %s' % (user_data,))# Good. `user_data` will be treated as a parameter to the query.query = MyModel.raw('SELECT * FROM my_table WHERE data = %s', user_data)# Bad! DO NOT DO THIS!query = MyModel.select().where(SQL('Some SQL expression %s' % user_data))# Good. `user_data` will be treated as a parameter.query = MyModel.select().where(SQL('Some SQL expression %s', user_data)) 返回元组/字典/名称元组有时候不需要创建模型实例的开销，只需要数据即可，可以使用： dicts() namedtuples() tuples() objects() – 接受用行元组调用的任意构造函数。 12345678stats = (Stat .select(Stat.url, fn.Count(Stat.url)) .group_by(Stat.url) .tuples())# iterate over a list of 2-tuples containing the url and countfor stat_url, stat_count in stats: print(stat_url, stat_count) 同样也可以使用 dicts() 将数据作为字典返回 12345678stats = (Stat .select(Stat.url, fn.Count(Stat.url).alias('ct')) .group_by(Stat.url) .dicts())# iterate over a list of 2-tuples containing the url and countfor stat in stats: print(stat['url'], stat['ct']) 查询操作符Peewee 支持以下类型的比较： 对照 含义 == x 等于 y &lt; x 小于 y &lt;= x 小于或等于 y > x 大于 y >= x 大于或等于 y != x 不等于 y &lt;&lt; x IN y, y 是一个列表或查询 >&gt; x IS y, 当 y 是 None 或者 NULL % x LIKE y, 当 y 可能包含通配符 ** x ILIKE y, 当 y 可能包含通配符 ^ x XOR y ~ 非 (例如：NOT x) 还有一些查询可以用方法： 方法含义.contains(substr)通配符搜索子字符串.startswith(prefix)搜索以prefix为前缀的值.endswith(suffix)搜索以suffix为后缀的值.between(low,high)搜索low和 high之间的值.regexp(exp)正则表达式匹配.bin_and(value)二进制 AND.bin_or(value)二进制 OR.in_(value)值是否属于.not_in(value)值是否不属于.is_null(is_null)是 NULL 或者不是 NULL .concat(other)连接两个字符串.distinct()标记不同的选择列 要使用逻辑运算符来组合子句，使用： 操作符意思示例&amp;AND(User.is_active==True)&amp;(User.is_admin==True)|OR(User.is_admin)|(User.is_superuser)~NOT~(User.username&lt;&lt;[‘foo’,‘bar’,‘baz’]) 如何使用查询操作符的示例： 1234567891011# Find the user whose username is "charlie".User.select().where(User.username == 'charlie')# Find the users whose username is in [charlie, huey, mickey]User.select().where(User.username &lt;&lt; ['charlie', 'huey', 'mickey'])Employee.select().where(Employee.salary.between(50000, 60000))Employee.select().where(Employee.name.startswith('C'))Blog.select().where(Blog.title.contains(search_string)) 这里是如何组合表达式的示例： 1234567891011121314151617# Find any users who are active administrations.User.select().where( (User.is_admin == True) &amp; (User.is_active == True))# Find any users who are either administrators or super-users.User.select().where( (User.is_admin == True) | (User.is_superuser == True))# Find any Tweets by users who are not admins (NOT IN).admins = User.select().where(User.is_admin == True)non_admin_tweets = Tweet.select().where(~(Tweet.user &lt;&lt; admins))# Find any users who are not my friends (strangers).friends = User.select().where(User.username.in_(['charlie', 'huey', 'mickey']))strangers = User.select().where(User.id.not_in(friends)) 请记住： 使用 .in_() 和 .not_in() 替换 in 和 not in 使用 &amp; 替换 and 使用 | 替换 or 使用 ~ 替换 not 使用 .is_null() 替换 is None 或者 == None 在使用逻辑运算符时，不要忘记使用圆括号包含比较结果 用户自定义操作符如果发现自己需要的操作符不在上表中，可以非常容易的自定义操作符，比如取模运算 这里是如何在 SQLite 中添加取模运算的支持： 12345from peewee import *from peewee import Expression # the building block for expressionsdef mod(lhs, rhs): return Expression(lhs, '%', rhs) 现在可以将自定义运算符来构建更丰富的查询 12# Users with even ids.User.select().where(mod(User.id, 2) == 0) 附录Peewee 的详细使用说明请翻阅 Peewee官方文档]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>python</tag>
        <tag>peewee</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP基础学习]]></title>
    <url>%2F2018%2F03%2F12%2F2018%2FPHP%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%2F</url>
    <content type="text"><![CDATA[简介 PHP全称PHP Hypertext Preprocessor，是一种通用开源脚本语言。语法吸收了C语言、Java和Perl的特点，利于学习，使用广泛，主要适用于Web开发领域。PHP 独特的语法混合了C、Java、Perl以及PHP自创的语法。它可以比CGI或者Perl更快速地执行动态网页。用PHP做出的动态页面与其他的编程语言相比，PHP是将程序嵌入到HTML文档中去执行，执行效率比完全生成HTML标记的CGI要高许多；PHP还可以执行编译后代码，编译可以达到加密和优化代码运行，使代码运行更快。 环境搭建Windows开发环境 系统环境为Windows 10，这里使用当前最新版，Windows版PHP下载地址为：点此打开 当前最新版PHP为7.2.3 点此下载 F盘中创建phpstudy目录 在phpstudy目录中创建php-7.2.3、src目录 将下载好的php-7.2.3-nts-Win32-VC15-x64.zip解压到php-7.2.3目录中 将php-7.2.3目录下的php.ini-development重命名为php.ini 创建start.bat文件，并写入以下内容1F:\phpstudy\php-7.2.3\php.exe -S 127.0.0.1:8088 -t F:\phpstudy\src 当前目录结构应该如下所示： 双击start.bat会打开一个cmd窗口 显示内容如下： F:\phpstudy&gt;F:\phpstudy\php-7.2.3\php.exe -S 127.0.0.1:8088 -t F:\phpstudy\src PHP 7.2.3 Development Server started at Tue Mar 6 13:00:13 2018 Listening on http://127.0.0.1:8088 Document root is F:\phpstudy\src Press Ctrl-C to quit. 在src目录下创建phpinfo.php文件，并写入以下内容 123&lt;?php phpinfo();?&gt; 打开浏览器访问: http://127.0.0.1:8088/phpinfo.php 出现如下信息 PHP开发环境就搭建完成了。 语法基本语法PHP标记PHP只会解析文档中&lt;?php ... ?&gt;代码块的内容，其他的内容都会忽略 如果文件内容是纯PHP代码，最好在文件末尾删除PHP的结束标记，这样可以避免在PHP结束标记之后万一意外加入了空格或者换行符，会导致 PHP 开始输出这些空白，而脚本中此时并无输出的意图。 12345&lt;?php echo "Hello World"; // Other Code echo "Last statement" // 脚本结束，不需要 ?&gt; 作为结束标记 PHP还有一种标记方式123&lt;script language="php"&gt; echo 'Hello World';&lt;/script&gt; 显然&lt;?php ... ?&gt;的方式更为方便 嵌入到HTML文档因为PHP只会解析文档中的PHP标记，所以可以很方便的将PHP嵌入到HTML文档中123&lt;p&gt;This is going to be ignored by PHP and displayed by the browser.&lt;/p&gt;&lt;?php echo 'While this is going to be parsed.'; ?&gt;&lt;p&gt;This will also be ignored by PHP and displayed by the browser.&lt;/p&gt; 将文档保存为src目录下的index.php，然后浏览器访问http://127.0.0.1:8088/。可以看到三条语句都被打印出来了，但是通过PHP的echo打印的语句需要先解析，所以速度肯定是比较慢的。 PHP解析器遇到?&gt;结束标记时就简单的将其后内容原样输出直到再碰到下一个&lt;?php标记。例外的是出于条件语句中间时，PHP解析器会根据条件判断来决定哪些输出，哪些跳过。如下所示：12345&lt;?php if (true): ?&gt; This will show if the expression is true.&lt;?php else: ?&gt; Otherwise this will show.&lt;?php endif; ?&gt; 当if的条件为true时，输出This will show if the expression is true.，否则输出Otherwise this will show.。要输出大段文本时，跳出PHP解析模式通常比将文本通过echo或print输出更有效率。 指令分隔符PHP和C或者Perl一样，每条语句的末尾使用分号结束指令。如果指令是PHP代码的最后一行，则可以省略掉分号。 1234&lt;?phpecho "First line&lt;br&gt;";echo "Last line"?&gt; 如果想要省略掉?&gt; 则最后一行语句必须有分号123&lt;?phpecho "First line&lt;br&gt;";echo "Last line"; 注释PHP支持三种注释方法12345678910&lt;?php// This is a one-line c++ style comment/*This is a multi line commentyet another line of comment*/# This is a one-line shell-style comment?&gt; 类型 PHP支持9种原始数据类型，其中有四种标量类型，三种复合类型，两种特殊类型 标量类型boolean 布尔型要指定一个布尔值，使用常量TRUE和FALSE，两个都不区分大小写。 1234&lt;?php$a = true;$b = false;?&gt; 当整数和浮点数的零，空字符串，空数组，NULL，从空标记生成的SimpleXML对象转换为布尔型时 都会认为是FALSE，其他的值都被认为是TRUE 1234567&lt;?phpvar_dump((bool) "");var_dump((bool) 0);var_dump((bool) 0.0);var_dump((bool) []);var_dump((bool) NULL);?&gt; integer 整型所有的正整数和负整数都属于整数 1234567&lt;?php$a = 1234; // 十进制数$a = -123; // 负数$a = 0123; // 八进制数 (等于十进制 83)$a = 0x1A; // 十六进制数 (等于十进制 26)$a = 0b11111111; // 二进制数字 (等于十进制 255)?&gt; 其他类型转为整数时，FALSE会转为0，TRUE会转为1，浮点型会向下取整。 注意：32位平台整数最大为2147483647，64位平台整数最大为9223372036854775807。溢出后将自动转为浮点型。 float 浮点型浮点型就是带小数位的数，可以用以下任一语法定义：12345&lt;?php$a = 1.234; $b = 1.2e3; $c = 7E-10;?&gt; string 字符串一个字符串就是由一系列的字符组成，其中每个字符等同于一个字节。这意味着PHP只能支持256的字符集，因此不支持Unicode 。 PHP的字符串有四种方式表达 单引号 双引号 heredoc语法结构 nowdoc语法结构 (PHP 5.3.0 起) 单引号定义一个字符串的最简单的方法是用单引号把它包围起来（字符 ‘）。 要表达一个单引号自身，需在它的前面加个反斜线（\）来转义。要表达一个反斜线自身，则用两个反斜线（\\）。其它任何方式的反斜线都会被当成反斜线本身：也就是说如果想使用其它转义序列例如 \r 或者 \n，并不代表任何特殊含义，就单纯是这两个字符本身。 1234567891011&lt;?phpecho 'this is a simple string';echo 'You can also have embedded newlines in strings this way as it isokay to do';echo 'Arnold once said: "I\'ll be back"';echo 'You deleted C:\\*.*?';echo 'You deleted C:\*.*?';echo 'This will not expand: \n a newline';echo 'Variables do not $expand $either';?&gt; 输出： this is a simple string You can also have embedded newlines in strings this way as it is okay to do Arnold once said: &quot;I&apos;ll be back&quot; You deleted C:\*.*? You deleted C:\*.*? This will not expand: \n a newline Variables do not $expand $either 双引号如果字符串是包围在双引号(&quot;)中， PHP 将对一些特殊的字符进行解析： 转义字符 序列含义\n换行（ASCII 字符集中的 LF 或 0x0A）\r回车（ASCII 字符集中的 CR 或 0x0D）\t水平制表符（ASCII 字符集中的 HT 或 0x09）\v垂直制表符（ASCII 字符集中的 VT 或 0x0B）（自PHP 5.2.5 起）\eEscape（ASCII 字符集中的 ESC 或 0x1B）（自PHP 5.4.0 起）\f换页（ASCII 字符集中的 FF 或 0x0C）（自PHP 5.2.5 起）\反斜线\$美元标记\”双引号[0-7]{1,3}符合该正则表达式序列的是一个以八进制方式来表达的字符\x[0-9A-Fa-f]{1,2}符合该正则表达式序列的是一个以十六进制方式来表达的字符 用双引号定义的字符串最重要的特征是变量会被解析 1234&lt;?php$a = "World";echo "Hello $a";?&gt; 输出： Hello World Heredoc结构第三种表达字符串的方法是用 heredoc 句法结构：&lt;&lt;&lt;。在该运算符之后要提供一个标识符，然后换行。接下来是字符串 string 本身，最后要用前面定义的标识符作为结束标志。 结束时所引用的标识符必须在该行的第一列，而且，标识符的命名也要像其它标签一样遵守 PHP 的规则：只能包含字母、数字和下划线，并且必须以字母和下划线作为开头。 123456789101112&lt;?php$str = &lt;&lt;&lt;ENDExample of stringspanning multiple lines&lt;/br&gt;END;echo $str;$name = 'MyName';echo &lt;&lt;&lt;ENDMy name is $name.END;?&gt; 输出： Example of string spanning multiple lines. My name is MyName. 自 PHP 5.3.0 起还可以在 Heredoc 结构中用双引号来声明标识符： 12345&lt;?phpecho &lt;&lt;&lt;"FOOBAR"Hello World!FOOBAR;?&gt; Nowdoc 结构就象 heredoc 结构类似于双引号字符串，Nowdoc 结构是类似于单引号字符串的。Nowdoc 结构很象 heredoc 结构，但是 nowdoc 中不进行解析操作。 一个 nowdoc 结构也用和 heredocs 结构一样的标记&lt;&lt;&lt;， 但是跟在后面的标识符要用单引号括起来，即&lt;&lt;&lt;&#39;END&#39;。Heredoc 结构的所有规则也同样适用于 Nowdoc 结构，尤其是结束标识符的规则。 123456789101112&lt;?php$str = &lt;&lt;&lt;'END'Example of stringspanning multiple lines&lt;/br&gt;END;echo $str;$name = 'MyName';echo &lt;&lt;&lt;'END'My name is $name.END;?&gt; 输出： Example of string spanning multiple lines My name is $name. 变量解析当使用双引号或者Heredoc结构定义时，其中的变量将会解析。 变量解析有两种语法规则，一种简单规则，一种复杂规则。简单规则最常见和方便，它可以用最少的代码在一个string中嵌入一个变量、一个array的值、或一个object的属性。 复杂规则是用花括号包围的表达式。 简单规则 1234567891011121314&lt;?php$name = 'Tom';echo "Hello $name&lt;/br&gt;";$juices = array("apple", "orange", "koolaid1" =&gt; "purple");echo "He drank some $juices[0] juice.&lt;/br&gt;";echo "He drank some $juices[koolaid1] juice.&lt;/br&gt;";class people &#123; public $john = "John Smith";&#125;$people = new people();echo "My name is $people-&gt;john.";?&gt; 输出： Hello Tom He drank some apple juice. He drank some purple juice. My name is John Smith. 复杂规则 复杂语法不是因为其语法复杂而得名，而是因为它可以使用复杂的表达式。 任何具有 string 表达的标量变量，数组单元或对象属性都可使用此语法。只需简单地像在 string 以外的地方那样写出表达式，然后用花括号把它括起来即可。 1234567891011121314&lt;?php$name = &apos;Tom&apos;;echo &quot;Hello &#123;$name&#125;&lt;/br&gt;&quot;;$juices = array(&quot;apple&quot;, &quot;orange&quot;, &quot;koolaid1&quot; =&gt; &quot;purple&quot;);echo &quot;He drank some &#123;$juices[0]&#125; juice.&lt;/br&gt;&quot;;echo &quot;He drank some &#123;$juices[&apos;koolaid1&apos;]&#125; juice.&lt;/br&gt;&quot;;class people &#123; public $john = &quot;John Smith&quot;;&#125;$people = new people();echo &quot;My name is &#123;$people-&gt;john&#125;.&quot;;?&gt; 注意：只有通过花括号才能正确解析带引号的键名{$juices[&#39;koolaid1&#39;]} 输出： Hello Tom He drank some apple juice. He drank some purple juice. My name is John Smith. 存取和修改字符串string 中的字符可以通过一个从 0 开始的下标，用类似 array 结构中的方括号包含对应的数字来访问和修改，比如 $str[42]。可以把 string 当成字符组成的 array。函数 substr() 和 substr_replace() 可用于操作多于一个字符的情况。 小提示：string 也可用花括号访问，比如 $str{42}。 12345678910&lt;?php$str = 'This is a test';echo "First: $str[1]&lt;/br&gt;";$last = $str[strlen($str)-1];echo "Last: $last&lt;/br&gt;";$str = 'Look at the sea';$str[strlen($str)-1] = 'e';echo "$str";?&gt; 输出： First: h Last: t Look at the see 复合类型array 数组PHP 中的数组实际上是一个有序映射。映射是一种把 values 关联到 keys 的类型。此类型在很多方面做了优化，因此可以把它当成真正的数组，或列表（向量），散列表（是映射的一种实现），字典，集合，栈，队列以及更多可能性。由于数组元素的值也可以是另一个数组，树形结构和多维数组也是允许的。 定义数组：可以用 array() 语言结构来新建一个数组。它接受任意数量用逗号分隔的 键（key） =&gt; 值（value）对。 数组的键可以是一个整数或字符串，值可以是任意类型的值。自 5.4 开始可以使用[]代替array()。 12345678910111213141516&lt;?php$array = array( "foo" =&gt; "bar", "bar" =&gt; "foo",);// 自 5.4 开始$array = [ "foo" =&gt; "bar", "bar" =&gt; "foo",];// 没有键名的索引数组$array = ["foo", "bar", 6=&gt;"hello", "world"];var_dump($array);?&gt; 如果键名重复，则会使用最后一个键名，前面的都被覆盖了。没有键名的索引数组，键名默认从0开始，如果只对部分单元指定键名，其后面的键名会根据这个单元的键名开始。 输出： array(4) { [0]=&gt; string(3) &quot;foo&quot; [1]=&gt; string(3) &quot;bar&quot; [6]=&gt; string(5) &quot;hello&quot; [7]=&gt; string(5) &quot;world&quot; } 使用方括号访问和修改数组单元 123456789101112131415&lt;?php$array = array( "foo" =&gt; "bar", 42 =&gt; 24, "multi" =&gt; array( "dimensional" =&gt; array( "array" =&gt; "foo" ) ));echo "\$array['foo'] = &#123;$array['foo']&#125;&lt;/br&gt;";echo "\$array[42] = $array[42]&lt;/br&gt;";echo "\$array['multi']['dimensional']['array'] = &#123;$array['multi']['dimensional']['array']&#125;&lt;/br&gt;";?&gt; 输出： $array[&apos;foo&apos;] = bar $array[42] = 24 $array[&apos;multi&apos;][&apos;dimensional&apos;][&apos;array&apos;] = foo 小提示：和字符串一样 数组也可以使用花括号访问单元 例如 array{&#39;foo&#39;} 要修改某个值，通过其键名给该单元赋一个新值，要删除某个键值对，对其调用unset()函数。 123456789&lt;?php$arr = array(5 =&gt; 1, 12 =&gt; 2);$arr[] = 56; // This is the same as $arr[13] = 56; // at this point of the script$arr["x"] = 42; // This adds a new element to // the array with key "x" unset($arr[5]); // This removes the element from the arrayunset($arr); // This deletes the whole array?&gt; object 对象要创建一个新的对象 object，使用 new 语句实例化一个类： 1234567891011&lt;?phpclass foo&#123; function do_foo() &#123; echo "Doing foo."; &#125;&#125;$bar = new foo;$bar-&gt;do_foo();?&gt; callable 可调用一些函数如 call_user_func() 或 usort() 可以接受用户自定义的回调函数作为参数。回调函数不止可以是简单函数，还可以是对象的方法，包括静态类方法。除了普通的用户自定义函数外，也可传递匿名函数给回调参数。 特殊类型resource 资源资源 resource 是一种特殊变量，保存了到外部资源的一个引用。资源是通过专门的函数来建立和使用的。由于资源类型变量保存有为打开文件、数据库连接、图形画布区域等的特殊句柄，因此将其它类型的值转换为资源没有意义。引用计数系统是 Zend 引擎的一部分，可以自动检测到一个资源不再被引用了（和 Java 一样）。这种情况下此资源使用的所有外部资源都会被垃圾回收系统释放。因此，很少需要手工释放内存。 NULL 无类型特殊的 NULL 值表示一个变量没有值。NULL 类型唯一可能的值就是 NULL。 在下列情况下一个变量被认为是 NULL： 被赋值为 NULL。 尚未被赋值。 被 unset()。 PHP 包括几个函数可以判断变量的类型，例如：gettype()，is_array()，is_float()，is_int()，is_object() 和 is_string() 变量基础PHP 中的变量用一个美元符号后面跟变量名来表示。变量名是区分大小写的。$this 是一个特殊的变量，它不能被赋值。 123456789&lt;?php$var = 'Bob';$Var = 'Joe';echo "$var, $Var"; // 输出 "Bob, Joe"$4site = 'not yet'; // 非法变量名；以数字开头$_4site = 'not yet'; // 合法变量名；以下划线开头$i站点is = 'mansikka'; // 合法变量名；可以用中文?&gt; PHP 也提供了另外一种方式给变量赋值：引用赋值。这意味着新的变量简单的引用了原始变量。改动新的变量将影响到原始变量，反之亦然。使用引用赋值，简单地将一个 &amp; 符号加到将要赋值的变量前。例如，下列代码片断将输出“My name is Bob”两次： 1234567&lt;?php$foo = 'Bob'; // 将 'Bob' 赋给 $foo$bar = &amp;$foo; // 通过 $bar 引用 $foo$bar = "My name is $bar"; // 修改 $bar 变量echo "$bar&lt;/br&gt;";echo $foo; // $foo 的值也被修改?&gt; 预定义变量对于全部脚本而言，PHP 提供了大量的预定义变量。这些变量将所有的外部变量表示成内建环境变量，并且将错误信息表示成返回头。 超全局变量 — 超全局变量是在全部作用域中始终可用的内置变量 $GLOBALS — 引用全局作用域中可用的全部变量 $_SERVER — 服务器和执行环境信息 $_GET — HTTP GET 变量 $_POST — HTTP POST 变量 $_FILES — HTTP 文件上传变量 $_REQUEST — HTTP Request 变量 $_SESSION — Session 变量 $_ENV — 环境变量 $_COOKIE — HTTP Cookies $php_errormsg — 前一个错误信息 $HTTP_RAW_POST_DATA — 原生POST数据 $http_response_header — HTTP 响应头 $argc — 传递给脚本的参数数目 $argv — 传递给脚本的参数数组 变量范围一个局部函数范围将被引入。任何用于函数内部的变量按缺省情况将被限制在局部函数范围内。例如： 12345678&lt;?php$a = 1; /* global scope */function Test()&#123; echo $a; /* reference to local scope variable */&#125;Test();?&gt; 这个脚本不会有任何输出，因为 echo 语句引用了一个局部版本的变量 $a，而且在这个范围内，它并没有被赋值。你可能注意到 PHP 的全局变量和 C 语言有一点点不同，在 C 语言中，全局变量在函数中自动生效，除非被局部变量覆盖。这可能引起一些问题，有些人可能不小心就改变了一个全局变量。PHP 中全局变量在函数中使用时必须声明为 global。 1234567891011&lt;?php$a = 1;$b = 2;function Sum()&#123; global $a, $b; $b = $a + $b;&#125;Sum();echo $b;?&gt; 在全局范围内访问变量的第二个办法，是用特殊的 PHP 自定义$GLOBALS 数组。前面的例子可以写成： 12345678910&lt;?php$a = 1;function Sum()&#123; $GLOBALS['b'] = $GLOBALS['a'] + $GLOBALS['b'];&#125;Sum();echo $b;?&gt; $GLOBALS 是一个关联数组，每一个变量为一个元素，键名对应变量名，值对应变量的内容。$GLOBALS 之所以在全局范围内存在，是因为 $GLOBALS 是一个超全局变量。 可变变量可变变量，就是一个变量的变量名可以动态的设置和使用。语法形式是PHP的特殊语法，其他语言中少见。 123456&lt;?php$a = 'hello';$$a = 'world'; // 相当于$hello = 'world'echo "$a $&#123;$a&#125;&lt;/br&gt;";echo "$a $hello";?&gt; 输出： hello world hello world 来自PHP之外的变量HTML表单（GET和POST）当一个表单提交给 PHP 脚本时，表单中的信息会自动在脚本中可用。有很多方法访问此信息，例如： test.html123456789&lt;html&gt;&lt;body&gt; &lt;form action="welcome.php" method="post"&gt; Name: &lt;input type="text" name="name"&gt;&lt;br&gt; E-mail: &lt;input type="text" name="email"&gt;&lt;br&gt; &lt;input type="submit"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; welcome.php123456&lt;html&gt;&lt;body&gt; Welcome &lt;?php echo $_POST["name"]; ?&gt;&lt;br&gt; Your email address is: &lt;?php echo $_POST["email"]; ?&gt;&lt;/body&gt;&lt;/html&gt; 访问 http://127.0.0.1:8088/test.html，输入信息后提交，可以看到跳转到了http://127.0.0.1:8088/welcome.php页面，并且前面输入的数据已经被PHP通过_POST获取了。 GET也类似，只需要将test.html中的method=&quot;post&quot;改为method=&quot;get&quot;，然后将welcome.php中的$_POST改为$_GET就可以了。但是在上传敏感数据的时候比如用户密码时最好使用POST方法，GET方法会将数据编码到URL上，这样其他用户也可能会获取密码信息了。 IMAGE SUBMIT 变量名当提交表单时，可以用一幅图像代替标准的提交按钮，用类似这样的标记： 1&lt;input type="image" src="image.gif" name="sub" /&gt; 当用户点击到图像中的某处时，相应的表单会被传送到服务器，并加上两个变量 sub_x 和 sub_y。它们包含了用户点击图像的坐标。有经验的用户可能会注意到被浏览器发送的实际变量名包含的是一个点而不是下划线（即 sub.x 和 sub.y），但 PHP 自动将点转换成了下划线。 HTTP Cookies使用$_COOKIE可以获取HTTP Cookies数据，在获取前可以使用setcookie()函数设定cookies。 123456789&lt;?phpif (isset($_COOKIE['count'])) &#123; $count = $_COOKIE['count'] + 1;&#125; else &#123; $count = 1;&#125;setcookie('count', $count, time()+3600);echo $count;?&gt; 浏览器访问然后刷新数据，可以看到每刷新一次数字就增加1。 常量常量表示脚本执行期间不能改变值。传统上常量标识符总是大写的。 可以使用const关键字定义常量，而且一旦定义就不可以再修改或者取消定义。常量只能包含boolean、integer、float、string，虽然也可以定义resource常量，但应该尽量避免。与变量不同，不应该在常量前面加上$符号。用get_defined_constants()获取所有已定义的常量列表。 123456&lt;?phpdefine("CONSTANT", "Hello world1.&lt;/br&gt;");echo CONSTANT;const CONSTANT2 = 'Hello world2.&lt;/br&gt;';echo CONSTANT2;?&gt; 输出： Hello world1. Hello world2. 小提示：和使用 define() 来定义常量相反的是，使用 const 关键字定义常量必须处于最顶端的作用区域，因为用此方法是在编译时定义的。这就意味着不能在函数内，循环内以及 if 语句之内用 const 来定义常量。 魔法常量PHP 向它运行的任何脚本提供了大量的预定义常量。不过很多常量都是由不同的扩展库定义的，只有在加载了这些扩展库时才会出现，或者动态加载后，或者在编译时已经包括进去了。 有八个魔术常量它们的值随着它们在代码中的位置改变而改变。例如 __LINE__ 的值就依赖于它在脚本中所处的行来决定。这些特殊的常量不区分大小写，如下： 名称 说明 __LINE__ 文件中的当前行号。 __FILE__ 文件的完整路径和文件名。 __DIR__ 文件所在的目录。 __FUNCTION__ 函数名称。 __CLASS__ 类的名称。 __TRAIT__ Trait 的名字。Trait 名包括其被声明的作用区域。 __METHOD__ 类的方法名。返回该方法被定义时的名字。 __NAMESPACE__ 当前命名空间的名称。 运算符运算符优先级下表按照优先级从高到低列出了运算符。同一行中的运算符具有相同优先级，此时它们的结合方向决定求值顺序。 结合方向运算符附加信息无clone newclone 和 new左[array()右**算术运算符右++–类型和递增／递减无instanceof类型右!逻辑运算符左/%算术运算符左+-.算术运算符和字符串运算符左&lt;&lt;&gt;&gt;位运算符无&lt;&lt;=&gt;&gt;=比较运算符无== !====!==&lt;&gt;&lt;=&gt;比较运算符左&amp;位运算符和引用左^位运算符左|位运算符左&amp;&amp;逻辑运算符左||逻辑运算符左??比较运算符左?:三元运算符右=+=-==**=/=.=%=&amp;=|=^=&lt;&lt;=&gt;&gt;=赋值运算符左and逻辑运算符左xor逻辑运算符左or逻辑运算符 算术运算符 例子 名称 结果 -$a 取反 $a 的负值。 $a + $b 加法 $a 和 $b 的和。 $a - $b 减法 $a 和 $b 的差。 $a * $b 乘法 $a 和 $b 的积。 $a / $b 除法 $a 除以 $b 的商。 $a % $b 取模 $a 除以 $b 的余数。 $a ** $b 取幂 $a 的 $b 次方。 赋值运算符基本的赋值运算符是“=”。一开始可能会以为它是“等于”，其实不是的。它实际上意味着把右边表达式的值赋给左边的运算数。 赋值运算表达式的值也就是所赋的值。也就是说，“$a = 3”的值是 3。这样就可以做一些小技巧：123&lt;?php$a = ($b = 4) + 5; // $a 现在成了 9，而 $b 成了 4。?&gt; 在基本赋值运算符之外，还有适合于所有二元算术，数组集合和字符串运算符的“组合运算符”，这样可以在一个表达式中使用它的值并把表达式的结果赋给它，例如： 123456&lt;?php$a = 3;$a += 5; // sets $a to 8, as if we had said: $a = $a + 5;$b = "Hello ";$b .= "There!"; // 将 $b 的值设置为 "Hello There!", 相当于 $b = $b . "There!";?&gt; 小提示：.在PHP中用作两个字符串连接。 PHP 支持引用赋值，使用“$var = &amp;$othervar;”语法。引用赋值意味着两个变量指向了同一个数据，没有拷贝任何东西。 123456789&lt;?php$a = 3;$b = &amp;$a; // $b 是 $a 的引用print "$a\n"; // 输出 3print "$b\n"; // 输出 3$a = 4; // 修改 $aprint "$a\n"; // 输出 4print "$b\n"; // 也输出 4，因为 $b 是 $a 的引用，因此也被改变?&gt; 位运算符例子名称结果$a &amp; $bAnd（按位与）将把 $a 和 $b 中都为 1 的位设为 1。$a | $bOr（按位或）将把 $a 和 $b 中任何一个为 1 的位设为 1。$a ^ $bXor（按位异或）将把 $a 和 $b 中一个为 1 另一个为 0 的位设为 1。~ $aNot（按位取反）将 $a 中为 0 的位设为 1，反之亦然。$a &lt;&lt; $bShift left（左移）将 $a 中的位向左移动 $b 次（每一次移动都表示“乘以 2”）。$a &gt;&gt; $bShift right（右移）将 $a 中的位向右移动 $b 次（每一次移动都表示“除以 2”）。 比较运算符例子名称结果$a == $b等于TRUE，如果类型转换后 $a 等于 $b。$a === $b全等TRUE，如果 $a 等于 $b，并且它们的类型也相同。$a != $b不等TRUE，如果类型转换后 $a 不等于 $b。$a &lt;&gt; $b不等TRUE，如果类型转换后 $a 不等于 $b。$a !== $b不全等TRUE，如果 $a 不等于 $b，或者它们的类型不同。$a &lt; $b小与TRUE，如果 $a 严格小于 $b。$a &gt; $b大于TRUE，如果 $a 严格大于 $b。$a &lt;= $b小于等于TRUE，如果 $a 小于或者等于 $b。$a &gt;= $b大于等于TRUE，如果 $a 大于或者等于 $b。$a &lt;=&gt; $b太空船运算符当$a小于、等于、大于$b时 分别返回一个小于、等于、大于0的integer 值。 PHP7开始提供.$a ?? $b ?? $cNULL 合并操作符从左往右第一个存在且不为 NULL 的操作数。如果都没有定义且不为 NULL，则返回 NULL。PHP7开始提供。 错误控制运算符PHP 支持一个错误控制运算符：@。当将其放置在一个 PHP 表达式之前，该表达式可能产生的任何错误信息都被忽略掉。 如果用 set_error_handler() 设定了自定义的错误处理函数，仍然会被调用，但是此错误处理函数可以（并且也应该）调用 error_reporting()，而该函数在出错语句前有 @ 时将返回 0。 @ 运算符只对表达式有效。 执行运算符PHP 支持一个执行运算符：反引号（``）。注意这不是单引号！PHP 将尝试将反引号中的内容作为 shell 命令来执行，并将其输出信息返回。使用反引号运算符`的效果与函数 shell_exec() 相同。 123&lt;?phpecho `ipconfig`;?&gt; 注意：反引号运算符在激活了安全模式或者关闭了 shell_exec() 时是无效的。 递增／递减运算符 例子 名称 效果 ++$a 前加 $a 的值加一，然后返回 $a。 $a++ 后加 返回 $a，然后将 $a 的值加一。 –$a 前减 $a 的值减一， 然后返回 $a。 $a– 后减 返回 $a，然后将 $a 的值减一。 逻辑运算符例子名称结果$a and $bAnd（逻辑与）TRUE，如果 $a 和 $b 都为 TRUE。$a or $bOr（逻辑或）TRUE，如果 $a 或 $b 任一为 TRUE。$a xor $bXor（逻辑异或）TRUE，如果 $a 或 $b 任一为 TRUE，但不同时是。!$aNot（逻辑非）TRUE，如果 $a 不为 TRUE。$a &amp;&amp;$bAnd（逻辑与）TRUE，如果 $a 和 $b 都为 TRUE。$a || $bOr（逻辑或）TRUE，如果 $a 或 $b 任一为 TRUE。 字符串运算符有两个字符串（string）运算符。第一个是连接运算符 .，它返回其左右参数连接后的字符串。第二个是连接赋值运算符 .=，它将右边参数附加到左边的参数之后。 1234567&lt;?php$a = "Hello ";$b = $a . "World!"; // 现在 $b 等于 "Hello World!"$a = "Hello ";$a .= "World!"; // 现在 $a 等于 "Hello World!"?&gt; 数组运算符例子名称结果$a + $b联合$a 和 $b 的联合。$a == $b相等如果 $a 和 $b 具有相同的键／值对则为 TRUE。$a === $b全等如果 $a 和 $b 具有相同的键／值对并且顺序和类型都相同则为 TRUE。$a != $b不等如果 $a 不等于 $b 则为 TRUE。$a &lt;&gt;$b不等如果 $a 不等于 $b 则为 TRUE。$a !== $b不全等如果 $a 不全等于 $b 则为 TRUE。 类型运算符instanceof 用于确定一个 PHP 变量是否属于某一类 class 的实例： 12345678&lt;?phpclass MyClass &#123;&#125;class NotMyClass&#123;&#125;$a = new MyClass;var_dump($a instanceof MyClass);echo '&lt;/br&gt;';var_dump($a instanceof NotMyClass);?&gt; 输出： bool(true) bool(false) 流程控制任何 PHP 脚本都是由一系列语句构成的。一条语句可以是一个赋值语句，一个函数调用，一个循环，一个条件语句或者甚至是一个什么也不做的语句（空语句）。语句通常以分号结束。此外，还可以用花括号将一组语句封装成一个语句组。语句组本身可以当作是一行语句。 条件判断if语法： &lt;?php if (expr) { statement } ?&gt; 如果有多个表达式，使用花括号括起来 例子： 12345&lt;?phpif ($a &gt; $b) &#123; echo "a is greater than b";&#125;?&gt; if-else语法： &lt;?php if (expr) { statement } else { statement } ?&gt; 例子： 123456789&lt;?php$a = 2;$b = 4;if ($a &gt; $b) &#123; echo "a is greater than b";&#125; else &#123; echo "a is NOT greater than b";&#125;?&gt; if-elseif-else语法： &lt;?php if (expr) { statement } elseif (expr) { statement } else { statement } ?&gt; 例子： 1234567891011&lt;?php$a = 2;$b = 2;if ($a &gt; $b) &#123; echo "a is bigger than b";&#125; elseif ($a == $b) &#123; echo "a is equal to b";&#125; else &#123; echo "a is smaller than b";&#125;?&gt; 在同一个 if 语句中可以有多个 elseif 部分，其中第一个表达式值为 TRUE 的 elseif 部分将会执行。在 PHP 中，也可以写成”else if”，它和”elseif”的行为完全一样。 流程控制的替代语法PHP 提供了一些流程控制的替代语法，包括 if，while，for，foreach 和 switch。替代语法的基本形式是把左花括号 { 换成冒号 : ，把右花括号 } 分别换成 endif;，endwhile;，endfor;，endforeach; 以及 endswitch;。 1234&lt;?php $a = 5; ?&gt;&lt;?php if ($a == 5): ?&gt; A is equal to 5&lt;?php endif; ?&gt; 同样还可以用在 else 和 elseif 中 123456789101112&lt;?php$a = 6;if ($a == 5): echo "a equals 5"; echo "...";elseif ($a == 6): echo "a equals 6"; echo "!!!";else: echo "a is neither 5 nor 6";endif;?&gt; 注意：不支持在同一个控制块内混合使用两种语法。 循环while循环while 循环是 PHP 中最简单的循环类型。它和 C 语言中的 while 表现地一样。while 语句的基本格式是： while (expr) { statement } 如果表达式只有一句 也可以将花括号省略掉。 while 语句的含义很简单，只要 while 的表达式值为 TRUE ，就重复执行嵌套中的循环语句，表达式的值在每次开始循环时检查，直到表达式为 FALSE 为止。 123456&lt;?php$a = 0;while ($i &lt;= 10) &#123; echo $i++;&#125;?&gt; do-while循环do-while 循环是先循环 后判断，所以 do-while 不管表达式是否为 TRUE 都会至少循环一次。 123456&lt;?php$i = 0;do &#123; echo $i++;&#125; while ($i &lt;= 10);?&gt; for循环for循环是相对比较复杂但同时更强大的循环方法。for循环的语法是： for (expr1; expr2; expr3) { statement } 第一个表达式(expr1)在循环前执行一次。第二个表达式在每次循环开始前执行，如果值为 TRUE 则继续执行，FALSE 则跳出循环。第三个表达式在每次循环之后被执行。 每个表达式都可以为空或包括逗号分隔的多个表达式，表达式 expr2 中，所有用逗号分隔的表达式都会计算，但只取最后一个结果。expr2 为空意味着将无限循环下去。如果死循环，可以在循环语句中使用break跳出去。 123456789101112&lt;?phpfor ($i = 1; $i &lt;= 10; $i++) &#123; echo $i;&#125;echo "&lt;/br&gt;";for ($i = 1; ; $i++) &#123; if ($i &gt; 10) &#123; break; &#125; echo $i;&#125;?&gt; PHP 也支持用冒号的 for 循环的替代语法。 for (expr1; expr2; expr3): statement; ... endfor; foreachforeach 语法结构提供了遍历数组的简单方式。foreach 仅能够应用于数组和对象，如果尝试应用于其他数据类型的变量，或者未初始化的变量将发出错误信息。有两种语法： foreach (array_expression as $value) statement foreach (array_expression as $key =&gt; $value) statement 第一种格式遍历给定的 array_expression 数组。每次循环中，当前单元的值被赋给 $value 并且数组内部的指针向前移一步（因此下一次循环中将会得到下一个单元）。 第二种格式做同样的事，只除了当前单元的键名也会在每次循环中被赋给变量 $key。 可以很容易地通过在 $value 之前加上 &amp; 来修改数组的元素。此方法将以引用赋值而不是拷贝一个值。 12345678&lt;?php$arr = array(1, 2, 3, 4);foreach ($arr as &amp;$value) &#123; $value = $value * 2;&#125;// $arr is now array(2, 4, 6, 8)unset($value); // 最后取消掉引用?&gt; PHP 5.5 增添了遍历一个数组的数组的功能并且把嵌套的数组解包到循环变量中，只需将 list() 作为值提供。 123456789101112&lt;?php$array = [ [1, 2], [3, 4],];foreach ($array as list($a, $b)) &#123; // $a contains the first element of the nested array, // and $b contains the second element. echo "A: $a; B: $b\n";&#125;?&gt; list() 中的单元可以少于嵌套数组的，此时多出来的数组单元将被忽略。如果 list() 中列出的单元多于嵌套数组则会发出一条消息级别的错误信息。 break 跳出循环break 结束当前 for，foreach，while，do-while 或者 switch 结构的执行。 break 可以接受一个可选的数字参数来决定跳出几重循环。 12345678910111213141516171819202122232425&lt;?php$arr = array('one', 'two', 'three', 'four', 'stop', 'five');while (list (, $val) = each($arr)) &#123; if ($val == 'stop') &#123; break; /* You could also write 'break 1;' here. */ &#125; echo "$val&lt;br /&gt;\n";&#125;/* 使用可选参数 */$i = 0;while (++$i) &#123; switch ($i) &#123; case 5: echo "At 5&lt;br /&gt;\n"; break 1; /* 只退出 switch. */ case 10: echo "At 10; quitting&lt;br /&gt;\n"; break 2; /* 退出 switch 和 while 循环 */ default: break; &#125;&#125;?&gt; 注意：在PHP 5.4.0 之后，取消变量作为参数传递（例如 $num = 2; break $num;）。 continue 跳出本次循环continue 在循环结构用用来跳过本次循环中剩余的代码并在条件求值为真时开始执行下一次循环。 小提示：注意在 PHP 中 switch 语句被认为是可以使用 continue 的一种循环结构。continue 接受一个可选的数字参数来决定跳过几重循环到循环结尾。默认值是 1，即跳到当前循环末尾。 12345678910111213141516171819202122&lt;?phpwhile (list ($key, $value) = each($arr)) &#123; if (!($key % 2)) &#123; // skip odd members continue; &#125; do_something_odd($value);&#125;$i = 0;while ($i++ &lt; 5) &#123; echo "Outer&lt;br /&gt;\n"; while (1) &#123; echo "Middle&lt;br /&gt;\n"; while (1) &#123; echo "Inner&lt;br /&gt;\n"; continue 3; &#125; echo "This never gets output.&lt;br /&gt;\n"; &#125; echo "Neither does this.&lt;br /&gt;\n";&#125;?&gt; 注意：在PHP 5.4.0 之后，取消变量作为参数传递（例如 $num = 2; continue $num;）。 switch 分支选择switch 语句类似于具有同一个表达式的一系列 if 语句。很多场合下需要把同一个变量（或表达式）与很多不同的值比较，并根据它等于哪个值来执行不同的代码。这正是 switch 语句的用途。 小提示：注意和其它语言不同，continue 语句作用到 switch 上的作用类似于 break。如果在循环中有一个 switch 并希望 continue 到外层循环中的下一轮循环，用 continue 2。 switch 结构示例： 123456789101112131415&lt;?phpswitch ($i) &#123; case 0: echo "i equals 0"; break; case 1: echo "i equals 1"; break; case 2: echo "i equals 2"; break; default: echo "i is not equal to 0, 1 or 2";&#125;?&gt; switch 结构中 case 的目标还可以是字符串。case 会依次执行。如果没有 break 将会继续执行下面的 case 代码。default 是所有的 case 都没有匹配时执行。 declaredeclare 结构用来设定一段代码的执行指令。declare 的语法和其它流程控制结构相似： declare (directive) statement directive 部分允许设定 declare 代码段的行为。目前只认识两个指令：ticks 以及 encoding，declare 调试内部程序使用. declare(ticks=n) 和 register_tick_function(&#39;handel_function&#39;) 一般是配合使用的。ticks 参数表示运行多少语句调用一次 register_tick_function 的函数。并且declare支持两种写法： 12345declare(ticks = 1); //整个脚本declare(ticks = 1) &#123; ...... // 内部的代码做记录&#125; 例如： 12345678910111213141516&lt;?phpdeclare(ticks=1);// A function called on each tick eventfunction tick_handler()&#123; echo "tick_handler() called\n";&#125;register_tick_function('tick_handler');$a = 1;if ($a &gt; 0) &#123; $a += 2; print($a);&#125;?&gt; encoding 指令来对每段脚本指定其编码方式。 1234&lt;?phpdeclare(encoding='ISO-8859-1');// code here?&gt; 在 PHP 5.3 中除非在编译时指定了 --enable-zend-multibyte，否则 declare 中的 encoding 值会被忽略。 return如果在一个函数中调用 return 语句，将立即结束此函数的执行并将它的参数作为函数的值返回。return 也会终止 eval() 语句或者脚本文件的执行。 如果在全局范围中调用，则当前脚本文件中止运行。如果当前脚本文件是被 include 的或者 require 的，则控制交回调用文件。此外，如果当前脚本是被 include 的，则 return 的值会被当作 include 调用的返回值。如果在主脚本文件中调用 return，则脚本中止运行。如果当前脚本文件是在 php.ini 中的配置选项 auto_prepend_file 或者 auto_append_file所指定的，则此脚本文件中止运行。 requirerequire 和 include 几乎完全一样，除了处理失败的方式不同之外。require 在出错时产生 E_COMPILE_ERROR 级别的错误。换句话说将导致脚本中止而 include 只产生警告 E_WARNING ，脚本会继续运行。 还有一个和 require 作用完全相同的是 require_once，不同的是如果这个文件已经被包含，require_once 则不会再次包含这个文件。 include被包含文件先按参数给出的路径寻找，如果没有给出目录（只有文件名）时则按照 include_path 指定的目录寻找。如果在 include_path 下没找到该文件则 include 最后才在调用脚本文件所在的目录和当前工作目录下寻找。如果最后仍未找到文件则 include 结构会发出一条警告；这一点和 require 不同，后者会发出一个致命错误。include_path 是在 php.ini 配置文件中定义的。 如果定义了路径——不管是绝对路径还是当前目录的相对路径 include_path 都会被完全忽略。例如一个文件以 ../ 开头，则解析器会在当前目录的父目录下寻找该文件。 当一个文件被包含时，其中所包含的代码继承了 include 所在行的变量范围。从该处开始，调用文件在该行处可用的任何变量在被调用的文件中也都可用。不过所有在包含文件中定义的函数和类都具有全局作用域。 vars.php1234&lt;?php$color = 'green';$fruit = 'apple';?&gt; test.php12345&lt;?phpecho "A $color $fruit"; // Ainclude 'vars.php';echo "A $color $fruit"; // A green apple?&gt; 如果 include 出现于调用文件中的一个函数里，则被调用的文件中所包含的所有代码将表现得如同它们是在该函数内部定义的一样。所以它将遵循该函数的变量范围。 test2.php123456789&lt;?phpfunction foo() &#123; global $color; include 'vars.php'; echo "A $color $fruit";&#125;foo(); // A green appleecho "A $color $fruit"; // A green?&gt; include_once 可以用于在脚本执行期间同一个文件有可能被包含超过一次的情况下，想确保它只被包含一次以避免函数重定义，变量重新赋值等问题。 goto 跳转goto 操作符可以用来跳转到程序中的另一位置。该目标位置可以用目标名称加上冒号来标记，而跳转指令是 goto 之后接上目标位置的标记。PHP 中的 goto 有一定限制，目标位置只能位于同一个文件和作用域，也就是说无法跳出一个函数或类方法，也无法跳入到另一个函数。也无法跳入到任何循环或者 switch 结构中。可以跳出循环或者 switch，通常的用法是用 goto 代替多层的 break。 1234567&lt;?phpgoto a;echo 'Foo'; a:echo 'Bar';?&gt; 跳出循环示例： 12345678910&lt;?phpfor($i=0,$j=50; $i&lt;100; $i++) &#123; while($j--) &#123; if($j==17) goto end; &#125; &#125;echo "i = $i";end:echo 'j hit 17';?&gt; goto 可以跳出循环 而不可以跳进循环内。 函数自定义函数任何有效的 PHP 代码都有可能出现在函数内部，甚至包括其它函数和类定义。 123456789&lt;?phpfoo();bar();function foo() &#123; function bar() &#123; echo "I don't exist until foo() is called."; &#125;&#125;?&gt; 可以看到，函数并非只有定义后才能调用。而且bar()函数只有foo()函数调用后才会创建的。 PHP 中的所有函数和类都具有全局作用域，可以定义在一个函数之内而在之外调用，反之亦然。PHP 不支持函数重载，也不可能取消定义或者重定义已声明的函数。PHP 的函数支持可变数量的参数和默认参数。 在 PHP 中还可以递归调用函数，但是要避免递归超过100-200层，因为可能会使堆栈崩溃从而使当前脚本终止。 无限递归可视为编程错误。 函数参数普通参数通过参数列表可以传递信息到函数。 1234567&lt;?phpfunction takes_array($input)&#123; echo "$input[0] + $input[1] = ", $input[0]+$input[1];&#125;takes_array([2, 4]);?&gt; 传递引用默认情况下，函数参数通过值传递。如果希望允许函数修改它的参数值，必须通过引用传递参数。 123456789&lt;?phpfunction add_some_extra(&amp;$string)&#123; $string .= 'and something extra.';&#125;$str = 'This is a string, ';add_some_extra($str);echo $str; // outputs 'This is a string, and something extra.'?&gt; 参数默认值在函数中可以给参数提供一个默认值 123456789&lt;?phpfunction makecoffee($type = "cappuccino")&#123; return "Making a cup of $type.\n";&#125;echo makecoffee();echo makecoffee(null);echo makecoffee("espresso");?&gt; 默认值必须是常量表达式，不能是诸如变量，类成员，或者函数调用等。 注意：当使用默认参数时，任何默认参数必须放在任何非默认参数的右侧。否则，函数将不会按照预期的情况工作。 比如下面代码将不能正确运行： 1234567&lt;?phpfunction makeyogurt($type = "acidophilus", $flavour)&#123; return "Making a bowl of $type $flavour.\n";&#125;echo makeyogurt("raspberry"); // won't work as expected?&gt; 类型声明类型声明允许函数在调用时要求参数为特定类型。 如果给出的值类型不对，那么将会产生一个错误： 在PHP 5中，这将是一个可恢复的致命错误，而在PHP 7中将会抛出一个TypeError异常。 为了指定一个类型声明，类型应该加到参数名前。这个声明可以通过将参数的默认值设为NULL来实现允许传递NULL。 可用类型： 类型 描述 最低PHP版本 类/接口名 参数必须是特定的类或接口的名称 PHP 5.0.0 self 参数必须是自身的方法 PHP 5.0.0 array 参数必须是一个数组 PHP 5.1.0 callable 参数必须是一个可调用对象 PHP 5.4.0 bool 参数必须是一个布尔值 PHP 7.0.0 float 参数必须是一个浮点数 PHP 7.0.0 int 参数必须是一个整型 PHP 7.0.0 string 参数必须是一个字符串 PHP 7.0.0 基础类类型声明：123456789101112131415&lt;?phpclass C &#123;&#125;class D extends C &#123;&#125;// This doesn't extend C.class E &#123;&#125;function f(C $c) &#123; echo get_class($c)."\n";&#125;f(new C);f(new D);f(new E); // 这里会报错，因为f()只接受C类和C类的子类的实例?&gt; 可变参数PHP 在用户自定义函数中支持可变数量的参数列表。在 PHP 5.6 及以上的版本中，由 ... 语法实现；在 PHP 5.5 及更早版本中，使用函数 func_num_args()，func_get_arg()，和 func_get_args() 。 在 PHP 5.6+12345678910&lt;?phpfunction sum(...$numbers) &#123; $acc = 0; foreach ($numbers as $n) &#123; $acc += $n; &#125; return $acc;&#125;echo sum(1, 2, 3, 4);?&gt; 还可以使用 ... 来提供参数 123456&lt;?phpfunction add($a, $b) &#123; return $a + $b;&#125;echo add(...[1, 2]);?&gt; 在 PHP 5.5 和之前版本访问参数列表 12345678910&lt;?phpfunction sum() &#123; $acc = 0; foreach (func_get_args() as $n) &#123; $acc += $n; &#125; return $acc;&#125;echo sum(1, 2, 3, 4);?&gt; 返回值值通过使用可选的返回语句返回。可以返回包括数组和对象的任意类型。返回语句会立即中止函数的运行，并且将控制权交回调用该函数的代码行。如果省略了 return，则返回值为 NULL。 示例： 1234567&lt;?phpfunction square($num)&#123; return $num * $num;&#125;echo square(4); // outputs '16'.?&gt; 函数不能返回多个值，但可以通过返回一个数组来得到类似的效果。 1234567&lt;?phpfunction small_numbers()&#123; return array (0, 1, 2);&#125;list ($zero, $one, $two) = small_numbers();?&gt; 从函数返回一个引用，必须在函数声明和指派返回值给一个变量时都使用引用运算符 &amp;： 1234567&lt;?phpfunction &amp;returns_reference()&#123; return $someref;&#125;$newref =&amp; returns_reference();?&gt; 返回一个对象： 1234567&lt;?phpclass C &#123;&#125;function getC(): C &#123; return new C;&#125;var_dump(getC());?&gt; 可变函数PHP 支持可变函数的概念。这意味着如果一个变量名后有圆括号，PHP 将寻找与变量的值同名的函数，并且尝试执行它。可变函数可以用来实现包括回调函数，函数表在内的一些用途。 可变函数不能用于例如 echo，print，unset()，isset()，empty()，include，require 以及类似的语言结构。需要使用自己的包装函数来将这些结构用作可变函数。 示例：12345678910111213141516171819&lt;?phpfunction foo() &#123; echo "In foo()&lt;br /&gt;\n";&#125;function bar($arg = '') &#123; echo "In bar(); argument was '$arg'.&lt;br /&gt;\n";&#125;// 使用 echo 的包装函数function echoit($string)&#123; echo $string;&#125;$func = 'foo';$func(); // 将调用 foo()$func = 'bar';$func('test'); // 将调用 bar()$func = 'echoit';$func('test'); // 将调用 echoit()?&gt; 也可以用可变函数的语法来调用一个对象的方法。 12345678910111213141516&lt;?phpclass Foo &#123; function Variable() &#123; $name = 'Bar'; $this-&gt;$name(); // This calls the Bar() method &#125; function Bar() &#123; echo "This is Bar"; &#125;&#125;$foo = new Foo();$funcname = "Variable";$foo-&gt;$funcname(); // This calls $foo-&gt;Variable()?&gt; 内置函数PHP 有很多标准的函数和结构。还有一些函数需要和特定地 PHP 扩展模块一起编译，否则在使用它们的时候就会得到一个致命的“未定义函数”错误。例如，要使用 image 函数中的 imagecreatetruecolor()，需要在编译 PHP 的时候加上 GD 的支持。或者，要使用 mysql_connect() 函数，就需要在编译 PHP 的时候加上 MySQL 支持。有很多核心函数已包含在每个版本的 PHP 中如字符串和变量函数。调用 phpinfo() 或者 get_loaded_extensions() 可以得知 PHP 加载了那些扩展库。 匿名函数匿名函数也叫闭包函数，就是创建一个没有函数名的函数。最经常用作回调函数。 闭包函数也可以作为变量的值来使用。PHP 会自动把此种表达式转换成内置类 Closure 的对象实例。把一个 closure 对象赋值给一个变量的方式与普通变量赋值的语法是一样的，最后也要加上分号： 12345678&lt;?php$greet = function($name)&#123; printf("Hello %s\r\n", $name);&#125;;$greet('World');$greet('PHP');?&gt; 闭包可以从父作用域中继承变量。 任何此类变量都应该用 use 语言结构传递进去。 PHP 7.1 起，不能传入此类变量： superglobals、 $this 或者和参数重名。 从父作用域继承变量1234567891011121314151617181920212223242526272829303132333435363738&lt;?php$message = 'hello';// 没有 "use"$example = function () &#123; var_dump($message);&#125;;echo $example()."&lt;/br&gt;";// 继承 $message$example = function () use ($message) &#123; var_dump($message);&#125;;echo $example()."&lt;/br&gt;";// 继承变量的值是在定义函数时，而不是在调用时定义的$message = 'world';echo $example()."&lt;/br&gt;";// 重新设置 $message$message = 'hello';// 继承引用$example = function () use (&amp;$message) &#123; var_dump($message);&#125;;echo $example()."&lt;/br&gt;";// 父作用域中的更改值反映在函数调用中。$message = 'world';echo $example()."&lt;/br&gt;";// 匿名函数也可以接受参数。$example = function ($arg) use ($message) &#123; var_dump($arg . ' ' . $message);&#125;;$example("hello");?&gt; 输出： Notice: Undefined variable: message in F:\phpstudy\src\index.php on line 6 NULL string(5) &quot;hello&quot; string(5) &quot;hello&quot; string(5) &quot;hello&quot; string(5) &quot;world&quot; string(11) &quot;hello world&quot; 这些变量都必须在函数或类的头部声明。 从父作用域中继承变量与使用全局变量是不同的。全局变量存在于一个全局的范围，无论当前在执行的是哪个函数。而闭包的父作用域是定义该闭包的函数。 小提示：可以在闭包中使用 func_num_args()，func_get_arg() 和 func_get_args()。 类与对象自 PHP 5 起完全重写了对象模型以得到更佳性能和更多特性。这是自 PHP 4 以来的最大变化。PHP 5 具有完整的对象模型。PHP 5 中的新特性包括访问控制，抽象类和 final 类与方法，附加的魔术方法，接口，对象复制和类型约束。PHP 对待对象的方式与引用和句柄相同，即每个变量都持有对象的引用，而不是整个对象的拷贝。 基本概念每个类的定义都以关键字 class 开头，后面跟着类名，后面跟着一对花括号，里面包含有类的属性与方法的定义。一个类可以包含有属于自己的常量，变量（称为”属性”）以及函数（称为”方法”）。 类的定义一个简单的类定义：123456789101112&lt;?phpclass SimpleClass&#123; // 属性声明 public $var = 'a default value'; // 方法声明 public function displayVar() &#123; echo $this-&gt;var; &#125;&#125;?&gt; $this 伪变量当一个方法在类定义内部被调用时，有一个可用的伪变量 $this。$this 是一个到主叫对象的引用 $this 的使用示例：1234567891011121314151617181920212223242526&lt;?phpclass A &#123; function foo() &#123; if (isset($this)) &#123; echo '$this is defined ('; echo get_class($this); echo ")\n"; &#125; else &#123; echo "\$this is not defined.\n"; &#125; &#125;&#125;class B &#123; function bar() &#123; A::foo(); &#125;&#125;$a = new A();$a-&gt;foo();A::foo();$b = new B();$b-&gt;bar();B::bar();?&gt; 输出： $this is defined (A) $this is not defined. $this is not defined. $this is not defined. new 创建实例要创建一个类的实例，必须使用 new 关键字。当创建新对象时该对象总是被赋值，除非该对象定义了构造函数并且在出错时抛出了一个异常。 如果在 new 之后跟着的是一个包含有类名的字符串，则该类的一个实例被创建。如果该类属于一个名字空间，则必须使用其完整名称。 创建一个实例：1234567&lt;?php$instance = new SimpleClass();// 也可以这样做$className = 'Foo';$instance = new $className(); // Foo()?&gt; 当把一个对象已经创建的实例赋给一个新变量时，新变量会访问同一个实例，就和用该对象赋值一样。此行为和给函数传递入实例时一样。可以用克隆给一个已创建的对象建立一个新实例。 123456789101112131415&lt;?phpclass SimpleClass &#123;&#125;;$instance = new SimpleClass();$assigned = $instance;$reference =&amp; $instance;$instance-&gt;var = '$assigned will have this value';$instance = null; // $instance and $reference become nullvar_dump($instance);echo '&lt;/br&gt;';var_dump($reference);echo '&lt;/br&gt;';var_dump($assigned);?&gt; 输出： NULL NULL object(SimpleClass)#1 (1) { [&quot;var&quot;]=&gt; string(30) &quot;$assigned will have this value&quot; } ::class自 PHP 5.5 起，关键词 class 也可用于类名的解析。使用 ClassName::class 你可以获取一个字符串，包含了类 ClassName 的完全限定名称。这对使用了 命名空间 的类尤其有用。 示例：123456&lt;?phpnamespace NS &#123; class ClassName &#123; &#125; echo ClassName::class;&#125;?&gt; 输出： NS\ClassName 属性类的变量成员叫做”属性”，属性声明是由关键字 public，protected 或者 private 开头，然后跟一个普通的变量声明来组成。属性中的变量可以初始化，但是初始化的值必须是常数，这里的常数是指 PHP 脚本在编译阶段时就可以得到其值，而不依赖于运行时的信息才能求值。 在类的成员方法里面，可以用 -&gt;（对象运算符）：$this-&gt;property（其中 property 是该属性名）这种方式来访问非静态属性。静态属性则是用 ::（双冒号）：self::$property 来访问。更多静态属性与非静态属性的区别参见 static 关键字。 属性声明： 12345678910111213141516171819202122&lt;?phpclass SimpleClass&#123; // 错误的属性声明 public $var1 = 'hello ' . 'world'; public $var2 = &lt;&lt;&lt;EODhello worldEOD; public $var3 = 1+2; public $var4 = self::myStaticMethod(); public $var5 = $myVar; // 正确的属性声明 public $var6 = myConstant; public $var7 = array(true, false); //在 PHP 5.3.0 及之后，下面的声明也正确 public $var8 = &lt;&lt;&lt;'EOD'hello worldEOD;&#125;?&gt; 类常量可以把在类中始终保持不变的值定义为常量。在定义和使用常量的时候不需要使用 $ 符号。常量的值必须是一个定值，不能是变量，类属性，数学运算的结果或函数调用。 定义和使用一个常量：1234567891011121314151617181920&lt;?phpclass MyClass&#123; const constant = 'constant value'; function showConstant() &#123; echo self::constant . "\n"; &#125;&#125;echo MyClass::constant . "\n";$classname = "MyClass";echo $classname::constant . "\n"; // 自 5.3.0 起$class = new MyClass();$class-&gt;showConstant();echo $class::constant."\n"; // 自 PHP 5.3.0 起?&gt; 类的自动加载在编写面向对象程序时，很多开发者为每个类新建一个 PHP 文件。 这会带来一个烦恼：每个脚本的开头，都需要 include 一个长长的列表。 在 PHP 5 中，已经不再需要这样了。 spl_autoload_register() 函数可以注册任意数量的自动加载器，当使用尚未被定义的类和接口时自动去加载。通过注册自动加载器，脚本引擎在 PHP 出错失败前有了最后一个机会加载所需的类。 尝试分别从 MyClass1.php 和 MyClass2.php 文件中加载 MyClass1 和 MyClass2 类。 MyClass1.php12345&lt;?phpclass MyClass1 &#123; const VAR = 'MyClass1&lt;/br&gt;';&#125;;?&gt; MyClass2.php12345&lt;?phpclass MyClass2 &#123; const VAR = 'MyClass2&lt;/br&gt;';&#125;;?&gt; MyClass3.php12345678910&lt;?phpspl_autoload_register(function ($class_name) &#123; require_once $class_name . '.php';&#125;);$obj = new MyClass1();$obj2 = new MyClass2();echo $obj::VAR;echo $obj2::VAR;?&gt; 当 new 一个尚未定义的类 MyClass1 时，将自动寻找文件名为类名的 php 文件，也就是 MyClass1.php 文件。 当加载的类文件不存在时，将抛出一个异常，可以用 try/catch 进行异常处理 抛出一个异常并在 try/catch 语句块中演示：123456789101112&lt;?phpspl_autoload_register(function ($name) &#123; echo "Want to load $name.\n"; throw new Exception("Unable to load $name.");&#125;);try &#123; $obj = new NonLoadableClass();&#125; catch (Exception $e) &#123; echo $e-&gt;getMessage(), "\n";&#125;?&gt; 输出： Want to load NonLoadableClass. Unable to load NonLoadableClass. 构造函数和析构函数构造函数PHP 5 允行开发者在一个类中定义一个方法作为构造函数。具有构造函数的类会在每次创建新对象时先调用此方法，所以非常适合在使用对象之前做一些初始化工作。 如果子类中定义了构造函数则不会隐式调用其父类的构造函数。要执行父类的构造函数，需要在子类的构造函数中调用 parent::__construct()。如果子类没有定义构造函数则会如同一个普通的类方法一样从父类继承。 1234567891011121314151617181920&lt;?phpclass BaseClass &#123; function __construct() &#123; print "In BaseClass constructor&lt;/br&gt;"; &#125;&#125;class SubClass extends BaseClass &#123; function __construct() &#123; parent::__construct(); print "In SubClass constructor&lt;/br&gt;"; &#125;&#125;class OtherSubClass extends BaseClass &#123; &#125;$obj = new BaseClass();$obj = new SubClass();$obj = new OtherSubClass();?&gt; 输出： In BaseClass constructor In BaseClass constructor In SubClass constructor In BaseClass constructor 为了实现向后兼容性，如果 PHP 5 在类中找不到 __construct() 函数并且也没有从父类继承一个的话，它就会尝试寻找旧式的构造函数，也就是和类同名的函数。因此唯一会产生兼容性问题的情况是：类中已有一个名为 __construct() 的方法却被用于其它用途时。 与其它方法不同，当 __construct() 被与父类 __construct() 具有不同参数的方法覆盖时，PHP 不会产生一个 E_STRICT 错误信息。 自 PHP 5.3.3 起，在命名空间中，与类名同名的方法不再作为构造函数。这一改变不影响不在命名空间中的类。 析构函数PHP 5 引入了析构函数的概念，这类似于其它面向对象的语言，如 C++。析构函数会在到某个对象的所有引用都被删除或者当对象被显式销毁时执行。 1234567891011121314&lt;?phpclass MyDestructableClass &#123; function __construct() &#123; print "In constructor&lt;/br&gt;"; $this-&gt;name = "MyDestructableClass"; &#125; function __destruct() &#123; print "Destroying " . $this-&gt;name . "&lt;/br&gt;"; &#125;&#125;$obj = new MyDestructableClass();?&gt; 和构造函数一样，父类的析构函数不会被引擎暗中调用。要执行父类的析构函数，必须在子类的析构函数体中显式调用 parent::__destruct()。此外也和构造函数一样，子类如果自己没有定义析构函数则会继承父类的。 析构函数即使在使用 exit() 终止脚本运行时也会被调用。在析构函数中调用 exit() 将会中止其余关闭操作的运行。 访问控制对属性或方法的访问控制，是通过在前面添加关键字 public（公有），protected（受保护）或 private（私有）来实现的。被定义为公有的类成员可以在任何地方被访问。被定义为受保护的类成员则可以被其自身以及其子类和父类访问。被定义为私有的类成员则只能被其定义所在的类访问。 属性的访问控制类属性必须定义为公有，受保护，私有之一。如果没有定义 默认是公有。 123456789101112131415161718192021222324252627282930313233343536373839404142&lt;?php/** * Define MyClass */class MyClass &#123; public $public = 'Public'; protected $protected = 'Protected'; private $private = 'Private'; function printHello() &#123; echo $this-&gt;public; echo $this-&gt;protected; echo $this-&gt;private; &#125;&#125;$obj = new MyClass();echo $obj-&gt;public; // 这行能被正常执行echo $obj-&gt;protected; // 这行会产生一个致命错误echo $obj-&gt;private; // 这行也会产生一个致命错误$obj-&gt;printHello(); // 输出 Public、Protected 和 Private/** * Define MyClass2 */class MyClass2 extends MyClass &#123; // 可以对 public 和 protected 进行重定义，但 private 而不能 protected $protected = 'Protected2'; function printHello() &#123; echo $this-&gt;public; echo $this-&gt;protected; echo $this-&gt;private; &#125;&#125;$obj2 = new MyClass2();echo $obj2-&gt;public; // 这行能被正常执行echo $obj2-&gt;private; // 未定义 privateecho $obj2-&gt;protected; // 这行会产生一个致命错误$obj2-&gt;printHello(); // 输出 Public、Protected2 和 Undefined?&gt; 方法的访问控制类中的方法可以被定义为公有，私有或受保护。如果没有设置这些关键字，则该方法默认为公有。 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576&lt;?php/** * Define MyClass */class MyClass &#123; // 声明一个公有的构造函数 public function __construct() &#123; &#125; // 声明一个公有的方法 public function MyPublic() &#123; &#125; // 声明一个受保护的方法 protected function MyProtected() &#123; &#125; // 声明一个私有的方法 private function MyPrivate() &#123; &#125; // 此方法为公有 function Foo() &#123; $this-&gt;MyPublic(); $this-&gt;MyProtected(); $this-&gt;MyPrivate(); &#125;&#125;$myclass = new MyClass;$myclass-&gt;MyPublic(); // 这行能被正常执行$myclass-&gt;MyProtected(); // 这行会产生一个致命错误$myclass-&gt;MyPrivate(); // 这行会产生一个致命错误$myclass-&gt;Foo(); // 公有，受保护，私有都可以执行/** * Define MyClass2 */class MyClass2 extends MyClass&#123; // 此方法为公有 function Foo2() &#123; $this-&gt;MyPublic(); $this-&gt;MyProtected(); $this-&gt;MyPrivate(); // 这行会产生一个致命错误 &#125;&#125;$myclass2 = new MyClass2;$myclass2-&gt;MyPublic(); // 这行能被正常执行$myclass2-&gt;Foo2(); // 公有的和受保护的都可执行，但私有的不行class Bar &#123; public function test() &#123; $this-&gt;testPrivate(); $this-&gt;testPublic(); &#125; public function testPublic() &#123; echo "Bar::testPublic&lt;/br&gt;"; &#125; private function testPrivate() &#123; echo "Bar::testPrivate&lt;/br&gt;"; &#125;&#125;class Foo extends Bar &#123; public function testPublic() &#123; echo "Foo::testPublic&lt;/br&gt;"; &#125; private function testPrivate() &#123; echo "Foo::testPrivate&lt;/br&gt;"; &#125;&#125;$myFoo = new foo();$myFoo-&gt;test(); // 输出：Bar::testPrivate // 输出：Foo::testPublic?&gt; 对象继承继承已为大家所熟知的一个程序设计特性，PHP 的对象模型也使用了继承。继承将会影响到类与类，对象与对象之间的关系。比如，当扩展一个类，子类就会继承父类所有公有的和受保护的方法。除非子类覆盖了父类的方法，被继承的方法都会保留其原有功能。 继承对于功能的设计和抽象是非常有用的，而且对于类似的对象增加新功能就无须重新再写这些公用的功能。 一个类可以在声明中用 extends 关键字继承另一个类的方法和属性。PHP不支持多重继承，一个类只能继承一个基类。被继承的方法和属性可以通过用同样的名字重新声明被覆盖。但是如果父类定义方法时使用了 final，则该方法不可被覆盖。可以通过 parent:: 来访问被覆盖的方法或属性。当覆盖方法时，参数必须保持一致否则 PHP 将发出 E_STRICT 级别的错误信息。但构造函数例外，构造函数可在被覆盖时使用不同的参数。 简单的继承示例： 123456789101112131415161718192021222324&lt;?phpclass foo &#123; public function printItem($string) &#123; echo 'Foo: ' . $string . '&lt;/br&gt;'; &#125; public function printPHP() &#123; echo 'PHP is great.' . '&lt;/br&gt;'; &#125;&#125;class bar extends foo &#123; public function printItem($string) &#123; echo 'Bar: ' . $string . '&lt;/br&gt;'; &#125;&#125;$foo = new foo();$bar = new bar();$foo-&gt;printItem('baz'); // Output: 'Foo: baz'$foo-&gt;printPHP(); // Output: 'PHP is great' $bar-&gt;printItem('baz'); // Output: 'Bar: baz'$bar-&gt;printPHP(); // Output: 'PHP is great'?&gt; 继承后可以重新定义父类的方法 1234567891011121314151617&lt;?phpclass SimpleClass &#123; function displayVar() &#123; echo 'a default value'; &#125;&#125;class ExtendClass extends SimpleClass &#123; // 重新定义父类方法 function displayVar() &#123; echo "Extending class&lt;/br&gt;"; parent::displayVar(); &#125;&#125;$extended = new ExtendClass();$extended-&gt;displayVar();?&gt; 输出： Extending class a default value 范围解析操作符(::)范围解析操作符或者更简单地说是一对冒号，可以用于访问静态成员，类常量，还可以用于覆盖类中的属性和方法。 当在类定义之外引用到这些项目时，要使用类名。 在类的外部使用::操作符12345678910&lt;?phpclass MyClass &#123; const CONST_VALUE = 'A constant value&lt;/br&gt;';&#125;$classname = 'MyClass';echo $classname::CONST_VALUE; // 自 PHP 5.3.0 起echo MyClass::CONST_VALUE;?&gt; 输出： A constant value A constant value 在类的内部使用::操作符1234567891011121314151617&lt;?phpclass MyClass &#123; const CONST_VALUE = 'A constant value&lt;/br&gt;';&#125;class OtherClass extends MyClass &#123; public static $my_static = 'static var'; public static function doubleColon() &#123; echo parent::CONST_VALUE; echo self::$my_static . "&lt;/br&gt;"; &#125;&#125;$classname = 'OtherClass';$classname::doubleColon(); // 自 PHP 5.3.0 起OtherClass::doubleColon();?&gt; 输出： A constant value static var A constant value static var static 关键字声明类属性或方法为静态，就可以不实例化类而直接访问。静态属性不能通过一个类已实例化的对象来访问（但静态方法可以）。如果没有指定访问控制，属性和方法默认为公有。由于静态方法不需要通过对象即可调用，所以伪变量 $this 在静态方法中不可用。静态属性不可以由对象通过 -&gt; 操作符来访问。用静态方式调用一个非静态方法会导致一个 E_STRICT 级别的错误。就像其它所有的 PHP 静态变量一样，静态属性只能被初始化为文字或常量，不能使用表达式。所以可以把静态属性初始化为整数或数组，但不能初始化为另一个变量或函数返回值，也不能指向一个对象。可以用一个变量来动态调用类。但该变量的值不能为关键字 self，parent 或 static。 静态属性示例： 12345678910111213141516171819202122232425262728&lt;?phpclass Foo &#123; public static $my_static = 'foo'; public function staticValue() &#123; return self::$my_static; &#125;&#125;class Bar extends Foo &#123; public function fooStatic() &#123; return parent::$my_static; &#125;&#125;print Foo::$my_static . "&lt;/br&gt;";$foo = new Foo();print $foo-&gt;staticValue() . "&lt;/br&gt;";print $foo-&gt;my_static . "&lt;/br&gt;"; // Undefined "Property" my_static print $foo::$my_static . "&lt;/br&gt;";$classname = 'Foo';print $classname::$my_static . "&lt;/br&gt;"; // As of PHP 5.3.0print Bar::$my_static . "&lt;/br&gt;";$bar = new Bar();print $bar-&gt;fooStatic() . "&lt;/br&gt;";?&gt; 静态方法示例: 123456789&lt;?phpclass Foo &#123; public static function aStaticMethod() &#123; &#125;&#125;Foo::aStaticMethod();$classname = 'Foo';$classname::aStaticMethod(); // 自 PHP 5.3.0 起?&gt; 抽象类PHP 5 支持抽象类和抽象方法。定义为抽象的类不能被实例化。任何一个类，如果它里面至少有一个方法是被声明为抽象的，那么这个类就必须被声明为抽象的。被定义为抽象的方法只是声明了其调用方式（参数），不能定义其具体的功能实现。 继承一个抽象类的时候，子类必须定义父类中的所有抽象方法；另外，这些方法的访问控制必须和父类中一样（或者更为宽松）。例如某个抽象方法被声明为受保护的，那么子类中实现的方法就应该声明为受保护的或者公有的，而不能定义为私有的。此外方法的调用方式必须匹配，即类型和所需参数数量必须一致。例如，子类定义了一个可选参数，而父类抽象方法的声明里没有，则两者的声明并无冲突。 这也适用于 PHP 5.4 起的构造函数。在 PHP 5.4 之前的构造函数声明可以不一样的。 抽象类示例：12345678910111213141516171819202122232425262728293031323334353637383940&lt;?phpabstract class AbstractClass &#123; // 强制要求子类定义这些方法 abstract protected function getValue(); abstract protected function prefixValue($prefix); // 普通方法（非抽象方法） public function printOut() &#123; print $this-&gt;getValue() . "&lt;/br&gt;"; &#125;&#125;class ConcreteClass1 extends AbstractClass &#123; protected function getValue() &#123; return "ConcreteClass1"; &#125; public function prefixValue($prefix) &#123; return "&#123;$prefix&#125;ConcreteClass1"; &#125;&#125;class ConcreteClass2 extends AbstractClass &#123; public function getValue() &#123; return "ConcreteClass2"; &#125; public function prefixValue($prefix) &#123; return "&#123;$prefix&#125;ConcreteClass2"; &#125;&#125;$class1 = new ConcreteClass1;$class1-&gt;printOut();echo $class1-&gt;prefixValue('FOO_') ."&lt;/br&gt;";$class2 = new ConcreteClass2;$class2-&gt;printOut();echo $class2-&gt;prefixValue('FOO_') ."&lt;/br&gt;";?&gt; 输出： ConcreteClass1 FOO_ConcreteClass1 ConcreteClass2 FOO_ConcreteClass2 子类定义可选参数 123456789101112131415161718192021222324&lt;?phpabstract class AbstractClass &#123; // 我们的抽象方法仅需要定义需要的参数 abstract protected function prefixName($name);&#125;class ConcreteClass extends AbstractClass &#123; // 我们的子类可以定义父类签名中不存在的可选参数 public function prefixName($name, $separator = ".") &#123; if ($name == "Pacman") &#123; $prefix = "Mr"; &#125; elseif ($name == "Pacwoman") &#123; $prefix = "Mrs"; &#125; else &#123; $prefix = ""; &#125; return "&#123;$prefix&#125;&#123;$separator&#125; &#123;$name&#125;"; &#125;&#125;$class = new ConcreteClass;echo $class-&gt;prefixName("Pacman"), "&lt;/br&gt;";echo $class-&gt;prefixName("Pacwoman"), "&lt;/br&gt;";?&gt; 输出： Mr. Pacman Mrs. Pacwoman 对象接口使用接口，可以指定某个类必须实现哪些方法，但不需要定义这些方法的具体内容。接口是通过 interface 关键字来定义的，就像定义一个标准的类一样，但其中定义所有的方法都是空的。接口中定义的所有方法都必须是公有，这是接口的特性。 要实现一个接口，使用 implements 操作符。类中必须实现接口中定义的所有方法，否则会报一个致命错误。类可以实现多个接口，用逗号来分隔多个接口的名称。 实现多个接口时，接口中的方法不能有重名。接口也可以继承其他接口，通过使用 extends 操作符，接口允许多继承。类要实现接口，必须使用和接口中所定义的方法完全一致的方式。否则会导致致命错误。 实现接口接口示例： 123456789101112131415161718192021222324252627282930313233&lt;?php// 声明一个'iTemplate'接口interface iTemplate &#123; public function setVariable($name, $var); public function getHtml($template);&#125;// 实现接口// 下面的写法是正确的class Template implements iTemplate&#123; private $vars = array(); public function setVariable($name, $var) &#123; $this-&gt;vars[$name] = $var; &#125; public function getHtml($template) &#123; foreach($this-&gt;vars as $name =&gt; $value) &#123; $template = str_replace('&#123;' . $name . '&#125;', $value, $template); &#125; return $template; &#125;&#125;// 下面的写法是错误的，会报错，因为没有实现 getHtml()：// Fatal error: Class BadTemplate contains 1 abstract methods// and must therefore be declared abstract (iTemplate::getHtml)class BadTemplate implements iTemplate &#123; private $vars = array(); public function setVariable($name, $var) &#123; $this-&gt;vars[$name] = $var; &#125;&#125;?&gt; 继承多个接口12345678910111213141516&lt;?phpinterface a &#123; public function foo();&#125;interface b &#123; public function bar();&#125;interface c extends a, b &#123; public function baz();&#125;class d implements c &#123; public function foo() &#123;&#125; public function bar() &#123;&#125; public function baz() &#123;&#125;&#125;?&gt; 使用接口常量12345678910111213&lt;?phpinterface a &#123; const b = 'Interface constant';&#125;// 输出接口常量echo a::b;// 错误写法，因为常量不能被覆盖。接口常量的概念和类常量是一样的。class b implements a &#123; const b = 'Class constant';&#125;?&gt; Trait自 PHP 5.4.0 起，PHP 实现了一种代码复用的方法，称为 trait。可以将多个类中，共用的一些属性和方法提取出来做来公共trait类，就像是装配汽车的配件，如果你的类中要用到这些配件，就直接用 use 导入就可以了，相当于把 trait 中的代码复制到当前类中。因为 trait 不是类，所以不能有静态成员，类常量，当然也不可能被实例化。 trait 使用示例：1234567891011121314&lt;?phptrait sayHello &#123; public function say()&#123; echo 'Hello'; &#125;&#125;class Base &#123; use sayHello;&#125;$b = new Base();$b-&gt;say();?&gt; 输出： Hello 优先级从基类继承的成员会被 trait 插入的成员所覆盖。优先顺序是：当前类成员 &gt; trait的方法 &gt; 当前类继承的方法 123456789101112131415161718192021&lt;?phpclass Base &#123; public function sayHello() &#123; echo 'Hello '; &#125;&#125;trait SayWorld &#123; public function sayHello() &#123; parent::sayHello(); echo 'World!'; &#125;&#125;class MyHelloWorld extends Base &#123; use SayWorld;&#125;$o = new MyHelloWorld();$o-&gt;sayHello();?&gt; 输出： Hello World! 多个 trait通过逗号分隔，在 use 声明列出多个 trait，可以都插入到一个类中。 12345678910111213141516171819202122232425&lt;?phptrait Hello &#123; public function sayHello() &#123; echo 'Hello '; &#125;&#125;trait World &#123; public function sayWorld() &#123; echo 'World'; &#125;&#125;class MyHelloWorld &#123; use Hello, World; public function sayExclamationMark() &#123; echo '!'; &#125;&#125;$o = new MyHelloWorld();$o-&gt;sayHello();$o-&gt;sayWorld();$o-&gt;sayExclamationMark();?&gt; 输出： Hello World! 同名冲突如果两个 trait 都插入了一个同名的方法，如果没有明确解决冲突将会产生一个致命错误。为了解决多个 trait 在同一个类中的命名冲突，需要使用 insteadof 操作符来明确指定使用冲突方法中的哪一个。以上方式仅允许排除掉其它方法，as 操作符可以 为某个方法引入别名。 注意：as 操作符不会对方法进行重命名，也不会影响其方法。 123456789101112131415161718192021222324252627282930313233343536373839&lt;?phptrait A &#123; public function smallTalk() &#123; echo 'a'; &#125; public function bigTalk() &#123; echo 'A'; &#125;&#125;trait B &#123; public function smallTalk() &#123; echo 'b'; &#125; public function bigTalk() &#123; echo 'B'; &#125;&#125;class Talker &#123; use A, B &#123; B::smallTalk insteadof A; A::bigTalk insteadof B; &#125;&#125;class Aliased_Talker &#123; use A, B &#123; B::smallTalk insteadof A; A::bigTalk insteadof B; B::bigTalk as talk; &#125;&#125;$a = new Aliased_Talker();$a-&gt;smallTalk(); // 输出 b$a-&gt;bigTalk(); // 输出 A$a-&gt;talk(); // 输出 B?&gt; 修改方法的访问控制使用 as 语法还可以用来调整方法的访问控制。 123456789101112131415161718&lt;?phptrait HelloWorld &#123; public function sayHello() &#123; echo 'Hello World!'; &#125;&#125;// 修改 sayHello 的访问控制class MyClass1 &#123; use HelloWorld &#123; sayHello as protected; &#125;&#125;// 给方法一个改变了访问控制的别名// 原版 sayHello 的访问控制则没有发生变化class MyClass2 &#123; use HelloWorld &#123; sayHello as private myPrivateHello; &#125;&#125;?&gt; 从 trait 来组成 trait正如 class 能够使用 trait 一样，其它 trait 也能够使用 trait。在 trait 定义时通过使用一个或多个 trait，能够组合其它 trait 中的部分或全部成员。 12345678910111213141516171819202122232425&lt;?phptrait Hello &#123; public function sayHello() &#123; echo 'Hello '; &#125;&#125;trait World &#123; public function sayWorld() &#123; echo 'World!'; &#125;&#125;trait HelloWorld &#123; use Hello, World;&#125;class MyHelloWorld &#123; use HelloWorld;&#125;$o = new MyHelloWorld();$o-&gt;sayHello();$o-&gt;sayWorld();?&gt; 输出： Hello World! trait 的抽象成员为了对使用的类施加强制要求，trait 支持抽象方法的使用。 1234567891011121314151617181920212223&lt;?phptrait Hello &#123; public function sayHelloWorld() &#123; echo 'Hello '.$this-&gt;getWorld(); &#125; abstract public function getWorld();&#125;class MyHelloWorld &#123; private $world; use Hello; public function getWorld() &#123; return $this-&gt;world; &#125; public function setWorld($val) &#123; $this-&gt;world = $val; &#125;&#125;$a = new MyHelloWorld();$a-&gt;setWorld("World!");$a-&gt;sayHelloWorld();?&gt; 输出： Hello World! trait 的静态成员Traits 可以定义静态变量和静态方法 1234567891011121314151617181920&lt;?phptrait StaticExample &#123; public function inc() &#123; static $c = 0; $c = $c + 1; echo "$c\n"; &#125; public static function doSomething() &#123; return 'Doing something'; &#125;&#125;class Example &#123; use StaticExample;&#125;$a = new Example();$a-&gt;inc();echo '&lt;/br&gt;';echo Example::doSomething();?&gt; 输出： 1 Doing something 定义属性Trait 同样可以定义属性。 123456789101112&lt;?phptrait PropertiesTrait &#123; public $x = 1;&#125;class PropertiesExample &#123; use PropertiesTrait;&#125;$example = new PropertiesExample;echo $example-&gt;x; // 输出 1?&gt; Trait 定义了一个属性后，类就不能定义同样名称的属性，否则会产生 fatal error。 有种情况例外：属性是兼容的（同样的访问可见度、初始默认值）。 在 PHP 7.0 之前，属性是兼容的，则会有 E_STRICT 的提醒。 123456789101112&lt;?phptrait PropertiesTrait &#123; public $same = true; public $different = false;&#125;class PropertiesExample &#123; use PropertiesTrait; public $same = true; // PHP 7.0.0 后没问题，之前版本是 E_STRICT 提醒 public $different = true; // 致命错误&#125;?&gt; 匿名类PHP 7 开始支持匿名类。 匿名类很有用，可以创建一次性的简单对象。 12345678910111213141516&lt;?php// PHP 7 之前的代码class Logger &#123; public function log($msg) &#123; echo $msg; &#125;&#125;$util-&gt;setLogger(new Logger());// 使用了 PHP 7+ 后的代码$util-&gt;setLogger(new class &#123; public function log($msg) &#123; echo $msg; &#125;&#125;); 可以传递参数到匿名类的构造器，也可以 extend 其他类、实现接口，以及像其他普通的类一样使用 trait。 12345678910111213&lt;?phpclass SomeClass &#123;&#125;interface SomeInterface &#123;&#125;trait SomeTrait &#123;&#125;var_dump(new class(10) extends SomeClass implements SomeInterface &#123; private $num; public function __construct($num) &#123; $this-&gt;num = $num; &#125; use SomeTrait;&#125;); 匿名类被嵌套进普通 Class 后，不能访问这个外部类的 private、protected方法或者属性。为了访问外部类 protected 属性或方法，匿名类可以 extend 此外部类。 为了使用外部类的 private 属性，必须通过构造器传进来。 12345678910111213141516171819202122&lt;?phpclass Outer&#123; private $prop = 1; protected $prop2 = 2; protected function func1() &#123; return 3; &#125; public function func2() &#123; return new class($this-&gt;prop) extends Outer &#123; private $prop3; public function __construct($prop) &#123; $this-&gt;prop3 = $prop; &#125; public function func3() &#123; return $this-&gt;prop2 + $this-&gt;prop3 + $this-&gt;func1(); &#125; &#125;; &#125;&#125;echo (new Outer)-&gt;func2()-&gt;func3(); // 输出 6?&gt; 重载PHP中的”重载”与其它绝大多数面向对象语言不同。传统的”重载”是用于提供多个同名的类方法，但各方法的参数类型和个数不同。PHP所提供的”重载”是指动态地”创建”类属性和方法。我们是通过魔术方法（magic methods）来实现的。当调用当前环境下未定义或不可见的类属性或方法时，重载方法会被调用。所有的重载方法都必须被声明为 public。 属性重载public void __set ( string $name , mixed $value )public mixed __get ( string $name )public bool __isset ( string $name )public void __unset ( string $name ) 注：mixed 说明一个参数可以接受多种不同的类型。 在给不可访问属性赋值时，__set() 会被调用。读取不可访问属性的值时，__get() 会被调用。当对不可访问属性调用 isset() 或 empty() 时，__isset() 会被调用。当对不可访问属性调用 unset() 时，__unset() 会被调用。参数 $name 是指要操作的变量名称。__set() 方法的 $value 参数指定了 $name 变量的值。属性重载只能在对象中进行。在静态方法中，这些魔术方法将不会被调用。所以这些方法都不能被 声明为 static。从 PHP 5.3.0 起, 将这些魔术方法定义为 static 会产生一个警告。 示例： 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253&lt;?phpclass PropertyTest &#123; /** 被重载的数据保存在此 */ private $data = array(); /** 重载不能被用在已经定义的属性 */ public $declared = 1; /** 只有从类外部访问这个属性时，重载才会发生 */ private $hidden = 2; public function __set($name, $value) &#123; echo "Setting '$name' to '$value'\n"; $this-&gt;data[$name] = $value; &#125; public function __get($name) &#123; echo "Getting '$name'\n"; if (array_key_exists($name, $this-&gt;data)) &#123; return $this-&gt;data[$name]; &#125; else &#123; return 'Not exists'; &#125; &#125; public function __isset($name) &#123; echo "Is '$name' set?\n"; return isset($this-&gt;data[$name]); &#125; public function __unset($name) &#123; echo "Unsetting '$name'\n"; unset($this-&gt;data[$name]); &#125; /** 非魔术方法 */ public function getHidden() &#123; return $this-&gt;hidden; &#125;&#125;echo "&lt;pre&gt;\n";$obj = new PropertyTest;$obj-&gt;a = 1;echo $obj-&gt;a . "\n\n";var_dump(isset($obj-&gt;a));unset($obj-&gt;a);var_dump(isset($obj-&gt;a));echo "\n";echo $obj-&gt;declared . "\n\n";echo "Let's experiment with the private property named 'hidden':\n";echo "Privates are visible inside the class, so __get() not used...\n";echo $obj-&gt;getHidden() . "\n";echo "Privates not visible outside of class, so __get() is used...\n";echo $obj-&gt;hidden . "\n";?&gt; 输出： Setting &apos;a&apos; to &apos;1&apos; Getting &apos;a&apos; 1 Is &apos;a&apos; set? bool(true) Unsetting &apos;a&apos; Is &apos;a&apos; set? bool(false) 1 Let&apos;s experiment with the private property named &apos;hidden&apos;: Privates are visible inside the class, so __get() not used... 2 Privates not visible outside of class, so __get() is used... Getting &apos;hidden&apos; Not exists 方法重载public mixed __call ( string $name , array $arguments )public static mixed __callStatic ( string $name , array $arguments ) 在对象中调用一个不可访问方法时，__call() 会被调用。在静态上下文中调用一个不可访问方法时，__callStatic() 会被调用。$name 参数是要调用的方法名称。$arguments 参数是一个枚举数组，包含着要传递给方法 $name 的参数。 123456789101112131415161718192021&lt;?phpclass MethodTest &#123; public function __call($name, $arguments) &#123; // 注意: $name 的值区分大小写 echo "Calling object method '$name' " . implode(', ', $arguments). "\n"; &#125; /** PHP 5.3.0之后版本 */ public static function __callStatic($name, $arguments) &#123; // 注意: $name 的值区分大小写 echo "Calling static method '$name' " . implode(', ', $arguments). "\n"; &#125;&#125;echo '&lt;pre&gt;';$obj = new MethodTest;$obj-&gt;runTest('in object context');MethodTest::runTest('in static context'); // PHP 5.3.0之后版本?&gt; 输出： Calling object method &apos;runTest&apos; in object context Calling static method &apos;runTest&apos; in static context 遍历对象PHP 5 提供了一种定义对象的方法使其可以通过单元列表来遍历，例如用 foreach 语句。默认情况下，所有可见属性都将被用于遍历。 简单遍历123456789101112131415161718192021222324&lt;?phpclass MyClass &#123; public $var1 = 'value 1'; public $var2 = 'value 2'; public $var3 = 'value 3'; protected $protected = 'protected var'; private $private = 'private var'; function iterateVisible() &#123; echo "MyClass::iterateVisible:\n"; foreach($this as $key =&gt; $value) &#123; print "$key =&gt; $value\n"; &#125; &#125;&#125;$class = new MyClass();echo '&lt;pre&gt;';foreach($class as $key =&gt; $value) &#123; print "$key =&gt; $value\n";&#125;$class-&gt;iterateVisible();?&gt; 输出： var1 =&gt; value 1 var2 =&gt; value 2 var3 =&gt; value 3 MyClass::iterateVisible: var1 =&gt; value 1 var2 =&gt; value 2 var3 =&gt; value 3 protected =&gt; protected var private =&gt; private var 实现 iterator 接口更进一步，可以实现 Iterator 接口。可以让对象自行决定如何遍历以及每次遍历时那些值可用。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647&lt;?phpclass MyIterator implements Iterator &#123; private $var = array(); public function __construct($array) &#123; if (is_array($array)) &#123; $this-&gt;var = $array; &#125; &#125; public function rewind() &#123; echo "rewinding\n"; reset($this-&gt;var); &#125; public function current() &#123; $var = current($this-&gt;var); echo "current: $var\n"; return $var; &#125; public function key() &#123; $var = key($this-&gt;var); echo "key: $var\n"; return $var; &#125; public function next() &#123; $var = next($this-&gt;var); echo "next: $var\n"; return $var; &#125; public function valid() &#123; $var = $this-&gt;current() !== false; echo "valid: &#123;$var&#125;\n"; return $var; &#125;&#125;$values = array(1,2,3);$it = new MyIterator($values);echo '&lt;pre&gt;';foreach ($it as $a =&gt; $b) &#123; print "$a: $b\n";&#125;?&gt; 输出： rewinding current: 1 valid: 1 current: 1 key: 0 0: 1 next: 2 current: 2 valid: 1 current: 2 key: 1 1: 2 next: 3 current: 3 valid: 1 current: 3 key: 2 2: 3 next: current: valid: 通过实现 IteratorAggregate可以用 IteratorAggregate 接口以替代实现所有的 Iterator 方法。IteratorAggregate 只需要实现一个方法 IteratorAggregate::getIterator()，其应返回一个实现了 Iterator 的类的实例。 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556575859606162&lt;?php&lt;?phpclass MyIterator implements Iterator &#123; private $var = array(); public function __construct($array) &#123; if (is_array($array)) &#123; $this-&gt;var = $array; &#125; &#125; public function rewind() &#123; echo "rewinding\n"; reset($this-&gt;var); &#125; public function current() &#123; $var = current($this-&gt;var); echo "current: $var\n"; return $var; &#125; public function key() &#123; $var = key($this-&gt;var); echo "key: $var\n"; return $var; &#125; public function next() &#123; $var = next($this-&gt;var); echo "next: $var\n"; return $var; &#125; public function valid() &#123; $var = $this-&gt;current() !== false; echo "valid: &#123;$var&#125;\n"; return $var; &#125;&#125;class MyCollection implements IteratorAggregate &#123; private $items = array(); private $count = 0; // Required definition of interface IteratorAggregate public function getIterator() &#123; return new MyIterator($this-&gt;items); &#125; public function add($value) &#123; $this-&gt;items[$this-&gt;count++] = $value; &#125;&#125;$coll = new MyCollection();$coll-&gt;add('value 1');$coll-&gt;add('value 2');$coll-&gt;add('value 3');foreach ($coll as $key =&gt; $val) &#123; echo "key/value: [$key -&gt; $val]\n\n";&#125;?&gt; 魔术方法__construct()， __destruct()， __call()， __callStatic()， __get()， __set()， __isset()， __unset()， __sleep()， __wakeup()， __toString()， __invoke()， __set_state()，__clone() 和 __debugInfo() 等方法在 PHP 中被称为”魔术方法”（Magic methods）。在命名自己的类方法时不能使用这些方法名，除非是想使用其魔术功能。 PHP 将所有以 __（两个下划线）开头的类方法保留为魔术方法。所以在定义类方法时，除了上述魔术方法，建议不要以 __ 为前缀。 魔法方法 说明 __sleep 序列化对象前被调用，可用于清理对象 __wakeup 反序列化前被调用 __toString 可以将对象当成字符串 比如echo一个对象时调用 __invoke 可以让对象当函数进行调用 __set_state 调用 var_export() 导出类时此方法被调用 __debugInfo 调用 var_dump() 打印对象时被调用 PHP 5.6可用 简单例子： 123456789101112131415161718&lt;?phpclass foo &#123; public function __toString() &#123; return "This is " . self::class . "&lt;/br&gt;"; &#125; public function __debugInfo() &#123; return ["message"=&gt;"called __debugInfo()"]; &#125; public function __invoke() &#123; return "called __invoke()&lt;/br&gt;"; &#125;&#125;$f = new foo;echo $f;echo $f();var_dump($f);?&gt; final 关键字PHP 5 新增了一个 final 关键字。如果父类中的方法被声明为 final，则子类无法覆盖该方法。如果一个类被声明为 final，则不能被继承。 final 方法： 123456789101112131415161718&lt;?phpclass BaseClass &#123; public function test() &#123; echo "BaseClass::test() called\n"; &#125; final public function moreTesting() &#123; echo "BaseClass::moreTesting() called\n"; &#125;&#125;class ChildClass extends BaseClass &#123; public function moreTesting() &#123; echo "ChildClass::moreTesting() called\n"; &#125;&#125;// Results in Fatal error: Cannot override final method BaseClass::moreTesting()?&gt; final 类：12345678910111213141516&lt;?phpfinal class BaseClass &#123; public function test() &#123; echo "BaseClass::test() called\n"; &#125; // 这里无论你是否将方法声明为final，都没有关系 final public function moreTesting() &#123; echo "BaseClass::moreTesting() called\n"; &#125;&#125;class ChildClass extends BaseClass &#123;&#125;// 产生 Fatal error: Class ChildClass may not inherit from final class (BaseClass)?&gt; 对象复制在多数情况下，我们并不需要完全复制一个对象来获得其中属性。但有一个情况下确实需要：如果你有一个 GTK 窗口对象，该对象持有窗口相关的资源。你可能会想复制一个新的窗口，保持所有属性与原来的窗口相同，但必须是一个新的对象（因为如果不是新的对象，那么一个窗口中的改变就会影响到另一个窗口）。还有一种情况：如果对象 A 中保存着对象 B 的引用，当你复制对象 A 时，你想其中使用的对象不再是对象 B 而是 B 的一个副本，那么你必须得到对象 A 的一个副本。 对象复制可以通过 clone 关键字来完成（如果可能，这将调用对象的 __clone() 方法）。对象中的 __clone() 方法不能被直接调用。 当对象被复制后，PHP 5 会对对象的所有属性执行一个浅复制（shallow copy）。所有的引用属性 仍然会是一个指向原来的变量的引用。 示例：12345678910111213141516&lt;?phpclass MyCloneable &#123; public $val = "val"; public function __clone() &#123; echo "called __clone()&lt;/br&gt;"; &#125;&#125;$obj = new MyCloneable();$obj2 = clone $obj;echo "obj =&gt; ".$obj-&gt;val.'&lt;/br&gt;';echo "obj2 =&gt; ".$obj2-&gt;val.'&lt;/br&gt;';$obj2-&gt;val = "val2";echo "obj =&gt; ".$obj-&gt;val.'&lt;/br&gt;';echo "obj2 =&gt; ".$obj2-&gt;val.'&lt;/br&gt;';?&gt; 对象比较当使用比较运算符（==）比较两个对象变量时，比较的原则是：如果两个对象的属性和属性值都相等，而且两个对象是同一个类的实例，那么这两个对象变量相等。 而如果使用全等运算符（===），这两个对象变量一定要指向某个类的同一个实例（即同一个对象）。 1234567891011&lt;?phpclass BaseClass &#123;&#125;$b1 = new BaseClass;$b2 = new BaseClass;$b3 = $b2;echo '&lt;pre&gt;';var_dump($b1 == $b2); // truevar_dump($b1 === $b2); // falsevar_dump($b2 === $b3); // truevar_dump($b2 == $b3); // false?&gt; 类型约束PHP 5 可以使用类型约束。函数的参数可以指定必须为对象（在函数原型里面指定类的名字），接口，数组（PHP 5.1 起）或者 callable（PHP 5.4 起）。不过如果使用 NULL 作为参数的默认值，那么在调用函数的时候依然可以使用 NULL 作为实参。 如果一个类或接口指定了类型约束，则其所有的子类或实现也都如此。 类型约束不能用于标量类型如 int 或 string。Traits 也不允许。 示例：123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051525354&lt;?phpclass MyClass&#123; // 测试函数 第一个参数必须为 OtherClass 类的一个对象 public function test(OtherClass $otherclass) &#123; echo $otherclass-&gt;var; &#125; // 另一个测试函数 第一个参数必须为数组 public function test_array(array $input_array) &#123; print_r($input_array); &#125;&#125; // 第一个参数必须为递归类型 public function test_interface(Traversable $iterator) &#123; echo get_class($iterator); &#125; // 第一个参数必须为回调类型 public function test_callable(callable $callback, $data) &#123; call_user_func($callback, $data); &#125;&#125;// OtherClass 类定义class OtherClass &#123; public $var = 'Hello World';&#125;$myclass = new MyClass;$otherclass = new OtherClass;// 致命错误：第一个参数必须是 OtherClass 类的一个对象$myclass-&gt;test('hello');// 致命错误：第一个参数必须为 OtherClass 类的一个实例$foo = new stdClass;$myclass-&gt;test($foo);// 致命错误：第一个参数不能为 null$myclass-&gt;test(null);// 正确：输出 Hello World $myclass-&gt;test($otherclass);// 致命错误：第一个参数必须为数组$myclass-&gt;test_array('a string');// 正确：输出数组$myclass-&gt;test_array(array('a', 'b', 'c'));// 正确：输出 ArrayObject$myclass-&gt;test_interface(new ArrayObject(array()));// 正确：输出 int(1)$myclass-&gt;test_callable('var_dump', 1);?&gt; 类型约束不只是用在类的成员函数里，也能使用在函数里： 123456789101112131415&lt;?php// 如下面的类class MyClass &#123; public $var = 'Hello World';&#125;// 测试函数 第一个参数必须是 MyClass 类的一个对象function MyFunction (MyClass $foo) &#123; echo $foo-&gt;var;&#125;// 正确$myclass = new MyClass;MyFunction($myclass);?&gt; 类型约束允许 NULL 值： 123456&lt;?php/* 接受 NULL 值 */function test(stdClass $obj = NULL) &#123; &#125;test(NULL);test(new stdClass);?&gt; 后期静态绑定自 PHP 5.3.0 起，PHP 增加了一个叫做后期静态绑定的功能，用于在继承范围内引用静态调用的类。 准确说，后期静态绑定工作原理是存储了在上一个”非转发调用”（non-forwarding call）的类名。当进行静态方法调用时，该类名即为明确指定的那个（通常在 :: 运算符左侧部分）；当进行非静态方法调用时，即为该对象所属的类。所谓的”转发调用”（forwarding call）指的是通过以下几种方式进行的静态调用：self::，parent::，static:: 以及 forward_static_call()。可用 get_called_class() 函数来得到被调用的方法所在的类名，static:: 则指出了其范围。 该功能从语言内部角度考虑被命名为”后期静态绑定”。”后期绑定”的意思是说，static:: 不再被解析为定义当前方法所在的类，而是在实际运行时计算的。也可以称之为”静态绑定”，因为它可以用于（但不限于）静态方法的调用。 self:: 的限制123456789101112131415161718&lt;?phpclass A &#123; public static function who() &#123; echo __CLASS__; &#125; public static function test() &#123; self::who(); &#125;&#125;class B extends A &#123; public static function who() &#123; echo __CLASS__; &#125;&#125;B::test();?&gt; 输出： A 后期静态绑定的用法123456789101112131415161718&lt;?phpclass A &#123; public static function who() &#123; echo __CLASS__; &#125; public static function test() &#123; static::who(); // 后期静态绑定从这里开始 &#125;&#125;class B extends A &#123; public static function who() &#123; echo __CLASS__; &#125;&#125;B::test();?&gt; 输出： B 在非静态环境下，所调用的类即为该对象实例所属的类。由于 $this-&gt; 会在同一作用范围内尝试调用私有方法，而 static:: 则可能给出不同结果。另一个区别是 static:: 只能用于静态属性。 对象和引用在php5 的对象编程经常提到的一个关键点是“默认情况下对象是通过引用传递的”。但其实这不是完全正确的。下面通过一些例子来说明。 PHP 的引用是别名，就是两个不同的变量名字指向相同的内容。在 PHP 5，一个对象变量已经不再保存整个对象的值。只是保存一个标识符来访问真正的对象内容。 当对象作为参数传递，作为结果返回，或者赋值给另外一个变量，另外一个变量跟原来的不是引用的关系，只是他们都保存着同一个标识符的拷贝，这个标识符指向同一个对象的真正内容。 12345678910111213141516171819202122232425&lt;?phpclass A &#123; public $foo = 1;&#125; $a = new A;$b = $a; // $a ,$b都是同一个标识符的拷贝 // ($a) = ($b) = &lt;id&gt;$b-&gt;foo = 2;echo $a-&gt;foo."&lt;/br&gt;";$c = new A;$d = &amp;$c; // $c ,$d是引用 // ($c,$d) = &lt;id&gt;$d-&gt;foo = 2;echo $c-&gt;foo."&lt;/br&gt;";$e = new A;function foo($obj) &#123; // ($obj) = ($e) = &lt;id&gt; $obj-&gt;foo = 2;&#125;foo($e);echo $e-&gt;foo."&lt;/br&gt;";?&gt; 输出： 2 2 2 对象序列化所有php里面的值都可以使用函数serialize()来返回一个包含字节流的字符串来表示。unserialize()函数能够重新把字符串变回php原来的值。 序列化一个对象将会保存对象的所有变量，但是不会保存对象的方法，只会保存类的名字。 为了能够unserialize()一个对象，这个对象的类必须已经定义过。如果序列化类A的一个对象，将会返回一个跟类A相关，而且包含了对象所有变量值的字符串。 如果要想在另外一个文件中解序列化一个对象，这个对象的类必须在解序列化之前定义，可以通过包含一个定义该类的文件或使用函数spl_autoload_register()来实现。 classa.inc12345678&lt;?phpclass A &#123; public $one = 1; public function show_one() &#123; echo $this-&gt;one; &#125;&#125;?&gt; page1.php1234567&lt;?phpinclude("classa.inc");$a = new A;$s = serialize($a);// 把变量$s保存起来以便文件page2.php能够读到file_put_contents('store', $s);?&gt; page2.php12345678&lt;?php// 要正确了解序列化，必须包含下面一个文件include("classa.inc");$s = file_get_contents('store');$a = unserialize($s);// 现在可以使用对象$a里面的函数 show_one()$a-&gt;show_one();?&gt; 先执行 page1.php 再执行 page2.php 就可以看到结果了。 命名空间命名空间概述什么是命名空间？从广义上来说，命名空间是一种封装事物的方法。在很多地方都可以见到这种抽象概念。例如，在操作系统中目录用来将相关文件分组，对于目录中的文件来说，它就扮演了命名空间的角色。具体举个例子，文件 foo.txt 可以同时在目录/home/greg 和 /home/other 中存在，但在同一个目录中不能存在两个 foo.txt 文件。另外，在目录 /home/greg 外访问 foo.txt 文件时，我们必须将目录名以及目录分隔符放在文件名之前得到 /home/greg/foo.txt。这个原理应用到程序设计领域就是命名空间的概念。 在PHP中，命名空间用来解决在编写类库或应用程序时创建可重用的代码如类或函数时碰到的两类问题： 用户编写的代码与PHP内部的类/函数/常量或第三方类/函数/常量之间的名字冲突。 为很长的标识符名称(通常是为了缓解第一类问题而定义的)创建一个别名（或简短）的名称，提高源代码的可读性。 PHP 命名空间提供了一种将相关的类、函数和常量组合到一起的途径。 定义命名空间虽然任意合法的PHP代码都可以包含在命名空间中，但只有以下类型的代码受命名空间的影响，它们是：类（包括抽象类和traits）、接口、函数和常量。 命名空间通过关键字namespace 来声明。如果一个文件中包含命名空间，它必须在其它所有代码之前声明命名空间，除了一个以外：declare关键字。 123456&lt;?phpnamespace MyProject;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */ &#125;?&gt; 在声明命名空间之前唯一合法的代码是用于定义源文件编码方式的 declare 语句。另外，所有非 PHP 代码包括空白符都不能出现在命名空间的声明之前： 1234&lt;html&gt;&lt;?phpnamespace MyProject; // 致命错误 - 命名空间必须是程序脚本的第一条语句?&gt; 另外，与PHP其它的语言特征不同，同一个命名空间可以定义在多个文件中，即允许将同一个命名空间的内容分割存放在不同的文件中。 定义子命名空间与目录和文件的关系很象，PHP 命名空间也允许指定层次化的命名空间的名称。因此，命名空间的名字可以使用分层次的方式定义： 123456&lt;?phpnamespace MyProject\Sub\Level;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */ &#125;?&gt; 上面的例子创建了常量 MyProject\Sub\Level\CONNECT_OK，类 MyProject\Sub\Level\Connection 和函数 MyProject\Sub\Level\connect。 同一个文件多个命名空间也可以在同一个文件中定义多个命名空间。在同一个文件中定义多个命名空间有两种语法形式。 简单组合语法：1234567891011&lt;?phpnamespace MyProject;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */ &#125;namespace AnotherProject;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */ &#125;?&gt; 不建议使用这种语法在单个文件中定义多个命名空间。建议使用下面的大括号形式的语法。 大括号语法：12345678910111213&lt;?phpnamespace MyProject &#123;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */ &#125;&#125;namespace AnotherProject &#123;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */ &#125;&#125;?&gt; 在实际的编程实践中，非常不提倡在同一个文件中定义多个命名空间。这种方式的主要用于将多个 PHP 脚本合并在同一个文件中。 将全局的非命名空间中的代码与命名空间中的代码组合在一起，只能使用大括号形式的语法。全局代码必须用一个不带名称的 namespace 语句加上大括号括起来，例如： 12345678910111213&lt;?phpnamespace MyProject &#123;const CONNECT_OK = 1;class Connection &#123; /* ... */ &#125;function connect() &#123; /* ... */ &#125;&#125;namespace &#123; // global codesession_start();$a = MyProject\connect();echo MyProject\Connection::start();&#125;?&gt; 除了开始的declare语句外，命名空间的括号外不得有任何PHP代码。 使用命名空间：基础在讨论如何使用命名空间之前，必须了解 PHP 是如何知道要使用哪一个命名空间中的元素的。可以将 PHP 命名空间与文件系统作一个简单的类比。在文件系统中访问一个文件有三种方式： 相对文件名形式如foo.txt。它会被解析为 currentdirectory/foo.txt，其中 currentdirectory 表示当前目录。因此如果当前目录是 /home/foo，则该文件名被解析为 /home/foo/foo.txt。 相对路径名形式如 subdirectory/foo.txt。它会被解析为 currentdirectory/subdirectory/foo.txt。 绝对路径名形式如 /main/foo.txt。它会被解析为 /main/foo.txt。 PHP 命名空间中的元素使用同样的原理。例如，类名可以通过三种方式引用： 非限定名称，或不包含前缀的类名称，例如 $a=new foo(); 或 foo::staticmethod();。如果当前命名空间是 currentnamespace，foo 将被解析为 currentnamespace\foo。如果使用 foo 的代码是全局的，不包含在任何命名空间中的代码，则 foo 会被解析为 foo。 警告：如果命名空间中的函数或常量未定义，则该非限定的函数名称或常量名称会被解析为全局函数名称或常量名称。 限定名称，或包含前缀的名称，例如 $a = new subnamespace\foo(); 或 subnamespace\foo::staticmethod();。如果当前的命名空间是 currentnamespace，则 foo 会被解析为 currentnamespace\subnamespace\foo。如果使用 foo 的代码是全局的，不包含在任何命名空间中的代码，foo 会被解析为 subnamespace\foo。 完全限定名称，或包含了全局前缀操作符的名称，例如，$a = new \currentnamespace\foo(); 或 \currentnamespace\foo::staticmethod();。在这种情况下，foo 总是被解析为代码中的文字名 currentnamespace\foo。 示例： file1.php12345678&lt;?phpnamespace Foo\Bar\subnamespace;const FOO = 1;function foo() &#123;&#125;class foo &#123; static function staticmethod() &#123;&#125;&#125;?&gt; file2.php12345678910111213141516171819202122232425&lt;?phpnamespace Foo\Bar;include 'file1.php';const FOO = 2;function foo() &#123;&#125;class foo &#123; static function staticmethod() &#123;&#125;&#125;/* 非限定名称 */foo(); // 解析为方法 Foo\Bar\foo foo::staticmethod(); // 解析为类 Foo\Bar\foo 的静态方法 staticmethod。echo FOO; // 解析为常量 Foo\Bar\FOO/* 限定名称 */subnamespace\foo(); // 解析为函数 Foo\Bar\subnamespace\foosubnamespace\foo::staticmethod(); // 解析为类 Foo\Bar\subnamespace\foo 的静态方法 staticmethodecho subnamespace\FOO; // 解析为常量 Foo\Bar\subnamespace\FOO /* 完全限定名称 */\Foo\Bar\foo(); // 解析为函数 Foo\Bar\foo\Foo\Bar\foo::staticmethod(); // 解析为类 Foo\Bar\foo, 以及类的方法 staticmethodecho \Foo\Bar\FOO; // 解析为常量 Foo\Bar\FOO?&gt; 注意：访问任意全局类、函数或常量，都可以使用完全限定名称，例如 \strlen() 或 \Exception 或 \INI_ALL。 命名空间和动态语言特征PHP 命名空间的实现受到其语言自身的动态特征的影响。因此，如果要将下面的代码转换到命名空间中： example1.php1234567891011121314151617&lt;?phpclass classname &#123; function __construct() &#123; echo __METHOD__,"\n"; &#125;&#125;function funcname() &#123; echo __FUNCTION__,"\n";&#125;const constname = "global";$a = 'classname';$obj = new $a; // prints classname::__construct$b = 'funcname';$b(); // prints funcnameecho constant('constname'), "\n"; // prints global?&gt; 必须使用完全限定名称（包括命名空间前缀的类名称）。注意因为在动态的类名称、函数名称或常量名称中，限定名称和完全限定名称没有区别，因此其前导的反斜杠是不必要的。 example2.php1234567891011121314151617181920212223242526272829303132&lt;?phpnamespace namespacename;class classname &#123; function __construct() &#123; echo __METHOD__,"\n"; &#125;&#125;function funcname() &#123; echo __FUNCTION__,"\n";&#125;const constname = "namespaced";include 'example1.php';$a = 'classname';$obj = new $a; // prints classname::__construct$b = 'funcname';$b(); // prints funcnameecho constant('constname'), "\n"; // prints global/* note that if using double quotes, "\\namespacename\\classname" must be used */$a = '\namespacename\classname';$obj = new $a; // prints namespacename\classname::__construct$a = 'namespacename\classname';$obj = new $a; // also prints namespacename\classname::__construct$b = 'namespacename\funcname';$b(); // prints namespacename\funcname$b = '\namespacename\funcname';$b(); // also prints namespacename\funcnameecho constant('\namespacename\constname'), "\n"; // prints namespacedecho constant('namespacename\constname'), "\n"; // also prints namespaced?&gt; __NAMESPACE__常量PHP支持两种抽象的访问当前命名空间内部元素的方法，__NAMESPACE__ 魔术常量和 namespace 关键字。 __NAMESPACE__ 示例： 1234&lt;?phpnamespace MyProject;echo __NAMESPACE__; // 输出 MyProject?&gt; 全局代码：1echo __NAMESPACE__; // 输出空白 __NAMESPACE__为空字符串。 常量 __NAMESPACE__ 在动态创建名称时很有用，例如： 123456789&lt;?phpnamespace MyProject;function get($classname)&#123; $a = __NAMESPACE__ . '\\' . $classname; return new $a;&#125;?&gt; namespace关键字关键字 namespace 可用来显式访问当前命名空间或子命名空间中的元素。它等价于类中的 self 操作符。 1234567891011121314&lt;?phpnamespace MyProject;use blah\blah as mine; // 查看下一节内容 使用命名空间：别名/导入blah\mine(); // 调用函数 MyProject\blah\mine()namespace\blah\mine(); // 调用函数 MyProject\blah\mine()namespace\func(); // 调用函数 MyProject\func()namespace\sub\func(); // 调用函数 MyProject\sub\func()namespace\cname::method(); // 调用 MyProject\cname 类的静态方法 "method" of class $a = new namespace\sub\cname(); // MyProject\sub\cname 类的实例对象$b = namespace\CONSTANT; // 将 MyProject\CONSTANT 的常量赋值给 $b?&gt; 使用命名空间：别名/导入允许通过别名引用或导入外部的完全限定名称，是命名空间的一个重要特征。这有点类似于在类 unix 文件系统中可以创建对其它的文件或目录的符号连接。 所有支持命名空间的PHP版本支持三种别名或导入方式：为类名称使用别名、为接口使用别名或为命名空间名称使用别名。PHP 5.6开始允许导入函数或常量或者为它们设置别名。 在PHP中，别名是通过操作符 use 来实现的. 下面是一个使用所有可能的五种导入方式的例子： 123456789101112131415161718192021222324252627&lt;?phpnamespace foo;use My\Full\Classname as Another;// 下面的例子与 use My\Full\NSname as NSname 相同use My\Full\NSname;// 导入一个全局类use ArrayObject;// importing a function (PHP 5.6+)use function My\Full\functionName;// aliasing a function (PHP 5.6+)use function My\Full\functionName as func;// importing a constant (PHP 5.6+)use const My\Full\CONSTANT;$obj = new namespace\Another; // 实例化 foo\Another 对象$obj = new Another; // 实例化 My\Full\Classname 对象NSname\subns\func(); // 调用函数 My\Full\NSname\subns\func$a = new ArrayObject(array(1)); // 实例化 ArrayObject 对象// 如果不使用 "use \ArrayObject" ，则实例化一个 foo\ArrayObject 对象func(); // calls function My\Full\functionNameecho CONSTANT; // echoes the value of My\Full\CONSTANT?&gt; 注意对命名空间中的名称（包含命名空间分隔符的完全限定名称如 Foo\Bar以及相对的不包含命名空间分隔符的全局名称如 FooBar）来说，前导的反斜杠是不必要的也不推荐的，因为导入的名称必须是完全限定的，不会根据当前的命名空间作相对解析。为了简化操作，PHP还支持在一行中使用多个use语句 123456&lt;?phpuse My\Full\Classname as Another, My\Full\NSname;$obj = new Another; // 实例化 My\Full\Classname 对象NSname\subns\func(); // 调用函数 My\Full\NSname\subns\func?&gt; 导入操作是在编译执行的，但动态的类名称、函数名称或常量名称则不是。 导入和动态名称：1234567&lt;?phpuse My\Full\Classname as Another, My\Full\NSname;$obj = new Another; // 实例化一个 My\Full\Classname 对象$a = 'Another';$obj = new $a; // 实际化一个 Another 对象?&gt; 另外，导入操作只影响非限定名称和限定名称。完全限定名称由于是确定的，故不受导入的影响。 导入和完全限定名称：12345678&lt;?phpuse My\Full\Classname as Another, My\Full\NSname;$obj = new Another; // instantiates object of class My\Full\Classname$obj = new \Another; // instantiates object of class Another$obj = new Another\thing; // instantiates object of class My\Full\Classname\thing$obj = new \Another\thing; // instantiates object of class Another\thing?&gt; 全局空间如果没有定义任何命名空间，所有的类与函数的定义都是在全局空间，与 PHP 引入命名空间概念前一样。在名称前加上前缀 \ 表示该名称是全局空间中的名称，即使该名称位于其它的命名空间中时也是如此。 12345678910&lt;?phpnamespace A\B\C;/* 这个函数是 A\B\C\fopen */function fopen() &#123; /* ... */ $f = \fopen(...); // 调用全局的fopen函数 return $f;&#125; ?&gt; 后备全局函数/常量在一个命名空间中，当 PHP 遇到一个非限定的类、函数或常量名称时，它使用不同的优先策略来解析该名称。类名称总是解析到当前命名空间中的名称。因此在访问系统内部或不包含在命名空间中的类名称时，必须使用完全限定名称，例如： 12345678&lt;?phpnamespace A\B\C;class Exception extends \Exception &#123;&#125;$a = new Exception('hi'); // $a 是类 A\B\C\Exception 的一个对象$b = new \Exception('hi'); // $b 是类 Exception 的一个对象$c = new ArrayObject; // 致命错误, 找不到 A\B\C\ArrayObject 类?&gt; 对于函数和常量来说，如果当前命名空间中不存在该函数或常量，PHP 会退而使用全局空间中的函数或常量。 123456789101112131415161718&lt;?phpnamespace A\B\C;const E_ERROR = 45;function strlen($str) &#123; return \strlen($str) - 1;&#125;echo E_ERROR, "\n"; // 输出 "45"echo INI_ALL, "\n"; // 输出 "7" - 使用全局常量 INI_ALLecho strlen('hi'), "\n"; // 输出 "1"if (is_array('hi')) &#123; // 输出 "is not array" echo "is array\n";&#125; else &#123; echo "is not array\n";&#125;?&gt; 名称解析规则名称解析遵循下列规则： 对完全限定名称的函数，类和常量的调用在编译时解析。例如 new \A\B 解析为类 A\B。 所有的非限定名称和限定名称（非完全限定名称）根据当前的导入规则在编译时进行转换。例如，如果命名空间 A\B\C 被导入为 C，那么对 C\D\e() 的调用就会被转换为 A\B\C\D\e()。 在命名空间内部，所有的没有根据导入规则转换的限定名称均会在其前面加上当前的命名空间名称。例如，在命名空间 A\B 内部调用 C\D\e()，则 C\D\e() 会被转换为 A\B\C\D\e() 。 非限定类名根据当前的导入规则在编译时转换（用全名代替短的导入名称）。例如，如果命名空间 A\B\C 导入为C，则 new C() 被转换为 new A\B\C() 。 在命名空间内部（例如A\B），对非限定名称的函数调用是在运行时解析的。例如对函数 foo() 的调用是这样解析的： 在当前命名空间中查找名为 A\B\foo() 的函数 尝试查找并调用 全局(global) 空间中的函数 foo()。 在命名空间（例如A\B）内部对非限定名称或限定名称类（非完全限定名称）的调用是在运行时解析的。下面是调用 new C() 及 new D\E() 的解析过程： new C()的解析: 在当前命名空间中查找A\B\C类。 尝试自动装载类A\B\C。 new D\E()的解析: 在类名称前面加上当前命名空间名称变成：A\B\D\E，然后查找该类。 尝试自动装载类 A\B\D\E。 为了引用全局命名空间中的全局类，必须使用完全限定名称 new \C()。 Errors错误基础可悲的是，不管我们在写代码时多么小心，错误始终是有的。PHP将会为许多常见的我文件和运行问题提供错误，警告和一些通知，同时让我们知道如何检测和处理这些错误，使得调试程序容易的多。 PHP会报告与各种错误条件相对应的各种错误。 如果没有设置错误处理程序，则PHP将根据其配置处理错误。哪些错误报告或者哪些错误忽略是通过error_reporting指令控制（php.ini）。或者在运行时调用error_reporting()，但是不推荐这样配置，因为在脚本执行之前可能也会发生一些错误。 在开发环境，你应该配置error_reporting为E_ALL，因为你需要了解并解决PHP提出的问题。在生产环境，你可能希望将此设置的不太详细，比如 E_ALL, E_NOTICE, E_STRICT, E_DEPRECATED。但在许多情况下，E_ALL也是合适的，因为它可以提供潜在问题的早期预警。 PHP对错误的处理取决于两个 php.ini 指令。display_errors 控制是否将错误显示为脚本输出的一部分。应该始终在生产环境中禁用它，因为它可以包含诸如数据库密码之类的机密信息，但是它常常在开发环境启用，因为它可以确保立即报告问题。 除了显示错误，PHP也可以启用 log_errors 指令来记录错误日志。它将记录任何错误到错误日志文件，这在生产环境非常适用，你可以记录发生的错误，然后根据错误生成报告。 PHP 7 错误处理PHP 7 改变了大多数错误的报告方式。不同于传统（PHP 5）的错误报告机制，现在大多数错误被作为 Error 异常抛出。 这种 Error 异常可以像 Exception 异常一样被第一个匹配的 try / catch 块所捕获。如果没有匹配的 catch 块，则调用异常处理函数（事先通过 set_exception_handler() 注册）进行处理。 如果尚未注册异常处理函数，则按照传统方式处理：被报告为一个致命错误（Fatal Error）。 Error 类并非继承自 Exception 类，所以不能用 catch (Exception $e) { ... } 来捕获 Error。你可以用 catch (Error $e) { ... }，或者通过注册异常处理函数 set_exception_handler() 来捕获 Error。 异常异常处理PHP 5 有一个类似于其他语言的异常处理模型。在PHP中可以主动抛出和捕获一个异常。代码被包含在 try 代码块中以便可以捕获，每一个 try 代码块都至少要有一个 catch 代码块或者 finally 代码块。 可以使用多个 catch 块来捕获不同类别的异常，代码正常执行（try 代码块中没有抛出异常）则不会执行所有 catch 代码块的内容，异常也可以在 catch 代码块中重新抛出。当抛出异常时，将不会继续执行下面的代码，PHP将尝试查找第一个匹配的 catch 块，如果一个异常没有捕捉到，将发出一个未捕捉的异常的消息，除非处理程序已定义了 set_exception_handler()。 在 PHP 5 和更高的版本，finally 代码块可以在最后一个 catch 块后指定，finally 块在 try 和 catch 执行完后总会执行的，不管是否抛出异常，finally 块的内容总会执行。 除了代码运行产生的异常 还可以使用 throw 主动抛出一个异常，抛出的异常需要是一个异常的类的对象。 示例： 1234567891011121314151617181920&lt;?phpfunction inverse($x) &#123; if (!$x) &#123; throw new Exception('Division by zero.&lt;/br&gt;'); &#125; return 1/$x;&#125;try &#123; echo inverse(5) . "&lt;/br&gt;"; echo inverse(0) . "&lt;/br&gt;";&#125; catch (Exception $e) &#123; echo 'Caught exception: ', $e-&gt;getMessage();&#125; finally &#123; echo "Second finally.&lt;/br&gt;";&#125;// Continue executionecho "Hello World&lt;/br&gt;";?&gt; 输出： 0.2 Caught exception: Division by zero. Second finally. Hello World 自定义异常可以通过继承异常类来自定义异常，Exception 是所有异常的基类。 Exception 类摘要：123456789101112131415161718class Exception &#123; /* 属性 */ protected string $message ; // 异常消息内容 protected int $code ; // 异常代码 protected string $file ; // 抛出异常的文件名 protected int $line ; // 抛出异常在该文件中的行号 /* 方法 */ public __construct ([ string $message = "" [, int $code = 0 [, Throwable $previous = NULL ]]] ) final public string getMessage ( void ) final public Throwable getPrevious ( void ) final public int getCode ( void ) final public string getFile ( void ) final public int getLine ( void ) final public array getTrace ( void ) final public string getTraceAsString ( void ) public string __toString ( void ) final private void __clone ( void )&#125; 继承异常类： 12345678910&lt;?phpclass MyException extends Exception &#123; &#125;try &#123; throw new MyException("自定义异常");&#125; catch (MyException $e) &#123; echo $e . '&lt;/br&gt;'; echo "捕捉到了自定义异常&lt;/br&gt;";&#125;?&gt; 输出： MyException: 自定义异常 in F:\phpstudy\src\index.php:5 Stack trace: #0 {main} 捕捉到了自定义异常 生成器生成器总览生成器提供了一种更容易的方法来实现简单的对象迭代，相比较定义类实现 Iterator 接口的方式，性能开销和复杂性大大降低。 生成器允许你在 foreach 代码块中写代码来迭代一组数据而不需要在内存中创建一个数组, 那会使你的内存达到上限，或者会占据可观的处理时间。相反，你可以写一个生成器函数，就像一个普通的自定义函数一样, 和普通函数只返回一次不同的是, 生成器可以根据需要 yield 多次，以便生成需要迭代的值。 一个简单的例子就是使用生成器来重新实现 range() 函数。 标准的 range() 函数需要在内存中生成一个数组包含每一个在它范围内的值，然后返回该数组, 结果就是会产生多个很大的数组。 比如，调用 range(0, 1000000) 将导致内存占用超过 100 MB。 做为一种替代方法, 我们可以实现一个 xrange() 生成器, 只需要足够的内存来创建 Iterator 对象并在内部跟踪生成器的当前状态，这样只需要不到1K字节的内存。 将 range() 实现为生成器： 123456789101112131415161718192021222324252627282930&lt;?phpfunction xrange($start, $limit, $step = 1) &#123; if ($start &lt; $limit) &#123; if ($step &lt;= 0) &#123; throw new LogicException('Step must be +ve'); &#125; for ($i = $start; $i &lt;= $limit; $i += $step) &#123; yield $i; &#125; &#125; else &#123; if ($step &gt;= 0) &#123; throw new LogicException('Step must be -ve'); &#125; for ($i = $start; $i &gt;= $limit; $i += $step) &#123; yield $i; &#125; &#125;&#125;// 注意下面range()和xrange()输出的结果是一样的。echo 'Single digit odd numbers from range(): ';foreach (range(0,10) as $number) &#123; echo "$number ";&#125;echo "&lt;/br&gt;";echo 'Single digit odd numbers from xrange(): ';foreach (xrange(0,10) as $number) &#123; echo "$number ";&#125;?&gt; 生成器对象：当第一次调用生成器的时候，返回生成器类的一个对象。这个对象与迭代器对象使用相同的方式实现了迭代器接口，并提供可以调用的方法来处理生成器的状态，包括从它返回值或者向它发送值。 生成器语法一个生成器函数看起来像一个普通的函数，不同的是普通函数返回一个值，而一个生成器可以yield生成许多它所需要的值。 当一个生成器被调用的时候，它返回一个可以被遍历的对象.当你遍历这个对象的时候(例如通过一个foreach循环)，PHP 将会在每次需要值的时候调用生成器函数，并在产生一个值之后保存生成器的状态，这样它就可以在需要产生下一个值的时候恢复调用状态。 一旦不再需要产生更多的值，生成器函数可以简单退出，而调用生成器的代码还可以继续执行，就像一个数组已经被遍历完了。 在一个生成器函数中不可以存在 return ，否则将产生一个错误。 yield 关键字生成器函数的核心是yield关键字。它最简单的调用形式看起来像一个return申明，不同之处在于普通return会返回值并终止函数的执行，而yield会返回一个值给循环调用此生成器的代码并且只是暂停执行生成器函数。 示例： 123456789101112&lt;?phpfunction gen_one_to_three() &#123; for ($i = 1; $i &lt;= 3; $i++) &#123; //注意变量$i的值在不同的yield之间是保持传递的。 yield $i; &#125;&#125;$generator = gen_one_to_three();foreach ($generator as $value) &#123; echo "$value&lt;/br&gt;";&#125;?&gt; 输出： 1 2 3 使用引用来生成值 生成函数可以像使用值一样来使用引用生成。这个和从函数返回一个引用一样：通过在函数名前面加一个引用符号。 123456789101112131415&lt;?phpfunction &amp;gen_reference() &#123; $value = 3; while ($value &gt; 0) &#123; yield $value; &#125;&#125;// 我们可以在循环中修改$number的值，而生成器是使用的引用值来生成// 所以gen_reference()内部的$value值也会跟着变化。foreach (gen_reference() as &amp;$number) &#123; echo (--$number).'... ';&#125;?&gt; 输出： 2... 1... 0... 引用的解释引用是什么在 PHP 中引用意味着用不同的名字访问同一个变量内容。这并不像 C 的指针：例如你不能对他们做指针运算，他们并不是实际的内存地址…… 替代的是，引用是符号表别名。注意在PHP 中，变量名和变量内容是不一样的， 因此同样的内容可以有不同的名字。最接近的比喻是 Unix 的文件名和文件本身——变量名是目录条目，而变量内容则是文件本身。引用可以被看作是 Unix 文件系统中的硬链接。 引用做什么PHP 的引用允许用两个变量来指向同一个内容。意思是，当这样做时： 123&lt;?php$a =&amp; $b;?&gt; 这意味着 $a 和 $b 指向了同一个变量。 同样的语法可以用在函数中，它返回引用，以及用在 new 运算符中 1234&lt;?php$bar =&amp; new fooclass();$foo =&amp; find_var($bar);?&gt; 自 PHP 5 起，new 自动返回引用，因此在此使用 =&amp; 已经过时了并且会产生 E_STRICT 级别的消息。 引用做的第二件事是用引用传递变量。这是通过在函数内建立一个本地变量并且该变量在呼叫范围内引用了同一个内容来实现的。例如： 1234567&lt;?phpfunction foo(&amp;$var) &#123; $var++;&#125;$a=5;foo($a);?&gt; 将使 $a 变成 6。这是因为在 foo 函数中变量 $var 指向了和 $a 指向的同一个内容。 引用不是什么如前所述，引用不是指针。这意味着下面的结构不会产生预期的效果： 1234567&lt;?phpfunction foo(&amp;$var)&#123; $var =&amp; $GLOBALS["baz"];&#125;foo($bar);?&gt; 这将使 foo 函数中的 $var 变量在函数调用时和 $bar 绑定在一起，但接着又被重新绑定到了 $GLOBALS[“baz”] 上面。不可能通过引用机制将 $bar 在函数调用范围内绑定到别的变量上面，因为在函数 foo 中并没有变量 $bar（它被表示为 $var，但是 $var 只有变量内容而没有调用符号表中的名字到值的绑定）。可以使用引用返回来引用被函数选择的变量。 引用传递可以将一个变量通过引用传递给函数，这样该函数就可以修改其参数的值。语法如下： 123456789&lt;?phpfunction foo(&amp;$var) &#123; $var++;&#125;$a=5;foo($a);// $a is 6 here?&gt; 以下内容可以通过引用传递： 变量，例如 foo($a) New 语句，例如 foo(new foobar()) 从函数中返回的引用，例如： 1234567&lt;?phpfunction &amp;bar() &#123; $a = 5; return $a;&#125;foo(bar());?&gt; 任何其它表达式都不能通过引用传递。 引用返回引用返回用在当想用函数找到引用应该被绑定在哪一个变量上面时。不要用返回引用来增加性能，引擎足够聪明来自己进行优化。仅在有合理的技术原因时才返回引用！要返回引用，使用此语法： 12345678910111213&lt;?phpclass foo &#123; public $value = 42; public function &amp;getValue() &#123; return $this-&gt;value; &#125;&#125;$obj = new foo;$myValue = &amp;$obj-&gt;getValue(); // $myValue 是 $obj-&gt;value 的引用，现在值是 42$obj-&gt;value = 2;echo $myValue; // 打印 $obj-&gt;value 的值, 现在是 2?&gt; 取消引用当 unset 一个引用，只是断开了变量名和变量内容之间的绑定。这并不意味着变量内容被销毁了。例如： 12345&lt;?php$a = 1;$b =&amp; $a;unset($a);?&gt; 不会 unset $b，只是 $a。再拿这个和 Unix 的 unlink 调用来类比一下可能有助于理解。 引用定位许多 PHP 的语法结构是通过引用机制实现的，所以上述有关引用绑定的一切也都适用于这些结构。一些结构，例如引用传递和返回，已经在上面提到了。其它使用引用的结构有： global 引用 当用 global $var 声明一个变量时实际上建立了一个到全局变量的引用。也就是说和这样做是相同的： 123&lt;?php$var =&amp; $GLOBALS["var"];?&gt; 这意味着，例如，unset $var 不会 unset 全局变量。 $this 在一个对象的方法中，$this 永远是调用它的对象的引用。 预定义变量对于全部脚本而言，PHP 提供了大量的预定义变量。这些变量将所有的外部变量表示成内建环境变量，并且将错误信息表示成返回头。 超全局变量超全局变量 — 超全局变量是在全部作用域中始终可用的内置变量 PHP 中的许多预定义变量都是“超全局的”，这意味着它们在一个脚本的全部作用域中都可用。在函数或方法中无需执行 global $variable; 就可以访问它们。 这些超全局变量是： $GLOBALS $_SERVER $_GET $_POST $_FILES $_COOKIE $_SESSION $_REQUEST $_ENV $GLOBALS$GLOBALS – 引用全局作用域中可用的全部变量，一个包含了全部变量的全局组合数组。变量的名字就是数组的键。 示例：1234567891011&lt;?phpfunction test() &#123; $foo = "local variable"; echo '$foo in global scope: ' . $GLOBALS["foo"] . "\n"; echo '$foo in current scope: ' . $foo . "\n";&#125;$foo = "Example content";test();?&gt; $_SERVER$_SERVER – 服务器和执行环境信息。$_SERVER 是一个包含了诸如头信息(header)、路径(path)、以及脚本位置(script locations)等等信息的数组。这个数组中的项目由 Web 服务器创建。不能保证每个服务器都提供全部项目；服务器可能会忽略一些，或者提供一些没有在这里列举出来的项目。 PHP_SELF – 当前执行脚本的文件名，与 document root 有关。例如，在地址为 http://example.com/foo/bar.php 的脚本中使用 $_SERVER[&#39;PHP_SELF&#39;] 将得到 /foo/bar.php。__FILE__ 常量包含当前(例如包含)文件的完整路径和文件名。 从 PHP 4.3.0 版本开始，如果 PHP 以命令行模式运行，这个变量将包含脚本名。之前的版本该变量不可用。 argv – 传递给该脚本的参数的数组。当脚本以命令行方式运行时，argv 变量传递给程序 C 语言样式的命令行参数。当通过 GET 方式调用时，该变量包含query string。 argc – 包含命令行模式下传递给该脚本的参数的数目(如果运行在命令行模式下)。 GATEWAY_INTERFACE – 服务器使用的 CGI 规范的版本；例如，”CGI/1.1”。 SERVER_ADDR – 当前运行脚本所在的服务器的 IP 地址。 SERVER_NAME – 当前运行脚本所在的服务器的主机名。如果脚本运行于虚拟主机中，该名称是由那个虚拟主机所设置的值决定。 SERVER_SOFTWARE – 服务器标识字符串，在响应请求时的头信息中给出。 SERVER_PROTOCOL – 请求页面时通信协议的名称和版本。例如，”HTTP/1.0”。 REQUEST_METHOD – 访问页面使用的请求方法；例如，”GET”, “HEAD”，”POST”，”PUT”。 REQUEST_TIME – 请求开始时的时间戳。从 PHP 5.1.0 起可用。 REQUEST_TIME_FLOAT – 请求开始时的时间戳，微秒级别的精准度。 自 PHP 5.4.0 开始生效。 QUERY_STRING – query string（查询字符串），如果有的话，通过它进行页面访问。 DOCUMENT_ROOT – 当前运行脚本所在的文档根目录。在服务器配置文件中定义。 HTTP_ACCEPT – 当前请求头中 Accept: 项的内容，如果存在的话。 HTTP_ACCEPT_CHARSET – 当前请求头中 Accept-Charset: 项的内容，如果存在的话。例如：iso-8859-1,*,utf-8。 HTTP_ACCEPT_ENCODING – 当前请求头中 Accept-Encoding: 项的内容，如果存在的话。例如：gzip。 HTTP_ACCEPT_LANGUAGE – 当前请求头中 Accept-Language: 项的内容，如果存在的话。例如：en。 HTTP_CONNECTION – 当前请求头中 Connection: 项的内容，如果存在的话。例如：Keep-Alive。 HTTP_HOST – 当前请求头中 Host: 项的内容，如果存在的话。 HTTP_REFERER – 引导用户代理到当前页的前一页的地址（如果存在）。由 user agent 设置决定。并不是所有的用户代理都会设置该项，有的还提供了修改 HTTP_REFERER 的功能。简言之，该值并不可信。 HTTP_USER_AGENT – 当前请求头中 User-Agent: 项的内容，如果存在的话。该字符串表明了访问该页面的用户代理的信息。一个典型的例子是：Mozilla/4.5 [en] (X11; U; Linux 2.2.9 i586)。除此之外，你可以通过 get_browser() 来使用该值，从而定制页面输出以便适应用户代理的性能。 HTTPS – 如果脚本是通过 HTTPS 协议被访问，则被设为一个非空的值。 REMOTE_ADDR – 浏览当前页面的用户的 IP 地址。 REMOTE_HOST – 浏览当前页面的用户的主机名。DNS 反向解析不依赖于用户的 REMOTE_ADDR。 REMOTE_PORT – 用户机器上连接到 Web 服务器所使用的端口号。 REMOTE_USER – 经验证的用户 REDIRECT_REMOTE_USER – 验证的用户，如果请求已在内部重定向。 SCRIPT_FILENAME – 当前执行脚本的绝对路径。 SERVER_ADMIN – 该值指明了 Apache 服务器配置文件中的 SERVER_ADMIN 参数。如果脚本运行在一个虚拟主机上，则该值是那个虚拟主机的值。 SERVER_PORT – Web 服务器使用的端口。默认值为 “80”。如果使用 SSL 安全连接，则这个值为用户设置的 HTTP 端口。 SERVER_SIGNATURE – 包含了服务器版本和虚拟主机名的字符串。 PATH_TRANSLATED – 当前脚本所在文件系统（非文档根目录）的基本路径。这是在服务器进行虚拟到真实路径的映像后的结果。 SCRIPT_NAME – 包含当前脚本的路径。这在页面需要指向自己时非常有用。__FILE__ 常量包含当前脚本(例如包含文件)的完整路径和文件名。 REQUEST_URI – URI 用来指定要访问的页面。例如 /index.html。 PHP_AUTH_DIGEST – 当作为 Apache 模块运行时，进行 HTTP Digest 认证的过程中，此变量被设置成客户端发送的”Authorization” HTTP 头内容（以便作进一步的认证操作）。 PHP_AUTH_USER – 当 PHP 运行在 Apache 或 IIS（PHP 5 是 ISAPI）模块方式下，并且正在使用 HTTP 认证功能，这个变量便是用户输入的用户名。 PHP_AUTH_PW – 当 PHP 运行在 Apache 或 IIS（PHP 5 是 ISAPI）模块方式下，并且正在使用 HTTP 认证功能，这个变量便是用户输入的密码。 AUTH_TYPE – 当 PHP 运行在 Apache 模块方式下，并且正在使用 HTTP 认证功能，这个变量便是认证的类型。 PATH_INFO – 包含由客户端提供的、跟在真实脚本名称之后并且在查询语句（query string）之前的路径信息，如果存在的话。例如，如果当前脚本是通过 URL http://www.example.com/php/path_info.php/some/stuff?foo=bar 被访问，那么 $_SERVER[&#39;PATH_INFO&#39;] 将包含 /some/stuff。 ORIG_PATH_INFO – 在被 PHP 处理之前，PATH_INFO 的原始版本。 示例： 12345&lt;?phpecho '&lt;pre&gt;';echo $_SERVER['SERVER_NAME'];echo $_SERVER['HTTP_USER_AGENT'];?&gt; $_GET$_GET – HTTP GET 变量，通过 URL 参数传递给当前脚本的变量的数组。 示例： 123&lt;?phpecho 'Hello ' . htmlspecialchars($_GET["name"]) . '!';?&gt; 浏览器访问：http://127.0.0.1:8088/?name=World $_POST$_POST HTTP POST 变量，当 HTTP POST 请求的 Content-Type 是 application/x-www-form-urlencoded 或 multipart/form-data 时，会将变量以关联数组形式传入当前脚本。 示例： post.html12345678&lt;html&gt;&lt;body&gt; &lt;form action="post.php" method="post"&gt; Name: &lt;input type="text" name="name"&gt; &lt;input type="submit"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; post.php123&lt;?phpecho 'Hello ' . htmlspecialchars($_POST["name"]) . '!';?&gt; 浏览器访问：http://127.0.0.1:8088/post.html，输入内容后提交。 $_FILES$_FILES – HTTP 文件上传变量，通过 HTTP POST 方式上传到当前脚本的项目的数组 示例： file.html12345678&lt;html&gt;&lt;body&gt; &lt;form action="file.php" enctype="multipart/form-data" method="post"&gt; File: &lt;input type="file" name="name"&gt; &lt;input type="submit"&gt; &lt;/form&gt;&lt;/body&gt;&lt;/html&gt; file.php123&lt;?phpvar_dump($_FILES);?&gt; $_REQUEST$_REQUEST – HTTP Request 变量，默认情况下包含了 $_GET，$_POST 和 $_COOKIE 的数组。 $_SESSION$_SESSION – Session 变量，当前脚本可用 SESSION 变量的数组。Session 是浏览器会话保持机制。 示例： 123456789&lt;?phpsession_start();if (!isset($_SESSION['count'])) &#123; $_SESSION['count'] = 0;&#125; else &#123; $_SESSION['count']++;&#125;echo $_SESSION['count'];?&gt; 然后不断的访问这个页面，可以看到数值不断增加。 $_ENV$_ENV – 环境变量，通过环境方式传递给当前脚本的变量的数组。 这些变量被从 PHP 解析器的运行环境导入到 PHP 的全局命名空间。很多是由支持 PHP 运行的 Shell 提供的，并且不同的系统很可能运行着不同种类的 Shell，所以不可能有一份确定的列表。请查看你的 Shell 文档来获取定义的环境变量列表。 其他环境变量包含了 CGI 变量，而不管 PHP 是以服务器模块还是 CGI 处理器的方式运行。 示例： 123&lt;?phpvar_dump($_ENV);?&gt; $_COOKIE$_COOKIE – HTTP Cookies，通过 HTTP Cookies 方式传递给当前脚本的变量的数组。Cookie 也是浏览器会话保持机制，与 Session 不同的是，Session 的内容保存在服务器端，而 Cookie 的内容保存在浏览器，所以安全性不如 Session 。 示例：12345678910&lt;?phpif (!isset($_COOKIE['count'])) &#123; $count = 0; setcookie('count', $count, time()+3600);&#125; else &#123; $count = ++$_COOKIE['count']; setcookie('count', $count, time()+3600);&#125;echo $count;?&gt; 然后不断的访问这个页面，可以看到数值不断增加。 $http_response_header$http_response_header – HTTP 响应头，$http_response_header 将会被 HTTP 响应头信息填充。$http_response_header 将被创建于局部作用域中。 示例： 123456789&lt;?phpfunction get_contents() &#123; file_get_contents("http://www.baidu.com"); var_dump($http_response_header);&#125;get_contents();echo '&lt;/br&gt;';var_dump($http_response_header);?&gt; 可以看到 $http_response_header 只在 get_contents() 中被创建。 $argc$argc – 传递给脚本的参数数目，仅在命令行执行有效。 注意：脚本的文件名总是作为参数传递给当前脚本，因此 $argc 的最小值为 1。 argc.php1234&lt;?phpecho $argc;echo "\r\n";?&gt; 在终端里运行：php argc.php a a a a 输出：5 $argv$argv – 传递给脚本的参数数组，仅在命令行执行有效。 argv.php123&lt;?phpvar_dump($argv);?&gt; 在终端里运行：php argv.php a b c d输出： array(5) { [0]=&gt; string(8) &quot;argv.php&quot; [1]=&gt; string(1) &quot;a&quot; [2]=&gt; string(1) &quot;b&quot; [3]=&gt; string(1) &quot;c&quot; [4]=&gt; string(1) &quot;d&quot; } 预定义接口Traversable 接口Traversable（遍历）接口，检测一个类是否可以使用 foreach 进行遍历的接口。无法被单独实现的基本抽象接口。相反它必须由 IteratorAggregate 或 Iterator 接口实现。 接口摘要： 1Traversable &#123; &#125; 这个接口没有任何方法，它的作用仅仅是作为所有可遍历类的基本接口。 Iterator 接口Iterator（迭代器）接口，可在内部迭代自己的外部迭代器或类的接口。 接口摘要：12345678Iterator extends Traversable &#123;/* 方法 */ abstract public mixed current ( void ) abstract public scalar key ( void ) abstract public void next ( void ) abstract public void rewind ( void ) abstract public bool valid ( void )&#125; 基本用法： 123456789101112131415161718192021222324252627282930313233343536373839&lt;?phpclass myIterator implements Iterator &#123; private $position = 0; private $array = array( "firstelement", "secondelement", "lastelement", ); public function __construct() &#123; $this-&gt;position = 0; &#125; function rewind() &#123; var_dump(__METHOD__); $this-&gt;position = 0; &#125; function current() &#123; var_dump(__METHOD__); return $this-&gt;array[$this-&gt;position]; &#125; function key() &#123; var_dump(__METHOD__); return $this-&gt;position; &#125; function next() &#123; var_dump(__METHOD__); ++$this-&gt;position; &#125; function valid() &#123; var_dump(__METHOD__); return isset($this-&gt;array[$this-&gt;position]); &#125;&#125;$it = new myIterator;foreach($it as $key =&gt; $value) &#123; var_dump($key, $value); echo "\n";&#125;?&gt; 只要实现了 Iterator 这个接口的类，它的对象就可以使用 foreach 迭代了。 其中要实现的方法： Iterator::current — 返回当前元素，此函数没有参数，可返回任何类型。 Iterator::key — 返回当前元素的键，此函数没有参数，成功返回标量，失败则返回 NULL。 Iterator::next — 向前移动到下一个元素，此函数没有参数，任何返回都将被忽略。 Iterator::rewind — 返回到迭代器的第一个元素，此函数没有参数，任何返回都将被忽略。 Iterator::valid — 检查当前位置是否有效，此函数没有参数，返回将被转换为布尔型。成功时返回 TRUE， 或者在失败时返回 FALSE。 IteratorAggregate 接口IteratorAggregate（聚合式迭代器）接口，创建外部迭代器的接口。 接口摘要：1234IteratorAggregate extends Traversable &#123; /* 方法 */ abstract public Traversable getIterator ( void )&#125; 基本用法：123456789101112131415161718192021&lt;?phpclass myData implements IteratorAggregate &#123; public $property1 = "Public property one"; public $property2 = "Public property two"; public $property3 = "Public property three"; public function __construct() &#123; $this-&gt;property4 = "last property"; &#125; public function getIterator() &#123; return new ArrayIterator($this); &#125;&#125;$obj = new myData;foreach($obj as $key =&gt; $value) &#123; var_dump($key, $value); echo "\n";&#125;?&gt; 方法：IteratorAggregate::getIterator 返回一个外部迭代器，此函数没有参数，返回实现了 Iterator 或 Traversable 接口的类的一个实例。 ArrayAccess 接口ArrayAccess（数组式访问）接口，提供像访问数组一样访问对象的能力的接口。 接口摘要： 1234567ArrayAccess &#123; /* 方法 */ abstract public boolean offsetExists ( mixed $offset ) abstract public mixed offsetGet ( mixed $offset ) abstract public void offsetSet ( mixed $offset , mixed $value ) abstract public void offsetUnset ( mixed $offset )&#125; 示例：1234567891011121314151617181920212223242526272829303132333435363738394041&lt;?phpclass obj implements arrayaccess &#123; private $container = array(); public function __construct() &#123; $this-&gt;container = array( "one" =&gt; 1, "two" =&gt; 2, "three" =&gt; 3, ); &#125; public function offsetSet($offset, $value) &#123; if (is_null($offset)) &#123; $this-&gt;container[] = $value; &#125; else &#123; $this-&gt;container[$offset] = $value; &#125; &#125; public function offsetExists($offset) &#123; return isset($this-&gt;container[$offset]); &#125; public function offsetUnset($offset) &#123; unset($this-&gt;container[$offset]); &#125; public function offsetGet($offset) &#123; return isset($this-&gt;container[$offset]) ? $this-&gt;container[$offset] : null; &#125;&#125;$obj = new obj;var_dump(isset($obj["two"]));var_dump($obj["two"]);unset($obj["two"]);var_dump(isset($obj["two"]));$obj["two"] = "A value";var_dump($obj["two"]);$obj[] = 'Append 1';$obj[] = 'Append 2';$obj[] = 'Append 3';print_r($obj);?&gt; ArrayAccess::offsetExists – 检查一个偏移位置是否存在 ArrayAccess::offsetGet – 获取一个偏移位置的值 ArrayAccess::offsetSet – 设置一个偏移位置的值 ArrayAccess::offsetUnset – 复位一个偏移位置的值 序列化接口Serializable 自定义序列化的接口。 实现此接口的类将不再支持 sleep() 和 wakeup()。不论何时，只要有实例需要被序列化，serialize 方法都将被调用。它将不会调用 __destruct() 或有其他影响，除非程序化地调用此方法。当数据被反序列化时，类将被感知并且调用合适的 unserialize() 方法而不是调用 __construct()。如果需要执行标准的构造器，你应该在这个方法中进行处理。 接口摘要： 12345Serializable &#123; /* 方法 */ abstract public string serialize ( void ) abstract public mixed unserialize ( string $serialized )&#125; 示例： 12345678910111213141516171819202122&lt;?phpclass obj implements Serializable &#123; private $data; public function __construct() &#123; $this-&gt;data = "My private data"; &#125; public function serialize() &#123; return serialize($this-&gt;data); &#125; public function unserialize($data) &#123; $this-&gt;data = unserialize($data); &#125; public function getData() &#123; return $this-&gt;data; &#125;&#125;$obj = new obj;$ser = serialize($obj);$newobj = unserialize($ser);var_dump($newobj-&gt;getData());?&gt; Serializable::serialize — 对象的字符串表示 Serializable::unserialize — 构造对象 Closure 类用于代表匿名函数的类。 匿名函数会产生这个类型的对象。在过去，这个类被认为是一个实现细节，但现在可以依赖它做一些事情。自 PHP 5.4 起，这个类带有一些方法，允许在匿名函数创建后对其进行更多的控制。 除了此处列出的方法，还有一个 __invoke 方法。这是为了与其他实现了 __invoke() 魔术方法 的对象保持一致性，但调用匿名函数的过程与它无关。 类摘要： 123456Closure &#123; /* 方法 */ __construct ( void ) public static Closure bind ( Closure $closure , object $newthis [, mixed $newscope = 'static' ] ) public Closure bindTo ( object $newthis [, mixed $newscope = 'static' ] )&#125; Closure::__construct — 用于禁止实例化的构造函数 Closure::bind — 复制一个闭包，绑定指定的$this对象和类作用域。 Closure::bindTo — 复制当前闭包对象，绑定指定的$this对象和类作用域。 生成器类Generator 对象是从 generators 返回的，Generator 对象不能通过 new 实例化。 类摘要： 1234567891011Generator implements Iterator &#123; /* 方法 */ public mixed current ( void ) public mixed key ( void ) public void next ( void ) public void rewind ( void ) public mixed send ( mixed $value ) public void throw ( Exception $exception ) public bool valid ( void ) public void __wakeup ( void )&#125; Generator::current — 返回当前产生的值 Generator::key — 返回当前产生的键 Generator::next — 生成器继续执行 Generator::rewind — 重置迭代器 Generator::send — 向生成器中传入一个值 Generator::throw — 向生成器中抛入一个异常 Generator::valid — 检查迭代器是否被关闭 Generator::__wakeup — 序列化回调 附录到这里 PHP 的基础语法就结束了，想要用 PHP 去解决一些实际的事情就需要学习 PHP 如何应用了。 本篇根据整理学习 PHP 官方手册 完成。]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>php</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB分片集群]]></title>
    <url>%2F2018%2F03%2F02%2F2018%2FMongoDB%E5%88%86%E7%89%87%E9%9B%86%E7%BE%A4%2F</url>
    <content type="text"><![CDATA[简介 当面对海量数据的时候，单台MongoDB的承受能力显然达不到数据要求。分片(Sharding)是MongoDB将大型的集合分割到不同服务器上的方法。分片起源于关系型数据库的分区，但是和关系型数据库的分区相比，MongoDB已经帮用户做了所有能自动完成的事情。MongoDB会自动将需要分片的集合均衡的分布到不同的服务器上，配合副本集保障了数据的可用性和安全性，而这一切对用户都是透明的。 概念分片的目的高数据量和吞吐量的数据库应用会对单机的性能造成较大压力。随着数据的增大，单台MongoDB的QPS会严重下降。较大的查询甚至会将单机的CPU和内存资源耗尽。为了解决MongoDB的性能问题，一般有两种解决方法：垂直扩展和水平扩展。 垂直扩展 就是升级服务器的硬件，增加更多的CPU，增加更大的内存。但是这种方法很容易就达到硬件提升的瓶颈，而且可能需要付出更高的代价。水平扩展 就是一台服务器不行就多台，将数据分布到多个服务器上，需要查询数据的时候根据相应的算法知道数据存放在哪台服务器上就可以了。 分片的设计一个MongoDB分片集群有三种角色 分片服务器(Shard Server) mongod实例，用于存储实际的数据块。分片服务器可以是一个副本集集群共同来提供服务 防止单点故障。 配置服务器(Config Server) mongod实例，存储整个集群和分片的元数据，就像是一本书的目录，保存的只是数据的分布表。 路由服务器(Route Server) mongos实例，客户端由此接入，本身不存放数据，仅供程序连接，起到一个路由的作用。 路由服务器对整个MongoDB分片集群进行了抽象，用户访问mongos提供的监听就像访问一个mongod一样。而分片服务器使用副本集来保障了数据的可用性和安全性。分片集群还提供了良好的扩展能力，随着数据量增大可以方便的增加分片服务器来扩展整个集群的容量。 用户对分片集群一次完整的读取数据过程如下： 数据分发在MongoDB分片集群中，将集合的数据拆分成块(chunk)，然后将块分不到不同的分片服务器上。MongoDB的块大小默认是64M，大于64M的块将自动分裂为两个较小的块。MongoDB内置均衡器(balancer)就是用于拆分块和分发块的。 块的分发主要有两种方式：基于块的数量的分发 和 基于片键范围的定向分发 基于块的数量的分发MongoDB内置均衡器按照集合的索引字段来进行数据分发，该字段叫做片键(sharded key)片键一般有三种类型：升序片键，随机片键和基于分组的片键。 升序片键升序片键类似自增长的ID。假如集合foo有10个文档，1-4的文档所在块在分片服务器A上，5-8的文档所在块在分片服务器B上，9-10的文档所在块在分片服务器C上。当有新的文档需要写入时会插入到C服务器上所在的块，当块的大小超过限制后会分裂为两个块，分裂后的旧数据所在块可能会移动到其他服务器，继续新增的数据还会插入到拥有最大ID的块，导致所有的写请求都被路由到了C分片服务器上，数据写入不均匀。 但是如果按照片键进行范围读取时，数据可能都在同一个块上，读取的性能就比较高了。 随机片键随机片键是指片键的值不是固定增长，而是一些没有规律的键值。由于写入数据是随机分发的，各分片增长的速度大致相同，减少了chunk 迁移的次数。使用随机分片的弊端是：写入的位置是随机的，如果使用Hash Index来产生随机值，那么范围查询的速度会很慢。 基于分组的片键基于分组的片键是两字段的复合片键，第一个字段用于分组，第二个字段用于自增，所以第二个字段最好是自增字段。这种片键策略是最好的，能够实现多热点数据的读写。 选择合适的片键需要对项目是写为主还是读为主的权衡。 基于片键范围的定向分发如果希望特定范围的块被分发到特定的分片服务器中，可以为分片添加标签，然后为标签指定相应的片键范围，这样，如果一个文档属于某个标签的片键范围，就会被定向到特定的分片服务器中了。 环境使用三台测试机来搭建环境 使用不同的端口号来启动不同的MongoDB实例。 系统环境 主机名 系统 IP mongo-A CentOS 6.8 10.0.0.3 mongo-B CentOS 6.8 10.0.0.4 mongo-C CentOS 6.8 10.0.0.5 拓扑结构 mongo-A mongo-B mongo-C Mongos Mongos Mongos Config Server Config Server Config Server Shard Server 1 主 Shard Server 1 备 Shard Server 1 仲裁 Shard Server 2 主 Shard Server 2 备 Shard Server 2 仲裁 Shard Server 3 主 Shard Server 3 备 Shard Server 3 仲裁 服务信息 角色 数据目录 端口 副本集名称 Mongos None 27017 None Config Server /data/cs 20000 cs Shard Server 1 /data/ss1 21001 ss1 Shard Server 2 /data/ss2 21002 ss2 Shard Server 3 /data/ss3 21003 ss3 步骤安装MongoDB这里使用Linux平台当前最新版 3.6.3 点此下载 所有节点全部执行12345tar xf mongodb-linux-x86_64-3.6.3.tgz -C /usr/local/ln -s /usr/local/mongodb-linux-x86_64-3.6.3/ /usr/local/mongodbmkdir -p /data/&#123;cs,ss1,ss2,ss3&#125;echo &apos;export PATH=/usr/local/mongodb/bin/:$PATH&apos; &gt; /etc/profile.d/mongodb.shsource /etc/profile.d/mongodb.sh 配置分片集群启动服务所有节点执行1234mongod --configsvr --dbpath /data/cs --fork --logpath /var/log/mongodcs.log --bind_ip 0.0.0.0 --port 20000 --replSet cs mongod --shardsvr --dbpath /data/ss1 --fork --logpath /var/log/mongodss1.log --bind_ip 0.0.0.0 --port 21001 --replSet ss1mongod --shardsvr --dbpath /data/ss2 --fork --logpath /var/log/mongodss2.log --bind_ip 0.0.0.0 --port 21002 --replSet ss2mongod --shardsvr --dbpath /data/ss3 --fork --logpath /var/log/mongodss3.log --bind_ip 0.0.0.0 --port 21003 --replSet ss3 配置Config Server随便连接到一个服务器的20000端口1mongo 127.0.0.1:20000 初始化Config Server，在mongo中执行以下代码 123456var cfg = &#123;_id:"cs", configsvr:true, members:[ &#123;_id:0,host:'10.0.0.3:20000'&#125;, &#123;_id:1,host:'10.0.0.4:20000'&#125;, &#123;_id:2,host:'10.0.0.5:20000'&#125; ]&#125;;rs.initiate(cfg) 结果输出： &gt; rs.initiate(cfg) { &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1519896701, 1), &quot;$gleStats&quot; : { &quot;lastOpTime&quot; : Timestamp(1519896701, 1), &quot;electionId&quot; : ObjectId(&quot;000000000000000000000000&quot;) }, &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1519896701, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) } } } 配置Shard Server 1连接mongo-A的21001端口1mongo 10.0.0.3:21001 初始化Shard Server 1123456var cfg = &#123;_id:"ss1",members:[ &#123;_id:0,host:'10.0.0.3:21001',priority:2&#125;, &#123;_id:1,host:'10.0.0.4:21001',priority:1&#125;, &#123;_id:2,host:'10.0.0.5:21001',arbiterOnly:true&#125;] &#125;;rs.initiate(cfg) 配置Shard Server 2接着连接mongo-A的21002端口1mongo 10.0.0.3:21002 初始化Shard Server 2123456var cfg = &#123;_id:"ss2",members:[ &#123;_id:0,host:'10.0.0.3:21002',priority:2&#125;, &#123;_id:1,host:'10.0.0.4:21002',priority:1&#125;, &#123;_id:2,host:'10.0.0.5:21002',arbiterOnly:true&#125;] &#125;;rs.initiate(cfg) 配置Shard Server 3连接mongo-A的21003端口1mongo 10.0.0.3:21003 初始化Shard Server 3123456var cfg = &#123;_id:"ss3",members:[ &#123;_id:0,host:'10.0.0.3:21003',priority:2&#125;, &#123;_id:1,host:'10.0.0.4:21003',priority:1&#125;, &#123;_id:2,host:'10.0.0.5:21003',arbiterOnly:true&#125;] &#125;;rs.initiate(cfg) 配置mongos路由服务选择一台服务器当作mongos路由服务，这里使用mongo-A 在mongo-A上执行1mongos --configdb cs/10.0.0.3:20000,10.0.0.4:20000,10.0.0.5:20000 --fork --logpath /var/log/mongos.log --bind_ip 0.0.0.0 mongos默认监听27017端口 也是mongod默认监听的端口 添加分片服务器到集群登陆路由服务1mongo 10.0.0.3:27017 添加分片服务器到集群123sh.addShard("ss1/10.0.0.3:21001,10.0.0.4:21001,10.0.0.5:21001")sh.addShard("ss2/10.0.0.3:21002,10.0.0.4:21002,10.0.0.5:21002")sh.addShard("ss3/10.0.0.3:21003,10.0.0.4:21003,10.0.0.5:21003") 使用sh.status()查看集群状态 mongos&gt; sh.status() --- Sharding Status --- sharding version: { &quot;_id&quot; : 1, &quot;minCompatibleVersion&quot; : 5, &quot;currentVersion&quot; : 6, &quot;clusterId&quot; : ObjectId(&quot;5a97c88a1b0ab73e5d64fc6c&quot;) } shards: { &quot;_id&quot; : &quot;ss1&quot;, &quot;host&quot; : &quot;ss1/10.0.0.3:21001,10.0.0.4:21001&quot;, &quot;state&quot; : 1 } { &quot;_id&quot; : &quot;ss2&quot;, &quot;host&quot; : &quot;ss2/10.0.0.3:21002,10.0.0.4:21002&quot;, &quot;state&quot; : 1 } { &quot;_id&quot; : &quot;ss3&quot;, &quot;host&quot; : &quot;ss3/10.0.0.3:21003,10.0.0.4:21003&quot;, &quot;state&quot; : 1 } active mongoses: &quot;3.6.3&quot; : 1 autosplit: Currently enabled: yes balancer: Currently enabled: yes Currently running: no Failed balancer rounds in last 5 attempts: 0 Migration Results for the last 24 hours: No recent migrations databases: { &quot;_id&quot; : &quot;config&quot;, &quot;primary&quot; : &quot;config&quot;, &quot;partitioned&quot; : true } mongos&gt; 至此MongoDB分片集群就搭建完了。 数据库的分片配置激活数据库的分片功能激活mydb的分片功能 1sh.enableSharding(&quot;mydb&quot;) mongos&gt; sh.enableSharding(&quot;mydb&quot;) { &quot;ok&quot; : 1, &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1519954632, 6), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) } }, &quot;operationTime&quot; : Timestamp(1519954632, 6) } mongos&gt; 测试升序片键对mydb库的test集合进行分片，然后插入100000条数据 12345use mydbsh.shardCollection("mydb.test",&#123;id:1&#125;)for (var i = 1; i &lt;= 100000; i++)&#123; db.test.insert(&#123;"id":i,"name":"xiaoming","age":22,"data":new Date()&#125;)&#125; 可以看到test集合的数据都集中在ss3副本集上。 mongos&gt; db.test.stats() { &quot;sharded&quot; : true, &quot;capped&quot; : false, &quot;ns&quot; : &quot;mydb.test&quot;, &quot;count&quot; : 100000, &quot;size&quot; : 8000000, &quot;storageSize&quot; : 2519040, &quot;totalIndexSize&quot; : 2592768, &quot;indexSizes&quot; : { &quot;_id_&quot; : 942080, &quot;id_1&quot; : 1650688 }, &quot;avgObjSize&quot; : 80, &quot;nindexes&quot; : 2, &quot;nchunks&quot; : 1, &quot;shards&quot; : { &quot;ss3&quot; : { &quot;ns&quot; : &quot;mydb.test&quot;, &quot;size&quot; : 8000000, &quot;count&quot; : 100000, &quot;avgObjSize&quot; : 80, &quot;storageSize&quot; : 2519040, &quot;capped&quot; : false, &quot;wiredTiger&quot; : { &quot;metadata&quot; : { &quot;formatVersion&quot; : 1 }, 测试哈希片键使用哈希片键的方式重新插入100000条数据 123456use mydbdb.test.drop()sh.shardCollection("mydb.test",&#123;id:"hashed"&#125;)for (var i = 1; i &lt;= 100000; i++)&#123; db.test.insert(&#123;"id":i,"name":"xiaoming","age":22,"data":new Date()&#125;)&#125; 再次使用db.test.stats()可以看到文档已经分散到三个副本集了。 mongos&gt; db.test.stats() { &quot;sharded&quot; : true, &quot;capped&quot; : false, &quot;ns&quot; : &quot;mydb.test&quot;, &quot;count&quot; : 100000, &quot;size&quot; : 8000000, &quot;storageSize&quot; : 2572288, &quot;totalIndexSize&quot; : 4280320, &quot;indexSizes&quot; : { &quot;_id_&quot; : 1040384, &quot;id_hashed&quot; : 3239936 }, &quot;avgObjSize&quot; : 80, &quot;nindexes&quot; : 2, &quot;nchunks&quot; : 6, &quot;shards&quot; : { &quot;ss1&quot; : { &quot;ns&quot; : &quot;mydb.test&quot;, &quot;size&quot; : 2700400, &quot;count&quot; : 33755, &quot;avgObjSize&quot; : 80, &quot;storageSize&quot; : 868352, &quot;capped&quot; : false, &quot;wiredTiger&quot; : { &quot;metadata&quot; : { &quot;formatVersion&quot; : 1 }, ... &quot;ss2&quot; : { &quot;ns&quot; : &quot;mydb.test&quot;, &quot;size&quot; : 2651440, &quot;count&quot; : 33143, &quot;avgObjSize&quot; : 80, &quot;storageSize&quot; : 851968, &quot;capped&quot; : false, &quot;wiredTiger&quot; : { &quot;metadata&quot; : { &quot;formatVersion&quot; : 1 }, ... &quot;ss3&quot; : { &quot;ns&quot; : &quot;mydb.test&quot;, &quot;size&quot; : 2648160, &quot;count&quot; : 33102, &quot;avgObjSize&quot; : 80, &quot;storageSize&quot; : 851968, &quot;capped&quot; : false, &quot;wiredTiger&quot; : { &quot;metadata&quot; : { &quot;formatVersion&quot; : 1 }, 分片集群的管理集群添加分片服务器1sh.addShard("ss1/10.0.0.3:21001,10.0.0.4:21001,10.0.0.5:21001") 从集群中移除分片服务器12use admindb.runCommand(&#123;removeshard:"ss1"&#125;) 需要注意的是，如果要移除的分片服务器是某个集合的主键，需要先将数据移到其他节点。 查看集群状态1sh.status() 附录]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>MongoDB</tag>
        <tag>NoSQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MongoDB初探]]></title>
    <url>%2F2018%2F02%2F27%2F2018%2FMongoDB%E5%88%9D%E6%8E%A2%2F</url>
    <content type="text"><![CDATA[简介 MongoDB 是一个基于分布式文件存储的数据库。由C++语言编写。旨在为WEB应用提供可扩展的高性能数据存储解决方案。MongoDB 是一个介于关系数据库和非关系数据库之间的产品，是非关系数据库当中功能最丰富，最像关系数据库的。他支持的数据结构非常松散，是类似json的bson格式，因此可以存储比较复杂的数据类型。Mongo最大的特点是他支持的查询语言非常强大，其语法有点类似于面向对象的查询语言，几乎可以实现类似关系数据库单表查询的绝大部分功能，而且还支持对数据建立索引。 环境 在 CentOS6.8 上使用MongoDB的二进制包 只要不是太古老的Linux系统都可以直接运行。也可以选择在Windows上使用MongoDB。 各版本MongoDB下载地址 系统类型 下载地址 Linux 点击打开 Windows 点击打开 下载合适的版本 这里使用Linux平台当前最新版 3.6.3 点此下载 入门篇安装与启动由于使用的是二进制版的MongoDB，直接解压就可以使用了。 1234tar xf mongodb-linux-x86_64-3.6.3.tgz -C /usr/local/ln -s /usr/local/mongodb-linux-x86_64-3.6.3/ /usr/local/mongodbmkdir /usr/local/mongodb/data/usr/local/mongodb/bin/mongod --dbpath /usr/local/mongodb/ 当显示waiting for connections on port 27017时MongoDB就成功启动了。使用Ctrl+C停止MongoDB。 后台运行 如果想让MongoDB在后台运行 可以使用--fork 1/usr/local/mongodb/bin/mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log 使用--fork必须配合--logpath指定日志输出位置。 使用--bind_ip 0.0.0.0可以将服务监听到所有网络 --port配置监听端口。 注意：3.6以前的版本默认是监听在0.0.0.0的，而3.6之后默认监听在127.0.0.1了。 配置环境变量12echo &apos;export PATH=/usr/local/mongodb/bin/:$PATH&apos; &gt; /etc/profile.d/mongodb.shsource /etc/profile.d/mongodb.sh 这样就可以不用绝对路径来使用mongo相关的命令了。 使用mongo命令 进入MongoDB交互环境，使用show dbs列出当前默认数据库。 &gt; show dbs admin 0.000GB config 0.000GB local 0.000GB &gt; 到了这一步MongoDB就安装启动成功了，接下来就看看MongoDB如何使用的吧。 开发篇 MongoDB使用JavaScript做shell，自MongoDB 2.4以后的版本采用V8引擎执行所有JavaScript代码，对于熟悉JavaScript的开发者MongoDB可以说是非常亲切了。 基本概念MongoDB是一种非关系型数据库(NoSQL)，非关系型数据库以键值对(key-value)存储。键可以理解为关系型数据库的字段名，值为字段值。但是它的结构是不固定的，关系型数据库的每一条记录的字段都是相同的，而NoSQL可以有不同的键，并且NoSQL值的类型都可以是不同的。 数据库的概念 MongoDB中和关系型数据库相同，使用show dbs看到的就是已经存在的数据库。而表的概念在MongoDB中叫做集合，表中的一行数据 在MongoDB中叫文档。表字段在MongoDB中叫键(key)，表字段值在MongoDB中叫值(value) 关系型数据库和非关系型数据库对比 对比项 MongoDB MySQL 数据库 数据库 数据库 表格 集合 二维表 表记录 文档 一条记录 字段名 键 字段名 字段值 值 字段值 题外话：MongoDB的数据库有点像Python中命令空间的概念，集合就是个列表，而文档就是一个字典了。字典里的键和值也对应着MongoDB的键和值。 默认的数据库 admin 类似于MySQL的默认mysql库 用于存放用户账户信息和权限。 local 这个库用于存放主从复制相关的数据 config 当MongoDB用于分片设置时 config数据库在内部使用，用于保存分片的相关信息 基本操作切换数据库使用db命令查看当前使用的数据库，使用use &lt;DB&gt;切换数据库 &gt; show dbs admin 0.000GB config 0.000GB local 0.000GB &gt; db test &gt; MongoDB默认使用的是test库，可是show dbs为什么没有看到test库呢？是因为MongoDB不需要什么创建数据库的语句，也不需要创建表的语句，在需要的时候 也就是你向库中写入数据的时候，如果不存在则才会自动创建。 接下来切换到mydb中 1use mydb 集合中插入文档MongoDB中也不需要显性的创建一个集合，直接向某个集合中插入文档就可以了，如果集合不存在 则会自动创建。 insert方法比如我在一个名为person的集合插入一条文档数据 &gt; db.person.insert({&quot;name&quot;:&quot;xiaoming&quot;,&quot;age&quot;:21}) WriteResult({ &quot;nInserted&quot; : 1 }) &gt; 现在看看库和集合是不是自动创建了呢 &gt; show dbs; admin 0.000GB config 0.000GB local 0.000GB mydb 0.000GB &gt; show tables; person &gt; 查询集合中的文档find方法再向集合中插入一个文档 &gt; db.person.insert({&quot;name&quot;:&quot;xiaohong&quot;,&quot;age&quot;:20}) WriteResult({ &quot;nInserted&quot; : 1 }) &gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 21 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } &gt; 使用find方法可以查看person集合中的所有文档，面向对象的操作方法 是不是感觉非常简单呢。mongo会给每条文档自动生成_id键，这个可以理解为关系型数据库的主键。 find方法使用查询条件来过滤输出，相当于关系型数据库的where 普通条件查询查询name为xiaoming的文档 &gt; db.person.find({&quot;name&quot;:&quot;xiaoming&quot;}) { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 21 } &gt; 查询age小于21的文档 &gt; db.person.find({&quot;age&quot;:{$lt:21}}) { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } &gt; 小于等于使用$lte，大于使用$gt，大于等于使用$gte，不等于使用$ne AND条件查询查询name为xiaoming 并且age为21的文档 &gt; db.person.find({&quot;name&quot;:&quot;xiaoming&quot;,&quot;age&quot;:21}) { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 21 } &gt; OR条件查询查询name为xiaoming 或者age为20的文档，可以看到所有匹配的记录都被查到了。 &gt; db.person.find({$or:[{&quot;name&quot;:&quot;xiaoming&quot;},{&quot;age&quot;:20}]}) { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 21 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } &gt; AND和OR联合使用类似于 WHERE name=&quot;xiaohong&quot; AND (name=&quot;xiaoming&quot; OR age=20) &gt; db.person.find({&quot;name&quot;:&quot;xiaohong&quot;,$or:[{&quot;name&quot;:&quot;xiaoming&quot;},{&quot;age&quot;:20}]}) { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } &gt; limit方法使用limit方法可以只输出指定的文档条数 &gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952a2606b5ba9661fa06f1&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad106b5ba9661fa06f2&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } &gt; db.person.find().limit(2) { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } &gt; skip方法skip方法输出跳过多少条文档 &gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952a2606b5ba9661fa06f1&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad106b5ba9661fa06f2&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } &gt; db.person.find().skip(2) { &quot;_id&quot; : ObjectId(&quot;5a952a2606b5ba9661fa06f1&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad106b5ba9661fa06f2&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } &gt; sort方法sort方法对数据进行排序。sort方法可以通过参数指定排序的字段，并使用 1 和 -1 来指定排序的方式，其中 1 为升序排列，而 -1 是用于降序排列。 &gt; db.person.find().sort({&quot;age&quot;:1}) { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 } &gt; db.person.find().sort({&quot;age&quot;:-1}) { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } &gt; 题外话：可以使用db.person.find().pretty()来美化数据输出格式。 更新文档数据 MongoDB中可以使用update和save方法来更新文档数据，两个方法的应用还是有些区别的。 update方法 update方法 第一个参数是查询条件，第二个参数是要修改的键值 将name为xiaoming的记录 age值修改为22 &gt; db.person.update({&quot;name&quot;:&quot;xiaoming&quot;},{$set:{&quot;age&quot;:22}}) WriteResult({ &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 }) &gt; db.person.find({&quot;name&quot;:&quot;xiaoming&quot;}) { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 22 } &gt; 需要注意的是 update默认只更新匹配到的第一条文档，如果想要更改所有匹配的 使用{multi:true} db.person.update({&quot;name&quot;:&quot;xiaoming&quot;}, {$set:{&quot;age&quot;:20}}, {multi:true}) 从3.2版本开始，MongoDB提供了updateOne()来更新单个文档，updateMany()来更新多个文档。 save方法 save方法直接传入一个新的文档保存到集合中，如果文档的_id存在 则会替换掉旧文档。 使用save方法 &gt; db.person.save({ &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 }) WriteResult({ &quot;nMatched&quot; : 1, &quot;nUpserted&quot; : 0, &quot;nModified&quot; : 1 }) &gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } &gt; 删除文档 删除文档前 先使用find方法验证匹配条件是否正确是一个好习惯 remove方法 remove方法默认会删除所有匹配的文档，第二个参数传入{justOne: true}则只会删除匹配的一个。 使用remove方法 &gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952a2606b5ba9661fa06f1&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad106b5ba9661fa06f2&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } { &quot;_id&quot; : ObjectId(&quot;5a952ad206b5ba9661fa06f3&quot;), &quot;name&quot; : &quot;xiaoming&quot;, &quot;age&quot; : 20 } &gt; db.person.remove({&quot;name&quot;:&quot;xiaoming&quot;}) WriteResult({ &quot;nRemoved&quot; : 3 }) &gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a951e3a06b5ba9661fa06ef&quot;), &quot;name&quot; : &quot;xiaobai&quot;, &quot;age&quot; : 22 } { &quot;_id&quot; : ObjectId(&quot;5a951eb306b5ba9661fa06f0&quot;), &quot;name&quot; : &quot;xiaohong&quot;, &quot;age&quot; : 20 } &gt; 想要删除集合中的所有文档 可以使用remove({})。MongoDB官方推荐使用deleteOne和deleteMany来删除文档。 删除集合drop方法&gt; db.person.drop() true &gt; db.person.find() &gt; 删除数据库dropDatabase方法&gt; db.dropDatabase() { &quot;dropped&quot; : &quot;mydb&quot;, &quot;ok&quot; : 1 } &gt; show dbs admin 0.000GB config 0.000GB local 0.000GB &gt; 运维篇权限控制 默认MongoDB是没有启用权限控制的，这样无疑非常不安全。 添加管理员账号&gt; use admin switched to db admin &gt; db.createUser({user:&quot;root&quot;,pwd:&quot;123456&quot;,roles:[{&quot;role&quot;:&quot;root&quot;,&quot;db&quot;:&quot;admin&quot;}]}) Successfully added user: { &quot;user&quot; : &quot;root&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;root&quot;, &quot;db&quot; : &quot;admin&quot; } ] } &gt; 修改启动参数关闭MongoDB后重新启动1mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log --bind_ip 0.0.0.0 --auth 添加--auth参数则可以启用MongoDB的认证功能。 接下来重新连接MongoDB，看看操作是不是需要认证了。 &gt; use admin switched to db admin &gt; show tables 2018-02-28T07:57:45.759+0000 E QUERY [thread1] Error: listCollections failed: { &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not authorized on admin to execute command { listCollections: 1.0, filter: {}, $db: \&quot;admin\&quot; }&quot;, &quot;code&quot; : 13, &quot;codeName&quot; : &quot;Unauthorized&quot; } 用户认证使用db.auth(user,password)来进行登陆数据库。 &gt; use admin switched to db admin &gt; db.auth(&quot;root&quot;,&quot;123456&quot;) 1 &gt; show tables; system.users system.version &gt; 可以看到可以操作admin库了 为其他库配置认证 需要注意的是 添加认证的库必须存在。 还是需要先切换到admin库中才能为其他库创建认证。 &gt; use admin switched to db admin &gt; db.auth(&quot;root&quot;,&quot;123456&quot;) 1 &gt; db.createUser({user:&quot;op&quot;,pwd:&quot;123456&quot;,roles:[{&quot;role&quot;:&quot;readWrite&quot;,&quot;db&quot;:&quot;mydb&quot;}]}) Successfully added user: { &quot;user&quot; : &quot;op&quot;, &quot;roles&quot; : [ { &quot;role&quot; : &quot;readWrite&quot;, &quot;db&quot; : &quot;mydb&quot; } ] } &gt; 退出后重新登陆MongoDB &gt; use mydb switched to db mydb &gt; show tables; 2018-02-28T08:05:19.021+0000 E QUERY [thread1] Error: listCollections failed: { &quot;ok&quot; : 0, &quot;errmsg&quot; : &quot;not authorized on mydb to execute command { listCollections: 1.0, filter: {}, $db: \&quot;mydb\&quot; }&quot;, &quot;code&quot; : 13, &quot;codeName&quot; : &quot;Unauthorized&quot; } &gt; db.auth(&quot;op&quot;,&quot;123456&quot;) 1 &gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a96637de474606ab43c8e33&quot;) } { &quot;_id&quot; : ObjectId(&quot;5a966385e474606ab43c8e34&quot;), &quot;a&quot; : 1 } &gt; 数据备份恢复 数据备份恢复对于数据库系统来说是个非常重要的话题。 数据备份(mongodump)命令用法如下:mongodump -h &lt;HOST&gt; -d &lt;DB&gt; -o &lt;PATH&gt; -h 指定连接的主机 格式是IP或者IP:PORT-d 指定备份的库名-o 指定备份的输出路径 默认是当前路径下的dump目录中 如果库需要认证的话 还需要使用-u和-p参数指定用户名和密码如果不指定库名 则备份所有库。 比如:1mongodump -h 127.0.0.1:27017 -d mydb -o /tmp/dump 备份目标目录不存在会自动创建。 数据恢复(mongorestore)命令用法如下:mongorestore -h &lt;HOST&gt; -d &lt;DB&gt; &lt;PATH&gt; -h 指定连接的主机 格式是IP或者IP:PORT-d 指定备份的库名&lt;PATH&gt; 最后直接给出从哪恢复数据的目录 比如将刚才备份的mydb恢复到newdb中1mongorestore -h 127.0.0.1:27017 -d newdb /tmp/dump/mydb/ 如果想恢复备份的所有库 可以不指定库名 然后指定所有库所在的父目录即可1mongorestore -h 127.0.0.1:27017 /tmp/dump/ 这样子就会按照库名进行恢复了。 其他备份恢复方式MongoDB还提供了mongoexport和mongoimport工具对数据进行备份，可以将数据备份为csv, json的格式。 或者还可以停掉MongoDB的服务 直接对MongoDB的数据目录进行备份，注意备份后的目录还存在mongod.lock文件的话需要删除才能在新的库上启动，不过如果存在mongod.lock文件 倒是需要担心备份的数据是否完整了。 MongoDB集群MongoDB主从复制 主从复制提供了数据的冗余备份，提高了数据的可用性，并可以保证数据的安全性。官方已经不推荐使用主从复制方式，搭建MongoDB集群还有更好的方式。 主从复制的好处 提高数据安全性，多台服务器同时硬盘损坏的概率是小于单台的 数据的高可用性，多台服务器同时宕机的概率是小于单台的 灾难恢复能力，当发生硬盘损坏，数据还有副本以便恢复 热备份能力，无需关闭或者降级服务就可以对数据进行备份、压缩等。 分布式读取数据，读取请求可以分发到多台服务器，降低单实例的读写压力。 主从复制原理MongoDB的主从复制至少需要两个节点，一个Master节点，其他的都是Slave节点。 还记得MongoDB启动后默认的local这个库吗，当Master进行写操作时，Master将写操作记录在local库的oplog集合里。Slave节点就通过读取Master节点的oplog将数据复制到自身一份，并且还会将复制信息写入到自己的oplog中，这样即使是Slave节点 也可以将自己作为同步源给其他Slave节点了。 需要注意的是，oplog是有固定大小的，到达最大大小后，新的记录会覆盖掉旧的记录。 主从复制配置 需要先关闭已经运行的MongoDB进程 Master节点执行1mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log --bind_ip 0.0.0.0 --master 可以看到只需要在主节点是添加--master 表示这一个Master节点就可以了。 Slave节点执行1mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log --bind_ip 0.0.0.0 --slave --source 192.168.8.253:27017 Slave节点添加--slave 并指明Master节点的地址--source 192.168.8.253:27017 验证数据是否同步Master节点执行 &gt; use mydb switched to db mydb &gt; db.test.insert({&quot;a&quot;:1}) WriteResult({ &quot;nInserted&quot; : 1 }) &gt; Slave节点执行 &gt; rs.slaveOk() &gt; use mydb switched to db mydb &gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a9619088cd96bc4a16514a9&quot;), &quot;a&quot; : 1 } &gt; 由于Slave节点默认是不允许读写的，所以需要执行rs.slaveOk()来允许读取。 MongoDB副本集 Replica Sets方式，也是MongoDB官方推荐的方式。副本集方式比传统的主从复制改进的地方就是可以进行故障自动转移。如果主节点挂了，会自动选举一个从节点作为主，这个过程对用户是透明的。 副本集原理一个副本集即为服务于同一数据集的多个 MongoDB 实例，其中一个为主节点，其余的都为从节点。主节点上能够完成读写操作，从节点仅能用于读操作。主节点需要记录所有改变数据库状态的操作，这些记录 保存在local数据库的oplog中，各个从节点通过此 oplog来复制数据并应用于本地。 集群中的各节点还会通过传递心跳信息来检测各自的健康状况。当主节点故障时。多个从节点会触发一次新的选举操作，并选举其中的一个成为新的主节点(通常谁的优先级更高，谁就是新的主节点)。心跳信息默认每2秒传递一次。副本集中的副本节点在主节点挂掉后通过心跳机制检测到后，就会在集群内发起主节点的选举机制，自动选举出一位新的主服务器。 副本集可以包括三种节点：主节点、从节点、仲裁节点。 主节点负责处理客户端请求，读、写数据, 记录在其上所有操作的oplog; 从节点定期轮询主节点的oplog进行同步数据。默认情况下从节点不支持客户端读取数据，但可以设置(rs.slaveOk())；副本集的机制在于主节点出现故障的时候，余下的节点会选举出一个新的主节点，从而保证系统可以正常运行。 仲裁节点不复制数据，仅参与投票。由于它没有访问的压力，比较空闲，因此不容易出故障。由于副本集出现故障的时候，存活的节点必须大于副本集节点总数的一半，否则无法选举主节点，或者主节点会自动降级为从节点，整个副本集变为只读。因此，增加一个不容易出故障的仲裁节点，可以增加有效选票，降低整个副本集不可用的风险。仲裁节点可多于一个。也就是说只参与投票，不接收复制的数据，也不能成为活跃节点。仲裁节点并非必须存在。 MongoDB 3.0之后官方推荐MongoDB副本集节点最少为3台，最多50台，仲裁节点最大为7个。为了避免脑裂发生 副本集成员最好为奇数。太多的副本集成员会增加复制成本，反而拖累整个集群。 副本集配置 注意：--dbpath的路径如果已经存在数据 最好先清除。 所有节点执行1mongod --dbpath /usr/local/mongodb/data/ --fork --logpath /var/log/mongod.log --bind_ip 0.0.0.0 --replSet rstest 只需要在启动参数上增加--replSet rstest，rstest是副本集的名称。 登陆某个节点执行 &gt; var cfg = {_id:&quot;rstest&quot;,members:[ {_id:0,host:&apos;10.0.0.3:27017&apos;,priority:2}, {_id:1,host:&apos;10.0.0.4:27017&apos;,priority:1}, {_id:2,host:&apos;10.0.0.5:27017&apos;,arbiterOnly:true}] }; &gt; rs.initiate(cfg) { &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1519793379, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1519793379, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) } } } rstest:SECONDARY&gt; 将10.0.0.3的优先级配置为2，10.0.0.5配置为仲裁节点。稍等一下，然后执行rs.status()方法看看10.0.0.3是否被选举为了PRIMARY &quot;members&quot; : [ { &quot;_id&quot; : 0, &quot;name&quot; : &quot;10.0.0.3:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 228, &quot;optime&quot; : { &quot;ts&quot; : Timestamp(1519794123, 1), &quot;t&quot; : NumberLong(2) }, &quot;optimeDate&quot; : ISODate(&quot;2018-02-28T05:02:03Z&quot;), &quot;electionTime&quot; : Timestamp(1519793982, 1), &quot;electionDate&quot; : ISODate(&quot;2018-02-28T04:59:42Z&quot;), &quot;configVersion&quot; : 1, &quot;self&quot; : true }, rs.status()方法可以详细的看到集群中每个节点的状态。 验证副本集数据同步主节点插入数据 rstest:PRIMARY&gt; use mydb switched to db mydb rstest:PRIMARY&gt; db.person.insert({&quot;a&quot;:1}) WriteResult({ &quot;nInserted&quot; : 1 }) rstest:PRIMARY&gt; 从节点验证数据 rstest:SECONDARY&gt; rs.slaveOk() rstest:SECONDARY&gt; show dbs; admin 0.000GB config 0.000GB local 0.000GB mydb 0.000GB rstest:SECONDARY&gt; use mydb switched to db mydb rstest:SECONDARY&gt; db.person.find() { &quot;_id&quot; : ObjectId(&quot;5a96386fe6101b17e4e221f0&quot;), &quot;a&quot; : 1 } rstest:SECONDARY&gt; 验证副本集故障转移关闭主节点服务 rstest:PRIMARY&gt; use admin switched to db admin rstest:PRIMARY&gt; db.shutdownServer() 登陆其他节点查看主节点是否更变 &gt; rs.status() { &quot;_id&quot; : 1, &quot;name&quot; : &quot;10.0.0.4:27017&quot;, &quot;health&quot; : 1, &quot;state&quot; : 1, &quot;stateStr&quot; : &quot;PRIMARY&quot;, &quot;uptime&quot; : 812, &quot;optime&quot; : { &quot;ts&quot; : Timestamp(1519794720, 1), &quot;t&quot; : NumberLong(3) }, &quot;optimeDate&quot; : ISODate(&quot;2018-02-28T05:12:00Z&quot;), &quot;electionTime&quot; : Timestamp(1519794589, 1), &quot;electionDate&quot; : ISODate(&quot;2018-02-28T05:09:49Z&quot;), &quot;configVersion&quot; : 1, &quot;self&quot; : true }, 当原本的主节点上线后，会根据优先级重新选举，所以主节点就恢复到10.0.0.3上了。 副本集的常用操作查看集群配置信息local库的system.replset集合存放着集群所有节点的信息，也可以使用rs.conf()来查看 &gt; use local &gt; db.system.replset.find().pretty() &gt; rs.conf() 重新配置副本集 注意：重新配置副本集必须在主节点上进行 更改主从节点的优先级，使用rs.reconf()方法重新加载配置 rstest:PRIMARY&gt; var cfg = {_id:&quot;rstest&quot;,members:[ {_id:0,host:&apos;10.0.0.3:27017&apos;,priority:1}, {_id:1,host:&apos;10.0.0.4:27017&apos;,priority:2}, {_id:2,host:&apos;10.0.0.5:27017&apos;,arbiterOnly:true}] }; rstest:PRIMARY&gt; rs.reconfig(cfg) { &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1519795465, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1519795465, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) } } } rstest:PRIMARY&gt; 动态添加和删除节点添加从节点 rstest:PRIMARY&gt; rs.add(&quot;10.0.0.6:27017&quot;) { &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1519796327, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1519796327, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) } } } rstest:PRIMARY&gt; 添加仲裁节点 rstest:PRIMARY&gt; rs.addArb(&quot;10.0.0.7:27017&quot;) { &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1519796416, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1519796416, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) } } } 删除节点 rstest:PRIMARY&gt; rs.remove(&quot;10.0.0.7:27017&quot;) { &quot;ok&quot; : 1, &quot;operationTime&quot; : Timestamp(1519796468, 1), &quot;$clusterTime&quot; : { &quot;clusterTime&quot; : Timestamp(1519796468, 1), &quot;signature&quot; : { &quot;hash&quot; : BinData(0,&quot;AAAAAAAAAAAAAAAAAAAAAAAAAAA=&quot;), &quot;keyId&quot; : NumberLong(0) } } } Mongodb分片集群 Sharding cluster是一种可以水平扩展的模式，在数据量很大时特给力。 分片集群原理在数据量非常大的情况下，单台MongoDB数据库的性能会严重下降，而将数据分片可以很好的解决单台服务器磁盘空间、内存、CPU等硬件资源的限制问题。 把数据水平拆分出去，降低单节点的访问压力。每个分片都是一个独立的数据库，所有的分片组合起来构成一个逻辑上的完整的数据库。因此，分片机制降低了每个分片的数据操作量及需要存储的数据量，达到多台服务器来应对不断增加的负载和数据的效果。 一个分片集群需要三种角色 分片服务器(Shard Server) mongod实例，用于存储实际的数据块。分片服务器可以是一个副本集集群共同来提供服务 防止单点故障。 配置服务器(Config Server) mongod实例，存储整个集群和分片的元数据，就像是一本书的目录，保存的只是数据的分布表。 路由服务器(Route Server) mongos实例，客户端由此接入，本身不存放数据，仅供程序连接，起到一个路由的作用。 分片集群在数据量非常大的情况下才能展现能力，这里只做简单讲解。 附录MongoDB配置文件实验中启动MongoDB都是通过命令行参数的方式启动的，这样显然并不是很友好。可以将参数写入到配置文件中，然后启动的时候通过--config或者-f启动。 比如 可以将参数写入以下配置文件 dbpath = /usr/local/mongodb/data/ fork = true logpath = /var/log/mongod.log bind_ip = 0.0.0.0 auth = true 像--fork和--auth 启用就填true，禁用就填false 重新启动MongoDB 12killall mongodmongod -f mongod.conf 也可以登陆到MongoDB中，使用admin库的shutdownServer方法关闭服务。 &gt; use admin switched to db admin &gt; db.shutdownServer() server should be down... 2018-02-28T08:24:49.077+0000 I NETWORK [thread1] trying reconnect to 127.0.0.1:27017 (127.0.0.1) failed]]></content>
      <categories>
        <category>MongoDB</category>
      </categories>
      <tags>
        <tag>nosql</tag>
        <tag>mongodb</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[高性能Web站点优化]]></title>
    <url>%2F2018%2F02%2F17%2F2018%2F%E9%AB%98%E6%80%A7%E8%83%BDWeb%E7%AB%99%E7%82%B9%E4%BC%98%E5%8C%96%2F</url>
    <content type="text"><![CDATA[简介 根据《构建高性能Web站点(修订版)》一书 加上自己的一些经验和理解写出了这篇博客，并在附录中留下了自己画的脑图。强烈推荐对Web站点优化有兴趣的开发者、web运维、架构师等阅读这本书。书中几乎涵盖了Web站点性能优化的所有内容，包括数据的网络传输、服务器并发处理能力、动态网页缓存、动态网页静态化、应用层数据缓存、分布式缓存、Web服务器缓存、反向代理缓存、脚本解释速度、页面组件分离、浏览器本地缓存、浏览器并发请求、文件的分发、数据库I/O优化、数据库访问、数据库分布式设计、负载均衡、分布式文件系统、性能监控等。 目录 由前端到后端的方式讲解web架构中可以优化的地方 客户端优化 客户端指用户的浏览器 html页面最终由浏览器渲染为用户所看到的界面。常用的浏览器有Chrome、Firefox、IE/Edge、Opera等，通常使用更新版本的浏览器可以获得更高的性能和更好的用户体验。浏览器一般都向下兼容，而由于历史遗留问题 依旧有大量用户使用较旧版本的浏览器 比如IE8/IE9 甚至还有IE6的用户，各浏览器的兼容性问题 也成了前端开发者要面临的严峻问题。 页面缓存 使用HTTP协议的缓存协议 将资源服务器资源缓存到浏览器本地，用户只需和服务器请求需要更新的数据即可，这样大大提升了页面的加载速度 也降低了服务器的带宽使用。下面看看HTTP协议中有关缓存的内容 Last-Modified浏览器向服务器发起资源请求，服务器响应用户资源的同时在响应的HTTP头部中添加Last-Modified字段，字段的值是这个资源的最后修改时间。比如Last-Modified: Thu, 15 Feb 2018 08:04:16 GMT 当客户端再次向浏览器请求这个资源时 会在HTTP请求头添加If-Mondified-Since字段，字段的值也是这个资源的最后修改时间。这意味着浏览器向服务器问 我请求的这个资源在此之后还有更新吗？这时候浏览器会检查这个资源在此之后有更新，如果没有更新就会返回304 Not Mondified。并不会返回资源的实体内容，而是告诉浏览器没有更新 可以使用本地缓存的内容。 如果服务器的资源发生改变了 则会重新向客户端发送更新后的资源，或者浏览器使用Ctrl + F5强制从服务器获取资源而无论资源是否有更新。 ETag服务端用一串编码对资源进行标记，这串编码就是ETag。ETag是服务器来生成的，生成的方式可以自定义，比如可以先计算哈希值 然后将这个哈希值作为ETag。 如果一个文件的Etag没有变化 那这个文件的内容也没有变化。浏览器向服务器请求某个资源，服务器响应这个资源时在相应HTTP头部中添加ETag标签 比如：ETag: 50d0e11a7d7a4d0b5。 当浏览器再次请求这个资源 会在HTTP请求头部添加If-None-Match: 50d0e11a7d7a4d0b5来询问服务器这个资源的Etag值还是这个吗？如果没有改变 服务器则响应304 Not Mondified。 ETag是在HTTP/1.1中支持的缓存协商方法 主要是为了解决Last-Modified的一些缺点，比负载均衡环境中 很难保证各节点文件时间戳是完全相同的，这样客户端在不同的服务端轮询请求 无论内容是否改变 服务端都会发送全部的内容，这个时候只要使用ETag则可以避免这个问题。 但是ETag的生成会比Last-Modified更消耗CPU资源，而Last-Modified则对HTTP/1.0也有支持，Nginx则会同时返回这两个字段。 Expires HTTP缓存的存在就是为了消灭不必要的请求 而Last-Modified和ETag明显还是存在请求和响应的，接下来的这两个协议就是完全不会发送HTTP请求的。 Expires告诉浏览器资源什么时候过期，在资源过期期间 浏览器会直接使用已缓存的资源而不会向服务器发起任何询问。 Expires的值是允许资源缓存到什么时候的一个时间戳 比如：Expires: Thu, 15 Feb 2018 08:04:16 GMT，浏览器根据当前时间和资源的过期时间进行对比 如果资源没有过期的话则直接使用资源。如果资源过期 并且存在ETag或者Last-Modified的情况 浏览器则会根据这两个字段询问服务器。 Cache-Control如果浏览器的时间跟服务器的时间不一致 比如浏览器比服务器时间快了十分钟，那对于缓存五分钟的资源来说 浏览器总是认为资源是过期的，这时候Expires就无法正常工作了。 幸运的是Cache-Control是用来补足Expires的不足，Cache-Control的格式是Cache-Control: max-age=&lt;second&gt;。max-age指定了缓存过期的相对本地时间 单位是秒。比如这个资源可以缓存3600秒，那么在3600秒内 浏览器都不会询问资源是否有更新了。 使用Ctrl + F5的方式刷新页面 会忽略缓存协议 所有内容都直接向服务端重新请求而使用F5或者点击浏览器的刷新按钮，它允许浏览器在请求中附加必要的缓存协议，但是不允许直接使用本地缓存，也就是说 它能让Last-Modified或ETag生效 但是会让Expires或Cache-Control失效 浏览器请求过程 代码优化 代码优化主要在提升用户体验上，这样即使用户网络质量不好的情况下 也经尽可能的提升用户体验。比如当网络质量不好 页面加载缓慢的情况下 可以提供一个loading的画面给用户 也可以显著的提升用户体验。 HTML的渲染过程 想知道一个页面是怎么出现在用户面前的 就需要了解浏览器是如何渲染html的 浏览器在网络上获取到HTML的相应字节时就开始对HTML进行构建了，但是由于浏览器渲染的一些机制 遇到某些情况浏览器页面就被阻塞了，这也就是用户看到页面卡住而无法操作的的原因，这种情况是非常影响用户体验的。 当遇到以下情况时 浏览器的UI界面会被阻塞 HTML的数据流被阻塞在了网络中 或者网络质量太差导致数据包接收过慢 未加载完的脚本或者脚本执行时间过长 遇到了script节点 但是此时还有未加载完的样式文件 将css样式文件放到HTML文档中head标签内，js脚本文件最好放到body标签中的最下面，这样可以一定程度的避免js脚本的执行过程中导致浏览器UI阻塞了。 懒加载技术 大家在查看百度图片的时候 会发现不断的滚动页面 就会有更多的图片加载出来，这个就是图片的懒加载技术。 当业务查询出的数据量特别大时，如果全部传输给浏览器 不仅对浏览器 对服务器也会照成很大的压力。而采用按需加载的方式，用户选择某个单元的时候 再加载这个单元需要的数据，这样既节约了系统相应时间，还提升了系统性能，更提高了用户体验 所以懒加载技术是非常有价值的。 懒加载技术也同样适用于Vue, Angular2等SPA框架(single page web application)。通过webpack打包的SPA应用是非常大的，浏览器第一次加载的时候可能会非常耗时，所以可以将不同路由对应的组件分割成不同的代码块，然后当路由被访问的时候才加载对应组件，这样就更加高效了。 使用Ajax交换数据大部分的HTML页面渲染过程是在服务端完成的，但是通过Ajax技术可以在浏览器页面加载之后异步向服务器发送HTTP请求，获取到动态的数据后由客户端的JavaScript来将数据渲染到HTML页面中。这样后端只提供一套Web接口，数据的渲染部分由前端完成，后端不仅拥有了更高的通用性，也省去了对HTML页面渲染的CPU开销。 加载动画当不得不存在一些耗时的页面时，使用加载动画 增加页面的趣味性也不失是一个好方法。可以在需要用户等待的页面时提供一个加载动画，然后数据准备完毕后移除动画。有了加载动画的存在 可以降低用户看到一片空白的等待页面由于不耐烦而关闭页面的概率。 传输优化 HTML文档在到达浏览器这段中可以有哪些优化呢 减少数据传输量浏览器减少http请求在页面中引用一个js文件和将js代码写入到html文档中 对于页面渲染结果来说是相同的，但是对于页面中引用js文件 浏览器需要向后端发送两次HTTP请求，而HTTP的请求和响应头部数据也是数据流的一部分，如果能减少HTTP的请求数量 也可以提升一部分浏览器渲染速度。 但是将css和js甚至图片都写入到一个html文档 显然是非常降低文档的可读性的，对日后的维护等影响也比较大。但是可以使用webpack等打包工具，将前端页面写完后 利用webpack打包成单个或者多个文件，浏览器只需要加载打包后的文件就可以了。而且webpack在打包过程中还会对代码进行压缩 去掉代码中没必要的空格、换行符，将代码中的变量名用a, b, c等简短的变量代替，打包后的代码大小也会大大减少。 启用Keep-Alive普通的一次HTTP请求 在服务器响应后就会关闭这次的TCP连接，下一个HTTP请求会继续开启和关闭一个TCP连接。如果能重用这个TCP连接就能省掉TCP连接和关闭的开销了，而Keep-Alive就是为此而生的。 只需要在HTTP头部加入Connection: Keep-Alive就可以启用Keep-Alive了，目前浏览器都支持HTTP/1.1协议，在HTTP/1.1协议中Keep-Alive是默认开启的。 gzip压缩数据文本类型的数据拥有很大的压缩比，几乎可以达到80%以上 也就是说一个100KB的文档，通过gzip压缩后的大小可能只有20KB左右，在提升网络数据传输上效果是非常显著的。 gzip压缩需要web服务器开启压缩功能，浏览器也需要在请求头部设置接受gzip压缩的字段：Accept-Encoding: gzip, deflate，表明浏览器支持gzip和deflate这两种压缩方式。 服务器接受到请求后判断浏览器是否支持压缩 如果支持就将数据压缩后传输。浏览器接受到数据后判断是否是已压缩的，如果是压缩的就先解压。 需要注意的是 有些数据类型即使压缩也不会有很大的压缩比的 比如大部分的图片和视频文件，对它们进行压缩不仅浪费宝贵的CPU资源 也获得不了很大的实际效果。所以需要在服务器配置排除掉对这些数据的压缩。 减少Cookie的大小由于HTTP是无状态的协议，服务器需要知道用户的身份就将用户数据放入到Cookie中，Cookie也是HTTP请求头部的一个字段，Cookie的值的大小浏览器限制不得超过4KB。 浏览器在对某个域发起HTTP请求时，如果存在这个域的Cookie数据，那么就会携带上Cookie进行请求。如果Cookie过大的话 显然也会降低数据的传输效率，而且Cookie是不安全的数据存放方式 除非必须 应该尽量避免掉 换用更安全的Session技术。 CDN加速CDN的全称是Content Delivery Network，即内容分发网络。CDN系统将数据分发到各CDN节点(其实就是缓存服务器)，当用户访问时智能的选择离用户最近的CND节点。 CND对用户访问体验可以带来很大的提升，但是也要面临数据更新同步到各CDN节点再到用户浏览器中有一定的延迟问题。 选择更合适的宽带总所周知联通的线路和电信的线路互通性并不是太好，BGP机房就是服务器租用商通过技术的手段，实现不同运营商能共同访问一个IP，并且不同运营商之间都能达到最快的接入速度的相关网络技术。BGP机房在一定程度上解决了各用户南北互通的问题，提高了用户的访问速度。 服务端优化 服务端优化指服务端的负载均衡器、Web静态资源服务器、真实后端服务器等程序的优化 应用服务器 这里将Web静态资源服务器和后端服务器都作为应用服务器 程序多进程使用多进程来提升服务器的并发能力和提高CPU的利用率。在Linux中和客户端每建立的一个TCP连接都作为一个进程打开的文件描述符，Linux对单个进程默认限制最大打开1024个文件描述符，能处理的Socket文件描述符就更少了。 除了提升Linux对最大文件描述符的限制外 通过多进程同时对外提供服务显然是更合适的方法，可以更高效的利用多核处理器的处理能力。 在Linux上使用ulimit -n可以查看当前最大文件描述符限制，使用ulimit -n 4096可以将最大文件描述符设置为4096。可以通过检索/proc/&lt;PID&gt;/limits文件查看正在运行的进程的最大文件描述符限制 Nginx中 修改worker_processes的值可以配置Nginx启动多少个worker进程 一般建立配置为auto。Apache的prefork模型，就是采用大量的进程来处理用户请求，当用户接入时，fork一个进程去处理。这样的好处是每个用户的请求相对隔离，不会因为一个用户请求处理进程崩溃而影响到其他用户的请求。但是在高并发下 内存的大量消耗和频繁的上下文切换可能成为瓶颈。php-fpm的fastcgi中 预先初始化多个cgi进程等待web服务器的动态页面请求，这样可以减少进程创建和销毁的开销。 Linux还有一个OOM机制(Out Of Memory killer)和进程的优先级机制(nice值)。 OOM机制会监控那些占用内存过大，尤其是瞬间很快消耗大量内存的进程，为了防止内存耗尽而内核会把该进程杀掉。为了防止重要的进程触发OOM机制而被杀死 可以设置进程/proc/&lt;PID&gt;/oom_adj文件的值为-17来临时关闭对这个进程的监控。但是最好还是不要对这些耗内存大的程序使用 否则照成sshd等重要的进程被杀死就得不偿失了。 优先级呢通过配置进程的nice值来更改进程占用CPU的百分比，nice值得范围是-20到+19，值越低 程序可以获取更多的CPU执行时间。使用nice -n -19 nginx 可以将Nginx进程的nice值设置为-19。Nginx派生的子进程也会继承这个nice值。对于已经存在的进程可以通过renice -n 10 &lt;PID&gt;将该进程的nice值设置为10，但是并不会对该进程的子进程生效。 多线程和多进程不同的是当客户建立连接后，派生一个线程去处理用户请求。线程的创建和销毁开销是低于进程的，内存使用也会减少一些。比如Apache的worker模型 同时使用了多进程和多线程，所有的线程共享同一个进程内存空间，如果一个线程崩溃 可能会影响到整个进程。 协程大家可能对进程和线程比较熟悉 而对协程比较陌生。原生支持协程的语言并不多 但是协程非常适合在高并发环境下使用。 协程没有抢占式调度，由代码内主动放弃执行权切换到其他协程执行 因此也不存在上下文切换的开销。协程始终是运行在单线程内 所以也不存在变量共享的锁竞争。 Go语言对协程有良好的支持 所以非常适合高并发的服务端网络编程，Python语言yield关键字提供了对协程的基本支持，Gevent、Tornado等库都对协程有良好的支持。Python3.5之后引入async/await关键字对协程则有了非常好的支持。 优化系统调用使用strace命令对Nginx的worker进程进行系统调用跟踪，可以分析出用户一次请求共进行了多少次系统调用。比如如果存在日志记录，那一定会存在每处理一条用户请求 都会向日志写入一条记录。每次对日志进行一次write操作 都是一次系统调用，如果关闭日志记录功能 就可以省掉一次日志写入的系统调用。但是对于Web服务器 日志存在的价值显然是高于能节约的响应时间。 使用strace -c -p &lt;PID&gt;可以对已启动的进程进行系统调用统计，使用Ctrl+C结束统计 root@ubuntu:~# strace -c -p 18803 strace: Process 18803 detached % time seconds usecs/call calls errors syscall ------ ----------- ----------- --------- --------- ---------------- 100.00 0.000200 50 4 stat 0.00 0.000000 0 1 write 0.00 0.000000 0 1 open 0.00 0.000000 0 2 close 0.00 0.000000 0 1 fstat 0.00 0.000000 0 1 writev 0.00 0.000000 0 1 sendfile 0.00 0.000000 0 2 recvfrom 0.00 0.000000 0 2 setsockopt 0.00 0.000000 0 2 epoll_wait 0.00 0.000000 0 1 epoll_ctl 0.00 0.000000 0 1 accept4 ------ ----------- ----------- --------- --------- ---------------- 100.00 0.000200 19 total 这里是Nginx的worker进行一次用户请求处理的系统调用统计，可以看到Nginx使用sendfile调用向用户发送数据。使用sendfile等更高效的大文件传输方式，尽量将操作在内核中完成，减少数据在内核态和用户态的复制。 使用更高效的系统调用方式和减少不必要的系统调用 就是对系统调用的优化了。 尽量避免锁竞争只要涉及到多进程或多线程的变量共享问题 就会涉及到锁竞争了。只要使用了锁，多进程或多线程就变成了线性的等待锁资源，对于高并发状态 锁竞争会严重降低系统性能。所以在设计后端的时候 开发者需要尽量避免变量共享问题。 更高效的IO模型Nginx的高并发能力源自它采用了多路IO就绪通知机制，常见的机制有select, poll, epoll等 其中Linux下性能最好的是epoll，跨平台的是select。 程序代码跟踪分析很多语言都有代码性能分析工具，利用这些工具可以分析出一段代码运行各部分的耗时。通过优化这些耗时的代码 可以更好的提升性能和对用户的响应。 可以使用xhprof对PHP的程序进行性能分析，使用cProfile对Python的代码进行性能分析。 缓存 这个缓存是在服务端的缓存 字节码缓存PHP、Python等动态语言的执行首先需要将源代码编译为字节码，比如PHP的字节码是在Zend虚拟机中运行，Python的字节码是在Python虚拟机中运行。 这些脚本在执行过程中会先将源代码编译为字节码，而直接将字节码缓存起来就可以省掉编译的过程了。比如PHP的XCache。而Python可以通过python -m compileall &lt;PATH&gt;将单个py文件或者目录中全部的py文件编译为.pyc文件（Python3之后是生成在__pycache__目录中）。 页面缓存 后端生成的html页面 也可以先缓存起来 这样就不用重新生成了。 页面缓存又分为三种 静态内容缓存 在Web服务器上将html, css, js等静态页面缓存到内存中或者Memcached等分布式缓存中。总所周知内存的速度是非常快的，对比从内存中取数据，从磁盘上取数据可以说是非常满的了。 如果存在代理服务器，在代理服务器上完成缓存可以更快的返回给用户 这样都不需要经过后端程序了。 动态内容缓存 动态页面的渲染后端可能需要从数据库中取数据 然后将数据渲染到html模板中 最后生成动态页面。对于一些时效性要求不高的页面，可以选择将页面缓存起来，提供一个缓存过期时间，在未过期之前就直接向用户返回缓存的页面。这样可以有效的减少对数据库的读写和CPU的页面渲染。 动态页面缓存也最好配置在代理服务器上。Redis的键值过期机制也非常适合做这种缓存服务器。 局部无缓存 如果一个页面中只有一部分的数据是需要更新的 其他部分的数据都不变 可以采用这种缓存方式。 比如采用SSI技术 只更新页面中动态的内容。但是需要服务器读取shtml模板页面，匹配和修改更新的内容，需要较大的CPU开销。 数据库读写缓存 如果能将数据库的查询结果也缓存起来 就可以避免某些对数据库的查询了。 读缓存 可以将select语句的查询结果缓存到缓存服务器中，当再次遇到相同的sql查询语句时就可以直接从缓存服务器获取结果而不必再次查询数据库了。但是需要注意缓存的生命周期，如果数据已经更新 而缓存还在生效 就会导致页面显示更新不及时。 写缓存 将频繁的数据库写入操作尝试合并为一次写入，比如累计用户登陆次数，先将数据存入memcached中，累计登陆10次后写入数据库中。但是这样想要获取准确的用户登陆次数信息 就要同时获取数据库记录而缓存服务器记录数的相加结果了，而且还要承受缓存服务器意外宕机导致的数据丢失问题。 数据共享后端服务器群中的数据共享问题，比如用户上传了头像或者照片，因为负载均衡的原因只上传到了一台服务器上，这样下次用户换个设备登陆的时候可能就找不到上传的图片了。这个时候就需要让所有服务器共享一个数据存储。 数据可以通过rsync或者scp进行同步 但是服务器如果比较多 而站点刚好是用户上传数据比较频繁的类型，这两种方式显然就不适合了。还可以采用NFS或者Samba共享等方式，有条件的话可以使用NAS网络存储，或者使用开源的分布式文件系统，比如FastDFS，HDFS等。 Web组件分离 随着业务的扩展和服务器规模的扩大，就需要对业务组件进行拆分了，将不同的组件部署在不同的服务器上。 不同组件使用不同的域名比如百度知道的域名为zhidao.baidu.com，而百度知道中的图片存放在域名为gss0.bdstatic.com的服务器上。不同的域名可以指定不同的IP，不同的业务便可以分散到不同的服务器上了。 另一个好处是可以避开浏览器对同一个域名的并发数限制，将资源分散到不同的域名也增快了页面最终呈现的速度。 数据库连接优化大多数的后端程序都有数据库连接池的概念，由数据库连接池来维护与数据库的连接，程序只用从数据库连接池中获取和释放连接就可以。程序对数据库连接池的获取和释放连接是非常廉价的，而数据库连接池会保证池内拥有一定量可用的数据库连接。 反向代理和负载均衡 当单台主机无法承受业务访问量的时候 就需要多台服务器同时工作了。而如何将用户请求均衡的分发到各后端服务器 就是负载均衡器的工作了，一般负载均衡器也是反向代理服务器。 动静分离将网站的静态资源和动态页面分离，一般PHP等后端服务并不擅长处理静态资源，这个时候就需要使用专业的静态资源服务器来处理网站的静态资源了。 比如以高并发著称的Nginx就非常适合做这件事情，由Nginx处理静态资源，动态内容则转发到后端的应用服务器处理。Nginx在这里也就是反向代理服务器了。 负载均衡通常由负载均衡软件或者专业的负载均衡设备来将用户请求分发到不同的后端服务器。 负载均衡器通常会根据一些算法来对用户请求进行分发，比如常用的轮询、加权轮询、ip_hash等。 负载均衡器往往还会对后端服务器进行健康检查，剔除意外宕机的后端服务器 以免某个用户刚好访问到宕机的服务器。同时负载均衡器上还要注意用户的登陆状态保持功能。 还可以在负载均衡器上配置ssl 这样就可以免去配置所有的后端服务器而获得一个https的网站了。 负载均衡的方式Nginx或者HAProxy四层负载均衡只根据传输层协议内容进行转发，而不关心传输层以上的数据。七层负载均衡则根据应用层协议内容进行转发，可以对应用层协议进行更精确的控制，比如可以判断用户的访问设备，然后根据设备发送不同的页面。 而Nginx和HAProxy对则四层负载均衡和七层负载均衡都有较好的支持。 HTTP重定向通过返回302状态码将用户请求按照算法重定向到其他的服务器域名。 优点是比较简单，容易实现，负载均衡器只做请求分发 所以不会是IO瓶颈。缺点是浏览器需要两次请求服务器才能完成一次访问，性能略差，302状态码还有可能降低搜索引擎的排名。 DNS简单轮询同一个域名添加多条A记录，用户进行DNS查询时依照轮询算法返回某一个服务器的IP地址。 优点是将负载均衡工作交给了DNS，省去维护负载均衡器的麻烦，同时DNS支持基于地理位置的解析，可以返回给用户最近的服务器地址。缺点：DNS是多级解析，每一级都可能有缓存，修改了DNS可能不会立即生效，控制权在运营商手里。实际上大型网站经常利用DNS作为第一级的负载均衡。 LVS负载均衡器 LVS负载均衡器是所有软件负载均衡器中性能最高的了 甚至比肩专业的负载均衡器设备。这里就单独拿出来介绍下LVS的三种负载方式。 LVS-NAT NAT模式 负载均衡工作在网络层 修改用户数据包的目标地址并转发到相应的后端服务器，后端服务器的默认网关应该指向NAT主机，LVS服务器收到回应后再将源地址改为自己的地址。但是此模式中 负载均衡器对所有的流量进行转发 所以随着后端服务器的增加，负载均衡器容易成为流量瓶颈。 LVS-DR 直接路由模式 负载均衡工作在数据链路层，通过修改数据包中的目标MAC地址，将数据包转发到后端服务器。最后数据直接由选中的后端服务器返回给用户，所以后端服务器也必须接入互联网。这时候LVS服务器不会是流量的瓶颈了 但是所有的后端服务器都需要有公网IP，而且必须和负载均衡器在同一个交换机上。 LVS-TUN IP隧道模式 和直接路由工作原理相似，可以跨机房，服务器之间通过IP隧道连接 拥有直接路由模式模式的优点。但是IP隧道实际上是对数据包的又一层封装，IP隧道数据包的封装和解包都会有一定的开销。 硬件升级 可能的情况下 升级硬件设备对性能的提升是非常巨大的。当然在升级硬件的时候也要考虑主板是否支持这些硬件。 CPU在选择CPU一般会考虑CPU的主频、核心数、制作工艺以及支持的指令集。 一般来说 CPU的主频越高 性能越强 但是功耗也会越高。核心数越多表示可以同时运行的进程越多，Intel的超线程技术 可以将一个物理核心数模拟为两个逻辑核心数，总性能大约可以提升20%左右。而随着CPU制作工艺的提升 芯片的体积可以越来越小 功耗也会更小。 内存选购内存一般考虑类型和主频。现在内存已经进入了DDR4时代 但是服务器硬件更新迭代的比较慢 大部分服务器依旧使用DDR3内存，DDR4有着比DDR3更高的主频，更快的速度，和更低的功耗 硬盘机械硬盘机械硬盘的单位容量更为廉价，也是服务器采用最多的存储方式。但是机械硬盘属于损耗品 大约工作5年左右就会出现故障，一般企业会选择磁盘阵列技术来对硬盘的数据进行容错和提升性能。服务器硬盘的转速多为10000rpm或者15000rpm 转速越高 硬盘的读写性能越强。 下面看看几种常见的磁盘阵列方式 Raid 1: 至少需要两块硬盘 其中一块作为数据备份，读取性能高，且允许故障一块硬盘，但是空间利用率只有50%。 Raid 5: 性能 数据安全 和存储成本兼顾的方案 至少三块硬盘的话 允许故障一块，空间利用率为硬盘总数减1，因为有差不多一块盘的空间用于存储奇偶校验信息，并散列存储在所有的硬盘上。 Raid 10: 集合Raid0的高性能读写和Raid1的安全 至少需要4块硬盘 最多允许坏两块硬盘 空间利用率也只有50%。 固态硬盘企业级固态硬盘的成本非常，但是性能也是非常强的。固态硬盘理论上支持无限次的读取，但是对擦写是由次数限制的。程序的运行很大一部分时间耗在了等待IO上，而使用固态硬盘可以大大提升文件的读写速度，程序的执行效率提升可以很明显的增强。通过对比使用固态硬盘的机器和机械硬盘的机器开机速度可以很明显的对比出固态硬盘对系统流畅度的提升。 几种常见的固态硬盘使用的闪存芯片 TLC闪存: 速度慢 寿命短 约500次擦写寿命 稳定性比较差 但是成本低。MLC闪存: 速度一般 寿命一般 3千到1万次擦写寿命 稳定性适中 成本适中。SLC闪存: 速度快 寿命长 10万次擦写寿命 稳定性强 企业级闪存 但是成本非常高。 网卡使用千兆网卡，并使用多网卡做bond，数据链路层的负载均衡，提高网卡可用性和最大带宽。 数据库优化 数据库可以说是Web站点的最后一部分了，后端程序执行很可能很大一部分时间是等待数据库返回需要的数据，提高数据库的查询速度可以很明显的提升Web站点性能。 数据分区 当随着数据的增多 单台数据库实例已经无法承受站点日益增多的数据 就需要考虑对数据进行分区了。 垂直分区如果数据库写操作频繁 从库则会将大量时间花在复制上 照成性能浪费。这时候就需要将写操作分散到不同的服务器上。最简单的就是将无关的库分散到不同的服务器上，然后不同的数据写入到不同的服务器上。为了方便日后数据库的垂直分区，设计数据库表结构的时候应该尽量减少外键约束和联合查询。 水平分区当单表的数据了日益增多，也达到了写操作的极限，垂直分区就不适用了。这个时候就可以通过特定的算法将同一数据表的数据写入到不同的数据库中，这就是水平分区了。 比如说将id为奇数的数据放入数据库A，为偶数的放入数据库B。如果需要分散到更多的数据库中，可以对id进行取余计算。需要注意的是 程序也需要知道相应的算法而从正确的数据库取数据。 也可以使用分区反向代理，Spock Proxy可以帮助应用程序实现水平分区的访问调度，我们也不应该在程序中维护分区对应关系。 集群和读写分离主从复制多台数据库之间数据同步，查询可以从多台服务器上进行 减少单台服务器的压力。 读写分离使用数据库反向代理 比如Mysql Proxy对后端数据库进行读写分离和负载平衡。读写分离的原理是让主数据库处理事务性查询，让从库处理数据查询，通过主从复制的方式将主库的数据更新到从库。 性能优化 对数据库软件的性能调优 选择合适的存储引擎对于MySQL数据库 常用的数据引擎有MyISAM和InnoDB，随着Innodb的不断更新改进，从MySQL5.5已经成为了默认存储引擎。 InnoDB: 行级锁 共享表空间 支持事务和外键 写性能比较好 支持热备份。MyISAM: 表级锁 独立表空间 不支持事务和外键 读性能比较好 不支持热备份。 所以如果网站的写操作比较多适合选择InnoDB，读操作比较多的话适合选择MyISAM。 Innodb缓存池大小InnoDB会在内存中维护一个缓冲池，用于缓存数据和索引。当用户执行查询操作时 如果缓存池中有数据会直接返回结果，否则会从磁盘读取数据，然后放到缓冲池中。配置一个合理的缓存池大小 可以将尽量多的数据缓存到内存中。如果MySQL数据库独占单个服务器，可以将缓存池的大小配置为物理内存的80%。 建立索引对经常作为查询条件的字段建立索引，这样查询的时候就不需要对表数据进行完整的扫描。但是索引有时候会比整体数据还要大。 减少表锁定等待MyISAM的UPDATE操作会排斥对当前表的所有其他操作，只有更新结束后才可以继续查询。InnoDB支持行级锁，在写操作比较多的情况下性能会好于MyISAM。 使用查询缓存将select查询的结果缓存在内存中 当下次遇到相同的select语句将直接。默认情况下 mysql是没有开启查询缓存的，修改配置文件query_cache项开启。 但是需要注意，如果对这个表的数据进行了插入或更改 MySQL将会清除这个表所有的缓存。在对表读写频繁的情况下 查询缓存可能会添乱。但是如果有大量的相同或相似的查询，而且很少修改表中的数据就非常适合了。 缓存线程池在配置文件中配置thread_cache_size，让MySQL创建的线程可以被重复利用，减少线程的创建和销毁的开销。 表结构设计和查询语句优化设计合理的表结构和编写高效的查询语句，将相关的数据尽量不要使用多表查询，联合查询等方式。 使用NoSQL放弃关系型数据库，根据项目选用更合适的非关系型数据库吧。。。 附录 PNG版脑图 SVG版脑图]]></content>
      <categories>
        <category>Web优化</category>
      </categories>
      <tags>
        <tag>Web优化</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[打造自己的ubuntu开发环境]]></title>
    <url>%2F2018%2F02%2F10%2F2018%2F%E6%89%93%E9%80%A0%E8%87%AA%E5%B7%B1%E7%9A%84ubuntu%E5%BC%80%E5%8F%91%E7%8E%AF%E5%A2%83%2F</url>
    <content type="text"><![CDATA[简介 对于经常在Linux做开发的开发者 打造一款让自己用的舒服 赏心悦目的系统开发环境是非常重要的。看着精美的主题和系统 心情也会变得更好，心情好了，代码的质量也就更高了。linux好的桌面发行版有Archlinux啊 Ubuntu啊 还有国产良心Deepin啊之类的，Archlinux太需要折腾了，Deepin呢 已经帮用户做的太多了，安装完毕后总觉得很多自己用不到的软件，桌面自己可以折腾的地方也不多，于是就选择了Ubuntu。鉴于下一个Ubuntu的LTS版18.04还有两个多月才发布 遂使用Ubuntu 16.04来折腾。 环境 由于Windows系统的便利性还是比Ubuntu高的 还有很多Ubuntu无法代替的地方 所以就只好吧Ubuntu安装到虚拟机里了 主机 内存 CPU 硬盘 Windows 10 64位 8G DDR4 i7 6代 256G SSD 虚拟机 内存 CPU 硬盘 Ubuntu 16.04 64位 4G DDR4 i7 6代 40G SSD 步骤获取Ubuntu 可以在ubuntu的官网获取 但是速度可能会比较慢。可以在国内的镜像站上免费下载ubuntu系统镜像 在阿里云镜像站获取最新版ubuntu 16.04的镜像 ubuntu-16.04.3-desktop-amd64.iso 点此下载 安装Ubuntu可以选择在虚拟机或者物理机上安装Ubuntu 在终端中更新升级软件 由于Ubuntu的官方镜像站有中国的服务器，中文版的也默认使用中国的服务器 所以就不更改镜像站了 执行以下命令12sudo apt-get updatesudo apt-get upgrade 接下来就是开始美化主题了 安装漂亮的主题 这里使用我比较喜欢的Numix主题 deb离线安装 由于安装Numix主题需要添加Numix的ppa源 官方源有时候并不稳定 因为也可以直接安装Numix的deb包。在ubuntu内用火狐浏览器打开此页面后下载，或者Windows上下载好后想办法传入到ubuntu中。如果想使用官方ppa源安装可以跳过这一段。 包名 下载地址 numix-gtk-theme 点此下载 numix-icon-theme-circle 点此下载 然后安装这两个包，如果没报错的话应该就安装成功了12dpkg -i numix-gtk-theme.debdpkg -i numix-icon-theme-circle.deb 注意：直接安装deb包只在当前ubuntu版本上测试通过，其他版本不保证可以使用，最好还是使用官方ppa源的安装方式。 使用Numix官方源安装 如果使用deb离线安装成功的话 这一步就不用继续了哦 123sudo add-apt-repository ppa:numix/ppasudo apt-get updatesudo apt-get install numix-gtk-theme numix-icon-theme-circle 还需要一款主题管理工具来更改主题1sudo apt-get install unity-tweak-tool 打开tweak工具 然后将主题、桌面壁纸等换成自己喜欢的吧 是不是瞬间感觉用户体验上升了一个档次呢 逼格也更高了 安装常用软件搜狗输入法Ubuntu内用火狐浏览器打开：https://pinyin.sogou.com/linux/ 点击立即下载64位。下载好后打开文件所在目录，然后在此目录打开终端 输入以下命令开始安装。1sudo apt-get install -f ./sogoupinyin_2.2.0.0102_amd64.deb 安装完后需要注销下重新登陆 然后打开浏览器 点击左上角小键盘的图标 切换到搜狗输入法。试试看，是不是可以很舒服的输入中文了。使用Shift键切换中英输入哦。 Chrome浏览器 由于Windows下一直使用Chrome浏览器，所以对Chrome比较情有独钟。下载需要自备梯子哦。 Chrome浏览器下载地址：https://www.google.cn/chrome/ 如果用Ubuntu中的火狐浏览器打开Chrome浏览器的主页，可以直接点击下载Chrome的图标。Windows下的话 需要点击下载适用于其他平台的Chrome，下载后传到Ubuntu中。 接下来安装deb包1sudo apt-get install -f ./google-chrome-stable_current_amd64.deb 其他软件的安装方式都大同小异 可以在Ubuntu应用商店找到的就在应用商店安装，找不到的就去官方找有没有ppa源或者deb包。 附录漂亮的锁屏界面]]></content>
      <categories>
        <category>Ubuntu</category>
      </categories>
      <tags>
        <tag>Ubuntu</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Hadoop入门笔记]]></title>
    <url>%2F2018%2F02%2F04%2F2018%2FHadoop%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简介 Hadoop是一个由Apache基金会所开发的分布式系统基础架构。用户可以在不了解分布式底层细节的情况下，开发分布式程序。充分利用集群的威力进行高速运算和存储。Hadoop实现了一个分布式文件系统，简称HDFS。HDFS有高容错性的特点，并且设计用来部署在低廉的硬件上；而且它提供高吞吐量来访问应用程序的数据，适合那些有着超大数据集的应用程序。Hadoop的核心设计是：HDFS、YARN和MapReduce。HDFS为海量的数据提供了存储，YARN提供资源调度，而MapReduce则为海量的数据提供了计算. 环境系统环境 为了避免防火墙等影响 默认已经关闭iptables和selinux 身份 系统 主机名 IP Hadoop master ubuntu 16.04 master 10.0.0.3 Hadoop slave1 ubuntu 16.04 slave1 10.0.0.4 Hadoop slave2 ubuntu 16.04 slave2 10.0.0.5 Hadoop slave3 ubuntu 16.04 slave3 10.0.0.6 软件环境 软件名称 版本号 下载地址 Hadoop 2.7.5 点击下载 jdk 1.8.0_161 点击下载 步骤安装Hadoop 下载的是官方编译好的二进制包 所以就不用再重新编译了。注意：下面的操作需要在所有主机上进行 或者配置好一台后rsync同步到其他主机 下载和解压1234# 软件包在windows上下载并上传到了Linux上 注意jdk下载需要先接受许可协议tar xf hadoop-2.7.5.tar.gz -C /usr/local/mv /usr/local/&#123;hadoop-2.7.5,hadoop&#125;tar xf jdk-8u161-linux-x64.tar.gz -C /usr/local/ 配置集群环境 集群环境为启动和使用Hadoop集群所需要的配置 配置jdk环境变量 将以下内容写入到 /etc/profile.d/jdk.sh export JAVA_HOME=/usr/local/jdk1.8.0_161 export PATH=$JAVA_HOME/bin:$PATH export CLASSPATH=.:$JAVA_HOME/lib/dt.jar:$JAVA_HOME/lib/tools.jar 修改 /usr/local/hadoop/etc/hadoop/hadoop-env.sh 找到 export JAVA_HOME=${JAVA_HOME} 修改为 export JAVA_HOME=/usr/local/jdk1.8.0_161 配置hadoop环境变量 将以下内容写入到 /etc/profile.d/hadoop.sh export HADOOP_HOME=/usr/local/hadoop export PATH=$HADOOP_HOME/bin:$HADOOP_HOME/sbin:$PATH 使环境变量立即生效 运行命令： 1source /etc/profile 配置主机名解析 将以下内容写入到/etc/hosts 10.0.0.3 master 10.0.0.4 slave1 10.0.0.5 slave2 10.0.0.6 slave3 Windows上也顺便更改下hosts文件 以便于后面的访问集群hosts文件位置：C:\Windows\System32\drivers\etc\hosts因为系统目录权限问题 可以将hosts文件拖到桌面修改后再拖回去覆盖了原文件即可 认识HDFS HDFS的全称是 “Hadoop分布式文件系统” ，可以简单理解为由用户进程模拟的一块大硬盘，为大数据处理提供了基础的数据存储服务，下面先看看HDFS是怎么一回事，再探究它到底是个什么东东。 启动HDFS Hadoop由三部分组成 HDFS则是其最基层的一部分。 配置文件语法 Hadoop的配置文件在/usr/local/hadoop/etc/hadoop/中，配置文件使用xml语法 &lt;property&gt; &lt;!-- 属性 --&gt; &lt;name&gt;&lt;/name&gt; &lt;!-- 名称 --&gt; &lt;value&gt;&lt;/value&gt; &lt;!-- 值 --&gt; &lt;/property&gt; 配置项需要写在配置文件的&lt;configuration&gt;&lt;/configuration&gt;代码块中 配置文件简单介绍 Hadoop可能需要经常改动的配置文件有四个，下面简单说说这四个都是干嘛用的，具体用到的配置文件，后面会详细说明。 配置文件 说明 core-site.xml Hadoop Core的配置项 hdfs-site.xml HDFS的配置项 比如配置HDFS数据存储位置等 yarn-site.xml yarn资源调度器的配置 比如yarn监听的地址等 mapred-site.xml MapReduce计算引擎的相关配置 修改配置文件 HDFS的配置文件为hdfs-site.xml 打开发现&lt;configuration&gt;&lt;/configuration&gt;中是空的。其实Hadoop已经为HDFS的各种参数配置了默认值，用户重写进配置文件的值会覆盖掉Hadoop默认的。启动HDFS集群需要让各slave节点知道要连接谁，而这个配置是在core-site.xml中。 将所有节点的 core-site.xml 修改为如下内容 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;fs.defaultFS&lt;/name&gt; &lt;value&gt;hdfs://master:9000&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 配置hdfs的slave都连接master的9000端口 启动HDFS集群 HDFS集群分为 NameNode 和 DataNode ，其中NameNode为master节点 DataNode为slave节点NameNode的作用就像一本书的目录 记录每一个文件存放在哪个slave节点上。而DataNode则是存放数据用的了。 启动前需要先对namenode进行目录格式化在master节点上执行NameNode格式化命令和启动的命令12hadoop namenode -formathadoop-daemon.sh start namenode 在所有slave节点上执行启动DataNode的命令1hadoop-daemon.sh start datanode 使用jps命令可以看到当前启动的java进程，可以看到master节点跑着的是NameNode进程，而slave节点跑着的是DataNode进程 验证是否启动成功 HDFS启动成功后 master会监听9000端口，并且还会监听50070端口，这个端口是HDFS的web管理界面。 可以使用命令的方式查看集群各节点的运行状况1hdfs dfsadmin -report 也可以在web界面上直观的看到HDFS集群的状况浏览器访问：http://master:50070 然后点击 Datanodes 可以看到三个slave正常在线 如果还想继续增加slave节点 只需要更改了slave节点的配置文件后启动就可以了。HDFS的总容量会随着节点的增多而增多 拓展性是不是非常好呢。但是随着节点的增加又一个问题出现了 现在slave节点拓展到一千多台了 我该怎么启动这个集群呢？ 集中式管理HDFS集群 Hadoop官方已经提供了一个批量启动和关闭HDFS集群的脚本了 而且以后用的更多的也是这些脚本。但是使用脚本之前 还需要做一些小配置。 配置ssh密钥认证 这一步配置master节点到其他slave节点的ssh密钥认证，其实就是master节点替你登陆到各slave节点启动DateNode了 此步骤只在master上进行 12345ssh-keygenssh-copy-id root@master # 没错 自己也要免密码登陆自己ssh-copy-id root@slave1ssh-copy-id root@slave2ssh-copy-id root@slave3 配置完成后可以ssh验证在master上是否可以免密码登陆所有slave节点了 配置slave节点 只有告诉了master有哪些slave节点 master才会帮助你启动或停止它们修改 /usr/local/hadoop/etc/hadoop/slaves 如下 slave1 slave2 slave3 如果有localhost这条记录需要删掉 这样master节点就不会也被当作slave节点了 停止HDFS集群 因为HDFS集群已经是启动状态了 那就先试试停止它们吧 在master上执行1stop-dfs.sh 再在各节点执行jps命令看看是不是NameNode和DataNode已经停止了呢 启动HDFS集群 停止使用的是stop-dfs.sh命令 那启动就肯定是start-dfs.sh喽 1start-dfs.sh 再用jps命令看看 是不是所有节点各自的服务都启动了呢但是master上的进程好像不太一样 多了一个SecondaryNameNode，那么这个进程是做什么的呢 这个进程是帮助NameNode更好的工作 解决NameNode运行中可能出现的一些问题的 这也是NameNode容错的一种机制，具体作用可以查阅官方文档或搜索引擎。 接下来 就该看看这个HDFS该怎么用了吧 既然是一种分布式文件系统 那么它体现在哪里呢？ HDFS的文件操作 先简单介绍下HDFS文件的存储方式。将文件上传到HDFS中后 HDFS会将文件按照128M为一块进行分块存储。每一块又默认会复制三次 然后存放在三个不同的节点上。这样如果有某台机器宕机了 就还可以从其他节点拿到这一块文件，所以提供了文件冗余机制，并且HDFS还会将宕机节点丢失的块再复制一份到其他节点 保证每一块都存在三份。 HDFS的特性：文件分块 文件冗余 容易拓展 命令行管理HDFS中的文件 通过java程序或者其他语言的HDFS库就可以操作HDFS中的文件了。在Linux上也提供了一些命令去操作HDFS 1234567891011hadoop fs -ls / # 查看HDFS集群根目录的文件 应该是空的hadoop fs -mkdir /hadoop # 创建/hadoop目录hadoop fs -put /tmp/hadoop-2.7.5.tar.gz /hadoop # 将这个文件上传到/hadoop目录中hadoop fs -ls /hadoop # 这个时候应该可以看到上传的文件了hadoop fs -put /etc/profile.d/jdk.sh / # 将jdk.sh 上传到根目录hadoop fs -cat /jdk.sh # 有没有发现这些命令和Linux的命令都差不多呢hadoop fs -rm /jdk.sh # 把jdk.sh删除hadoop fs -rm -r -f /hadoop # 和rm命令一样 也是可以带-r -f 参数的哦hadoop fs -put /tmp/jdk-8u161-linux-x64.tar.gz / # 把jdk上传上去 以便下面的测试hadoop fs -get /jdk-8u161-linux-x64.tar.gz /root/ # 把文件下载到root的家目录hadoop fs -help # 查看所有支持的操作 HDFS是不允许对文件进行更改的 所以如果非要修改 只能把文件下载下来修改后再上传 Web界面浏览HDFS中的文件 为什么说是浏览呢 因为Web界面内是没法对文件进行操作的 只能看 浏览器打开：http://master:50070 首页的Summary中可以看到集群的状态 因为HDFS会把一个文件分块后复制三份存放在不同的节点上 jdk的大小是180多M 三倍大小差不多就是547M了 点击 Utilities 中的 Browse the file system 就可以看到集群中的文件了 点击文件名称 可以查看文件的更多信息。HDFS的块大小为128M, jdk文件自然被分成了两块 每一块都存放在了三个节点上 HDFS的配置 默认HDFS会将文件复制三份 但是你觉得数据并不是那么重要 复制两份就满足数据冗余的需求了，那么如何更改这个配置呢 查阅官方文档 学习一个技术最好的方法就是查阅它的官方文档，官方文档永远是第一手资料。 打开Hadoop的官方首页：http://hadoop.apache.org/然后左侧栏点开 Documentation 找到自己的版本：http://hadoop.apache.org/docs/r2.7.5/左侧栏的最下方有个Configuration 既然是对HDFS进行配置 那肯定是看 hdfs-default.xml 的了点开后可以看到茫茫多的配置 这些配置都是HDFS的默认配置 只用修改相应的值就可以了。既然是复制 那就看看和复制有关的配置，在网页中搜索 &quot;replication&quot; dfs.replication 就是我们要更改的目标了 修改 hdfs-site.xm 只需要修改master节点的 hdfs-site.xml 就可以了 修改为如下： &lt;configuration&gt; &lt;property&gt; &lt;name&gt;dfs.replication&lt;/name&gt; &lt;value&gt;2&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; 保存退出后重启集群12stop-dfs.shstart-dfs.sh 接下来再测试下是否文件只复制2份了 上传一个新文件到HDFS中1hadoop fs -put /tmp/hadoop-2.7.5.tar.gz / 浏览器查看文件信息 可以看到 hadoop-2.7.5.tar.gz 只被复制了2份，并且文件的每一份都尽量平均的分散在集群的不同slave中。block0存放在slave2和slave3上，block1存放在slave1和slave3上，那么如果slave1宕机了 HDFS会做哪些操作呢 slave1宕机模拟 只要slave1和master不能正常通信就可以了，可以停掉slave1的datanode服务 或者开启slave1的防火墙阻止通信都可以。master会定期检测slave的状况 只有发现slave挂了后才会将缺少的文件再复制一份到其他节点。这个默认周期是300000毫秒 也就是5分钟。如果不想等待这么长时间 可以修改hdfs-site.xml，配置 dfs.namenode.heartbeat.recheck-interval 的值为10000 也就是10秒 在slave1上运行：1hadoop-daemon.sh stop datanode 过一阵子刷新浏览器 可以看到slave1已经离线了，并且又在slave2上复制了一份 测试完后记得重新启动 slave11hadoop-daemon.sh start datanode 刷新浏览器可以看到 slave1又上线了 修改数据存储路径 HDFS文件的数据块最终还是要真实存在硬盘上的，HDFS的默认数据存放路径为/tmp/下 这显然不是一个好主意 NameNode的数据存储位置定义在 dfs.namenode.name.dir 默认值为 file://${hadoop.tmp.dir}/dfs/nameDataNode的数据存储位置定义在 dfs.datanode.data.dir 默认值为 file://${hadoop.tmp.dir}/dfs/data 我们将数据目录修改到 /data/dfs 下master节点配置如下： &lt;property&gt; &lt;name&gt;dfs.namenode.name.dir&lt;/name&gt; &lt;value&gt;file:///data/dfs/name&lt;/value&gt; &lt;/property&gt; slave节点全部配置如下： &lt;property&gt; &lt;name&gt;dfs.datanode.data.dir&lt;/name&gt; &lt;value&gt;file:///data/dfs/data&lt;/value&gt; &lt;/property&gt; 以下操作在master上进行123stop-dfs.sh # 停止集群mkdir -p /data/dfs/name # 创建相应目录hadoop namenode -format # 重新格式化 接下来在slave节点上创建目录1mkdir -p /data/dfs/data 然后master上重新启动HDFS集群吧1start-dfs.sh HDFS的内容就先到这里吧 更多的配置项在以后用到的时候慢慢学习和了解 遇到不懂得地方记得查阅官方文档哦 YARN资源调度器 YARN是开源项目Hadoop的一个资源管理系统，最初设计是为了解决Hadoop中MapReduce计算模型中的资源管理问题，但是现在它已经是一个更加通用的资源管理系统，可以把MapReduce计算模型作为一个应用程序运行在YARN系统之上，通过YARN来管理资源。如果你的应用程序也需要借助YARN的资源管理功能，你也可以实现YARN提供的编程API，将你的应用程序运行于YARN之上，将资源的分配与回收统一交给YARN去管理，可以大大简化资源管理功能的开发。当前，也有很多应用程序已经可以构建于YARN之上，如Storm、Spark等计算模型。 YARN的基本概念 有了HDFS的基本概念 理解YARN也比较简单了 HDFS是将文件分布式存储在不同的slave节点上，而YARN是将任务拆分到不同的计算节点上。 Hadoop第一代中是没有YARN的概念的，Hadoop第二代开始专门将资源调度抽取出来了 所以才有了YARN。Hadoop第一代中 只有HDFS和一个MapReduce计算模型。但是MapReduce发展中发现了一些局限性，比如不支持内存模型、流式模型等计算模型。在Hadoop第二代的时候对这个问题进行了改进 在HDFS之上抽象出了一个资源调度模型，这个资源调度模型就是YARN（Yet Another Resource Negotiator）。 YARN对集群的内存、CPU资源进行调度，将计算任务按照算法分发到集群节点。有了这个抽象层 就可以在之上能跑的就不只有MapReduce了，还有各种各样的计算模型，比如Spark、Storm等。YARN只做调度 不参与计算。 YARN的master上运行ResourceManager，slave上运行NodeManager。YARN和HDFS是低耦合的，可以部署在一个集群中 也可以分开部署在两个集群中。把NodeManager和DataNode部署在同一个节点上，可以使NodeManager读取HDFS的效率更高 所以一般都将NodeManager和DataNode部署在一起。而ResourceManager和NameNode都比较吃内存，所以最好分开部署。实验中将ResourceManager和NameNode部署到了一起。 用户编写好计算的任务程序 然后去请求ResourceManager，ResourceManager将用户的任务拆分，然后分发到NodeManager节点进行计算，计算节点再从HDFS中获取数据。下面就看看YARN如何配置和启动。 配置YARN集群修改YARN的配置文件修改所有节点的yarn-site.xml文件 &lt;configuration&gt; &lt;property&gt; &lt;name&gt;yarn.resourcemanager.hostname&lt;/name&gt; &lt;value&gt;master&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.aux-services&lt;/name&gt; &lt;value&gt;mapreduce_shuffle&lt;/value&gt; &lt;/property&gt; &lt;property&gt; &lt;name&gt;yarn.nodemanager.auxservices.mapreduce.shuffle.class&lt;/name&gt; &lt;value&gt;org.apache.hadoop.mapred.ShuffleHandler&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; yarn.resourcemanager.hostname 指明ResourceManager在master上 只修改这一个 YARN集群就可以起来了。下面两个配置是NodeManager上运行的附属服务。需配置成mapreduce_shuffle，才可运行MapReduce程序。 启动YARN集群 YARN的启动和HDFS的启动类似 可以单个启动 也可以集群化方式启动 单独启动YARN节点master节点上执行12yarn-daemon.sh start resourcemanager # 启动ResourceManageryarn-daemon.sh stop resourcemanager # 停止ResourceManager slave节点上执行12yarn-daemon.sh start nodemanager # 启动NodeManageryarn-daemon.sh stop nodemanager # 停止NodeManager 集群化启动master节点上执行12start-yarn.sh # 启动整个YARN集群stop-yarn.sh # 停止整个YARN集群 Web界面查看集群状态 ResourceManager启动后 会在8088端口提供一个web界面，通过这个web界面可以看到节点状态，任务运行状态等 浏览器访问：http://master:8088/ YARN起来后怎么测试效果呢 那就跑个MapReduce计算看看吧 MapReduce计算模型 MapReduce最早是由Google公司研究提出的一种面向大规模数据处理的并行计算模型和方法。Hadoop的设计思想也来源自Google的几篇论文，MapReduce的论文里提到 MapReduce的灵感来自于函数式语言Lisp中的内置函数map和reduce。对于熟悉Python语言的人 应该都知道Python的两个内置函数 map 和 reduce，如果对着两个函数的运用也比较熟练的话，MapReduce计算模型也很容易理解了。下面就来看看利用MapReduce思想 是怎么解决数据处理中的问题的 第一个MapReduce程序 一个很简单的例子 统计一个文本文件中每个单词出现的次数。首先 先配置好MapReduce吧 修改配置文件 mapred-site.xml是MapReduce计算模型的配置文件。MapReduce和YARN也是低耦合的，跑MapReduce计算并不一定需要YARN，当然YARN上面并不只能跑MapReduce。这里就使用YARN来调度MapReduce使用的计算资源。 修改master节点的mapred-site.xml文件 mapred-site.xml文件不存在 所以需要先复制一份12cp /usr/local/hadoop/etc/hadoop/&#123;mapred-site.xml.template,mapred-site.xml&#125;vim /usr/local/hadoop/etc/hadoop/mapred-site.xml &lt;configuration&gt; &lt;property&gt; &lt;name&gt;mapreduce.framework.name&lt;/name&gt; &lt;value&gt;yarn&lt;/value&gt; &lt;/property&gt; &lt;/configuration&gt; mapreduce.framework.name 指定了MapReduce在YARN这个框架上跑，如果不配置就默认在本地单机上跑。 运行wordcount任务 /usr/local/hadoop/share/hadoop/mapreduce 中有一个 hadoop-mapreduce-examples-2.7.5.jar里面包含了一些官方给出里例子 wordcount就是其中的一个 创建测试文本 新建一个文件tmp.txt 然后写入以下内容： hello world hello python hello java hello java hi python hi c hi c++ hi lua hello lua 为了效果明显点 可以将这些内容多次写入到test.txt文件1while :; do cat tmp.txt &gt;&gt; test.txt ; done 这里已经获得了一个30M大小的文件了 root@slave1:~# ls -lh test.txt -rw-r--r-- 1 root root 30M Feb 8 08:34 test.txt 上传到HDFS中1hadoop fs -put test.txt / 开始测试吧！12cd /usr/local/hadoop/share/hadoop/mapreducehadoop jar hadoop-mapreduce-examples-2.7.5.jar wordcount /test.txt /testout 简单讲解下这条命令的意思 -jar 是运行这个jar包，wordcount是运行jar包中 wordcount这个类 /test.txt 是输入文件 /testout 是输出目录，一定要注意 /testout 一定要不存在才行。 现在可以看到命令的输出 Web界面也可以看到任务的运行状态 点击任务的ID 就可以看到这个任务是跑在了哪些节点上哦。因为30M对于Hadoop来说简直太小了 所以只分配了两个节点就够了。这个任务中 可以看到两个Maps进程都跑在slave1上 一个Reduces进程跑在slave3上 PS: 任务可以在任何节点跑 但是想要使用YARN进行资源调度的话 也需要修改相应节点的mapred-site.xml文件，否则就成了本地单机版的MapReduce了。ResourceManager节点重启后 所有的任务记录也都会丢失哦。 查看任务结果 还记得输出目录 /testout 吗 结果就在那里 先看一看/testout下有什么吧 root@master:~# hadoop fs -ls /testout Found 2 items -rw-r--r-- 2 root supergroup 0 2018-02-08 08:53 /testout/_SUCCESS -rw-r--r-- 2 root supergroup 95 2018-02-08 08:53 /testout/part-r-00000 _SUCCESS是表示这个任务执行成功part-r-00000 就是结果了 如果是个结果集的话 还会有part-r-00001、part-r-00002 …那就看看这个文件的内容吧 root@master:~# hadoop fs -cat /testout/part-r-00000 c 360944 c++ 360944 hello 1804720 hi 1443776 java 721888 lua 721888 python 721888 world 360944 可以看到每一个单词出现的次数都被统计出来了，那么它是怎么实现的呢？ MapReduce的运行原理 MapReduce的内部工作方式是怎样的呢？它是怎么解决单词统计这个任务的呢？ Map 和 Reduce举个简单的例子：顾客想知道他经常去的图书馆里有多少本书，于是找到了老板。“Hi! 老板 我想知道你的图书馆里有多少本书”“好嘞 我让手下去数一数”一共有二十个书架 领导分配了十个人去数，第一个人数1,2书架，第二个人数3,4书架以此类推等数完后将结果交给另外一个人去汇总 把每个书架的结果累加起来汇总完后 将结果给了老板后 老板告诉顾客有多少本书 这个例子中 顾客 就是开发者老板呢 就像是YARN进行工作调度所有的书就像是HDFS中存储的数据工人的工作就是所谓的Map了 而汇总统计的那个人做的工作 就是ReduceMap呢 就是将数据整理 归类 将复杂的数据变得简单有结构Reduce呢 就是拿到同类的数据后进行处理 计算 再讲一个做水果沙拉的例子：一堆不同种类的水果 要做成水果沙拉挑出一个 是香蕉 好 切成块挑出一个 是苹果 好 切成块挑出一个 是梨 好 切成块挑完也切完了 好 混在一起做成水果沙拉挑和切的动作 就可以看作Map，最后将所有的水果块做成水果沙拉 就可以看作是Reduce的过程了 Map和Reduce 只是一种思想 并不局限于一种固定的解决问题的模式 如何玩转这种思想 得到自己想要的结果 就是一门艺术了。这就是我所理解的MapReduce。 wordcount程序的实现 回到正题 看看这个自带的wordcount程序的实现是怎么样的呢 1. 输入（input） 将文档输入到Map进程 hello world hello python hello java hello java 2. 拆分（split） 将每一行都转为key-value形式 0 - hello world 1 - hello python 2 - hello java 3 - hello java 3. 映射（map）将每一行的每一个单词都形成一个新的key-value对 hello 1 world 1 hello 1 python 1 hello 1 java 1 hello 1 java 1 4. 派发（shuffle）将key相同的扔到一起去 hello 1 1 1 1 world 1 python 1 java 1 1 5. 缩减（reduce）将同一个key的结果相加起来 hello 4 world 1 python 1 java 2 6. 输出（output）将缩减之后的结果输出 自己写一个MapReduce程序 Map和Reduce的过程 是可以用户自定义的 那我们就自己实现一个统计字数的程序仍到Hadoop上跑吧不会写java不怕 hadoop-streaming-2.7.5.jar 这个包 提供了使用其他语言来写MapReduce程序的方法，这里用Python来实现。 Map 编写 mapper.py 文件 1234567#!/usr/bin/env pythonimport sysfor line in sys.stdin: words = line.split() for w in words: print(w+' '+'1') 1. 从标准输入获取数据 然后按行读取 hello world 2. 然后使用空白字符分割为一个列表 [&quot;hello&quot;,&quot;world&quot;] 3. 将列表中的每一个元素都转为key-value，并且写入到标准输出 hello 1 world 1 4. 继续从标准输入读取下一行 直到结束 Reduce 编写 reducer.py 文件 123456789101112#!/usr/bin/env pythonimport sysresult = &#123;&#125;for line in sys.stdin: key,value = line.split() if key in result: result[key] += int(value) else: result[key] = int(value)for k,v in result.items(): print(k+'\t'+str(v)) 1. 创建一个保存结果的字典 result 2. 从标准输入中读取一行 hello 1 3. 使用空白字符分割为一个列表 然后赋值给key和value key = hello, value = 1 4. 如果key存在result中了 那么他的值就加上变量value的值 如果key不存在result中 那么创建这个key 并将变量value赋值给它 {&quot;hello&quot;: 1} 5. 继续从标准输入读取下一行 直到结束 6. 将结果格式化写入到标准输出 运行自己的MapReduce程序 需要将两个脚本拷贝到所有节点相同的目录哦 因为不知道哪个节点会被调度运算 1234chmod +x mapper.py reducer.pyscp mapper.py reducer.py root@slave1:/tmpscp mapper.py reducer.py root@slave2:/tmpscp mapper.py reducer.py root@slave3:/tmp 使用 hadoop-streaming 跑起来吧！1234cd /usr/local/hadoop/share/hadoop/tools/lib # 这个jar包的路径# 注意：下面两行是一条命令hadoop jar hadoop-streaming-2.7.5.jar -input /test.txt \-output /pyout -mapper /tmp/mapper.py -reducer /tmp/reducer.py 命令参数什么的就不用说了吧 使用也是非常简单PS: 前期想测试下自己写的程序 可以使用管道模拟 比如 cat test.txt | ./mapper.py | ./reducer.py 也可以试试Linux的命令作为 mapper 和 reducer 的处理程序哦 比如12hadoop jar hadoop-streaming-2.7.5.jar -input /test.txt \-output /linuxout -mapper /usr/bin/sort -reducer /usr/bin/uniq 跑完了 有没有很开心呢 接下来该看看结果是否和自带的wordcount一样呢 root@slave1:~# hadoop fs -ls /pyout Found 2 items -rw-r--r-- 2 root supergroup 0 2018-02-08 15:44 /pyout/_SUCCESS -rw-r--r-- 2 root supergroup 95 2018-02-08 15:44 /pyout/part-00000 root@slave1:~# hadoop fs -cat /pyout/part-00000 hi 1443776 c++ 360944 c 360944 world 360944 java 721888 lua 721888 python 721888 hello 1804720 wordcount果然是大数据的Hello World学习到这里 也算是进入大数据的大门了 接下来就学习更高级的内容吧 附录学习过的资料 马士兵老师hadoop2.7入门系列 HDFS-百度百科 YARN-百度百科 Hadoop之MapReduce运行原理 关于MapReduce的理解 遇到的问题 如果主节点重新格式化了 子节点也需要将数据目录中的文件都删除 遇到会持续更新。。。]]></content>
      <categories>
        <category>Hadoop</category>
      </categories>
      <tags>
        <tag>Hadoop</tag>
        <tag>大数据</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Lua入门笔记]]></title>
    <url>%2F2018%2F01%2F12%2F2018%2FLua%E5%85%A5%E9%97%A8%E7%AC%94%E8%AE%B0%2F</url>
    <content type="text"><![CDATA[简介 Lua是一门脚本语言 其设计目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能。Lua由标准C编写而成，几乎在所有操作系统和平台上都可以编译，运行。Lua并没有提供强大的库，这是由它的定位决定的。所以Lua不适合作为开发独立应用程序的语言。Lua 有一个同时进行的JIT项目，提供在特定平台上的即时编译功能。 Lua特征 轻量级 使用标准C语言开发 编译后才100多K 可拓展 lua没有庞大的标准库，但是可以灵活使用宿主语言的功能 支持面向过程和函数式编程 自动内存管理 闭包 提供多线程（更像是协程） 应用场景 游戏开发 独立应用脚本 Web应用脚本 程序拓展或插件（Nginx, MySQL proxy） 安全系统 如入侵检测系统 Lua安装Linux编译安装lua依赖readline.h ubuntu系统安装libreadline-dev 12345wget http://www.lua.org/ftp/lua-5.3.4.tar.gztar xf lua-5.3.4.tar.gzcd lua-5.3.4make linuxmake install cd src &amp;&amp; install -p -m 0755 lua luac /usr/local/bin cd src &amp;&amp; install -p -m 0644 lua.h luaconf.h lualib.h lauxlib.h lua.hpp /usr/local/include cd src &amp;&amp; install -p -m 0644 liblua.a /usr/local/lib cd doc &amp;&amp; install -p -m 0644 lua.1 luac.1 /usr/local/man/man1 Lua向系统安装了这些文件 接下来就可以使用Lua命令了 Hello World用hello world作为lua第一个脚本的开始 lua也有一个交互式解释器 也可以写为后缀为.lua的文件来执行代码 1vim hello.lua 写入 print(&quot;Hello world!&quot;) 执行1lua hello.lua Lua的注释单行注释单行注释是两个减号 -- 单行注释 多行注释--[[ 多行注释 多行注释 --]] 标示符Lua中的标示符和其他语言的标示符都基本一致 关键字 关键字 关键字 关键字 关键字 and break do else elseif end false for function if in local nil not or repeat return then true until while Lua中的约定：以下划线开头的大写字母 被保留用于Lua的内部全局变量 数据类型Lua有8个基本类型 数据类型 描述 nil 表示无效值 空值 boolean 只有两个值：true和false number 表示双精度类型的实浮点数 string 字符串 可以用单引号也可以双引号 function 由C或者Lua编写的函数 userdata 表示任意存储在变量中的C数据结构 thread 表示执行的独立线程，用于执行协同程序 table Lua 中的表（table）其实是一个”关联数组” 使用type函数测试给定的值是什么类型 比如：1234print(type(1))print(type(&quot;hello&quot;))print(type(false))print(type(&#123;&#125;)) nil (空)nil类型表示没有任何有效值 nil类型只有一个值:nil 将全局变量或table表里的变量赋值nil 相当于删除了这个变量 boolean (布尔)boolean型只有两个值：true 和 false Lua只把false和nil看作是假 其他都为真！！！就算是0也是真！！！ number (数字)Lua的number只有一种类型：double类型 所有的数字都是double类型的 string (字符串)单行字符串可以用双引号或者单引号表示多行字符串用 [[string]] 表示 相当于python的三引号 如果一个数字型的字符串与数字进行运算 Lua会将字符串转为number！与JavaScript相反 Lua的字符串拼接使用”..” 两个点 比如：12print(&quot;str&quot;..1)print(2 ..3 ..4) 如果两个数字做字符串拼接 数字后面一定要带个空格 否则解释器会解释错 Lua使用#来计算字符串的长度 就像是python的len()一样123str = &quot;Hello world!&quot;print(#str)print(#&quot;lua&quot;) table (表)Lua的table类型比较有意思 像是python的字典，列表，集合的合体table类型的索引可以是数字 也可以是字符串Lua的数字索引是从1开始的！！！12345tbl1 = &#123;&#125;tbl2 = &#123;&quot;a&quot;,&quot;b&quot;,&quot;c&quot;&#125;tbl3 = &#123;a=1,b=2&#125;print(tbl2[1])print(tbl3[&quot;a&quot;]) 12345a = &#123;&#125;a[&quot;key&quot;] = &quot;value&quot;a[1] = 2print(a[&quot;key&quot;])print(a[1]) Lua取table中的数据可以用[] 如果key是字符串类型 还可以用.比如：12tbl1 = &#123;key=&quot;a&quot;&#125;print(tbl1.key) function (函数)Lua的函数跟JavaScript的函数很像 用function声明 还可以当作参数传给其他函数 1234567891011121314151617function map(fn, tab) count = 1 ltab = &#123;&#125; for k,v in pairs(tab) do ltab[k] = fn(v) end return ltabendmap(function(x) return x*x end, &#123;2,3,4,5&#125;) for k,v in pairs(rst) do print(&quot;new: &quot;..k..&quot;=&quot;..v)end thread (线程)Lua里的线程其实就是协程 userdata (自定义类型)userdata 是一种用户自定义数据，用于表示一种由应用程序或 C/C++ 语言库所创建的类型，可以将任意 C/C++ 的任意数据类型的数据（通常是 struct 和 指针）存储到 Lua 变量中调用。 变量默认情况下 Lua的变量总是全局的 不需要声明就可以直接赋值。访问一个不存在的变量会返回nil，想删除一个变量 将其赋值为nil就可以了Lua有三种变量：全局变量 本地变量 表中的域Lua除非用local声明为局部变量 否则都为全局变量 应该尽量使用局部变量 避免变量冲突 访问局部变量的速度更快 123456o = 10 --&gt; 全局变量function say() local o = 100 --&gt; 局部变量 print(o)endprint(o) 变量赋值Lua的变量赋值也比较灵活12345a,b,c = 1,2,3 --&gt; a=1,b=2,c=3a,b = b,a --&gt; swap a for ba,b = 1,2,3 --&gt; a=1,b=2 3 was dropa,b,c = 1,2 --&gt; a=1,b=2,c=nilprint(a,b,c) Lua循环while 循环while (condition) do statements end for 循环数值for循环for var=exp1,exp2,exp3 do statements end var从exp1变化到exp2，每次变化以exp3为步长递增var，并执行一次”执行体”。exp3是可选的，如果不指定，默认为1。123for i=10,1,-1 do print(i)end 泛型for循环泛型for循环通过一个迭代器函数来遍历所有值 for k,v in pairs(table) do statements end for i,v in ipairs(list) do statements end 在lua中pairs与ipairs两个迭代器的用法相近，但有一点是不一样的： pairs可以遍历表中所有的key，并且除了迭代器本身以及遍历表本身还可以返回nil; 但是ipairs则不能返回nil,只能返回数字0，如果遇到nil则退出。它只能遍历到表中出现的第一个不是整数的key repeat…until 循环类似于C的do while循环 先做后判断 repeat statements until(condition) break 跳出循环如果遇到break 就终止循环 很不幸的是 Lua没有continue，但是可以用嵌套循环模拟 12345678for i = 1, 10 do repeat if i == 5 then break end print(i) until trueend 流程控制if 语句if (condition) then statements end if…else 语句if (condition) then statements else statements end 函数Lua的函数定义格式如下 scope function name(arg1,arg2,...) statements return result scope 定义函数作用域 name 函数名 arg 参数 statements 函数内部语句 return 返回值 多返回值Lua可以一次返回多个值 同样需要多个参数来接收 12s,e = string.find(&quot;www.hinote.ga&quot;,&quot;hinote&quot;)print(s,e) 可变参数将Lua的参数放入一个叫arg的表中 #arg计算有多少个arg的值用”…”来表示函数有可变参数 1234function args(...) local arg = &#123;...&#125; print(#arg)end Lua 运算符设定A=10, B=20 算数运算符 操作符 描述 实例 + 加法 A+B=30 - 减法 A-B=-10 * 乘法 A*B=200 / 除法 B/A=2 % 取余 B%A=0 ^ 乘幂 A^2=100 关系运算符 操作符 描述 实例 == 等于 (A == B) 为 false ~= 不等于 (A ~= B) 为 true &gt; 大于 (A &gt; B) 为 false &lt; 小于 (A &lt; B) 为 true >= 大于等于 (A &gt;= B) 返回 false &lt;= 小于等于 (A &lt;= B) 返回 true 逻辑运算符A=true, B=false 操作符 描述 实例 and 逻辑与操作符 (A and B) 为 false or 逻辑或操作符 (A or B) 为 true not 逻辑非操作符 not(A and B) 为 true 其他运算符A=”Hello”, B=”World”|操作符|描述|实例||-|-|-||..|连接两个字符串|A..B 返回 “Hello World”||#|返回字符串或表的长度|#A 返回 5| 算数优先级^ not - (unary) * / + - .. &lt; &gt; &lt;= &gt;= ~= == and or 字符串字符串常用方法 方法 用途 string.upper 字符串转为全大写 string.lower 字符串转为全小写 string.gsub 字符串替换 string.find 字符串查找 string.reverse 字符串反转 string.format 格式化字符串 string.char 将ascii转为字符串 string.byte 将字符串转为ascii string.len 计算字符串长度 string.rep 返回字符串的N个拷贝 .. 连接两个字符串 string.gmatch 迭代器的方式匹配正则表达式 string.match 只寻找源字符串的第一个匹配 数组一维数组1arr = &#123;&quot;Hello&quot;, &quot;World&quot;&#125; 多维数组1arr = &#123;&quot;Hello&quot;,&#123;&quot;Hello&quot;,&quot;Lua&quot;&#125;&#125; 迭代器泛型for迭代器泛型 for 在自己内部保存迭代函数，实际上它保存三个值：迭代函数、状态常量、控制变量。 泛型 for 迭代器提供了集合的 key/value 对，语法格式如下：123for k, v in pairs(t) do print(k, v)end 下面我们看看泛型 for 的执行过程： 首先，初始化，计算in后面表达式的值，表达式应该返回泛型 for 需要的三个值：迭代函数、状态常量、控制变量；与多值赋值一样，如果表达式返回的结果个数不足三个会自动用nil补足，多出部分会被忽略。 第二，将状态常量和控制变量作为参数调用迭代函数（注意：对于for结构来说，状态常量没有用处，仅仅在初始化时获取他的值并传递给迭代函数）。 第三，将迭代函数返回的值赋给变量列表。 第四，如果返回的第一个值为nil循环结束，否则执行循环体。 第五，回到第二步再次调用迭代函数 无状态迭代器无状态的迭代器是指不保留任何状态的迭代器，因此在循环中我们可以利用无状态迭代器避免创建闭包花费额外的代价。 每一次迭代，迭代函数都是用两个变量（状态常量和控制变量）的值作为参数被调用，一个无状态的迭代器只利用这两个值可以获取下一个元素。这种无状态迭代器的典型的简单的例子是ipairs，它遍历数组的每一个元素 多状态迭代器很多情况下，迭代器需要保存多个状态信息而不是简单的状态常量和控制变量，最简单的方法是使用闭包，还有一种方法就是将所有的状态信息封装到table内，将table作为迭代器的状态常量，因为这种情况下可以将所有的信息存放在table内，所以迭代函数通常不需要第二个参数。 table (表)table是Lua的一种数据结构来帮助我们创建不同的数据类型Lua也是通过table来解决模块、包、和对象的 表的常用操作 方法 用途 table.concat 类似于python字符串的join table.insert 在数组的指定位置插入一个值 table.remove 移除数组中的一个值 table.sort 对给定的table升序排序 模块与包Lua5.1开始 加入了标准的模块管理机制Lua的模块是由变量和函数等元素组成的table, 最后返回这个table就可以了test.lua123456789module = &#123;&#125;function module.max(x,y) if (x &gt; y) then return x else return y endendreturn module 引入也很简单1234require(&quot;test&quot;)module.max(2,3) --&gt; 引入的是模块return的名字test = require(&quot;test&quot;) --&gt; 也可以这样将模块重命名test.max(2,3) 模块加载路径Lua内使用package.path可以看到默认的搜索路径如果找不到lua模块 则会去调用C库 使用package.cpath可以查看 也可以使用环境变量LUA_PATH来设置lua的搜索路径C库的环境变量是LUA_CPATH 元表 (Matatable)感觉像是python类的魔法方法，可以自己修改table的各种行为，比如两个table相加，又有点像JavaScript的原型链 高级话题 以后再研究 协程Lua 协同程序(coroutine)与线程比较类似：拥有独立的堆栈，独立的局部变量，独立的指令指针，同时又与其它协同程序共享全局变量和其它大部分东西。 基本语法 方法 描述 coroutine.create 创建coroutine,参数是一个函数 coroutine.resume 重启coroutine，和create配合使用 coroutine.yield 挂起coroutine，将coroutine设置为挂起状态 coroutine.status 查看coroutine的状态 coroutine.wrap 也是创建一个coroutine coroutine.running 返回正在运行的coroutine 高级话题 用到的时候再研究 文件IOLua的IO库用于读取和处理文件 分为简单模式和完全模式 简单模式 拥有一个当前输入和输出文件，并且提供针对文件的相关操作 它以一种面对对象的形式，将所有的文件操作定义为文件句柄的方法 打开文件操作语句如下1file = io.open (filename [, mode]) 其中mode和python的文件打开方式一摸一样 不再多说 简单模式读取文件内容1234file = io.open(&quot;/etc/passwd&quot;,&quot;r&quot;)io.input(file) --&gt; 设置输入文件为fileio.read(10) --&gt; 读取10个字节 默认是读取一行io.close(file) --&gt; 关闭文件 写入文件内容1234file = io.open(&quot;/tmp/lua&quot;,&quot;a&quot;) --&gt; 如果是w模式 文件存在则会清空文件io.output(file)io.write(&quot;Hello\n&quot;)io.close(file) io.read有多种参数 模式 描述 “*n” 读取一个数字并返回它 “*a” 读取全部内容 “*l” 读取下一行 默认行为 number 按照字节读取 其他的io方法 方法 描述 io.tmpfile 返回一个临时文件 “a”模式打开 io.type(file) 检测obj是否是个可用的文件句柄 io.flush 向文件写入缓冲中的所有数据 io.lines 返回一个迭代函数 每次调用返回一行 完全模式通常我们会在同一时间处理多个文件 简单模式就不够用了 文件读写123456f1 = io.open(&quot;/etc/passwd&quot;,&quot;r&quot;)f1:read() --&gt; 没看错 就是: f1:close()f2 = io.open(&quot;/tmp/lua&quot;,&quot;w&quot;)f2:write(&quot;Hi!\n&quot;)f2:close() 其他方法 模式 描述 file:seek 获取和设置当前文件指针 file:flush 将缓冲区输入写入到文件 错误处理assert 和 error123456function add(a,b) assert(type(a) == &quot;number&quot;, &quot;a 不是一个数字&quot;) assert(type(b) == &quot;number&quot;, &quot;b 不是一个数字&quot;) return a+bendadd(10) 实例中assert首先检查第一个参数，若没问题，assert不做任何事情；否则，assert以第二个参数作为错误信息抛出。12345function add(a,b) error(&quot;错误了&quot;) return a+bendadd(10) error更像是python的raise 主动抛出一个异常 pcall 和 xpcallLua中处理错误，可以使用函数pcall来包装需要执行的代码。 pcall传入需要运行的函数和函数的参数，如果函数运行的有错误就返回false 否则返回true 所以可以用if进行判断和处理 12pcall(function(i) print(i) end, 33)pcall(function(i) print(i) error(&quot;error&quot;) end, 33) xpcall可以接收一个错误处理函数来查看错误发生时的调用栈 1xpcall(function(i) print(i) error(&apos;error..&apos;) end, function() print(debug.traceback()) end, 33) xpacall的第二个参数是传入了一个错误处理函数 可以在这个函数中使用debug库获取错误的额外信息了 debug.debug 提供一个Lua提示符 让用户来检查错误的原因 debug.traceback 根据调用栈来构建一个扩展的错误信息 debug 调试 未完待续。。。 垃圾回收 未完待续。。。 面向对象 未完待续。。。]]></content>
      <categories>
        <category>Lua</category>
      </categories>
      <tags>
        <tag>Lua</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Leanote开源云笔记搭建]]></title>
    <url>%2F2018%2F01%2F02%2F2018%2FLeanote%E5%BC%80%E6%BA%90%E4%BA%91%E7%AC%94%E8%AE%B0%E6%90%AD%E5%BB%BA%2F</url>
    <content type="text"><![CDATA[简介 Leanote是一款开源的云笔记和博客系统 可以很方便的搭建自己的云笔记。在自己的云主机上搭建了Leanote后 就可以抛弃某云笔记了。而且还自带一套博客系统 写好的笔记可以一键生成到博客空间。Leanote还支持注册（注册功能可以关闭）或者手动添加用户，可以让好友也一起用的哦。Github地址: https://github.com/leanote/leanote 安装步骤 下载 leanote 二进制版。 安装和启动 mongodb。 导入初始数据。 配置 leanote。 运行 leanote。 下载 leanote 二进制版 下载地址: http://leanote.org/#download 下载后将压缩包解压到目录中 linux为例 12tar xf leanote-linux-amd64-v2.6.bin.tar.gz -C /usr/local/ls /usr/local/leanote/ 安装和启动 mongodb 可以使用包管理器下载比如apt或者yum 也可以从mongodb官方下载二进制包 1234567wget https://fastdl.mongodb.org/linux/mongodb-linux-x86_64-3.0.1.tgztar xf mongodb-linux-x86_64-3.0.1.tgz -C /usr/local/mv /usr/local/&#123;mongodb-linux-x86_64-3.0.1,mongodb&#125;mkdir /usr/local/mongodb/data/usr/local/mongodb/bin/mongod --dbpath /usr/local/mongodb/data/ &amp;&gt;&gt;/tmp/mongod &amp;/usr/local/mongodb/bin/mongo&gt; show dbs # 进入mongo cli后 查看所有库 导入初始数据 初始数据存放在 /usr/local/leanote/mongodb_backup/leanote_install_data/ 中 12/usr/local/mongodb/bin/mongorestore -h localhost -d leanote --dir \/usr/local/leanote/mongodb_backup/leanote_install_data/ 输出没有异常的话可以重新进入 mongo cli 然后 show dbs 看看是否存在leanote库了 配置 leanote 默认leanote已经存在两个用户 用户 密码 admin abc123 demo@leanote.com demo@leanote.com 编辑 /usr/local/leanote/conf/app.conf 文件 修改app.secret 可以随便更改几个字符串 1vim /usr/local/leanote/conf/app.conf 默认启动端口啥的 也看着改吧 运行 leanote12cd /usr/local/leanote/bin/bash run.sh 修改配置文件的http.addr为0.0.0.0可以外部访问leanote服务接下来就可以浏览器访问Leanote这个专为IT人员打造的云笔记系统了。 备注Leanote官网：https://leanote.com/可以在官网下载Windows客户端 还可以登录到自己搭建的私网leanote服务器]]></content>
      <categories>
        <category>Leanote</category>
      </categories>
      <tags>
        <tag>Leanote</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Linux挂载多分区的img镜像文件]]></title>
    <url>%2F2018%2F01%2F02%2F2018%2FLinux%E6%8C%82%E8%BD%BD%E5%A4%9A%E5%88%86%E5%8C%BA%E7%9A%84img%E9%95%9C%E5%83%8F%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[简介 有时候想挂载一个img镜像文件到系统目录，发现无法挂载。使用fdisk命令查看镜像结构 发现有多个分区，这个时候需要将所有分区映射为设备文件后才可以挂载。这个用处好像不太多 这个问题是当时为了修改树莓派的ubuntu镜像文件才用的。或者想自己制作一个linux启动镜像的时候可以玩玩。 环境 当然是在linux下进行操作了 步骤先看看loop设备已经映射了哪些镜像1losetup -a 将loop设备和img镜像绑定1losetup /dev/loop0 ubuntu-16.04.3.img 将loop0的所有分区映射出来1kpartx -av /dev/loop0 root@ubuntu-Lenovo:/home/ubuntu# kpartx -av /dev/loop0 add map loop0p1 (253:0): 0 262144 linear 7:0 8192 add map loop0p2 (253:1): 0 7540736 linear 7:0 270336 将用到的分区挂载到目录1mount /dev/mapper/loop0p2 /mnt/pi/ 需要注意的是映射的设备文件在/dev/mapper/目录下 卸载12umount /mnt/pi/losetup -d /dev/loop0 后记img镜像里面装个系统 就可以使用qemu等虚拟机启动了 挺好玩的如果遇到无法umount的问题 可以直接使用 fuser -ka /mnt/pi/ 强制卸载]]></content>
      <categories>
        <category>Linux</category>
      </categories>
      <tags>
        <tag>Linux</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Subversion(SVN)安装使用]]></title>
    <url>%2F2017%2F12%2F22%2F2017%2FSubversion(SVN)%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8%2F</url>
    <content type="text"><![CDATA[简介 SVN是Subversion的简称，是一个开放源代码的版本控制系统，相较于RCS、CVS，它采用了分支管理系统，它的设计目标就是取代CVS。互联网上很多版本控制服务已从CVS迁移到Subversion。说得简单一点SVN就是用于多个人共同开发同一个项目，共用资源的目的 环境系统环境 是在 CentoOS 6.8 上部署的 软件环境 源码包 版本 下载地址 Subversion 1.9.7 点击下载 Sqlite 3.2.1 点击下载 步骤安装依赖1yum install -y make gcc apr-devel apr-util-devel zlib-devel 编译安装12345678tar xf subversion-1.9.7.tar.bz2mkdir subversion-1.9.7/sqlite-amalgamation/tar xf sqlite-autoconf-3210000.tar.gz -C subversion-1.9.7/sqlite-amalgamation/./configure --prefix=/usr/local/subversionmake -j4 &amp;&amp; make installecho &apos;export PATH=$PATH:/usr/local/subversion/bin&apos; &gt; /etc/profile.d/subversion.shsource /etc/profile.d/subversion.sh 配置和使用12cd /data/svn/confecho &quot;svn = svn&quot; &gt; passwd # 修改passwd文件 添加用户和密码 格式：user = password 修改 authz 对svn用户配置访问权限 在文件末尾添加： [/] svn = rw * = r 修改 svnserve.conf 文件 [general]配置块添加以下内容 anon-access = read auth-access = write password-db = passwd authz-db = authz realm = mysvn svnserve -d -r /date/ 启动svn服务-d daemon模式 -r指定svn根目录比如指定/data为根 那么访问svn目录就是svn://ip/svn了/data下可以用svnadmin创建多个不同的svn目录 每个目录的配置都可以不同也可以直接将-r 指定为/data/svn 那访问snv://ip 就直接访问这个目录了-X 前台启动 --listen-port 更改监听端口号 默认3690 附录Windows的svn客户端可以使用TortoiseSVN官方地址：https://tortoisesvn.net/]]></content>
      <categories>
        <category>SVN</category>
      </categories>
      <tags>
        <tag>SVN</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python3编译安装]]></title>
    <url>%2F2017%2F12%2F21%2F2017%2FPython3%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介 Python是一种面向对象的解释型计算机程序设计语言，由荷兰人Guido van Rossum于1989年发明，第一个公开发行版发行于1991年。Python是纯粹的自由软件， 源代码和解释器CPython遵循GPL协议。Python的用处如今已经非常强大，人工智能、数据处理、Web后端、爬虫、运维等都能见到Python的身影。 环境系统环境 在 CentoOS 6.8 上编译的 软件环境 源码包 版本 下载地址 Python 3.6.4 点击下载 步骤安装依赖 Python的某些模块可以按需编译 比如tkinter sqlite3等 如果不安装它的devel包 Python编译过程中将忽略此模块 12yum -y install make gcc gcc-c++ zlib-devel bzip2-devel gdbm-devel \xz-devel tk-devel readline-devel sqlite-devel ncurses-devel openssl-devel 开始编译 解压源码包后进入源码目录 123./configure --enable-optimizations --prefix=/usr/local/python3 --enable-sharedsed -i &apos;s/test.regrtest/this/g&apos; Makefile # 此步骤屏蔽单元测试（耗时太长）make -j4 在make的过程中 如果有标准库中的模块依赖没有找到 标准输出会有显示 内容可能如下 Python build finished successfully! The necessary bits to build these optional modules were not found: _bz2 _curses _curses_panel _dbm _gdbm _lzma _sqlite3 _ssl _tkinter readline zlib To find the necessary bits, look in setup.py in detect_modules() for the module&apos;s name. 安装好相应的模块的devel包后 不需要重新configure 重新make即可 安装使用12345make install echo &apos;export PATH=$PATH:/usr/local/python3/bin&apos; &gt; /etc/profile.d/python3.shecho &apos;/usr/local/python3/lib&apos; &gt; /etc/ld.so.conf.d/python3.confldconfigsource /etc/profile.d/python3.sh 卸载 删除安装目录就可以了 123rm -rf /usr/local/python3/rm -rf /etc/profile.d/python3.shrm -rf /etc/ld.so.conf.d/python3.conf 附录如果不提前把Python的依赖安装好 虽然可以编译成功 但是会缺少不少的模块]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Galera集群编译安装]]></title>
    <url>%2F2017%2F08%2F06%2F2017%2FGalera%E9%9B%86%E7%BE%A4%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介 Galera是一种新型的高一致性MySQL集群架构，集成了Galera插件的MySQL集群，是一种新型的，数据不共享的，高度冗余的高可用方案。当有客户端要写入或者读取数据时，随便连接哪个实例都是一样的，读到的数据是相同的，写入某一个节点之后，集群自己会将新数据同步到其它节点上面，这种架构不共享任何数据，是一种高冗余架构。 环境系统环境 系统使用 CentOS 6.8 软件环境 源码包 版本 下载地址 mysql-wsrep None 点此自行选择合适的版本下载 步骤 建议查看官方文档：http://galeracluster.com/documentation-webpages/installmysqlsrc.html 安装编译环境12yum -y install make gcc-c++ gcc cmake bison-devel ncurses-devel perl bison git automake \autoconf libaio libaio-devel scons boost boost-devel openssl-devel openssl check check-devel 编译mysql 自行下载集成wsrep补丁的MySQL后解压 这里使用MySQL 5.6的版本 1234567cmake \-DCMAKE_INSTALL_PREFIX=/usr/local/mysql \-DMYSQL_DATADIR=/usr/local/mysql/data \-DSYSCONFDIR=/etc \-DWITH_WSREP=ON -DWITH_INNODB_DISALLOW_WRITES=ON ./make -j10 &amp;&amp; make install 编译galera插件123456git clone https://github.com/codership/galera.gitcd galerasconsstrip libgalera_smm.so # 裁剪库文件无用的调试信息 减小文件体积mv libgalera_smm.so /usr/local/mysql/lib/plugin/# 编译过程耗时较长 可以继续下面的步骤 初始化mysql运行环境12345678910111213useradd mysql -M -s /sbin/nologinchown -R mysql:mysql /usr/local/mysqlcp support-files/mysql.server /etc/init.d/mysqldchmod +x /etc/init.d/mysqldcd /usr/local/mysqlstrip bin/* lib/* lib/plugin/* # 同样进行裁剪scripts/mysql_install_db --datadir=/usr/local/mysql/data/ --user=mysqlecho /usr/local/mysql/lib &gt; /etc/ld.so.conf.d/mysql5.6.confldconfig -v |grep /usr/local/mysql/lib # 查看/usr/local/mysql/lib是否被加入到系统运行库中echo &apos;export PATH=$PATH:/usr/local/mysql/bin&apos; &gt; /etc/profile.d/mysql5.6.shsource /etc/profilemkdir -p /etc/mysql/conf.dmkdir /var/lib/mysql 修改配置文件修改 /etc/my.cnf [mysql] !includedir /etc/mysql/conf.d/ 编辑 /etc/mysql/conf.d/my_galera.cnf [mysql] #设置mysql client default character default-character-set=utf8 no-auto-rehash prompt=&quot;\\u@\\h:\\d \\r:\\m:\\s&gt;&quot; [mysqld] user=mysql bind-address=0.0.0.0 character-set-server=utf8 default-storage-engine=INNODB default-time-zone=&apos;+8:00&apos; datadir=/usr/local/mysql/data/ socket=/usr/local/mysql/data/mysql.sock skip-name-resolve #slow query slow_query_log=on log_output=FILE slow_query_log_file=slow_query.txt long_query_time=1 max_connections=5000 table_open_cache=2048 sort_buffer_size=8M thread_cache_size=16 #query_cache_size=32M #galera: Do not use query cache # Try number of CPU&apos;s*2 for thread_concurrency thread_concurrency=8 #MyISAM key_buffer_size=512M read_buffer_size=8M read_rnd_buffer_size=8M #InnoDB innodb_buffer_pool_size=1G innodb_additional_mem_pool_size=20M #galera innodb参数 binlog_format=ROW innodb_autoinc_lock_mode=2 innodb_flush_log_at_trx_commit=0 transaction-isolation=READ-COMMITTED #galera cluster参数 wsrep_provider=/usr/local/mysql/lib/plugin/libgalera_smm.so wsrep_provider_options=&quot;gcache.size=300M; gcache.page_size=1G&quot; wsrep_sst_method=rsync wsrep_sst_auth=wsrep_sst-user:123456 wsrep_cluster_name=MyCluster wsrep_cluster_address=&quot;gcomm://&quot; wsrep_node_name=galera.node1 wsrep_node_address=&quot;172.17.0.3&quot; 注意：根据实际情况更改配置文件，第一个启动的节点wsrep_cluster_address的值为gcomm://，其他节点启动的时候要将这个值改为第一个节点的IP 比如gcomm://172.17.0.3。wsrep_node_address修改为自己的IP就好了 启动集群 先启动集群的第一个节点 也就是wsrep_cluster_address的值为gcomm://的那个节点，然后依次启动其他的就好了。 1service mysqld start 附录Galera集群好像并不是那么可靠。。。 机器的数据越多 性能的提升率就越低。 参考文章：http://www.sohu.com/a/147032902_505779]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>MySQL</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Apache编译安装]]></title>
    <url>%2F2016%2F09%2F21%2F2016%2FApache%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介Apache是世界使用排名第一的Web服务器软件。它可以运行在几乎所有广泛使用的计算机平台上，由于其跨平台和安全性被广泛使用，是最流行的Web服务器端软件之一。它快速、可靠并且可通过简单的API扩充，将Perl/Python等解释器编译到服务器中。同时Apache音译为阿帕奇，是北美印第安人的一个部落，叫阿帕奇族，在美国的西南部。也是一个基金会的名称、一种武装直升机等等 环境 软件名称 版本号 下载地址 pcre 8.39 点击下载 openssl 1.0.1s 点击下载 apr 1.5.2 点击下载 apr-util 1.5.4 点击下载 httpd 2.4.23 点击下载 步骤 需要系统先初始化开发环境 yum install -y make gcc gcc-c++ perl tar bzip2 vim 编译安装apr和apr-util apr 和 apr-util 是 httpd 的运行依赖 1234567891011# apr-1.5.2tar xf apr-1.5.2.tar.bz2cd apr-1.5.2 ./configure --prefix=/usr/local/aprmake -j4 &amp;&amp; make install# apr-util-1.5.4tar xf apr-util-1.5.4.tar.bz2cd apr-util-1.5.4./configure --prefix=/usr/local/apr-util --with-apr=/usr/local/apr/make -j4 &amp;&amp; make install 编译安装pcre pcre是一个perl的正则表达式库 httpd的rewrite需要用到 1234tar xf pcre-8.39.tar.bz2cd pcre-8.39./configure --prefix=/usr/local/pcremake -j4 &amp;&amp; make install 编译安装openssl OpenSSL 是一个强大的安全套接字层密码库 搭建https的网站需要用到 1234tar xf openssl-1.0.1s.tar.gzcd openssl-1.0.1s./config -fPIC no-sharedmake depend &amp;&amp; make install 编译安装httpd1234567891011tar xf httpd-2.4.23.tar.bz2cd httpd-2.4.23./configure --prefix=/usr/local/httpd \--enable-ssl --enable-cgi \--enable-rewrite --enable-so \--with-pcre --with-apr=/usr/local/apr \--with-apr-util=/usr/local/apr-util/ \--with-pcre=/usr/local/pcre/ \--with-ssl=/usr/local/ssl \--with-mpm=event --with-zlibmake -j4 &amp;&amp; make install 运行httpd httpd默认运行用户是daemon 若不存在需要先创建 也可以在配置文件中重新指定运行用户 1234567891011121314修改配置文件vim /usr/local/httpd/conf/httpd.conf添加：ServerName localhost不添加这行配置 httpd服务也是可以正常启动的 但是会弹出提示然后就可以启动httpd服务了/usr/local/httpd/bin/httpd检查httpd是否正常监听netstat -anpt |grep httpdtcp 0 0 :::80 :::* LISTEN 51272/httpd通过浏览器访问服务器 看是否出现了大大的 It works! 附录httpd的主要目录作用 ls /usr/local/httpd/ bin build cgi-bin conf error htdocs icons include logs man manual modules bin: 存放着apache提供的一些小工具和httpd主程序 cgi-bin: 存放cgi脚本的目录 conf: 存放httpd的配置文件 主配置文件为httpd.conf htdocs: web的默认根目录 存放网页文件 logs: 存放着httpd的访问日志 错误日志 以及pid文件 modules: 存放着httpd动态编译的模块 比如刚才的openssl就被编译为了mod_ssl.so]]></content>
      <categories>
        <category>Apache</category>
      </categories>
      <tags>
        <tag>Apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Python爬虫入门]]></title>
    <url>%2F2016%2F07%2F25%2F2016%2FPython%E7%88%AC%E8%99%AB%E5%85%A5%E9%97%A8%2F</url>
    <content type="text"><![CDATA[简介 网络爬虫是一个自动提取网页的程序，它为搜索引擎从万维网上下载网页，是搜索引擎的重要组成。比如百度 google等搜索引擎通过程序爬取你的个人网站，然后建立索引 这样别人就可以通过搜索关键字找到你的网站了。爬虫的意义不仅如此 还可以做更多好玩的事情。 步骤 用Python写网络爬虫是非常简单的 大致需要学习以下知识点 了解HTTP协议 以及HTML标签等 掌握Python的基本语法 学习Python的urllib, urllib2等模块 学习正则表达式 或者XPath 使用Python爬虫框架帮助开发 学习网络爬虫 也有人称之为网络蜘蛛 互联网是一张大网 每个人都可以在上面搭建网站 平常我们用的百度搜索的所有内容 都是百度曾经访问过的内容 然后保存下来 建立了索引 这样才能供用户查询 能快速的找到自己想要的资源 而百度去访问这些网站资源 肯定不可能人工手动去访问然后记录 背后都是一个一个的程序去抓取网页 然后根据这个网页继续往下抓取 直到收集到需要的信息 就像一个爬虫或蜘蛛 在这张大网上爬来爬去一样 来自互联网的流量 有不小的一部分并不是人为访问的 而是各大搜索引擎的爬虫程序 可以写爬虫的语言非常多 但是因为python的简单 方便 越来越多的人使用python来写爬虫 也出现了各种优秀的爬虫框架 下面将由浅入深 一步一步的学习 如和使用python来写一个爬虫 了解HTTP协议 HTTP 全称 HyperText Transfer Protocol(超文本传输协议)，设计之初就是为了提供一种收发HTML页面的方法 下面详细看看一个URL是如何组成的 URL的含义 URL是URI的子集 关于URI的相关内容 这里不再解释 具体可以问度娘。URL 全称Universal Resource Identifier(统一资源定位符) 结构组成如下 比如我们看这样一个URL http://dev.mysql.com/get/Downloads/MySQL-5.6/mysql-5.6.28.tar.gz http://部分是协议部分还有类似的https, ftp, mailto, file等 作用是让程序知道如和处理要打开的资源 dev.mysql.com 部分是主机名或者IP 还可以加端口号 用:隔开 比如dev.mysql.com:8080 默认的端口是80 /get/Downloads/MySQL-5.6/mysql-5.6.28.tar.gz 就是服务器上的文件资源基于web根目录的绝对路径了 一次完整的HTTP请求 浏览器输入URL 比如 http://www.baidu.com/ 向DNS服务器查询www.baidu.com的IP地址 然后连接这个IP地址的80端口 如果成功连接到了80端口 浏览器发起http请求(Request) 通过GET方法 访问服务器的/ 服务器收到请求 如果是静态资源 比如图片之类的 读取文件后相应(Response)给客户端 如果请求的是.jsp或者.php等脚本 将由相应的后端程序处理 然后将生成的html页面返回给客户端 一次请求完成 服务端主动关闭连接 客户端解析获取的html页面 然后继续发起其他资源的请求 如果请求失败 服务器会有一个返回码 正常状态的返回码都是200 比如还有较为常见的404等 HTTP协议 HTTP协议的重点就在客户机发送的Request 和服务端返回的Response上 他们是按照怎样的格式发送的呢 Request： GET /login.html HTTP/1.1 Host: www.abc.com Connection: keep-alive Referer: www.abc.com User-Agent: Python-urllib/2.7 GET 是HTTP方法 常用的还有POST方法 通过GET方法传递的参数直接编码为URL的一部分 比如/login.html?user=username&amp;passwd=password 请求login.html的同时传递了user和passwd两个参数 而POST方法则不会 所以POST适合于密码传输 而且POST传递的数据没有大小限制 适合传递较大的文件 Referer字段标识这个请求时从哪个链接上发起的 服务端可以通过此字段设置防盗链 也是爬虫需要注意的 User-Agent字段是客户机标识自己的身份 有时候服务端会限制一些User-Agent的访问 但是爬虫可以伪装 Response： HTTP/1.1 200 OK Date: Mon, 25 Jul 2016 12:59:31 GMT Content-Length: 10901 Content-Type: text/html 200的返回的状态码 OK是简单的描述 常见的400以上的错误为客户端请求的错误 500以上为服务端错误 Content-Length字段告诉客户端响应内容主体的大小 Content-Type字段告诉客户端返回内容的类型 比如图片的就是image/png 还有非常多的类型 Request和Response的还有非常多的字段 暂时先简单了解下即可 下面开始进入正题 urllib库的基本使用 用爬虫挖掘数据的三个步骤: 获取网页数据 --&gt; 从数据中检索需要的数据 --&gt; 将数据保存入库先来研究爬虫的第一步 获取网页数据。python获取网页数据的标准库有urllib2 还有一些非常好用的第三方库 比如requests库 python的urllib库有两个 一个是urllib 另一个是urllib2 这两个库并不是可以互相替代的关系 反而是互补的关系 下面看一个最简单的爬虫 第一个简单的爬虫1234import urllib2response = urllib2.urlopen("http://www.baidu.com/")print response.codeprint response.read() 200 &lt;!DOCTYPE html&gt;&lt;!--STATUS OK--&gt;&lt;html&gt;&lt;head&gt;&lt;meta http-equiv=&quot;content-type&quot; ...... urllib2.urlopen类可以发起一个request的请求 用它打开链接就相当于浏览器请求一样 response.code是响应的状态码 response.read()则读取了访问baidu后获取的网页源代码 下面看看urlopen()类的常用参数 1urllib2.urlopen(url, data=None, timeout=socket) url参数 顾名思义 就是要访问的地址 这个参数还可以是一个urllib2.Request的对象 下面会讲到 默认urlopen使用了GET方法 如果给urlopen提供了data参数 则urlopen将使用POST方法提交数据 timeout则是访问超时时间 超过多长时间后如果还没有等到服务器响应数据 则抛出URLError异常 手动构造Request 手动构造Request的好处就是自己可以添加或修改Request的字段 比如修改User-Agent把自己伪装为浏览器去访问页面 urllib2访问网页的默认User-Agent是Python-urllib/2.7 1234import urllib2request = urllib2.Request("http://www.baidu.com/")response = urllib2.urlopen(request)print response.read() Request类允许用户自定义请求头部(header), 同样Request默认使用的也是GET方法 下面看看Request用法 1urllib2.Request(url, data=None, headers=&#123;&#125;) 如果给Request提供了data的值 那么请求将变成POST Headers信息修改 为了直观的看到headers的变化 我们先用socket模块 模拟一个web服务器出来 1234567891011121314#!/usr/bin/env pythonimport sockets = socket.socket(socket.AF_INET,socket.SOCK_STREAM)s.bind(('0.0.0.0',8080))s.listen(5)print 'Listen on 0.0.0.0:8080...'try: while True: conn,addr = s.accept() print conn.recv(99999) conn.send('HTTP/1.1 200 OK\r\nContent-Type: text/html\r\n\r\n&lt;h1&gt;Hello!&lt;/h1&gt;') conn.close()except: s.close() 将这个脚本启动 先确定8080端口未被占用 或者自行修改端口 接着尝试用urllib2打开这个地址 GET / HTTP/1.1 Accept-Encoding: identity Host: 192.168.4.233:8080 Connection: close User-Agent: Python-urllib/2.7 可以看到脚本输出了这样的信息 这个就是服务接受到urlopen发送的数据 可以看到是GET请求 有很多web网站为了防止爬虫的访问 做了User-Agent检查 如果发现不是正规浏览器访问的就会拒绝掉 那么现在尝试着修改下User-Agent的值 123456import urllib2headers = &#123; 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/47.0.2526.106 BIDUBrowser/8.5 Safari/537.36' &#125;request = urllib2.Request('http://192.168.4.233:8080',headers=headers)response = urllib2.urlopen(request) 可以将创立好的headers字典传递给Request的headers参数 也可以创建完Request对象后 手动将headers字典赋值给request.headers属性 或者通过request对象的add_header方法添加 12request.headers = headers # 或者request.add_header('User-Agent','Mozilla/5.0 (Windows NT 10.0; WOW64)......') 以上两种方法是等效的 但是不同的是 add_header只能一次添加一个头部字段 而通过传递字典可以添加多个比如我们可以针对做了防盗链处理的网站服务器 在request中添加Referer字段 表明示从那个页面发起访问的 1234567import urllib2headers = &#123; 'User-Agent':'Mozilla/5.0 (Windows NT 10.0; WOW64)......', 'Referer': '192.168.4.233:8080' &#125;request = urllib2.Request('http://192.168.4.233:8080',headers=headers)response = urllib2.urlopen(request) 接下来可以看到打印的headers中的User-Agent已经改变了 而且多了Referer字段 GET / HTTP/1.1 Accept-Encoding: identity Host: 192.168.4.233:8080 Referer: 192.168.4.233:8080 Connection: close User-Agent: Mozilla/5.0 (Windows NT 10.0; WOW64)...... 各大浏览器的User-Agent的值可以通过百度查询得到 也可以在浏览器中 通过开发者模式的network里查到 GET和POST方法传递数据 如果仅仅访问静态页面 简单的GET请求数据就可以了 但是现在大多的网站都是动态网站 需要向服务器传递一些数据才能获取想要的页面 比如有些页面必须登陆才可以浏览等 下面就看看如何使用urllib发送GET和POST请求 接下来就需要使用urllib模块中的urlencode方法对数据进行编码为适合在HTTP上传输的类型了 GET方法： 1234567import urllib, urllib2values = &#123;'user':'myusername','passwd':'11223344'&#125;data = urllib.urlencode(values)url = 'http://192.168.4.233:8080/login?'request = urllib2.Request(url+data)response = urllib2.urlopen(request)print response.read() GET /login?passwd=11223344&amp;user=myusername HTTP/1.1 Accept-Encoding: identity Host: 192.168.4.233:8080 Connection: close User-Agent: Python-urllib/2.7 最后我们实际请求的URL是 http://192.168.4.233:8080/login?passwd=11223344&amp;user=myusername 用?分隔服务器资源和向资源传递的参数 参数中用key=value的方式 两个key之间用&amp;隔开 如果value中有特殊字符了 比如空格 = 等特殊字符怎么处理 详细资料可以看urlencode和urldecode GET方法直接将需要传递的数据构造为URL的一部分 如果传送密码这样敏感的数据当然是不可以的 接下来就用到POST方法了 POST方法： 1234567import urllib, urllib2values = &#123;'user':'myusername','passwd':'11223344'&#125;data = urllib.urlencode(values)url = 'http://192.168.4.233:8080/login' # 因为不是GET方法 所以不需要?号分隔了request = urllib2.Request(url,data) # 注意是逗号隔开的 实际上是将data传递给了参数dataresponse = urllib2.urlopen(request)print response.read() 可以看到这回构造的request和GET方法构造的有很大不同 POST /login HTTP/1.1 Accept-Encoding: identity Content-Length: 31 Host: 192.168.4.233:8080 Content-Type: application/x-www-form-urlencoded Connection: close User-Agent: Python-urllib/2.7 passwd=11223344&amp;user=myusername 可以看到 多了Content-Length和Content-Type两个字段 一个说明内容的长度 一个说明内容类型 而且数据内容并不是直接显示在URL中的 这样就适合传送比较大的数据或者比较敏感的数据 还有一点需要注意 POST请求传递的数据可以是任意格式的 并不一定非要是通过urlencode编码后的数据 比如直接传输一个二进制文件 request = urllib2.Request(url,data=open(&apos;/bin/bash&apos;,&apos;rb&apos;).read()) 还有一个比较重要的地方就是Content-Type 这个字段决定了服务器或者客户端如和处理接收到的内容 如果传送的二进制数据 不确定类型的话 可以将Content-Type更改为application/octet-stream 具体其他类型的数据的Content-Type可以查阅 &quot;HTTP Content-type 对照表&quot; 使用Proxy访问网页 有些网站为了防止被爬虫程序 或者被Ddos攻击等 限定了单位时间内对服务器的请求次数 但是道高一尺魔高一丈 爬虫程序还是有方式绕过限制的 那就是使用代理 123456789101112import urllib2def setProxy(addr): proxy_handler = urllib2.ProxyHandler(&#123;"http" : addr&#125;) opener = urllib2.build_opener(proxy_handler) urllib2.install_opener(opener)request = urllib2.Request('http://cip.cc/')request.add_header('User-Agent','curl')print urllib2.urlopen(request).read()print '-------------proxy-------------'setProxy('122.96.xx.xxx:8080')print urllib2.urlopen(request).read() IP : 124.65.xxx.xx 地址 : 中国 北京市 运营商 : 联通 数据二 : 北京市 | 联通 URL : http://www.cip.cc/124.65.xx.xx -------------proxy------------- IP : 122.96.xx.xxx 地址 : 中国 江苏省 南京市 运营商 : 联通 数据二 : 江苏省南京市 | 联通 URL : http://www.cip.cc/122.96.xx.xxx cip.cc是个可以查询出口公网IP地址的网站 并且对curl工具的访问做了优化 所以模拟为curl工具访问 proxy_handler是使用代理的处理器 build_opener添加配置好的proxy_handler代理器 返回一个对象 这个对象也有个open方法 这个方法可以像urllib2.urlopen一样使用 不同的是只有open才会使用代理 install_opener则会创建一个全局使用的opener 也就是说 urllib2.urlopen的默认行为也会使用代理 来看下面的例子 12345678import urllib2proxy_handler = urllib2.ProxyHandler(&#123;"http" : '122.96.xx.xxx:8080'&#125;)opener = urllib2.build_opener(proxy_handler)request = urllib2.Request('http://cip.cc/')request.add_header('User-Agent','curl')print urllib2.urlopen(request).read()print '-------------opener-------------'print opener.open(request).read() IP : 124.65.xxx.xx 地址 : 中国 北京市 运营商 : 联通 数据二 : 北京市 | 联通 URL : http://www.cip.cc/124.65.xx.xx -------------opener------------- IP : 122.96.xx.xxx 地址 : 中国 江苏省 南京市 运营商 : 联通 数据二 : 江苏省南京市 | 联通 URL : http://www.cip.cc/122.96.xx.xxx 可以看到效果是完全相同的 只不过opener.open是局部的 而urllib2.urlopen是全局的 通过install_opener则可以把opener.open安装为全局的 build_opener还可以安装多个不同的Handler 开启Debug日志 开启urllib的Debug日志后 每次完成一次与服务器交互 都会将打印出request和response信息 这样更方便调试错误 1234567import urllib2proxy_handler = urllib2.ProxyHandler(&#123;"http" : '122.96.xx.xxx:8080'&#125;)http_handler = urllib2.HTTPHandler(debuglevel=1)opener = urllib2.build_opener(proxy_handler, http_handler)request = urllib2.Request('http://cip.cc/')request.add_header('User-Agent','curl')print opener.open(request).read() 同时给build_opener传入了两个处理器 执行opener.open的时候 可以发现两个处理器都生效了 以下是返回数据 send: &apos;GET http://cip.cc/ HTTP/1.1\r\nAccept-Encoding: identity\r\nHost: cip.cc\r\nConnection: close\r\nUser-Agent: curl\r\n\r\n&apos; reply: &apos;HTTP/1.1 200 OK\r\n&apos; header: Server: nginx header: Date: Tue, 26 Jul 2016 04:57:13 GMT header: Content-Type: text/html; charset=UTF-8 header: Transfer-Encoding: chunked header: Connection: close header: Vary: Accept-Encoding IP : 122.96.xx.xxx 地址 : 中国 江苏省 南京市 运营商 : 联通 数据二 : 江苏省南京市 | 联通 URL : http://www.cip.cc/122.96.xx.xxx send就是发送的request 而reply就是服务器的response了 如果是https页面 则需要设置HTTPSHandler urllib2.build_opener(proxy_handler, http_handler, urllib2.HTTPSHandler(debuglevel=1)) 使用cookie模拟登陆 HTTP协议是无状态的 也就是说你这次的请求 和下次的请求并没有联系 那么这样子 服务器怎么区分用户的身份呢 那么就是cookie的作用了可以这样理解 当用户登录网站成功了 网站就给这个用户下发一个令牌 也就是cookie 下次用户再访问网站的其他页面的时候 就顺便带上令牌 那么服务器端只要区分不同的令牌就知道用户的身份了所以 cookie是一个非常方便 又同时非常危险的东西 比如我在局域网中 抓取到某人登陆某网站的cookie 然后我就可以直接使用该cookie访问这个网站 那么就实现了免密码登陆了 这也是为什么很多敏感的网站cookie的有效期这么短 下次访问就有可能需要重新登陆的原因了 下面就看看urllib如和处理cookie和cookie模拟登陆的吧 使用已有的cookie登陆百度： 已登录网站的cookie可以通过开发者模式获取 这里以Chrome内核的浏览器为例 360浏览器等都相同 一般F12都可以直接打开开发者模式 然后点击 Network 刷新下你已经登陆了的百度的首页 然后看到Network -&gt; Name块出现了一堆请求的资源 找到www.baidu.com 打开后就可以看到Headers了 找到Request Headers中的Cookie字段 可以看到一大堆的字符串 这个字符串是经过加密的 复制下来 12345import urllib2request = urllib2.Request('http://www.baidu.com/')request.add_header('Cookie','BD_CK_SAM=1; H_PS_645EC=0c53pNyqSabVK%2BP......')result = urllib2.urlopen(request).read()open('baidu.html','w').write(result) 可以将url换成tieba.baidu.com 然后去访问百度贴吧 看看保存到本地的网页是不是已经登陆状态呢 这就是最简单的用cookie模拟登陆的方法了 但是我们不可能每次都通过这种方式获取cookie吧 这就需要用程序实现如和使用账号密码登陆 然后保存cookie 然后用cookie访问其他页面 使用账号密码登陆： 这个环节其实是非常复杂的 因为现在的大多网站 为了避免爬虫等工具 登陆需要短信验证 验证码验证等 而且密码可能被先经过算法加密后才上传的 甚至登陆的步骤还有非常多的坑 开发者模式以后将经常用到 这里的例子使用了公司内部的网站实现数据自动提交 1234567891011import urllibimport urllib2import cookielibcookie = cookielib.CookieJar()cookie_handler = urllib2.HTTPCookieProcessor(cookie)opener = urllib2.build_opener(cookie_handler)login_info = urllib.urlencode(&#123;'sysName':'aabbcc','sysPsw':'112233'&#125;)resp = opener.open('http://16.190.x.xxx/sysLoginAction.jsp',data=login_info,timeout=20)post_data = 'city1=%C8%FD%D1%C7&amp;zt1=%B9%CA%D5%CF%A3%ACrds%C8%EB%BF%E2%CD%A3%D6%B9'post_url = 'http://16.190.1.207/thesisFlatRoot/save_info1.jsp?ls=0'resp = opener.open(post_url,data=post_data,timeout=20) 代码没有任何的异常捕捉 就假设可以正常的执行完毕 这里引入了新库 cookielib 这个库是专门处理cookie的库 同样也是安装给opener 然后模拟登陆后带着获取的cookie去提交数据 这个login_info是通过开发者模式中 手动登录一次网站 然后分析想后端服务器POST的什么数据 而post_data则是每天的任务中点击提交按钮实际上POST上去的数据 通过脚本就不用每天登陆提交了 CookieJar是将cookie保存到一个变量中的 还可以将Cookie保存到文件中 这样就不用每次都登陆了 将cookie保存到文件 保存cookie到文件的对象是FileCookieJar 我们使用它的子类MozillaCookieJar来实现 1234567import urllib2,cookielibcookie_file = 'cookie.txt'cookie = cookielib.MozillaCookieJar(cookie_file)cookie_handler = urllib2.HTTPCookieProcessor(cookie)opener = urllib2.build_opener(cookie_handler)response = opener.open("http://www.baidu.com/")cookie.save(ignore_discard=True, ignore_expires=True) ignore_discard的意思是即使cookies将被丢弃也将它保存下来 ignore_expires的意思是如果在该文件中cookies已经存在 则覆盖原文件写入 可以看到当前目录出现了cookie.txt 接下来就是看看如何从文件中读取cookie了 从文件中读取cookie 从文件中读取cookie可以免去每次执行脚本都重新登陆一次 除非cookie过期的情况下才需要重新登录 12345import urllib2,cookielibcookie = cookielib.MozillaCookieJar()cookie.load('cookie.txt', ignore_discard=True, ignore_expires=True)opener = urllib2.build_opener(urllib2.HTTPCookieProcessor(cookie))response = opener.open("http://www.baidu.com/") 这样如果cookie.txt中保存的是你登陆百度后的cookie 那么下次通过cookie.txt就可以直接登陆百度了 现在数据获取方面的工作已经差不多了 数据获取还有一个比较优秀的requests库 可以自行研究下 接下来就是如何从网页数据中提取我们需要的信息了 正则表达式 在编写处理字符串的程序或网页时 经常会有查找符合某些复杂规则的字符串的需要 正则表达式就是用于描述这些规则的工具 换句话说 正则表达式就是记录文本规则的代码 下面看看正则表达式的常用项 常用元字符 代码 说明 . 匹配除换行符以外的任意字符 \w 匹配字母或数字或下划线或汉字 \s 匹配任意的空白符 \d 匹配数字 ^ 匹配字符串的开始 $ 匹配字符串的结束 常用限定符 代码 说明 * 重复零次或更多次 + 重复一次或更多次 ? 重复零次或一次 {n} 重复n次 {n,} 重复n次或更多次 {n,m} 重复n到m次 常用的反义代码 代码 说明 \W 匹配任意不是字母，数字，下划线，汉字的字符 \S 匹配任意不是空白符的字符 \D 匹配任意非数字的字符 \B 匹配不是单词开头或结束的位置 [^x] 匹配除了x以外的任意字符 [^aeiou] 匹配除了aeiou这几个字母以外的任意字符 常用分组语法 代码 说明 (exp) 匹配exp,并捕获文本到自动命名的组里 (?”name”exp) 匹配exp,并捕获文本到名称为name的组里 (?:exp) 匹配exp,不捕获匹配的文本，也不给此分组分配组号 (?=exp) 匹配exp前面的位置 (?&lt;=exp)&lt; span=””&gt; 匹配exp后面的位置 (?!exp) 匹配后面跟的不是exp的位置 (? 匹配前面不是exp的位置 (?#comment) 提供注释让人阅读 懒惰限定符 代码 说明 *? 重复任意次，但尽可能少重复 +? 重复1次或更多次，但尽可能少重复 ?? 重复0次或1次，但尽可能少重复 {n,m}? 重复n到m次，但尽可能少重复 {n,}? 重复n次以上，但尽可能少重复 简单用法 用最简单的例子 看看正则表达式在网页中如何匹配需要的信息 123456789101112131415&lt;html lang="cn"&gt; &lt;head&gt; &lt;title&gt;regex&lt;/title&gt; &lt;meta charset="utf-8"&gt;&lt;/meta&gt; &lt;/head&gt; &lt;body alink="red" bgcolor="black" vlink="yellow" text="blue"&gt; &lt;h1&gt;subject&lt;/h1&gt; &lt;hr size="10px" width="50%" /&gt; &lt;a href="http://127.0.0.1:5000/a.html"&gt; &lt;img src="img/123.jpg" width="140" height="100" alt="image"/&gt; &lt;/a&gt; &lt;a href="http://127.0.0.1/b.html"&gt;page1&lt;/a&gt;&lt;br /&gt; &lt;a href="http://127.0.0.1/c.html"&gt;page2&lt;/a&gt; &lt;/body&gt;&lt;/html&gt; 在python中 正则表达式的库是re库 现在只需要简单掌握re.findall的用法 12import reprint re.findall(r'&lt;title&gt;(.*?)&lt;/title&gt;',html) re.findall的用法是 re.findall(pattern, string, flags) 匹配的结果是 [&apos;regex&apos;] 这是一个列表 如果有多个符合条件的字符串 都会出现在列表内 html就是上面的那段html代码 r&apos;&lt;title&gt;(.*?)&lt;/title&gt;&apos; 就是用来匹配网页title的正则表达式 这里用到了()分组匹配 匹配被&lt;title&gt;和&lt;/title&gt;包裹的内容 .*?则是非贪婪模式匹配 如果需要匹配的字符有元字符等特殊字符 就需要用 \ 进行转义 比如匹配baidu.com就需要 baidu\.com 因为\是转义字符 如果要匹配\字符或者\b(数字) 就需要写成 \\ 和 \\b 这样带来了非常多的不便 所以在字符串的前面加入 r&apos;&apos; 表示原生字符串 就可以写成 r&apos;\&apos; 和 r&apos;\b&apos; 这样就完美的解决了问题 123import rere.findall('&lt;a href=".*?"&gt;.*?&lt;/a&gt;',html)re.findall('&lt;a href="(.*?)"&gt;(.*?)&lt;/a&gt;',html) 匹配的结果是 [&apos;&lt;a href=&quot;http://127.0.0.1/b.html&quot;&gt;page1&lt;/a&gt;&apos;, &apos;&lt;a href=&quot;http://127.0.0.1/c.html&quot;&gt;page2&lt;/a&gt;&apos;] [(&apos;http://127.0.0.1/b.html&apos;, &apos;page1&apos;), (&apos;http://127.0.0.1/c.html&apos;, &apos;page2&apos;)] 现在能深深的体会到()的重要性了吧 会对()内的字符串自动分组 但是有个奇怪的地方 好像有个链接丢失了 html中一共有三个&lt;a&gt;标签 但是只匹配到两个 仔细观察发现 第一个&lt;a&gt;标签和闭合标签&lt;/a&gt;不在同一行 因为 . 这个元字符匹配除换行符以外的任意字符 因为第一个&lt;a&gt;和&lt;/a&gt;被换行符隔断了 所以匹配不到 这时就需要用到flags这个参数了 比如re.I 忽略大小写 re.S 使 . 元字符完全匹配任何字符 12import rere.findall('&lt;a href="(.*?)"&gt;(.*?)&lt;/a&gt;',html,re.S) [(&apos;http://127.0.0.1:5000/a.html&apos;, &apos;\n &lt;img src=&quot;img/123.jpg&quot; ...... 可以看到 所有的&lt;a&gt;标签都被匹配到了 re还有许多的匹配方法 比如re.finditer re.sub re.search re.match等 可以自行学习 实战爬取数据 现在获取网页数据的方式和正则表达式都已经有了一定的了解 那就开始实际的爬取些有意思的东西 千趣网专题爬取 千趣网是个分享有意思新闻的网站 不需要登陆就可以浏览内容 也没有什么防爬措施 所以先拿它练手 1234567891011121314151617181920212223242526272829303132333435363738394041424344454647484950515253545556#!/usr/bin/env python# -*- coding:utf-8 -*-import reimport urllib2HOST = 'http://www.qianqu.cc' # 要爬的网站def getHTML(url): # 获取网页源码 request = urllib2.urlopen(url,timeout=5) return request.read()def makeUrl(baseUrl): # 用来构造每一页的URL地址 def getPageNum(): # 获取每个专栏有多少页 html = getHTML(baseUrl.format(1)) return int(re.findall(r'pages: (.*?),',html,re.S)[0]) for i in range(1,getPageNum()+1): yield baseUrl.format(i) # 返回一个可迭代的对象来节省内存def getTitle(url): # 获取一页有多少文章 返回文章的标题和URL request = urllib2.urlopen(url) html = request.read() div = re.findall(r'&lt;div class="article"&gt;(.*?)&lt;/div&gt;',html,re.S) for i in div: try: result = re.findall(r'&lt;a href="(.*?)".*&lt;/a&gt;.*&lt;p&gt;(.*?)&lt;/p&gt;.*',i,re.S)[0] except: raise StopIteration yield (HOST+result[0],result[1])def getContext(url): # 根据获取到的文章URL检索出内容 request = urllib2.urlopen(url) html = request.read() div = re.findall(r'&lt;div class="contentText"&gt;(.*?)&lt;/div&gt;',html,re.S)[0] div = div.replace('&amp;nbsp;','') text = '' for i in re.split('&lt;.*?&gt;',div): text += i+'\n' if i else '' return text.replace('点击阅读全文','')def main(): # 将函数组合起来进行工作 最后返回一个包含URL,标题,文章的字典 urlPool = makeUrl('http://www.qianqu.cc/tech/page/&#123;&#125;') for i in urlPool: for x in getTitle(i): news = &#123; 'url':x[0].decode('utf-8'), # 由于网页源码是utf-8编码 所以需要先解码 'title':x[1].decode('utf-8'), 'text':getContext(x[0]).decode('utf-8') &#125; yield newsif __name__ == '__main__': # 这个里面看你想如和处理收集到的数据了 for i in main(): # 可以打印出来 也可以存数据库 raw_input('Enter key continue ...') print i['title'] print i['text'] 千趣有许多专题 比如生活啊 科技啊之类的 这里以科技为例 现在分析下爬取内容的思路 def getHTML(url): 定义一个获取网页源码的函数 因为千趣网没有反爬措施 所以就非常简单的发送请求 然后返回内容 如果爬取其他网站发现失败 可以试着修改User-Agent等必要的字段试试 def makeUrl(baseUrl): 先进行分析千趣科技模块的URL 发现URL是http://www.qianqu.cc/tech 往下翻还有许多页数 所以就需要一个函数能自动生成这些页数的URL 想获取一共有多少页 还需要对网页内容进行分析 发现在页面的一段javascript脚本中 pages: 208, 而这个刚好就是这个科技专题的页码数 定义一个getPageNum()的函数 用正则表达式检索出这个数字 然后提供makeUrl去生成URL def getTitle(url): 接下来就是请求makeUrl生成的URL 获取每一个URL中有多少个文章的标题和文章的URL 在chrome内核的浏览器 Ctrl + U 打开页面的源代码 通过分析发现 每个文字标题都是通过&lt;div&gt;布局的 这样就可以先捕获每个标题所在的div 然后再进行二次匹配出需要的标题和文字的URL def getContext(url): 接下来就是获取标题内容页的数据了 对内容中的数据重新处理 去掉多余的HTML标签 并且去掉空格 和没有用处的字符串 def main(): 将需要的函数组合起来 开始工作 并最后返回一个字典 字典有三个字段 分别是url title 和text 对应着文章url 文章标题还有文章内容 可以发现 这个爬虫脚本还是有非常多可以改进的地方 比如没有异常处理等等 最后就是考虑如何处理这些数据了这里只是简单的打印了出来 最好的方法当然是保存到数据库 将数据保存入数据库 从千趣网抓取的数据可以选择存放到Nosql 比如mongodb redis等数据库中 也可以存放到普通的数据库 比如mysql sqlite3中 下面以python自带的标准库sqlite3为例 123456789101112if __name__ == '__main__': import sqlite3,time with sqlite3.connect('qianqu.sqlite3') as conn: db = conn.cursor() create_table = 'create table if not exists qianqu (id integer primary key autoincrement,title varchar(128),url varchar(128),text text)' db.execute(create_table) insert_sql = u'insert into qianqu (url,title,text) values (?,?,?)' for i in main(): db.execute(insert_sql,(i['url'],i['title'],i['text'])) conn.commit() print i['url']+' OK!' time.sleep(1) 只需要将if __name__ 的部分改为这样就可以了 这里导入sqlite3的库 然后用with管理一个sqlite3数据库的连接 然后按照字典key去建表 为了防止爬取速度太快 导致对方服务器可能封锁IP 所以就每1秒爬取一次 然后将数据写入数据库中 到这里 对python写爬虫已经有一个大致的学习了 这里没有用到任何的第三方库 都是用标准库实现的 程序还有很多不完善的地方 比如如果中途断开了 那么脚本往数据库插入数据又得重新开始 附录Python爬虫进阶 如果想进一步的提高自己的爬虫水平 就需要学习一些第三方库和一些优秀的爬虫框架了 下面做了一个总结 数据获取类 模块 说明 requests 一个非常好用的网络库 pycurl libcurl的绑定 非常强大 urllib3 HTTP库 安全连接池 支持文件post 可用性高 tornado 高效的非阻塞web框架 可以做HTTP Client aiohttp asyncio的HTTP客户端/服务器 数据解析工具 模块 说明 lxml C语言编写高效HTML/XML处理库 支持XPath cssselect 解析DOM树和CSS选择器 pyquery 解析DOM树和jQuery选择器 BeautifulSoup 低效但方便的HTML/XML处理库 html5lib 根据WHATWG规范生成HTML/ XML文档的DOM xmltodict 一个可以让你在处理XML时感觉像在处理JSON一样的模块 爬虫框架 模块 说明 grad 网络爬虫框架(基于pycurl/multicur) scrapy 网络爬虫框架(基于twisted) pyspider 一个强大的爬虫系统 cola 一个分布式爬虫框架 数据库驱动 模块 说明 mysqlclient python的mysql驱动 psycopg2 python的postgresql驱动 pymongo python的mongodb驱动 redis python的redis驱动 其他工具 模块 说明 PhantomJS 无界面的,可脚本编程的WebKit浏览器引擎 Selenium 自动化测试工具]]></content>
      <categories>
        <category>Python</category>
      </categories>
      <tags>
        <tag>Python</tag>
        <tag>网络爬虫</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LNMP环境部署]]></title>
    <url>%2F2016%2F07%2F19%2F2016%2FLAMP%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[简介 Linux+Apache+Mysql/MariaDB+Perl/PHP/Python一组常用来搭建动态网站或者服务器的开源软件，本身都是各自独立的程序，但是因为常被放在一起使用，拥有了越来越高的兼容度，共同组成了一个强大的Web应用程序平台。随着开源潮流的蓬勃发展，开放源代码的LAMP已经与J2EE和.Net商业软件形成三足鼎立之势，并且该软件开发的项目在软件方面的投资成本较低，因此受到整个IT界的关注。从网站的流量上来说，70%以上的访问流量是LAMP来提供的，LAMP是最强大的网站解决方案． 环境 本教程中的各服务搭建在不同的服务器上 当然也可以搭建在同一个服务器上 主机环境 身份 系统 IP Apache 服务器 CentOS 6.7 172.18.0.4 MySQL 服务器 CentOS 6.7 172.18.0.2 PHP-fpm 服务器 CentOS 6.7 172.18.0.3 软件环境 软件名称 版本号 下载地址 Apache 2.4.23 点击下载 MySQL 5.6.28 点击下载 PHP 5.6.19 点击下载 步骤 httpd和php结合的方式有两种 一种是和nginx相同的 通过php-fpm启动监听的方式 然后转发php页面请求给php-fpm服务 还有一种就是php编译为httpd模块的方式提供php页面的解析能力 编译安装各组件 服务器 安装文档地址 Apache 点击打开文档内容 MySQL 点击打开文档内容 PHP-fpm 点击打开文档内容 httpd + php-fpm 这个是httpd通过fast-cgi方式和php-fpm搭配 配置PHP-fpm打开编辑php-fpm.conf vim /usr/local/php/etc/php-fpm.conf 修改listen监听地址为0.0.0.0:9000 listen = 0.0.0.0:9000 配置仅允许连接的客户机 默认运行所有主机连接 172.0.0.7是Nginx服务器的IP listen.allowed_clients = 172.17.0.7 然后启动PHP-fpm的服务 service php-fpm start 修改httpd配置文件打开编辑httpd.conf vim /usr/local/httpd/conf/httpd.conf 修改 DocumentRoot 路径为&quot;/var/www/html&quot; 这个是网站根目录 紧接着的 Directory 配置段也修改为 &lt;Directory &quot;/var/www/html&quot;&gt; 去掉mod_proxy.so和mod_proxy_fcgi.so之前的注解 让httpd启动时加载这两个模块 LoadModule proxy_module modules/mod_proxy.so LoadModule proxy_fcgi_module modules/mod_proxy_fcgi.so 然后添加配置段 让php页面交给php-fpm去解析 &lt;FilesMatch \.php$&gt; SetHandler &quot;proxy:fcgi://172.18.0.3:9000&quot; &lt;/FilesMatch&gt; 然后定位DirectoryIndex配置项 添加index.php DirectoryIndex index.php index.html 最后启动httpd服务 /usr/local/httpd/bin/httpd 下面有详细的方法检测是否搭配成功 httpd + php模块 接下来开始介绍如何将php编译为httpd的模块方式搭配php和httpd 将php编译为httpd模块 将php编译为httpd模块方式和php-fpm模式的编译唯一的区别就是将–enable-fpm替换为–with-apxs2=/usr/local/httpd/bin/apxs 12345678910111213141516171819tar xf php-5.6.19.tar.xzcd php-5.6.19./configure \--prefix=/usr/local/php \--with-apxs2=/usr/local/httpd/bin/apxs \--with-mcrypt \--with-zlib --enable-mbstring \--with-openssl --with-mysql \--with-mysqli --with-mysql-sock \--with-gd --with-jpeg-dir=/usr/lib \--enable-gd-native-ttf \--enable-pdo --with-pdo-mysql \--with-gettext --with-curl \--with-pdo-mysql --enable-sockets \--enable-bcmath --enable-xml \--with-bz2 --enable-zip \--with-freetype-dir=/usr \--with-mcrypt=/usr/local/mcryptmake -j4 &amp;&amp; make install ls /usr/local/httpd/modules/libphp5.so 可以看到 在httpd的modules目录下 已经出现了libphp5.so这个模块了 接下来依然要给php模块提供个配置文件 cp ./php.ini-production /usr/local/php/lib/php.ini 修改httpd配置文件 php模块方式对httpd.conf的修改和php-fpm方式是完全不同的 cd到httpd的conf目录 可以发现多出来一个httpd.conf.bak的文件 这个是php安装期间 对httpd.conf做出修改后的备份 其实做的修改也仅仅是添加和启用了libphp5这个模块 LoadModule php5_module modules/libphp5.so 如果沿用的是刚才的php-fpm模式的配置文件 需要先清理掉&lt;FilesMatch \.php$&gt;配置段 如果是全新的配置 同样修改网站根目录和添加index.php 这里不再赘述 添加如下两行配置 AddType application/x-httpd-php .php AddType application/x-httpd-php-source .phps 最后启动httpd服务 /usr/local/httpd/bin/httpd 验证是否搭配成功 请注意 如果php-fpm和httpd服务不在同一个服务器 可以将网站根目录通过nfs共享访问 或者克隆一份web页面放到两台服务器相同的路径下 MySQL创建远程登录用户 php 允许所有地址连接 密码 php123grant all privileges on . to “php”@”%” identified by “php123”; 在/var/www/html中编写index.php &lt;?php phpinfo(); ?&gt; 在/var/www/html中编写dbtest.php &lt;?php $link=mysql_connect(&quot;172.18.0.2&quot;,&quot;php&quot;,&quot;php123&quot;); if(!$link) echo &quot;连接错误!&quot;; else echo &quot;可以连接!&quot;; ?&gt; 分别访问两个php文件 http://172.18.0.4/ 和 http://172.18.0.4/dbtest.php 若浏览器出现大大的PHP Version 5.6.19 则index.php被正常识别 访问dbtest.php若出现 &quot;可以连接!&quot; 则数据库连接成果 以下是用curl访问dbtest.php的结果 # curl http://172.18.0.4/dbtest.php 可以连接 附录可以看到 LAMP 和 LNMP 在php-fpm上是非常相似的 推荐使用php-fpm的方式 这样比php模块更节省服务器资源 因为httpd的高并发能力比Nginx弱很多 所以高并发环境下推荐使用LNMP]]></content>
      <categories>
        <category>LAMP</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>zabbix</tag>
        <tag>apache</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy常用配置详解]]></title>
    <url>%2F2016%2F07%2F18%2F2016%2FHAProxy%E5%B8%B8%E7%94%A8%E9%85%8D%E7%BD%AE%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介 HAProxy的安装非常简单 但是配置文件方面就比较复杂了 在安装路径下的doc目录下 有官方详细的使用文档。其实常用的配置也并不多 只要掌握了这些 HAProxy就可以很好的使用了 环境 软件名称 版本号 下载地址 haproxy 1.6.7 点击下载 步骤 根据功能和用途 HAProxy配置文件主要由五个部分组成 有些部分并不是必须的 可以根据实际情况使用 1. global部分 设置全局配置参数 2. defaults部分 默认参数配置部分 3. frontend部分 设置接受用户请求的前端虚拟节点 4. backend部分 设置后端服务器集群的配置 5. listen部分 frontend和backend部分的结合体 global部分global maxconn 10000 log 127.0.0.1 local0 info uid 200 gid 200 chroot /var/empty daemon nbproc 1 pidfile /var/run/haproxy.pid maxconn: 设定每个HAProxy进程可接受的最大并发连接数 (相当于ulimit -n的设置) log: 全局的日志配置 127.0.0.1 local0表示使用本机的rsys-log服务中的local0日志设备 还支持四种日志级别 err, warning, info, debug log-send-hostname: 在syslog信息的首部添加当前主机名 可以自定义字符串 默认当前主机名 uid/gid: 运行HAProxy进程的uid和gid 也可以用user/group代替 chroot: 限定运行用户的访问目录 daemon: 设置HAProxy进程后台运行 nbproc: 服务启动时创建的进程数 创建多个进程 可以减少每个进程的任务队列 但是可能使服务不稳定 pidfile: pid文件位置 启动用户必须有可写权限 stats: 用户访问统计数据的接口 node: 定义当前节点的名称 用于HA场景中多haproxy进程共享同一个IP地址时 defaults部分defaults mode http retries 3 timeout connect 10s timeout client 20s timeout server 30s timeout check 5s mode: 设置HAProxy实例默认运行模式 有tcp http health三个可选值 tcp: 在此模式下 只做数据转发 不对七层报文做检查 http: 会对七层报文做检查分析 health: 此模式基本已被废弃 retries: 设置后端服务器连接失败重试次数 超过次数 HAProxy标记此服务器不可用 timeout connect: 成功连接到一台服务器最长等待时间 timeout client: 设置连接客户端发送数据最长等待时间 默认单位毫秒 可以使用其他单位后缀 timeout server: 设置服务器回应客户最长等待时间 默认单位毫秒 可以使用其他单位后缀 timeout check: 设置对后端服务器检查超时时间 默认单位毫秒 可以使用其他单位后缀 frontend部分frontend www bind *:80 mode http option httplog option forwardfor option httpclose log global default_backend htmpool 通过frontend关键字定义了一个名为www的前端虚拟节点 bind: 只能用在frontend和listen部分 用户定义一个或多个监听的套接字 端口还可以是个段 比如80-100 option httplog: 开启日志记录HTTP请求 option forwardfor: 请求头中添加X-Forwardfor-For记录 可以让后端服务器获取用户真实IP option httpclose: 完成一次连接请求后 HAProxy将主动关闭此TCP连接 log global: 使用global中定义的日志选项配置格式 defaults_backend: 制定默认的后端服务器池 htmpool将在backend中定义 backend部分backend htmpool mode http option redispatch option abortonclose balance roundrobin cookie SERVERID option httpchk GET / server web1 192.168.4.233:80 cookie server1 weight 6 check inter 2000 rise 2 fall 3 server web2 192.168.4.234:80 cookie server2 weight 6 check inter 2000 rise 2 fall 3 option redispatch: 用于cookie保持环境下 如果后端服务器异常 将客户请求强制定向到另一台正常服务器 option abortonclose: 服务器负载很高的情况下 自动结束当前队列中处理时间比较长的连接 balance: 定义负载均衡算法 HAProxy支持多种负载均衡算法 常用的如下几种 roundrobin: 基于权重进行轮询的调度算法 static-rr: 也是基于权重进行轮询的调度算法 不过为静态方法 在运行时调整其服务器权重不会生效 source: 基于请求源IP的算法 可以使同一个客户端的IP请求始终由一台服务器处理 leastconn: 将新的连接请求转发到最有最少连接数目的后端服务器 长会话的环境中比较适用 uri: 此算法会对部分或整个URI进行hash运算 再经过与服务器的总权重相除 转发到匹配的服务器 uri-param: 根据URL路径中的参数转发 可以保证同一用户的请求始终分发到同一台服务器上 hdr: 根据http头进行转发 如果http头名称不存在 则使用roundrobin算法进行策略转发 cookie: 表示允许向cookie插入SERVERID 每台服务器的SERVERID可由server关键字定义 option httpchk &lt;method&gt; &lt;uri&gt; &lt;version&gt;: 表示启用HTTP的服务状态检测功能 method支持以下几种方式 OPTIONS GET HEAD 一般的健康检查只需要采用HEAD方式 只查看Response的状态码是否是200就可以了 uri则是要检测的URL地址 version指定检测时的HTTP版本号 默认HTTP/1.0 server &lt;name&gt; &lt;address&gt;[:port] [param*]: 这个则是定义多台后端服务器了 name: 为后端服务器指定一个名称 address: 后端真实服务器的IP port: 后端真实服务器监听的端口号 param*: 为后端服务器设定的一系列参数 常用参数如下 check: 表示对后端服务器执行健康检查 inter: 设置监控状态检测的时间 单位是毫秒 rise: 由故障状态转移到正常状态需要成功检查的次数 rise 2表示2次检查成功 此服务器才可用 fall: 由正常状态转移到故障状态需要失败检查的次数 cookies: 目的在于实现持久连接的功能 cookie server1 表示web1的serverid为server1 weight: 后端服务器的权重 默认1 最大256 设置0不参与负载均衡 权重越大 被选中的概率越大 backup: 不参与负载均衡 只有在所有服务器都不可用的情况下才启用 listen部分 frontend和backend部分的结合体 它们中的指令 listen中都能用 新版的haproxy为了兼容旧版的才保留了listen部分 目前haproxy中 两种配置方式选一个即可 listen admin_stats bind 0.0.0.0:9188 mode http log 127.0.0.1 local0 err stats refresh 30s stats uri /haproxy-status stats realm welcome login\ Haproxy stats auth admin:admin~!@ stats hide-version stats admin if TRUE stats refresh: 监控统计页面的自动刷新时间 stats uri: 监控统计页面的访问路径 stats realm: 访问统计页面时的文本提示信息 stats auth: 认证登陆的用户名和密码 stats hide-version: 隐藏版本信息 stats admin: 通过此选择 可以在监控页面上手工启用或禁用后端服务器 附录HAProxy的日志配置策略 默认情况下 HAProxy为了节省读写的I/0所消耗的性能 没有自动配置日志输出功能 但是为了方便维护和调试 还是需要开启的 确定系统已经安装rsyslog yum install -y rsyslog 添加配置文件 vim /etc/rsyslog.d/haproxy.conf $ModLoad imudp $UDPServerRun 514 local0.* /var/log/haproxy.conf 通过UDP 514端口接收日志 然后还要修改/etc/sysconfig/rsyslog 修改为: SYSLOGD_OPTIONS=&quot;-c 2 -r -m 0&quot; 然后重启rsyslog服务即可 service rsyslog restart 这里只讲解了HAProxy常用的配置方法 如果想深入了解其他配置项 可以查阅官方文档官方文档位置: /usr/local/haproxy/doc/haproxy/]]></content>
      <categories>
        <category>HAProxy</category>
      </categories>
      <tags>
        <tag>代理服务器</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[HAProxy编译安装]]></title>
    <url>%2F2016%2F07%2F18%2F2016%2FHAProxy%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介 HAProxy提供高可用性、负载均衡以及基于TCP和HTTP应用的代理，支持虚拟主机，它是免费、快速并且可靠的一种解决方案。HAProxy特别适用于那些负载特大的web站点，这些站点通常又需要会话保持或七层处理。HAProxy运行在当前的硬件上，完全可以支持数以万计的并发连接。并且它的运行模式使得它可以很简单安全的整合进您当前的架构中， 同时可以保护你的web服务器不被暴露到网络上。百度百科 环境 软件名称 版本号 下载地址 haproxy 1.6.7 点击下载 步骤 需要系统先初始化开发环境 yum install -y gcc gcc-c++ zlib-devel make 编译安装haproxy123456tar xf haproxy-1.6.7.tar.gzcd haproxy-1.6.7make -j4 TARGET=linux2628 USE_PCRE=1 USE_OPENSSL=1make install PREFIX=/usr/local/haproxymkdir /etc/haproxycp examples/content-sw-sample.cfg /etc/haproxy/haproxy.conf 需要注意的地方是 TARGET=linux2628 这个是根据内核版本来定的 具体如何使用看源码目录下的README文件 简单来说 只要你的内核版本大于2.6.28的 都可以使用TARGET=linux2628 编译安装是非常简单的 至此haproxy就编译安装完成了 剩下的就是看haproxy如何使用了 附录四层和七层负载均衡的区别常见的负载均衡方式 除了硬件负载均衡设备 还有软件的负载均衡产品 比如Nginx, LVS, HAProxy等 软件的方式又分为基于操作系统的和基于第三方软件的 比如LVS需要内核模块的支持 HAProxy则不需要 HAProxy可以实现TCP(四层)和HTTP(七层)应用的负载均衡 而早期Nginx只支持HTTP应用的负载均衡 不过Nginx在新版本1.9.0之后 也支持了TCP的代理和负载均衡 在1.9.13后支持了UDP代理和负载均衡 四层负载均衡也被称为四层交换机 主要通过修改数据包中目标IP地址和端口改为后端服务器的IP地址和端口 然后直接转发给该后端服务器 这样一个负载均衡的请求就完成了 并没有对数据包中的数据内容做修改 而负载均衡器只不过完成了一个类似路由的转发动作 在某些负载均衡策略下 甚至会修改报文的源地址 以保证数据包可以正确的传输 而七层负载均衡器又被称为七层交换机 位于应用层 此时负载均衡器可以支持多种应用协议 常见的有HTTP, FTP, SMTP等 七层负载均衡器不仅可以根据IP+端口的方式负载均衡 还可以根据内容 比如一个网站有为手机适配的页面和电脑适配的页面 可以分析HTTP的头部User-Agent信息 来智能跳转 而这些能力是在四层是无法实现的]]></content>
      <categories>
        <category>HAProxy</category>
      </categories>
      <tags>
        <tag>代理服务器</tag>
        <tag>负载均衡</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP模块拓展]]></title>
    <url>%2F2016%2F07%2F12%2F2016%2Fphp%E6%A8%A1%E5%9D%97%E6%8B%93%E5%B1%95%2F</url>
    <content type="text"><![CDATA[简介 在PHP开发环境中可能发现项目依赖一些先前并没有编译进入的模块 或者需要用到一些第三方模块 那么该如何对PHP进行动态的拓展模块 而不用重新编译PHP呢 环境 实验已安装环境为PHP 5.5.33版本 软件名称 版本号 下载地址 php 5.5.33 下载地址 php 5.6.19 下载地址 php 7.0.4 下载地址 memcache 3.0.8 下载地址 步骤 如果后期的开发需要用到php的其他模块 或者第三方模块 那就需要对php进行模块升级模块安装的方式有两种 在linux 可以选择将模块编译入php程序中 也可以作为单独的so文件让php加载 准备好php的源码包 要和当前php版本一致 下面用第三方模块memcache和自带模块soap做示例 编译安装自带模块soap 解压了PHP的源码包后 进入到源码包目录的ext目录下 这个是PHP自带的所有模块 123456tar xf php-5.5.33.tar.xzcd php-5.5.34/ext/soap//usr/local/php/bin/phpize./configure --with-php-config=/usr/local/php/bin/php-configmake &amp;&amp; mkdir /usr/local/php/extensions/cp modules/soap.so /usr/local/php/extensions/ 可以看到 ext目录下 有非常多的模块文件夹 进入soap目录中后 先执行phpize脚本才会生成configure文件 之后指定php-config的位置来进行生成Makefile文件 最后生成的二进制so文件在modules目录内 为什么不直接make install呢 因为make install安装到的目录感觉并不是非常方便管理 在php安装目录下建立一个文件夹 可以将所有的二进制so文件都放入到这个文件夹内 接下来就是让php加载这个模块了 修改php.ini文件 添加以下配置 extension_dir = &quot;/usr/local/php/extensions&quot; extension=soap.so 先是配置好拓展模块的目录 然后下面启用的模块就可以只写模块名了 否则需要写模块的完整路径 [root@e1adb08f8c82 lib]# /usr/local/php/bin/php -m |grep soap soap [root@e1adb08f8c82 lib]# 可以看到 php已经出现了soap这个模块 不放心的话 也可以通过phpinfo页面看看有没有soap模块 还有一种方法安装soap模块就是重新编译php 添加 --enable-soap 配置项即可 这里不再赘诉 编译安装第三方memcache模块 php所有的第三方模块都可以在 http://pecl.php.net/ 找到 这里以memcache为例 1234tar xf memcache-3.0.8.tgz/usr/local/php/bin/phpize ./configure --with-php-config=/usr/local/php/bin/php-configcp modules/memcache.so /usr/local/php/extensions/ 接下来也是修改php.ini文件 将memcache.so加载就可以了 extension=memcache.so [root@e1adb08f8c82 lib]# /usr/local/php/bin/php -m |grep memcache memcache [root@e1adb08f8c82 lib]# 可以看到 memcache也成功的出现在 php的模块中 附录不同版本的php模块是不能够通用的 反之如果环境相同的php 那么模块就不用重复编译了 模块不通用的原因是因为 不同版本的PHP 可能使用的API不相同 [root@e1adb08f8c82 memcache-3.0.8]# /usr/local/php/bin/phpize Configuring for: PHP Api Version: 20121113 Zend Module Api No: 20121212 Zend Extension Api No: 220121212 正如每次执行phpize脚本中显示的那样]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>LNMP</tag>
        <tag>php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis散列类型]]></title>
    <url>%2F2016%2F05%2F25%2F2016%2Fredis%E6%95%A3%E5%88%97%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[简介 Redis 是采用字典结构以键值对的形式存储数据的，而散列类型（hash）的键值也是一种字典结构，其存储了字段（field）和字段值的映射，但字段值只能是字符串，不支持其他数据类型，换句话说，散列类型不能嵌套其他的数据类型。一个散列类型键可以包含最多232最少1个字段 环境 软件名称 版本号 下载地址 redis 3.2.0 点击下载 简单认识散列类型散列类型适合存储对象：使用对象类别和 ID 构成键名，使用字段表示对象的属性，而字段值则存储属性值。需要注意 散列类型的字段值只能是字符串类型 不能嵌套其他类型 键:ID 字段 字段值 +----&gt; color -----&gt; white car:1 ----+----&gt; name -----&gt; Ferraris +----&gt; price -----&gt; 10 million 散列类型的字段可以随意拓增或者减少 所以散列类型的结构只是人为的约定 常用命令下面将详细说明操作Redis散列类型的相关命令 赋值与取值HSET key field value # 赋值 HGET key field # 取值 127.0.0.1:6379&gt; HSET car:1 color white (integer) 1 127.0.0.1:6379&gt; HSET car:1 name Ferraris (integer) 1 127.0.0.1:6379&gt; HSET car:1 price &apos;10 million&apos; (integer) 1 127.0.0.1:6379&gt; HGET car:1 color &quot;white&quot; 127.0.0.1:6379&gt; HGET car:1 name &quot;Ferraris&quot; 127.0.0.1:6379&gt; HGET car:1 price &quot;10 million&quot; 127.0.0.1:6379&gt; HSET不区分插入和更新操作 修改数据时不用事先判断字段是否存在插入或修改一个字段时 当字段不存在 HSET命令返回1 否则返回0 127.0.0.1:6379&gt; HSET car:1 color blue (integer) 0 127.0.0.1:6379&gt; HGET car:1 color &quot;blue&quot; 127.0.0.1:6379&gt; 和字符串类似 当需要给多个字段同时设定值 或获取值 也有相应的命令 HMSET key field value [field value ...] # 同时赋值 HGET key field # 同时取值 127.0.0.1:6379&gt; HMSET car:2 color red name Bentley price &apos;3 million&apos; OK 127.0.0.1:6379&gt; HMGET car:2 color name price 1) &quot;red&quot; 2) &quot;Bentley&quot; 3) &quot;3 million&quot; 127.0.0.1:6379&gt; 如果事先不知道这个car:2有哪些字段 那么如何获取这个key中所有的字段和值呢 HGETALL key # 获取所有字段值 127.0.0.1:6379&gt; HGETALL car:2 1) &quot;color&quot; 2) &quot;red&quot; 3) &quot;name&quot; 4) &quot;Bentley&quot; 5) &quot;price&quot; 6) &quot;3 million&quot; 127.0.0.1:6379&gt; 还可以单独获取字段名或字段值 HKEYS key # 只获取字段名 HVALS key # 只获取字段值 127.0.0.1:6379&gt; HKEYS car:1 1) &quot;name&quot; 127.0.0.1:6379&gt; HKEYS car:2 1) &quot;color&quot; 2) &quot;name&quot; 3) &quot;price&quot; 4) &quot;date&quot; 127.0.0.1:6379&gt; HVALS car:1 1) &quot;Ferraris&quot; 127.0.0.1:6379&gt; HVALS car:2 1) &quot;red&quot; 2) &quot;Bentley&quot; 3) &quot;3 million&quot; 4) &quot;2016-05-22&quot; 127.0.0.1:6379&gt; 判断字段是否存在HEXISTS key field # 判断字段是否存在 127.0.0.1:6379&gt; HEXISTS car:1 date (integer) 0 127.0.0.1:6379&gt; HSET car:1 date &apos;2016-05-22&apos; (integer) 1 127.0.0.1:6379&gt; HEXISTS car:1 date (integer) 1 127.0.0.1:6379&gt; 当字段不存在返回0 字段存在 返回1 字段不存在时赋值HSETNX key field value # 字段不存在时赋值 127.0.0.1:6379&gt; HSETNX car:2 color black (integer) 0 127.0.0.1:6379&gt; HGET car:2 color &quot;red&quot; 127.0.0.1:6379&gt; HSETNX car:2 date &apos;2016-05-22&apos; (integer) 1 127.0.0.1:6379&gt; HGET car:2 date &quot;2016-05-22&quot; 127.0.0.1:6379&gt; 可以看到 如果字段存在 赋值失败 并返回0 如果不存在 赋值成功 返回1 字段值自增自减HINCRBY key field increment # 字段值自增 127.0.0.1:6379&gt; HINCRBY car id 1 (integer) 1 127.0.0.1:6379&gt; HGET car id &quot;1&quot; 127.0.0.1:6379&gt; HINCRBY car id 2 (integer) 3 127.0.0.1:6379&gt; HGET car id &quot;3&quot; 127.0.0.1:6379&gt; 字段值的自增和字符串的自增道理相同 因为没有自减 所以可以用自增 -1 来实现 删除字段HDEL key field [field ...] # 删除指定的一个或多个字段 127.0.0.1:6379&gt; HDEL car:1 price date (integer) 2 127.0.0.1:6379&gt; HGETALL car:1 1) &quot;color&quot; 2) &quot;blue&quot; 3) &quot;name&quot; 4) &quot;Ferraris&quot; 127.0.0.1:6379&gt; HDEL car:1 price color (integer) 1 127.0.0.1:6379&gt; HDEL会返回删除成功的字段个数 获取字段数量HLEN key # 获取字段数量 127.0.0.1:6379&gt; HLEN car:1 (integer) 1 127.0.0.1:6379&gt; HLEN car:2 (integer) 4 127.0.0.1:6379&gt; 附录命令总结HSET key field value 给键的字段赋值 HGET key field 获取键的字段值 HMSET key field value [field value ...] 同时赋值 HGET key field 同时取值 HGETALL key 获取所有字段值 HKEYS key 只获取字段名 HVALS key 只获取字段值 HEXISTS key field 判断字段是否存在 HSETNX key field value 字段不存在时赋值 HINCRBY key field increment 字段值自增 HDEL key field [field ...] 删除指定的一个或多个字段 HLEN key 获取字段数量]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>Redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis有序集合类型]]></title>
    <url>%2F2016%2F05%2F24%2F2016%2Fredis%E6%9C%89%E5%BA%8F%E9%9B%86%E5%90%88%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[简介 有序集合类型 顾名思义 与集合类型的区别就是有序 这个有序是在集合类型的基础上 给每个元素关联了一个分数 按照分数进行排序 环境 软件名称 版本号 下载地址 redis 3.2.0 点击下载 步骤与列表类型的区别 有序集合类型在某些方面和列表类型相似 但是还是有很大的区别 与列表相似的地方: 1. 两者都是有序的 2. 两者都可以获取某一个范围的元素 与列表不同的地方: 1. 列表通过链表实现 所以访问两端数据比较快 访问中间数据会较慢 2. 而集合采用散列表和跳跃表 所以没有这个忧虑 3. 列表不能简单的调整某个元素的位置 但有序集合通过修改元素分数可以 4. 有序集合比列表类型更耗费内存 常用命令 下面将详细说明操作Redis有序集合类型的相关命令 增加元素1ZADD key score member [score member …] # 增加元素 127.0.0.1:6379&gt; ZADD num 1 a 2 b 3 c (integer) 3 127.0.0.1:6379&gt; ZADD num 2 a 2.5 d (integer) 1 127.0.0.1:6379&gt; 元素的分数可以修改 可以是小数 最后的排序方式就是按照分数排序的 获取元素分数1ZSCORE key member # 获取元素分数 127.0.0.1:6379&gt; ZSCORE num a &quot;2&quot; 127.0.0.1:6379&gt; ZADD num 3 a (integer) 0 127.0.0.1:6379&gt; ZSCORE num a &quot;3&quot; 127.0.0.1:6379&gt; 获取某个范围的元素12ZRANGE key start stop [WITHSCORES] # 获取某个索引范围的元素ZREVRANGE key start stop [WITHSCORES] # 获取某个索引范围的元素 反序排序 127.0.0.1:6379&gt; ZRANGE num 0 -1 1) &quot;b&quot; 2) &quot;d&quot; 3) &quot;a&quot; 4) &quot;c&quot; 127.0.0.1:6379&gt; ZRANGE num 0 1 WITHSCORES 1) &quot;b&quot; 2) &quot;2&quot; 3) &quot;d&quot; 4) &quot;2.5&quot; 127.0.0.1:6379&gt; ZRANGE的用法和LRANGE的用法大致一样 只不过多了个 WITHSCORES 可以同时显示分数 如果出现分数相同的情况 则按照 0 &lt; 9 &lt; A &lt; Z &lt; a &lt; z 规则排序 127.0.0.1:6379&gt; ZREVRANGE num 0 -1 1) &quot;c&quot; 2) &quot;a&quot; 3) &quot;d&quot; 4) &quot;b&quot; 127.0.0.1:6379&gt; 可以看到 ZREVRANGE 与 ZRANGE 结果是相反的 获取某个分数范围的元素12ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] # 获取某个分数范围的元素ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] # 获取某个分数范围的元素 反序排序 127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 1) &quot;d&quot; 2) &quot;a&quot; 3) &quot;c&quot; 127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 (3 1) &quot;d&quot; 127.0.0.1:6379&gt; ZRANGEBYSCORE num (2.5 3 1) &quot;a&quot; 2) &quot;c&quot; 127.0.0.1:6379&gt; 如果不希望获取端点值 可以在端点分数前加 &quot;(&quot; 这样就可以把端点值排除在外了 无穷大可以用 +inf 127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 LIMIT 0 2 1) &quot;d&quot; 2) &quot;a&quot; 127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 LIMIT 1 2 1) &quot;a&quot; 2) &quot;c&quot; 127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 LIMIT 1 3 1) &quot;a&quot; 2) &quot;c&quot; 127.0.0.1:6379&gt; ZRANGEBYSCORE num 2.5 3 LIMIT 0 3 1) &quot;d&quot; 2) &quot;a&quot; 3) &quot;c&quot; 127.0.0.1:6379&gt; WITHSCORES用法不在赘述 LIMIT是限制结果数量 LIMIT 1 2表示从结果的索引1开始 只要2个结果 ZREVRANGEBYSCORE的用法可以参考ZRANGE与ZREVRANGE的去别 也不再详细说明 增加某个元素的分数1ZINCRBY key increment member # 增加某个元素的分数 127.0.0.1:6379&gt; ZSCORE num a &quot;3&quot; 127.0.0.1:6379&gt; ZINCRBY num 4 a &quot;7&quot; 127.0.0.1:6379&gt; ZINCRBY num -2 a &quot;5&quot; 127.0.0.1:6379&gt; 如果指定的元素不存在 ZINCRBY同样会先创建 赋值为0后在增加分数 获取集合中元素数量1ZCARD key # 获取集合中元素数量 127.0.0.1:6379&gt; ZCARD num (integer) 4 127.0.0.1:6379&gt; ZADD num 6 e (integer) 1 127.0.0.1:6379&gt; ZCARD num (integer) 5 127.0.0.1:6379&gt; 获得指定分数范围内的元素个数1ZCOUNT key min max # 获得指定分数范围内的元素个数 127.0.0.1:6379&gt; ZRANGE num 0 -1 WITHSCORES 1) &quot;b&quot; 2) &quot;2&quot; 3) &quot;d&quot; 4) &quot;2.5&quot; 5) &quot;c&quot; 6) &quot;3&quot; 7) &quot;a&quot; 8) &quot;5&quot; 9) &quot;e&quot; 10) &quot;6&quot; 127.0.0.1:6379&gt; ZCOUNT num (2.5 5 (integer) 2 127.0.0.1:6379&gt; ZCOUNT num 2.5 5 (integer) 3 127.0.0.1:6379&gt; 获取分数为2.5到5之间元素个数 也可以使用 &quot;(&quot; 是否排查端点 删除一个或多个元素1ZREM key member [member …] # 删除一个或多个元素 127.0.0.1:6379&gt; ZREM num a b (integer) 2 127.0.0.1:6379&gt; ZRANGE num 0 -1 1) &quot;d&quot; 2) &quot;c&quot; 3) &quot;e&quot; 127.0.0.1:6379&gt; 命令返回删除成功的元素数量 按照排名范围删除元素1ZREMRANGEBYRANK key start stop # 按照排名范围删除元素 127.0.0.1:6379&gt; ZREMRANGEBYRANK num 0 1 (integer) 2 127.0.0.1:6379&gt; ZRANGE num 0 -1 WITHSCORES 1) &quot;e&quot; 2) &quot;6&quot; 127.0.0.1:6379&gt; 按照索引范围去删除元素 返回删除成功的元素个数 按照分数范围删除元素1ZREMRANGEBYSCORE key min max # 按照分数范围删除元素 127.0.0.1:6379&gt; ZADD num 2 a 3 b 4 d (integer) 3 127.0.0.1:6379&gt; ZREMRANGEBYSCORE num (2 4 (integer) 2 127.0.0.1:6379&gt; ZRANGE num 0 -1 1) &quot;a&quot; 2) &quot;e&quot; 127.0.0.1:6379&gt; 删除分数大于2 小于4的元素 返回删除成功的元素个数 获得元素的排名12ZRANK key member # 获得元素的排名 正序排序ZREVRANK key member # 获得元素的排名 反序排序 127.0.0.1:6379&gt; ZRANK num a (integer) 0 127.0.0.1:6379&gt; ZRANK num e (integer) 1 127.0.0.1:6379&gt; ZREVRANK num e (integer) 0 127.0.0.1:6379&gt; ZREVRANK num a (integer) 1 127.0.0.1:6379&gt; 排序从0开始 ZREVRANK会反序排序 集合运算12ZINTERSTORE dest numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX] # 交集ZUNIONSTORE dest numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX] # 并集 numkeys是参与计算的键的个数 WEIGHTS是权重 AGGREGATE绝定最后结果集合的元素分数是取平均数还是最大最小值 127.0.0.1:6379&gt; ZADD num1 1 a 2 b 3 c (integer) 3 127.0.0.1:6379&gt; ZADD num2 1 b 2 c 3 d (integer) 3 127.0.0.1:6379&gt; ZINTERSTORE tmp1 2 num1 num2 AGGREGATE SUM (integer) 2 127.0.0.1:6379&gt; ZRANGE tmp1 0 -1 WITHSCORES 1) &quot;b&quot; 2) &quot;3&quot; 3) &quot;c&quot; 4) &quot;5&quot; 127.0.0.1:6379&gt; 结果分数是取参与运算元素分数的总数 num1中b的分数是2 num2中b的分数是1 最后结果是3 如果不加AGGREGATE 默认也是去SUM值 所以可以不用加 WEIGHTS参数设置每个集合的权重，每个集合在参与计算时元素的分数会被乘上该集合的权重 127.0.0.1:6379&gt; ZINTERSTORE tmp2 2 num1 num2 WEIGHTS 1 10 (integer) 2 127.0.0.1:6379&gt; zrange tmp2 0 -1 WITHSCORES 1) &quot;b&quot; 2) &quot;12&quot; 3) &quot;c&quot; 4) &quot;23&quot; 127.0.0.1:6379&gt; ZUNIONSTORE与ZINTERSTORE用法相似 则不再赘述 附录 命令总结 ZADD key score member [score member …] 增加元素 ZSCORE key member 获取元素分数 ZRANGE key start stop [WITHSCORES] 获取某个索引范围的元素 ZREVRANGE key start stop [WITHSCORES] 获取某个索引范围的元素 反序排序 ZRANGEBYSCORE key min max [WITHSCORES] [LIMIT offset count] 获取某个分数范围的元素 ZREVRANGEBYSCORE key max min [WITHSCORES] [LIMIT offset count] 获取某个分数范围的元素 反序排序 ZINCRBY key increment member 增加某个元素的分数 ZCARD key 获取集合中元素数量 ZCOUNT key min max 获得指定分数范围内的元素个数 ZREM key member [member …] 删除一个或多个元素 ZREMRANGEBYRANK key start stop 按照排名范围删除元素 ZREMRANGEBYSCORE key min max 按照分数范围删除元素 ZRANK key member 获得元素的排名 正序排序 ZREVRANK key member 获得元素的排名 反序排序 ZINTERSTORE dest numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX] 交集 ZUNIONSTORE dest numkeys key [key ...] [WEIGHTS weight] [AGGREGATE SUM|MIN|MAX] 并集]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis集合类型]]></title>
    <url>%2F2016%2F05%2F24%2F2016%2Fredis%E9%9B%86%E5%90%88%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[简介 集合和列表有很多相似的地方 但是很容易将他们区分开 集合的元素有唯一性 而且元素是无序的。集合类型的常用操作是向集合中加入或删除元素、判断某个元素是否存在等。最方便的是多个集合类型键之间还可以进行并集、交集和差集运算 环境 软件名称 版本号 下载地址 redis 3.2.0 点击下载 步骤常用命令 下面将详细说明操作Redis集合类型的相关命令 增加和删除元素12SADD key member [member ...] # 向一个集合添加元素SREM key member [member ...] # 从一个集合删除元素 127.0.0.1:6379&gt; SADD num 1 2 2 3 (integer) 3 127.0.0.1:6379&gt; SREM num 1 1 2 (integer) 2 127.0.0.1:6379&gt; SADD执行成功会返回添加成功的个数 因为2相同 所以只有一个被添加 SREM也同样 返回被成功删除的个数 获取集合内所有元素1SMEMBERS num # 获取集合内所有元素 127.0.0.1:6379&gt; SMEMBERS num 1) &quot;3&quot; 127.0.0.1:6379&gt; SADD num 2 2 (integer) 1 127.0.0.1:6379&gt; SMEMBERS num 1) &quot;2&quot; 2) &quot;3&quot; 可以看到 num中只剩下3了 而且添加两个元素2 最后num中也只有一个2 判断元素是否在集合中1SISMEMBER num 2 # 判断元素是否在集合中 127.0.0.1:6379&gt; SISMEMBER num 2 (integer) 1 127.0.0.1:6379&gt; SISMEMBER num 1 (integer) 0 127.0.0.1:6379&gt; 如果命中了 则返回1 否则返回0 集合运算123SDIFF key1 [key2 ...] # 计算差集SINTER key1 [key2 ...] # 计算交集SUNION key1 [key2 ...] # 计算并集 SDIFF计算多个集合的差集 会想计算key1与key2的差集 然后将这个结果与key3继续计算 交集并集也同理 127.0.0.1:6379&gt; SADD num1 1 2 3 (integer) 3 127.0.0.1:6379&gt; SADD num2 2 3 4 (integer) 3 127.0.0.1:6379&gt; SDIFF num1 num2 1) &quot;1&quot; 127.0.0.1:6379&gt; SDIFF num2 num1 1) &quot;4&quot; 127.0.0.1:6379&gt; num1与num2的差集运算表示属于num1 且不属于num2的元素 反之亦然 127.0.0.1:6379&gt; SINTER num1 num2 1) &quot;2&quot; 2) &quot;3&quot; 127.0.0.1:6379&gt; SINTER 计算num1和num2的交集 127.0.0.1:6379&gt; SUNION num1 num2 1) &quot;1&quot; 2) &quot;2&quot; 3) &quot;3&quot; 4) &quot;4&quot; 127.0.0.1:6379 SUNION 计算num1和num2的合集 获取集合中元素个数1SCARD key # 获取集合中元素个数 127.0.0.1:6379&gt; SMEMBERS num1 1) &quot;1&quot; 2) &quot;2&quot; 3) &quot;3&quot; 127.0.0.1:6379&gt; SCARD num1 (integer) 3 127.0.0.1:6379&gt; SCARD 返回一个集合中元素个数 存储集合运算后的结果123SDIFFSTORE dest key [key …] # 将差集运算的结果保存为destSINTERSTORE dest key [key …] # 将交集运算的结果保存为destSUNIONSTORE dest key [key …] # 将并集运算的结果保存为dest 127.0.0.1:6379&gt; SUNIONSTORE all num1 num2 (integer) 4 127.0.0.1:6379&gt; SMEMBERS all 1) &quot;1&quot; 2) &quot;2&quot; 3) &quot;3&quot; 4) &quot;4&quot; 127.0.0.1:6379&gt; 和SDIFF唯一区别就是不将结果返回 而是将结果保存为新的集合 只返回新集合元素个数 其余两个道理相同 随机获得集合中的元素1SRANDMEMBER key [count] # 随机获得集合中的元素 count非必选项 用于每次获取多少个随机元素 count的正负体现的意义也不同 count &gt; 0 时 随机获取count个元素 但是元素不会出现重复获取的情况 也就是都是唯一的 count &lt; 0 时 随机获取count的绝对值个元素 元素可能被重复获取 如果count的值大于集合中的元素个数 则SRANDMEMBER会返回集合中的全部元素 127.0.0.1:6379&gt; SRANDMEMBER all &quot;1&quot; 127.0.0.1:6379&gt; SRANDMEMBER all &quot;2&quot; 127.0.0.1:6379&gt; SRANDMEMBER all 6 1) &quot;1&quot; 2) &quot;2&quot; 3) &quot;3&quot; 4) &quot;4&quot; 127.0.0.1:6379&gt; SRANDMEMBER all -6 1) &quot;2&quot; 2) &quot;1&quot; 3) &quot;1&quot; 4) &quot;3&quot; 5) &quot;2&quot; 6) &quot;2&quot; 127.0.0.1:6379&gt; 从集合中弹出一个元素1SPOP key # 从集合中弹出一个元素 127.0.0.1:6379&gt; SPOP all &quot;4&quot; 127.0.0.1:6379&gt; SMEMBERS all 1) &quot;1&quot; 2) &quot;2&quot; 3) &quot;3&quot; 127.0.0.1:6379&gt; SPOP all &quot;1&quot; 127.0.0.1:6379&gt; SMEMBERS all 1) &quot;2&quot; 2) &quot;3&quot; 127.0.0.1:6379&gt; 由于集合是无序的 所以SPOP会随机弹出一个值 附录 命令总结 SADD key member [member ...] 向一个集合添加元素 SREM key member [member ...] 从一个集合删除元素 SMEMBERS num 获取集合内所有元素 SISMEMBER num 2 判断元素是否在集合中 SDIFF key1 [key2 ...] 计算差集 SINTER key1 [key2 ...] 计算交集 SUNION key1 [key2 ...] 计算并集 SCARD key 获取集合中元素个数 SDIFFSTORE dest key [key …] 将差集运算的结果保存为dest SINTERSTORE dest key [key …] 将交集运算的结果保存为dest SUNIONSTORE dest key [key …] 将并集运算的结果保存为dest SRANDMEMBER key [count] 随机获得集合中的元素 SPOP key 从集合中弹出一个元素]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis字符串类型]]></title>
    <url>%2F2016%2F05%2F20%2F2016%2Fredis%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%B1%BB%E5%9E%8B%2F</url>
    <content type="text"><![CDATA[简介 字符串类型是 Redis 中最基本的数据类型，它能存储任何形式的字符串，包括二进制数据。你可以用其存储用户的邮箱、JSON 化的对象甚至是一张图片。一个字符串类型键允许存储的数据的最大容量是512 MB 环境 软件名称 版本号 下载地址 redis 3.2.0 点击下载 步骤命令返回值 与redis-server交互 当执行一条命令后 redis-server都会有一个命令返回值 redis-server的返回值类型有五种 下面分别说明 1. 状态回复 状态回复是最简单的一种回复 比如向Redis发送SET命名设置某个键值时 Redis会回复OK表示成功 127.0.0.1:6379&gt; SET a 1 OK 127.0.0.1:6379&gt; PING PONG 127.0.0.1:6379&gt; 2. 错误回复 当命令不存在或者命令格式有错误的情况下 Redis会返回错误回复 127.0.0.1:6379&gt; SET (error) ERR wrong number of arguments for &apos;set&apos; command 127.0.0.1:6379&gt; 3. 整数回复 获取当前数据库中键的数量等 返回以(integer)开头的回复 这个便是整数回复 127.0.0.1:6379&gt; dbsize (integer) 2 127.0.0.1:6379&gt; 4. 字符串回复 字符串回复是最常用的一种回复类型 比如当获得一个键的值 Redis返回的便是一个字符串值 127.0.0.1:6379&gt; get a &quot;1&quot; 127.0.0.1:6379&gt; 5. 多行字符串回复 当请求的并非一个键的值 而是一个列表等 就会收到多行字符串回复 每行字符串都以一个序号开头 127.0.0.1:6379&gt; keys * 1) &quot;a&quot; 2) &quot;b&quot; 127.0.0.1:6379&gt; 常用命令 下面将详细说明操作Redis字符串类型的相关命令 赋值与取值12SET key value # 赋值GET key # 取值 127.0.0.1:6379&gt; SET name xiaoming OK 127.0.0.1:6379&gt; GET name &quot;xiaoming&quot; 127.0.0.1:6379&gt; 如果需要给多个键同时赋值和取值 Redis还提供了MSET MGET两个命令 12MSET key value [key value ...] # 同时赋值MGET key [key ...] # 同时取值 127.0.0.1:6379&gt; MSET a 1 b 2 c 3 OK 127.0.0.1:6379&gt; MGET a c b 1) &quot;1&quot; 2) &quot;3&quot; 3) &quot;2&quot; 127.0.0.1:6379&gt; 用MSET 给a 赋值1 b赋值2 c赋值3 返回状态回复OK 用MGET 先获取a的值 再获取c的值 最后获取b的值 返回一个多行字符串回复 递增递减1INCR key # 递增 当Redis存储的字符串是整数时 Redis提供了一个INCR的命令 其作用就是让当前键值递增 127.0.0.1:6379&gt; INCR num (integer) 1 127.0.0.1:6379&gt; INCR num (integer) 2 127.0.0.1:6379&gt; INCR num (integer) 3 127.0.0.1:6379&gt; 当递增的key不存在时 Redis则自动创建这个key 并赋值为0 所以第一次递增后 就返回1了 可以看到 返回值类型是整数回复 如果递增的对象不是一个整数会怎样呢 127.0.0.1:6379&gt; INCR name (error) ERR value is not an integer or out of range 127.0.0.1:6379&gt; 可以看到 收到一条错误回复 如果想要递增指定的数字 这个就要引入第二条递增命令了 1INCRBY key increment # 递增指定整数 127.0.0.1:6379&gt; INCRBY num 10 (integer) 13 127.0.0.1:6379&gt; INCRBY num 3 (integer) 16 127.0.0.1:6379&gt; 可以看到 INCR和INCRBY的区别就是 INCRBY可以自定义递增数量 而INCR 只能每次加一 现在说说递减 递减其实也有专门的操作命令 12DECR key # 递减DECRBY key decrement # 递减指定整数 127.0.0.1:6379&gt; DECR num (integer) 15 127.0.0.1:6379&gt; DECRBY num 5 (integer) 10 127.0.0.1:6379&gt; 有没有想过 如果给INCRBY递增一个负数 或者给DECRBY递减一个负数会发生什么事情呢 127.0.0.1:6379&gt; DECRBY num -10 (integer) 20 127.0.0.1:6379&gt; INCRBY num -5 (integer) 15 127.0.0.1:6379&gt; 可以看到 正如所想的那样 负负得正还是成立的 不仅整数可以递增 Redis还存在递增浮点数的命令 1INCRBYFLOAT num increment # 递增指定浮点数 127.0.0.1:6379&gt; INCRBYFLOAT num 1.4 &quot;16.4&quot; 127.0.0.1:6379&gt; INCRBYFLOAT num -3.2 &quot;13.2&quot; 127.0.0.1:6379&gt; 向尾部追加值1APPEND key value # 向尾部追加值 127.0.0.1:6379&gt; APPEND name 123abc (integer) 14 127.0.0.1:6379&gt; GET name &quot;xiaoming123abc&quot; 127.0.0.1:6379&gt; 可以看到 APPEND 命令可以向字符串后面增加任意的字符串 返回增加后字符串长度 获取字符串长度1STRLEN key # 获取字符串长度 127.0.0.1:6379&gt; SET hello hello OK 127.0.0.1:6379&gt; STRLEN hello (integer) 5 127.0.0.1:6379&gt; SET hello 你好 OK 127.0.0.1:6379&gt; STRLEN hello (integer) 6 127.0.0.1:6379&gt; Redis可以存储所有编码的字符串 中文也不例外 例子中Redis接受的是UTF-8编码的中文 一个中文UTF-8编码长度是3 所以 &apos;你好&apos; 会返回6了 位操作 位操作是个很有意思的操作 操作的是这个字符串在内存中的比特位1234GETBIT key offset # 获取偏移多少位后的值SETBIT key offset value # 设置偏移多少位后的值BITCOUNT key [start end] # 获取比特位是1的个数BITPOS key bit [start] [end] # 获取第一个位值是0或1的位置 大家都知道 一个字节由8个比特位组成 而一个英文字符又正好一个字节 127.0.0.1:6379&gt; SET name abc a b c的三个字母的ASCII码分别是97 98 99 那么转换为二进制则如下 a b c 01100001 01100010 01100011 比特位获取索引从0开始 比如第0位是0 第1位是1 第2位也是1 127.0.0.1:6379&gt; GETBIT name 2 (integer) 1 127.0.0.1:6379&gt; GETBIT name 7 (integer) 1 127.0.0.1:6379&gt; GETBIT name 8 (integer) 0 127.0.0.1:6379&gt; GETBIT name 9 (integer) 1 127.0.0.1:6379&gt; GETBIT是获取比特位的 那么SETBIT自然可以更改比特位的值 更改比特位后 自然也更改了这个字符 分析a b c 三个字符的二进制数据 发现他们的区别在最后两位 01 10 11 那么修改这几个位的值试试 127.0.0.1:6379&gt; SETBIT name 6 1 (integer) 0 127.0.0.1:6379&gt; GET name &quot;cbc&quot; 127.0.0.1:6379&gt; 将a的第6位修改为1 那么原本a的二进制就变成了01100011 也就是和c相同了 a被变成了c BITCOUNT用来统计一定范围内比特位为1的个数 name的值变为cbc后 比特位如下 c b c 01100011 01100010 01100011 可以数出来 1的个数有11个 BITCOUNT还可以限定参与计算的字符范围 127.0.0.1:6379&gt; BITCOUNT name (integer) 11 127.0.0.1:6379&gt; BITCOUNT name 0 0 (integer) 4 127.0.0.1:6379&gt; 第一个0是从第几个字符开始 第二个0是到第几个字符结束 0 0 就表示只有第一个字符c参与计算 Redis 2.8.7版本以上才有BITPOS这个命令 可以获取指定键的第一个位值是0或者1的位置 也可以限定范围 127.0.0.1:6379&gt; BITPOS name 1 (integer) 1 127.0.0.1:6379&gt; BITPOS name 0 1 2 (integer) 8 127.0.0.1:6379&gt; 第一个命令 获取name中 位值为1的索引 可以看到 01100011中 位值为1的索引是1 第二个命令 限定从索引为1的字符开始 到索引为2的字符 位值为0的索引 字符b的第一位就是0 索引是8 附录 命令总结 SET key value 赋值 GET key 取值 MSET key value [key value …] 同时赋值 MGET key [key …] 同时取值 INCR key 递增 INCRBY key increment 递增指定整数 DECR key 递减 DECRBY key decrement 递减指定整数 INCRBYFLOAT num increment 递增指定浮点数 APPEND key value 向尾部追加值 STRLEN key 获取字符串长度 GETBIT key offset 获取偏移多少位后的值 SETBIT key offset value 设置偏移多少位后的值 BITCOUNT key [start end] 获取比特位是1的个数 BITPOS key bit [start] [end] 获取第一个位值是0或1的位置]]></content>
      <categories>
        <category>Redis</category>
      </categories>
  </entry>
  <entry>
    <title><![CDATA[Redis服务管理及配置文件]]></title>
    <url>%2F2016%2F05%2F18%2F2016%2Fredis%E6%9C%8D%E5%8A%A1%E7%AE%A1%E7%90%86%E5%8F%8A%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%2F</url>
    <content type="text"><![CDATA[简介 Redis启动后还需要对其进行管理 比如如何安全的关闭数据库 以及如何配置服务的监听地址 访问密码等下面将详细说明 Redis服务的简单管理 以及配置文件详解 环境 软件名称 版本号 下载地址 redis 3.2.0 点击下载 步骤启动和停止Redis 启动Redis很简单 可执行程序路径后面跟配置文件路径就可以了 如果在前台运行Redis的话 Ctrl+c就可以很安全的关闭Redis了 那么如果在后台运行呢 /usr/local/redis/bin/redis-server /etc/redis.conf --daemonize yes 通过--daemonize yes或者直接修改配置文件中的daemonize为yes 让Redis默认后台运行 [root@localhost ~]# netstat -anpt tcp 0 0 127.0.0.1:6379 0.0.0.0:* LISTEN 3268/redis-server 1 可以看到 Redis已经监听在本机127.0.0.1的6379端口 PID号为3268 关闭Redis也非常简单 因为Redis能很好的处理TREM信号 所以可以直接 kill 3268 同样 使用redis-cli客户端连接工具 向Redis服务发送SHUTDOWN命令也是可以安全关闭的 /usr/local/redis/bin/redis-cli -h 127.0.0.1 -p 6379 SHUTDOWN redis的命令不区分大小写 但是建议命令大写 如果服务监听在本机的127.0.0.1:6379 redis-cli可以直接连接 而不用指定主机和端口号 当redis收到结束命令或TERM信号后 会断开所有客户端连接 然后将内存数据序列化到硬盘 最后完成退出 Redis配置文件 Redis的启动监听地址 监听端口 以及配置PID文件路径等 有非常多的启动参数 如果都在启动redis的时候传入 那么将非常麻烦 而通过配置文件的方式 将大大简化这个过程Redis的配置项还分两种 一种是只能在启动Redis的时候配置的 比如监听端口等 还有一种可以在命令行中动态修改的 比如日志记录级别等 以下是Redis配置文件中常用配置项 include /path/to/other.conf # 包含其他配置文件 监听相关配置项 tcp-backlog 511 # TCP监听最大容纳数量 增大可以解决高并发下客户端连接缓慢问题 unixsocket /tmp/redis.sock # 非默认项 启动unix套接字监听 redis-cli -s /tmp/redis.sock连接 timeout 0 # 客户端多长时间没有操作redis关闭连接 0表示不关闭 tcp-keepalive 0 # tcp 心跳包 防止一个死的对端连接 推荐设置为60秒 一般配置项 daemonize no # Redis默认运行在前台 使用yes可以让Redis默认后台运行 pidfile /var/run/redis.pid # pid文件位置 loglevel notice # 日志记录级别 [debug | verbose | notice | warning] logfile /tmp/redis.log # 日志文件位置 默认是个空字符串 redis将日志打印到标准输出 syslog-enabled no # 如果想把日志记录到系统日志 就改为yes databases 16 # redis启动数据库空间个数 默认进入的是id为0空间 select dbID切换 数据库快照配置项 save 900 1 # 保存数据库到磁盘 900 秒内如果至少有 1 个 key 的值变化，则保存 save 300 10 # 300 秒内如果至少有 10 个 key 的值变化，则保存 save 60 10000 # 60 秒内如果至少有 10000 个 key 的值变化，则保存 save &quot;&quot; # 停用自动保存功能 不同的保存规则是可以都生效的 dbfilename dump.rdb # 保存数据的文件位置 stop-writes-on-bgsave-error yes # 后台保存数据出错 redis强制关闭写操作 rdbcompression yes # 是否在保存数据时压缩 可以减少磁盘使用 但是增大CPU负载 rdbchecksum yes # 是否校验rdb文件 dir ./ # dump.rdb就保存在dir目录中 主从复制配置项 slaveof 172.17.0.2 6379 # 作为172.17.0.2的从数据库 masterauth password # 如果主数据库需要认证 密码写这里 slave-serve-stale-data yes # 如果与主失去联系 从是否要继续提供查询服务 数据可能不是最新 slave-read-only yes # 默认从数据库不支持写入操作 repl-ping-slave-period 10 # 默认每10秒 从数据库发送ping命令道主数据库 repl-timeout 60 # 主从复制过期时间 一定要比repl-ping-slave-period大 repl-diskless-sync no # 默认情况下 复制是内存-&gt; 磁盘-&gt; 内存-&gt; slave端 yes后 将直接发到slave repl-diskless-sync-delay 5 # 收到第一个请求时 等待多个slave一起来请求之间的间隔时间 repl-backlog-size 1mb # 设置主从复制容量大小 slave断线重连 只恢复断开时丢失的数据 repl-backlog-ttl 3600 # 3600秒后 slave没有连接 master将释放backlog 0表示不释放 slave-priority 100 # 集群中用 master挂了 slave提升为master的优先级 min-slaves-to-write 3 # 至少3个slave才允许向master写数据 min-slaves-max-lag 10 # 至少3个slave 并且ping心跳的超时不超过10秒 才允许向master写数据 安全配置项 requirepass passwd # 连接需要密码 redis-cli 需要通过auth命令 或 -a 参数指定密码登陆 rename-command CONFIG &quot;&quot; # 给命令重命名 如果重命名为空字符串 则屏蔽命令 限制相关配置 maxclients 10000 # 最大连接客户端数量 超过的 redis将关闭新连接 maxmemory 1024mb # 数据库最大占用1024mb内存 超过的话 将按照策略移除keys maxmemory-policy noeviction # 内存超过后默认移除key的策略 maxmemory-samples 5 # 调整算法的速度和精度 默认从五个键中找到一个使用最少的键 以下是支持的策略: volatile-lru -&gt; 使用 LRU 算法移除包含过期设置的 key allkeys-lru -&gt; 根据 LRU 算法移除所有的 key volatile-random -&gt; 随机移除过期的key allkeys-random -&gt; 随机移除所有的key volatile-ttl -&gt; 删除最近到期的key noeviction -&gt; 不让任何 key 过期，只是给写入操作返回一个错误 AOF日志配置项 appendonly no # 默认不启用aof日志 appendfilename redis.aof # aof日志名称 和rdb快照共享dir路径 appendfsync everysec # aof日志同步硬盘数据策略 (fsync) 每次更改数据库内存后 AOF都会将命令记录到AOF文件 但是由于系统缓存机制 数据还并没真正写入硬盘 系统默认30秒写入一次硬盘 如果在这期间 系统异常退出 将导致数据丢失 以下是redis的解决策略: no -&gt; 不进行主动同步操作 always -&gt; 每次执行写入操作都进行一次同步 everysec -&gt; 每秒执行一次主动同步操作 no-appendfsync-on-rewrite no # 是否在Redis重写aof文件期间调用fsync auto-aof-rewrite-percentage 100 # aof文件增长超过上次aof文件大小100% 重写aof文件 0 禁用 auto-aof-rewrite-min-size 64mb # 触发aof重写的大小限制 只有aof大小超过64mb 上一条才生效 aof-load-truncated yes # redis在启动时可以加载被截断的AOF文件 Lua脚本配置项 lua-time-limit 5000 # 一个lua脚本最长执行时间 0或负数无限执行 默认5000毫秒 Redis集群配置项 cluster-enabled yes # 启用或禁用集群 cluster-config-file nodes.conf # 保存节点配置文件的路径 节点配置文件无须人为修改 cluster-node-timeout 15000 # 集群节点超时 默认15000毫秒 cluster-slave-validity-factor 10 # master失联多久 slave故障切换 0 表示一直尝试切换 cluster-migration-barrier 1 # 一个master可以拥有的最小slave数量 cluster-require-full-coverage yes # 当一定比例的键空间没有被覆盖到 集群就停止任何查询操作 慢查询日志配置项 slowlog-log-slower-than 10000 # 配置记录慢查询日志的条件 单位是微妙 负值关闭 0记录所有 slowlog-max-len 1024 # 记录慢查询日志最大条数 延时监控配置项 latency-monitor-threshold 0 # redis延迟监控子系统在运行时 会抽样检测可能导致延迟的不同操作 # 系统只记录超过设定值的操作 单位是毫秒 0表示禁用该功能 事件通知配置项 notify-keyspace-events &quot;&quot; # 空字符串表示关闭键空间通知功能 支持以下字符任意组合 K -&gt; 键空间通知 所有通知以 __keyspace@ __ 为前缀 E -&gt; 键事件通知，所有通知以 __keyevent@ __ 为前缀 g -&gt; DEL EXPIRE RENAME 等类型无关的通用命令的通知 $ -&gt; 字符串命令的通知 l -&gt; 列表命令的通知 s -&gt; 集合命令的通知 h -&gt; 哈希命令的通知 z -&gt; 有序集合命令的通知 x -&gt; 过期事件 每当有过期键删除时通知 e -&gt; 键淘汰事件 每当有键因为maxmemory-policy 策略被淘汰时通知 A -&gt; 参数g$lshzxe 的别名 高级配置 hash-max-ziplist-entries 512 # 指定在超过一定的数量或者最大的元素超过某一临界值时 hash-max-ziplist-value 64 # 采用一种特殊的哈希算法 list-max-ziplist-size -2 # 列表 集合 有序集合和哈希的一样 list-compress-depth 0 set-max-intset-entries 512 zset-max-ziplist-entries 128 zset-max-ziplist-value 64 hll-sparse-max-bytes 3000 # HyperLogLog稀疏表示限制设置 activerehashing yes # 如果对延迟要求较高 则设为no 禁止重新hash 但可能会浪费很多内存 client-output-buffer-limit normal 0 0 0 # 客户端缓存限制 硬限制 软限制 以及软限制持续秒数 client-output-buffer-limit slave 256mb 64mb 60 # 当满足硬限制 或者 软限制和持续秒数 与客户端断开 client-output-buffer-limit pubsub 32mb 8mb 60 hz 10 # 内部函数执行的后台任务的频率 如清除过期数据 客户端超时链接等 1~500 附录动态更改Redis配置 连接到redis后 用CONFIG GET * 可以看到所有的配置 用CONFIG SET则可以对配置进行修改 但是 并不是所有的配置都能动态修改 下面的例子 是用CONFIG SET 动态的给数据库添加认证密码 127.0.0.1:6379&gt; CONFIG SET requirepass 123.com OK 127.0.0.1:6379&gt; set a 100 (error) NOAUTH Authentication required. 127.0.0.1:6379&gt; auth 123.com OK 127.0.0.1:6379&gt; set a 100 OK 127.0.0.1:6379&gt; 可以看到 通过CONFIG GET已经可以看到刚才设置的密码 127.0.0.1:6379&gt; CONFIG GET requirepass 1) &quot;requirepass&quot; 2) &quot;123.com&quot; 127.0.0.1:6379&gt; 由于已经配置了密码 下次登陆的时候 也可以直接用 -a 参数提供认证密码 /usr/local/redis/bin/redis-cli -a 123.com]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>nosql</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Redis数据库编译安装]]></title>
    <url>%2F2016%2F05%2F17%2F2016%2Fredis%E6%95%B0%E6%8D%AE%E5%BA%93%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介 Redis是一个开源的使用ANSI C语言编写、支持网络、可基于内存亦可持久化的日志型、Key-Value数据库，并提供多种语言的API。从2010年3月15日起，Redis的开发工作由VMware主持。从2013年5月开始，Redis的开发由Pivotal赞助。百度百科 环境 软件名称 版本号 下载地址 redis 3.2.0 点击下载 步骤编译安装 redis的编译安装非常简单 只需要安装 make 和 gcc 开发工具即可 12345yum install make gcctar xf redis-3.2.0.tar.gzcd redis-3.2.0make -j4make PREFIX=/usr/local/redis install 通过PREFIX=/usr/local/redis可以指定redis安装路径 默认安装到/usr/local/bin/中 提供配置文件并启动redis redis的启动非常方便 有很多默认配置 不使用配置文件也可以启动 但是想要灵活配置就比较不方便了 12cp redis.conf /etc/redis.conf/usr/local/redis/bin/redis-server /etc/redis.conf 如果如图下所示 那么就启动成功了 redis默认在前台运行 Ctrl+c 停止 _._ _.-``__ &apos;&apos;-._ _.-`` `. `_. &apos;&apos;-._ Redis 3.2.0 (00000000/0) 64 bit .-`` .-```. ```\/ _.,_ &apos;&apos;-._ ( &apos; , .-` | `, ) Running in standalone mode |`-._`-...-` __...-.``-._|&apos;` _.-&apos;| Port: 6379 | `-._ `._ / _.-&apos; | PID: 3173 `-._ `-._ `-./ _.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | http://redis.io `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; |`-._`-._ `-.__.-&apos; _.-&apos;_.-&apos;| | `-._`-._ _.-&apos;_.-&apos; | `-._ `-._`-.__.-&apos;_.-&apos; _.-&apos; `-._ `-.__.-&apos; _.-&apos; `-._ _.-&apos; `-.__.-&apos; 如果不使用配置文件 可以通过命令行参数方式运行redis-server /usr/local/redis/bin/redis-server /etc/redis.conf --daemonize yes --port 1212 这个的意思就是在后台运行 监听端口1212 默认是监听6379 可以更改redis.conf中的 daemonize 值为yes 这样 redis-server通过配置文件启动就默认在后台运行了 如果在指定了配置文件又使用了命令行参数的情况 命令行参数会覆盖配置文件中的相同项 redis客户端连接 redis-cli便是redis-server的客户端连接工具 同时 redis还有很多其他语言的API接口 /usr/local/redis/bin/redis-cli -h 127.0.0.1 -p 6379 redis-cli 默认会连接本机的6379端口 所以如果服务监听在127.0.0.1:6379 redis-cli可以直接连接 redis是基于key-value的数据库 下面就测试一下redis工作的是否正常 127.0.0.1:6379&gt; set a 100 OK 127.0.0.1:6379&gt; get a &quot;100&quot; 127.0.0.1:6379&gt; redis的使用非常简单 所有的命令也一共就一百多条 常用的更少 通过set命令给 a 赋值 100 然后通过 get 命令获取 a 的值 可以看到 a 的值被正确获取 redis服务正常工作 附录redis各程序功能redis-benchmark # redis性能测试工具 redis-check-aof # aof日志检查工具 redis-check-rdb # rdb日志检查工具 redis-cli # redis服务客户端 redis-server # redis服务程序 redis-sentinel # redis哨兵 用于集群检查主从状态 实际上这个是redis-server的软链接 redis支持的键值数据类型 字符串类型 散列类型 列表类型 集合类型 有序集合类型]]></content>
      <categories>
        <category>Redis</category>
      </categories>
      <tags>
        <tag>nosql</tag>
        <tag>redis</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx配置文件详解]]></title>
    <url>%2F2016%2F05%2F17%2F2016%2Fnginx%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介 Nginx丰富的功能实现 都是通过配置文件完成的 Nginx配置文件的结构非常简单易懂 而且又十分强大 下面就是Nginx配置文件的结构说明 以及一些常用配置项的解释 环境 软件名称 版本号 下载地址 nginx 1.9.13 点击下载 步骤Nginx配置文件结构 Nginx配置文件是一个纯文本文件 默认位置位于 /conf/nginx.conf 配置文件内容是以block的形式组织 每个block用 {} 表示 block内可以包含block 其关系如下: +--------------------------------+ | main | main 全局配置 pid文件位置 运行用户等配置 | +-----------------------+ | | | events | | events 设定Nginx工作模式 比如epoll select等 | +-----------------------+ | | +---------------------------+ | | | HTTP | | HTTP核心模块 | | +-----------------------+ | | | | | server | | | server 每一个server都可以视为一个虚拟主机 | | | +-------------------+ | | | | | | | location | | | | location 匹配网页位置 | | | +-------------------+ | | | | | | +-------------------+ | | | | | | | location | | | | 一个server可以存在多个不同的location | | | +-------------------+ | | | | | +-----------------------+ | | | | +-----------------------+ | | | | | server | | | 多个server就可以启动多个虚拟主机 | | +-----------------------+ | | | +---------------------------+ | +--------------------------------+ Nginx配置文件参数#user nobody; # 默认运行用户 编译时未指定的话为nobody worker_processes 4; # Nginx主进程要开启多少个工作进程 一般为当前CPU核心数 worker_cpu_affinity 0001 0010 0100 1000; # 将每个进程绑定到CPU的每个核心上 可以略提高性能 #error_log logs/error.log; # 错误日志的位置 默认是安装目录下的logs/error.log #error_log logs/error.log notice; # 可以在日志后面添加纪录级别 #error_log logs/error.log info; # 可选项有: [debug|info|notice|warn|error|crit] #pid logs/nginx.pid; # pid文件路径 nginx -s 控制服务就是从这里读取主进程的PID worker_rlimit_nofile 65535; # 指定文件描述符数量 增大可以让Nginx处理更多连接 # 还需要增大系统允许进程打开文件描述符的上限 ulimit -n 65536 events { use epoll; # Nginx默认会选择最适合的工作模式 linux一般为epoll # 支持:[select | poll | kqueue | epoll | /dev/poll] worker_connections 65535; # Nginx每个工作进程最大的连接数 } # 最大客户连接数为 worker_processes * worker_connections http { include mime.types; # 其他的block配置 可以通过include导入 这样可以很方便管理配置 default_type application/octet-stream; # 响应类型未定义content-type时 文件默认类型为二进制流 # mime.types中包含文件扩展名与文件类型映射表 #log_format main &apos;$remote_addr - $remote_user [$time_local] &quot;$request&quot; &apos; # &apos;$status $body_bytes_sent &quot;$http_referer&quot; &apos; # &apos;&quot;$http_user_agent&quot; &quot;$http_x_forwarded_for&quot;&apos;; # 定义access.log日志的格式 main为格式名称 access_log logs/access.log main; # 默认access.log的位置 以及使用main中定义的格式 client_max_body_size 20m; # 设置允许客户上传大小 client_header_buffer_size 32k; # 客户端请求 header_buffer大小 默认1k large_client_header_buffers 4 32k; # 指定客户请求header_buffer的缓存最大数量和大小 sendfile on; # 开启高效的文件传输模式 tcp_nopush on; # 开启tcp_nopush和tcp_nodelay用于防止网络阻塞 tcp_nodelay on; #keepalive_timeout 0; keepalive_timeout 65; # 客户端连接后保持连接的超时时间 client_header_timeout 10; # 设置客户端请求头读取超时时间 # 超时将返回Request time out (408) client_body_timeout 10; # 设置客户端请求主体读取超时时间 超时也将返回408 send_timeout 10; # 指定响应客户端的超时时间 # 如果超过这个时间 客户端没有任何活的 Nginx将关闭连接 gzip on; # 开启还是关闭gzip模块 on表示开启 实时压缩输出数据流 gzip_min_length 1k; # 允许压缩页面最小字节数 小于1k的文件可能越压越大 gzip_buffers 4 16k; # 申请4个单位16KB的内存做压缩结果流缓存 默认源文件大小 gzip_http_version 1.1; # 用于识别HTTP协议版本 默认 1.1 gzip_comp_level 2; # 压缩等级 1 表示最快压缩 但压缩比最小 9反之 gzip_types text/plain application/x-javascript text/css application/xml; # 指定压缩类型 gzip_vary on; # 让前端的缓存服务器缓存经过gzip压缩的页面 server { # server段就是虚拟主机的配置 listen 80; # 监听所有IP的80端口 可以指定单个IP server_name localhost; # 用来指定IP地址或域名 多个域名间用空格分开 #charset koi8-r; # 用于设置网页默认编码 #access_log logs/host.access.log main; # 每一个虚拟主机也可以定义单独的access.log location / { # URL地址匹配设置 root /var/www/html; # 网页根目录 index index.html index.htm; # 默认首页地址 会先寻找index.html 然后往后 } location ~ .*\.(gif|jpg|jpeg|png|bmp|swf)$ { # 匹配以这些格式结尾的请求 root /var/www/static; # 匹配到的请求从这个目录找文件 expires 30d; # 客户端缓存静态文件过期时间30天 } error_page 404 /404.html; # 自定义404页面 /404.html为root指定的位置 # redirect server error pages to the static page /50x.html # error_page 500 502 503 504 /50x.html; # 自定义50x页面 到/50x.html location = /50x.html { # 匹配50x页面的请求 root html; # 匹配到的请求从这个目录找文件 } # proxy the PHP scripts to Apache listening on 127.0.0.1:80 # location ~ \.php$ { # 匹配php页面的请求 index index.php # 默认索引index.php proxy_pass http://127.0.0.1 # 匹配到的请求转发到本机80端口处理 } location ~ \.jsp$ { # 匹配jsp页面的请求 index index.jsp # 默认索引index.jsp proxy_pass http://127.0.0.1:8080 # 匹配到的请求转发到本机8080端口处理 } location /status { # 匹配status的请求 stub_status on; # 开启Nginx工作状态统计 access_log logs/status.log; # 状态统计页面访问日志 auth_basic &quot;Nginx Status&quot;; # 自定义提醒 认证界面会显示 auth_basic_user_file /var/www/htpasswd; # 认证密码文件 htpasswd工具由httpd提供 } # 访问http://host/status 就可以看到状态统计了 # pass the PHP scripts to FastCGI server listening on 127.0.0.1:9000 # #location ~ \.php$ { # FastCGI模式 # root /var/www/html; # php页面根目录 # fastcgi_pass 127.0.0.1:9000; # FastCGI监听地址 也可以使用unix套接字监听地址 # fastcgi_index index.php; # 索引文件 # fastcgi_param SCRIPT_FILENAME /var/www/html$fastcgi_script_name; # php脚本全路径 # include fastcgi_params; #} # deny access to .htaccess files, if Apache&apos;s document root # concurs with nginx&apos;s one # #location ~ /\.ht { # 匹配ht开头的文件 # deny all; # 规则是全部拒绝 #} } # another virtual host using mix of IP-, name-, and port-based configuration # #server { # 另一台虚拟主机 # listen 8000; # listen somename:8080; # server_name somename alias another.alias; # location / { # root html; # index index.html index.htm; # } #} # HTTPS server # #server { # 配置https网站 # listen 443 ssl; # 监听443端口 ssl加密 # server_name localhost; # ssl_certificate cert.pem; # 证书需要用openssl生成 nginx需要添加ssl模块 # ssl_certificate_key cert.key; # 证书key # ssl_session_cache shared:SSL:1m; # ssl_session_timeout 5m; # ssl_ciphers HIGH:!aNULL:!MD5; # ssl_prefer_server_ciphers on; # location / { # root html; # index index.html index.htm; # } #} } 附录 Nginx还有其他配置块 比如upstream (负载均衡) 或者其他模块提供的功能 这里只说明一些常用的配置块]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx服务控制]]></title>
    <url>%2F2016%2F05%2F16%2F2016%2Fnginx%E6%9C%8D%E5%8A%A1%E6%8E%A7%E5%88%B6%2F</url>
    <content type="text"><![CDATA[简介 Nginx可以通过向主进程发送信号的方式进行控制 甚至可以完成在不停止服务的情况下 对程序进行重启 升级 甚至回滚操作 环境 软件名称 版本号 下载地址 nginx 1.9.13 点击下载 步骤启动Nginx Nginx的启动很简单 如果配置了环境变量 可以直接通过nginx命令启动 也可以通过绝对路径启动 1/usr/local/nginx/sbin/nginx -c /usr/local/nginx/conf/nginx.conf 参数 “-c” 指定了配置文件的路径 如果不使用 “-c” 参数的话 nginx 会默认加载编译选项 --conf-path=PATH 中指定的路径 关闭Nginx 在早期 Nginx的关闭一般通过发送系统信号给Nginx主程序的方式来停止Nginx 之后的版本 Nginx添加了 “-s” 参数可以对Nginx主程序进行控制 通过信号的方式 需要先找到Nginx master进程的PID号 或者通过查看 nginx.pid文件来获取Nginx主进程的PIDNginx能处理的停止信号有两种 一种是 QUIT 当Nginx接受到这个信号时 会处理完当前所有的请求 并有序的关闭服务另一种是 TERM 或 INT Nginx收到这两种信号 会尽可能快的停止web服务 不保证处理完所有请求当然 还有一种Nginx不可控的信号 KILL 会强制杀死Nginx的进程 123PID=`ps aux |grep nginx |grep master |awk '&#123;print $2&#125;'`PID=`cat /var/run/nginx/nginx.pid`echo $PID 通过以上方法 即可获取Nginx主程序的PID号了 接下来就是通过kill命令向Nginx发送信号 1234kill -QUIT $PID # 安全从容的退出kill -INT $PID # 尽可能快的退出 kill $PID # 尽可能快的退出 因为默认kill发送的是TERM信号kill -KILL $PID # 强制杀死 较高版本的Nginx的 “-s” 参数也可以对Nginx进行控制 Nginx会读取nginx.pid文件来获取master进程的PID 然后向这个PID发送信号 12/usr/local/nginx/sbin/nginx -s quit # 安全从容的退出 实质上还是发送QUIT信号/usr/local/nginx/sbin/nginx -s stop # 尽可能快的退出 实质上发送TREM或INT信号 Nginx平滑重启 在Nginx运行过程中 如果修改了配置文件 但是又不想停止Nginx再重启让配置文件生效 也可以通过发送信号的方式 通知Nginx重新读取配置文件 1/usr/local/nginx/sbin/nginx -t -c /usr/local/nginx/conf/nginx.conf 修改nginx配置文件后 可以通过 -t 参数对配置文件进行检测 如果不通过 -c 指定配置文件 会检查默认的配置文件 当检查通过 就可以通知Nginx主进程重新读取了 12kill -HUP $PID # 通过HUP信号 可以通知Nginx主进程重新读取配置文件/usr/local/nginx/sbin/nginx -s reload # 同理 reload也是向Nginx主进程发送HUP信号 Nginx在收到HUP信号时 回先解析配置文件 如果解析成功 就应用新的配置文件 之后 Nginx运行新的工作进程 并从容关闭旧的工作进程 等所有的请求处理完毕后 旧的工作进程被关闭 Nginx平滑升级 如果想给正在运行中的Nginx升级版本 或者添加/删除服务模块 可以在服务不间断的情况下 对Nginx进行升级 备份原本的nginx二进制 为了意外恢复 并使用新的二进制程序代替了以前的位置 向Nginx主程序发送USR2信号 旧版的Nginx主程序将nginx.pid重命名为nginx.pid.oldbin 然后执行新版本的Nginx可执行程序 将新的PID写入nginx.pid文件 当前新旧两个Nginx进程会同时提供服务 还需要手动关闭旧Nginx主进程 仅保留新的Nginx主进程 1234mv /usr/local/nginx/sbin/&#123;nginx,nginx.old&#125;cp objs/nginx /usr/local/nginx/sbin/nginx # 默认nginx编译后在源码包的objs目录中 也可以直接make install覆盖安装kill -USR2 $PID # 向Nginx主进程的PID号发送USR2信号 现在可以看到 新旧两个Nginx主进程在同时提供服务 发送 WINCH 信号 可以通知Nginx主进程从容的关闭工作进程(worker process) 这时将只剩下新的Nginx的工作进程提供服务1kill -WINCH $PID 如果一段时间 新Nginx工作正常 就可以向旧版Nginx发送退出信号 结束掉旧Nginx的主进程了 旧进程退出后还会移除nginx.pid.oldbin文件1kill $OLD_PID 如果运行一段时间 发现并不是理想中的那种工作状态 那么可以发送 HUP 信号向旧Nginx主进程 让其重新打开工作进程 接着向新Nginx主进程发送 QUIT 信号 从容关闭主进程 最后恢复旧nginx的二进制文件123kill -HUP $OLD_PIDkill -QUIT $PIDmv /usr/local/nginx/sbin/&#123;nginx.old,nginx&#125; # 不要忘记恢复旧的二进制文件 Nginx日志控制 Nginx的访问日志会记录客户端的每次一请求 所以在用户量大的情况下 会很容易变得很大 也可以通过发送信号的方式进行控制日志 而不用关闭Nginx服务 Nginx主进程启动后 便会一直打开access.log日志文件 当服务器被长时间的访问 这个日志会越来越大 不利于日后的清理 由于这个日志文件被Nginx一直处于打开的状态 冒然删除这个日志文件并不是个很好的方法 而且删除后 Nginx还会向该文件的inode节点写入日志数据 因此 文件即使被删除 文件系统空间也不会释放 这样就只有重启Nginx才能释放空间并读写新的日志了 因此 管理access.log的方式不应该用直接删除文件的方式 如果对日志内容不在意 可以直接清空文件1echo &gt; /usr/local/nginx/logs/access.log 还有一个更好的方式 就是让Nginx重新打开一个新的文件进行读取 先将原来的access.log重命名 因为重命名并不会更改文件的inode节点 所以不会影响Nginx程序的日志写入 接着发送 USR1 信号 Nginx主程序将打开一个新的access.log文件开始写入12kill -USR1 $PID/usr/local/nginx/sbin/nginx -s reopen # 重新打开日志文件 和 USR1 同理 附录 Nginx支持的信号汇总 信号类型 功能 TREM 或 INT 快速关闭Nginx服务 QUIT 从容关闭Nginx服务 HUP 通知Nginx重新读取配置文件 USR1 重新打开日志文件 常用于日志分割 USR2 平滑升级可执行程序 WINCH 从容关闭工作进程]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx编译参数详解]]></title>
    <url>%2F2016%2F05%2F16%2F2016%2Fnginx%E7%BC%96%E8%AF%91%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3%2F</url>
    <content type="text"><![CDATA[简介 主要介绍Nginx编译安装的可选项 以后对Nginx进行升级 或者功能拓展都可以查阅 查找合适的模块 环境 软件名称 版本号 下载地址 nginx 1.9.13 点击下载 步骤123tar xf nginx-1.9.13.tar.gzcd nginx-1.9.13./configure --help --help 打印帮助信息 --prefix=PATH Nginx安装路径 默认 /usr/local/nginx --sbin-path=PATH Nginx可执行文件安装路径 默认 &lt;prefix&gt;/sbin/nginx --modules-path=PATH Nginx动态模块安装路径 默认 &lt;prefix&gt;/modules --conf-path=PATH Nginx配置文件的路径 默认 &lt;prefix&gt;/conf/nginx.conf --error-log-path=PATH nginx.conf中没有指定的情况下 错误日志默认路径 &lt;prefix&gt;/logs/error.log --pid-path=PATH nginx.conf中没有指定的情况下 pid文件默认路径 &lt;prefix&gt;/logs/nginx.pid --lock-path=PATH nginx.lock文件的路径 --user=USER nginx.conf中没有指定的情况下 Nginx使用的用户 默认 nobody --group=GROUP nginx.conf中没有指定的情况下 Nginx使用的用户组 默认 nobody --build=NAME 指定编译的名字 --builddir=DIR 指定编译的目录 --with-select_module 允许select模式 根据configure检测 如果没有更好的 select将是默认方式 --without-select_module 不允许select模式 --with-poll_module 允许poll模式 --without-poll_module 不允许poll模式 --with-threads 允许线程池支持 --with-file-aio 允许file aio支持 (文件异步读写模型) --with-ipv6 启动 ipv6 支持 --with-http_ssl_module 提供HTTPS支持 --with-http_v2_module 支持HTTP2协议 --with-http_realip_module 获取客户机真实IP模块 --with-http_addition_module 添加在响应之前或之后追加内容的模块 --with-http_xslt_module 通过XSLT模板转换XML应答 --with-http_xslt_module=dynamic 通过XSLT模板转换XML应答 编译为动态模块 --with-http_image_filter_module 传输JPEG/GIF/PNG 图片的一个过滤器 --with-http_image_filter_module=dynamic 同上 编译为动态模块 --with-http_geoip_module 获取IP所属地的模块 --with-http_geoip_module=dynamic 获取IP所属地的模块 编译为动态模块 --with-http_sub_module 允许替换响应中的一些文本 --with-http_dav_module 开启WebDAV扩展动作模块 --with-http_flv_module 提供flv播放服务的模块 --with-http_mp4_module 提供mp4播放服务的模块 --with-http_gunzip_module 提供gunzip压缩的模块 --with-http_gzip_static_module 在线实时压缩输出数据流 能有效节省带宽 --with-http_auth_request_module 客户子请求的认证基础 --with-http_random_index_module 随机目录索引 --with-http_secure_link_module 检查客户请求链接 可以用于下载防盗链 --with-http_degradation_module 允许在内存不足的情况下返回204或444码 --with-http_slice_module 切片模块 --with-http_stub_status_module Nginx工作状态统计模块 --without-http_charset_module 禁用重新编码web页面模块 --without-http_gzip_module 禁用在线实时压缩输出数据流 --without-http_ssi_module 禁用服务器端包含模块 --without-http_userid_module 禁用用户ID模块 该模块为用户通过cookie验证身份 --without-http_access_module 禁用访问模块 对于指定的IP段 允许访问配置 --without-http_auth_basic_module 禁用基本的认证模块 --without-http_autoindex_module 禁用目录自动索引模块 --without-http_geo_module 禁用Geo模块 --without-http_map_module 禁用Map模块 该模块允许你声明map区段 --without-http_split_clients_module 禁用基于某些条件将客户端分类模块 --without-http_referer_module 禁用 过滤请求 拒绝报头中Referer值不正确的请求的模块 --without-http_rewrite_module 禁用url重写模块 --without-http_proxy_module 禁用http代理模块 --without-http_fastcgi_module 禁用fastcgi模块 --without-http_uwsgi_module 禁用uwsgi模块 --without-http_scgi_module 禁用scgi模块 --without-http_memcached_module 禁用Memcached模块 --without-http_limit_conn_module 禁用连接限制模块 --without-http_limit_req_module 禁用限制用户连接总和的模块 --without-http_empty_gif_module 禁用empty_gif模块 --without-http_browser_module 禁用Browser模块 --without-http_upstream_hash_module 以下是禁用负载均衡相关的一些模块 --without-http_upstream_ip_hash_module --without-http_upstream_least_conn_module --without-http_upstream_keepalive_module --without-http_upstream_zone_module --with-http_perl_module 通过此模块 nginx可以直接使用perl --with-http_perl_module=dynamic 编译为动态模块 --with-perl_modules_path=PATH 设定模块路径 --with-perl=PATH 设定perl库文件路径 --http-log-path=PATH 设定http访问日志路径 --http-client-body-temp-path=PATH 设定http客户端请求临时文件路径 --http-proxy-temp-path=PATH 设定http代理临时文件路径 --http-fastcgi-temp-path=PATH 设定http fastcgi临时文件路径 --http-uwsgi-temp-path=PATH 设定http uwsgi临时文件路径 --http-scgi-temp-path=PATH 设定http scgi临时文件路径 --without-http 禁用http server功能 --without-http-cache 禁用http cache功能 --with-mail 启用POP3/IMAP4/SMTP代理模块支持 --with-mail=dynamic 编译为动态模块 --with-mail_ssl_module 启用加密的邮箱代理模块 --without-mail_pop3_module 禁用pop3模块 --without-mail_imap_module 禁用imap模块 --without-mail_smtp_module 禁用smtp模块 --with-stream 启动tcp/udp代理模块 --with-stream=dynamic 编译为动态模块 --with-stream_ssl_module 启动加密的tcp/udp代理模块 --without-stream_limit_conn_module --without-stream_access_module --without-stream_upstream_hash_module --without-stream_upstream_least_conn_module --without-stream_upstream_zone_module --with-google_perftools_module 启用google_perftools模块 优化高并发性能 --with-cpp_test_module 启用ngx_cpp_test_module支持 --add-module=PATH 启用拓展模块 指定路径 --add-dynamic-module=PATH 启用动态拓展模块 --with-cc=PATH 指定c编译器路径 --with-cpp=PATH 指定C预处理路径 --with-cc-opt=OPTIONS 设置C编译器参数 --with-ld-opt=OPTIONS 设置链接文件参数 --with-cpu-opt=CPU 指定编译的CPU 可选值: pentium, pentiumpro, pentium3, pentium4, athlon, opteron, sparc32, sparc64, ppc64 --without-pcre 禁用pcre库 (正则表达式) --with-pcre 启用pcre库 --with-pcre=DIR 指定pcre库文件目录 --with-pcre-opt=OPTIONS 在编译时为pcre库设置附加参数 --with-pcre-jit 构建pcre提供jit编译支持 --with-md5=DIR 指向md5库文件目录 --with-md5-opt=OPTIONS 在编译时为md5库设置附加参数 --with-md5-asm 使用md5汇编源 --with-sha1=DIR 指向sha1库目录 --with-sha1-opt=OPTIONS 在编译时为sha1库设置附加参数 --with-sha1-asm 使用sha1汇编源 --with-zlib=DIR 指向zlib库目录 --with-zlib-opt=OPTIONS 在编译时为zlib设置附加参数 --with-zlib-asm=CPU 为指定的CPU使用zlib汇编源进行优化 --with-libatomic 为原子内存的更新操作的实现提供一个架构 --with-libatomic=DIR 指向libatomic_ops安装目录 --with-openssl=DIR 指向openssl源码目录 --with-openssl-opt=OPTIONS 在编译时为openssl设置附加参数 --with-debug 启用debug信息 附录 只需要在编译nginx时添加相应的选项就可以了 Nginx详细编译安装教程]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>nginx</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[构建基于Busybox的Nginx服务容器]]></title>
    <url>%2F2016%2F04%2F22%2F2016%2F%E6%9E%84%E5%BB%BA%E5%9F%BA%E4%BA%8EBusybox%E7%9A%84Nginx%E6%9C%8D%E5%8A%A1%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[简介 用docker容器进行打包服务非常方便 不需要考虑依赖的问题 只要把容器复制到其他有docker daemon的服务器就可以直接启动 并能很方便的利用Cgroup, Namespace技术实现资源控制和资源隔离这篇文档以Nginx为例 其他的像redis mysql php等服务也是可以使用这个方法进行打包为最精简的 只包含必须依赖的服务容器 环境 系统是ubuntu server 15.10版 用ubuntu系统作为docker服务的载体 如果非ubuntu15.10发行版 尽量保证内核版本在3.18以上 Nginx是在CentOS 6.7的容器中编译的 之后在ubuntu上完成打包在容器中编译Nginx只是我的个人习惯 不喜欢将主机环境乱安装一些不必要的包 保持清洁就好 编译什么的就交给容器去做吧 主机环境 身份 系统 IP Docker服务 ubuntu 15.10 172.17.0.1 Docker容器 CentOS 6.7 172.17.0.3 软件环境 软件名称 版本号 下载地址 Nginx 1.9.15 点击下载 Docker 1.9.1 点击下载 kernel 4.2.0 系统自带 步骤以下是打包Nginx服务容器的基本思路 选用Busybox环境作为基础 在CentOS 容器中编译Nginx 将Nginx的运行依赖库和Nginx程序复制到主机环境 部署到Busybox构建的rootfs中 导入Docker 查看是否正常运行 构建Busybox最小容器 Busybox构建文档：点击打开文档内容构建完毕之后 busybox-1.24.2/_install 就是我们需要当作容器基础的rootfs了 将它复制到随便一个目录 留用 1cp -rf busybox-1.24.2/_install/ rootfs 编译安装Nginx Nginx的编译文档：点击打开文档内容只需要做到文档中make -j4 也就是编译完成就可以了 之后的安装步骤就不按照文档的走了 安装nginx到非默认根1make DESTDIR=/nginx install 通过DESTDIR更改安装Nginx的根位置 以/nginx目录作为nginx安装的根 [root@localhost nginx-1.9.15]# ls /nginx/ usr var [root@localhost nginx-1.9.15]# tree /nginx/ /nginx/ ├── usr │ └── local │ └── nginx │ ├── conf │ │ ├── fastcgi.conf │ │ ├── fastcgi.conf.default │ │ ├── fastcgi_params │ │ ├── fastcgi_params.default │ │ ├── koi-utf │ │ ├── koi-win │ │ ├── mime.types 123cd /nginx/mkdir lib lib64 # 创建两个依赖库文件夹strip usr/local/nginx/sbin/nginx # 裁剪nginx二进制的编译跟踪信息 缩减nginx体积 复制Nginx运行依赖库 接下来查看nginx程序的所有依赖 [root@localhost nginx]# ldd usr/local/nginx/sbin/nginx linux-vdso.so.1 =&gt; (0x00007fff3caa3000) libdl.so.2 =&gt; /lib64/libdl.so.2 (0x00007f9bc2ff8000) libpthread.so.0 =&gt; /lib64/libpthread.so.0 (0x00007f9bc2ddb000) libcrypt.so.1 =&gt; /lib64/libcrypt.so.1 (0x00007f9bc2ba3000) libz.so.1 =&gt; /lib64/libz.so.1 (0x00007f9bc298d000) libc.so.6 =&gt; /lib64/libc.so.6 (0x00007f9bc25f9000) /lib64/ld-linux-x86-64.so.2 (0x0000561c3968f000) libfreebl3.so =&gt; /lib64/libfreebl3.so (0x00007f9bc23f5000) 将依赖复制到刚才创建的lib或者lib64目录中 如果这个依赖库在系统的lib目录下 那么就复制到lib目录中1234567cp /lib64/libdl.so.2 lib64/cp /lib64/libpthread.so.0 lib64/cp /lib64/libcrypt.so.1 lib64/cp /lib64/libz.so.1 lib64/cp /lib64/libc.so.6 lib64/cp /lib64/ld-linux-x86-64.so.2 lib64/cp /lib64/libfreebl3.so lib64/ 由于Nginx运行需要使用普通用户 所以需要读取passwd文件 读取解析passwd文件需要用到libnss_files.so.2这个库 所以也需要复制这个库到lib64中 1cp /lib64/libnss_files.so.2 lib64/ 如果在ubuntu上编译的话libnss_files.so.2位置在/lib/x86_64-linux-gnu/libnss_files.so.2复制完成后lib64目录的内容应该如下所示： [root@localhost nginx]# ls lib64/ ld-linux-x86-64.so.2 libc.so.6 libfreebl3.so libpthread.so.0 libcrypt.so.1 libdl.so.2 libnss_files.so.2 libz.so.1 打包Nginx服务容器 Nginx以及Nginx的运行依赖都已经放到/nginx目录中了 将这个目录移动到和刚才的rootfs同一目录下 然后再创建两个目录 留用 1mkdir build target 认识overlayFS overlay是一种联合挂载的文件系统 可以将几个不同的目录挂载到一个目录中 然后将所有的文件展示出来 而且在挂载的目录中对文件的操作并不会影响到其他目录中实际的文件同时 在新版本的docker中 overlay便是docker容器默认使用的存储驱动 但是overlay在内核大于3.18的版本中才被支持 所以尽量用使用较新内核版本的发行版来玩Docker因为overlay的这些特性 用来辅助制作Nginx服务容器岂不是很方便 因为在挂载的目录中的操作并不会影响基层目录的文件 这样就算误删了文件 也是可以恢复的 现在看起来 应该是这个效果 root@ubuntu:~# ls -lh total 16K drwxr-xr-x 9 root root 4.0K Apr 22 12:50 build # overlay的工作目录 drwxr-xr-x 6 root root 4.0K Apr 22 15:34 nginx # 刚才安装的Nginx目录 drwxr-xr-x 18 root root 4.0K Apr 22 11:52 rootfs # busybox的目录 drwxr-xr-x 1 root root 4.0K Apr 22 12:50 target # 这个就是联合挂载到的目标目录 检查overlay驱动是否已经加载 否则加载overlay驱动12lsmod |grep overlaymodprobe overlay 如下所示 那么就可以使用overlay文件系统了 root@ubuntu:~# lsmod |grep overlay overlay 49152 1 root@ubuntu:~# cat /proc/filesystems |grep overlay nodev overlayfs nodev overlay 用rootfs和nginx做基层 其中rootfs是第一层 如果还有其他目录 依次用冒号隔开 build做为overlay工作目录 /tmp是overlay必须的一个空目录 将lowerdir中的目录都挂载到target目录上1mount -t overlay overlay -o lowerdir=rootfs:nginx,upperdir=build,workdir=/tmp target/ 接下来可以看到target目录中 rootfs和nginx目录中的内容同时出现在target目录中 root@ubuntu:~# ls target/ bin etc lib linuxrc mnt root sbin tmp var dev home lib64 media proc run sys usr root@ubuntu:~# ls target/bin/busybox target/bin/busybox root@ubuntu:~# ls target/usr/local/nginx/sbin/nginx target/usr/local/nginx/sbin/nginx 如果系统刚好不支持overlay文件系统的话 思想原理是相同的 直接将rootfs和nginx目录中的文件都复制到target中吧 Chroot进行根切换 接下来就是配置Nginx的运行环境了 这样才能保证Nginx打包为容器后能正常的运行通过chroot工具切换当前根到target目录中 这也算文件系统隔离一种的方式 1chroot target sh 可以看到 进入到了一个不同的shell中 ls / 竟然发现了linuxrc文件 现在已经将根切换到target目录中了 / # ls / bin etc lib linuxrc mnt root sbin tmp var dev home lib64 media proc run sys usr 根据执行Nginx的报错进行配置接下来的操作在这个根中进行 配置Nginx的运行环境 这些操作都是通过不断的执行nginx程序 查看nginx的报错总结的 123456adduser nginx # 添加nginx用户 mkdir -p /var/tmp/nginx/client/ # 创建nginx运行需要的目录mkdir -p /var/www/html # 以后将使用这个路径作为Nginx网页根目录ln -s /usr/local/nginx/sbin/nginx /usr/sbin/ # 添加nginx软链接到环境变量中ln -s /usr/local/nginx/conf/nginx.conf /etc/nginx.conf # 添加配置文件软连接到/etc目录echo '&lt;h1&gt;hello nginx&lt;/h1&gt;' &gt; /var/www/html/index.html # 创建一个索引文件 再次运行nginx程序 这时候遇到了ginx: [emerg] open(“/dev/null”) failed的错误 原因是打不开这个设备文件 这个只能通过启动为一个Docker容器来解决了 / # /usr/local/nginx/sbin/nginx nginx: [emerg] open(&quot;/dev/null&quot;) failed (2: No such file or directory) 修改Nginx配置文件剩下的就是修改nginx的配置文件了 1vi /etc/nginx.conf 第一行添加 daemon off; 让nginx前台运行 这个必须添加 http{}中添加 autoindex on; 运行目录索引 可以根据实际情况添加 http{ server{ location / { root /var/www/html; # root改为/var/www/html 可以根据实际情况更改 index index.html index.htm; } } } 将目录打包为Docker容器输入exit或者键入 Ctrl+d 就可以退出chroot 回到正常的根中了 接下来 将数据打包为Docker容器 可以看到 大小仅仅8M12cd target/tar -cf /dev/stdout *|docker import - nginx:1.9.15 root@ubuntu:~/target# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE nginx 1.9.15 99089cedcc48 3 seconds ago 8.071 MB 启动容器 检查是否成功然后后台启动这个容器 并且查看容器IP 通过curl命令检查nginx是否正常运行 可以看到 成功返回 hello nginx12docker run -d --name nginx nginx:1.9.15 nginxdocker inspect --format '&#123;&#123;.NetworkSettings.IPAddress&#125;&#125;' nginx root@ubuntu:~/target# docker run -d --name nginx nginx:1.9.15 nginx 0db0d45152948339fb0c9a23e8dfba6798c650e24075d725ba2d3021eb3b801b root@ubuntu:~/target# docker inspect --format &apos;{{.NetworkSettings.IPAddress}}&apos; nginx 172.17.0.8 root@ubuntu:~/target# curl 172.17.0.8 &lt;h1&gt;hello nginx&lt;/h1&gt; root@ubuntu:~/target# 这样 一个非常小 但是可以提供完整功能的Nginx服务容器就打包完成了 overlayFS文件误删的恢复如果在制作这个容器的过程中 不幸误删了target目录中的文件 还记的build这个文件吗1rm -rf linuxrc root@ubuntu:~/target# ls -l ../build/linuxrc c--------- 1 root root 0, 0 Apr 22 17:28 ../build/linuxrc 可以看到 build目录中出现了一个主次设备号都为0的字符设备 只要删除了这个字符设备 文件就恢复了1rm -rf ../build/linuxrc root@ubuntu:~/target# ls bin etc lib linuxrc mnt root sbin tmp var dev home lib64 media proc run sys usr 附录将Nginx容器镜像保存为文件 如果想把这个容器共享给其他人使用 除了使用push到仓库中 还可以直接通过文件的方式共享 配置一个默认启动命令 导入这个Nginx服务容器之后 每次启动都需要手动输入nginx命令 这样显的比较麻烦 可以通过Dockerfile的方式给这个容器配置一个默认的启动命令 1vim Dockerfile 键入以下内容： root@ubuntu:~# cat Dockerfile FROM nginx:1.9.15 CMD nginx nginx就是启动的命令 如果命令还带有参数 可以直接写出 例如 CMD nginx -s reload 1docker build -t nginx . # 给新镜像配置一个标签 记得不要忘记了最后的 . root@ubuntu:~# docker build -t nginx . Sending build context to Docker daemon 25.09 MB Step 1 : FROM nginx:1.9.15 ---&gt; 99089cedcc48 Step 2 : CMD nginx ---&gt; Running in 12b1a81d553c ---&gt; 114ba21e8f1c Removing intermediate container 12b1a81d553c Successfully built 114ba21e8f1c root@ubuntu:~# docker run -d nginx:latest 0f3f39dd3aea5a16b10a470ffecca716b31d0deab5420b07ee86bd1180bc2256 可以看到 启动这个新容器已经不需要输入nginx命令了 其实还有一个方法可以更改默认启动命令 通过直接修改镜像的配置文件可以看到 nginx:1.9.15镜像的ID是99089cedcc48 这只是完整ID的一部分 配置信息保存在/var/lib/docker/graph中 root@ubuntu:~# docker images REPOSITORY TAG IMAGE ID CREATED VIRTUAL SIZE nginx 1.9.15 99089cedcc48 48 minutes ago 8.071 MB 123cd /var/lib/docker/graphcd 99089cedcc48*vim json 这时就打开了这个镜像的配置文件 Cmd字段就是默认命令 还可以顺便改下comment信息 &quot;comment&quot;:&quot;nginx 1.9.15&quot;, # comment字段改为你想表达的信息 &quot;Cmd&quot;:[&quot;yunfwe&quot;], # Cmd字段有两个 第一个是作者信息 &quot;Cmd&quot;:[&quot;nginx&quot;], # 第二个才是启动命令 如果运行命令有其他参数的话 用逗号隔开 例如 &quot;Cmd&quot;:[&quot;nginx&quot;,&quot;-s&quot;,&quot;reload&quot;], 这样就相当于 nginx -s reload 了 接下来使用docker history nginx:1.9.11 查看信息 可以看到 CREATED BY 还有 COMMENT 是自己写的信息了 root@ubuntu:~# docker history 99089cedcc48 IMAGE CREATED CREATED BY SIZE COMMENT 99089cedcc48 58 minutes ago yunfwe 8.071 MB nginx 1.9.15 顺便可以看到运行命令也已经是nginx了 root@ubuntu:~# docker inspect --format {{.Config.Cmd}} nginx:1.9.15 {[nginx]} 这两种修改默认启动命令方法的一个重要区别是 第二种在原本的镜像上修改 是不会产生新的层的 而用Dockerfile修改 相当于新建了一个层 这个层提供了默认启动命令 不信可以使用docker history验证一下 保存为文件 默认docker导出的是个tar归档 这里直接将归档压缩为gz包 文件命名规则是REPOSITORY_TAG-Type.tar.gz其中的Type是标识这个文件是由镜像保存的还是已经生成的容器导出的 1docker save nginx:1.9.15 |gzip &gt; nginx_1.9.15-image.tar.gz 要恢复的话也很简单 docker支持直接从gz压缩包中恢复导入新的镜像 这个镜像的标签可能会丢失 但是id号还在 给这个id好重新打个标签 12docker load &lt; nginx_1.9.15-image.tar.gzdocker tag 99089cedcc48 nginx:1.9.15]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>nginx</tag>
        <tag>busybox</tag>
        <tag>docker</tag>
        <tag>overlay</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Busybox构建最小容器]]></title>
    <url>%2F2016%2F04%2F21%2F2016%2FBusybox%E6%9E%84%E5%BB%BA%E6%9C%80%E5%B0%8F%E5%AE%B9%E5%99%A8%2F</url>
    <content type="text"><![CDATA[简介 BusyBox 是一个集成了一百多个最常用linux命令和工具的软件。BusyBox 包含了一些简单的工具，例如ls、cat和echo等等，还包含了一些更大、更复杂的工具，例grep、find、mount以及telnet。有些人将 BusyBox 称为 Linux 工具里的瑞士军刀。简单的说BusyBox就好像是个大工具箱，它集成压缩了 Linux 的许多工具和命令，也包含了 Linux 系统的自带的shell。百度百科 环境 busybox编译安装方式和编译内核的方式一样 所以需要安装make, ncurses, gcc支持 ubuntu: apt-get install make gcc libncurses5-dev centos: yum install make gcc ncurses-devel 软件名称 版本号 下载地址 Busybox 1.24.2 下载地址 步骤配置Busybox编译选项123tar xf busybox-1.24.2.tar.bz2cd busybox-1.24.2make menuconfig 这时 将打开busybox编译的配置页面 为了方便起见 打算静态编译Busybox Busybox Settings ---&gt; # 这里是对busybox的设置 --- Applets # 以下的都是对小程序的配置 Archival Utilities ---&gt; Coreutils ---&gt; Console Utilities ---&gt; Debian Utilities ---&gt; Editors ---&gt; Finding Utilities ---&gt; Init Utilities ---&gt; Login/Password Management Utilities ---&gt; 静态编译Busybox属于Busybox的设定 上下键将光标选定Busybox Settings 回车进入 General Configuration ---&gt; # 这里是通用配置 Build Options ---&gt; # 这里是编译选项 Debugging Options ---&gt; Installation Options (&quot;make install&quot; behavior) ---&gt; Busybox Library Tuning ---&gt; 选择Build Options 回车进入 [*] Build BusyBox as a static binary (no shared libs) # 在这里 [ ] Force NOMMU build (NEW) [*] Build with Large File Support (for accessing files &gt; 2 GB) (NEW) () Cross Compiler prefix (NEW) () Path to sysroot (NEW) () Additional CFLAGS (NEW) () Additional LDFLAGS (NEW) () Additional LDLIBS (NEW) 光标处在Build BusyBox as a static binary处 空格键选择 [ ]变成了[*]然后左右键切换光标到exit 回车回到上一个页面 选择 General Configuration 回车进入 [*] Show applet usage messages (NEW) [*] Show verbose applet usage messages (NEW) [*] Store applet usage messages in compressed form (NEW) [*] Support --install [-s] to install applet links at runtime (NEW) [ ] Don&apos;t use /usr (NEW) [*] Enable locale support (system needs locale for this to work) # 在这里 [*] Support Unicode (NEW) [ ] Use libc routines for Unicode (else uses internal ones) (NEW) [ ] Check $LC_ALL, $LC_CTYPE and $LANG environment variables (NEW) (63) Character code to substitute unprintable characters with (NEW) 在 Enable locale support 处摁空格进行勾选 启动locale支持 然后一路的exit 直到以下界面 Do you wish to save your new configuration? &lt; Yes &gt; &lt; No &gt; 选择 &lt; Yes &gt; 后页面将会退出 配置也就完成了 修改源代码 提供中文显示支持 默认busybox不支持中文字符显示 接下来修改源代码 提供中文显示支持 vim ./libbb/printable_string.c 找到31,32行 删除或注释这两行找到45行 将”if (c &lt; ‘ ‘ || c &gt;= 0x7f)”注释”|| c &gt;= 0x7f” 29 if (c &lt; &apos; &apos;) 30 break; 31 // if (c &gt;= 0x7f) 32 // break; 45 if (c &lt; &apos; &apos;/* || c &gt;= 0x7f*/) 46 *d = &apos;?&apos;; 开始编译安装12makemake install 这时 busybox已经编译好了 就是当前目录下的busybox文件 检测一下busybox是否可以显示中文 root@ubuntu:~/busybox-1.24.2# touch 中文测试 root@ubuntu:~/busybox-1.24.2# ./busybox ls 中文测试 中文测试 root@ubuntu:~/busybox-1.24.2# ldd ./busybox not a dynamic executable 可以看到 中文名称的文件被正常显示 同时这个程序是个没有依赖的二进制文件 执行make install后 会将busybox和小程序的软链接都安装到当前目录中的_install/目录中 接下来就是打包为一个能正常启动docker容器 打包为docker镜像 如果只是编译安装Busybox的话 到这里就完了 下面是如何将Busybox制作为rootfs root@ubuntu:~/busybox-1.24.2# cd _install/ root@ubuntu:~/busybox-1.24.2/_install# ls bin linuxrc sbin usr 进入_install目录 可以看到已经存在几个busybox安装 小程序链接所存在的必须目录 root@ubuntu2:~/busybox-1.24.2/_install# ls -lh bin |head total 2.6M lrwxrwxrwx 1 root root 7 Apr 20 22:24 ash -&gt; busybox lrwxrwxrwx 1 root root 7 Apr 20 22:24 base64 -&gt; busybox -rwxr-xr-x 1 root root 2.6M Apr 20 22:24 busybox lrwxrwxrwx 1 root root 7 Apr 20 22:24 cat -&gt; busybox lrwxrwxrwx 1 root root 7 Apr 20 22:24 catv -&gt; busybox lrwxrwxrwx 1 root root 7 Apr 20 22:24 chattr -&gt; busybox lrwxrwxrwx 1 root root 7 Apr 20 22:24 chgrp -&gt; busybox lrwxrwxrwx 1 root root 7 Apr 20 22:24 chmod -&gt; busybox lrwxrwxrwx 1 root root 7 Apr 20 22:24 chown -&gt; busybox 可以看到 其实所有的命令都是软链接到busybox程序的 执行不同的命令 就有不同的效果 root@ubuntu:~/busybox-1.24.2/_install# bin/date Wed Apr 20 23:07:48 EDT 2016 root@ubuntu:~/busybox-1.24.2/_install# bin/uname -a Linux ubuntu 4.2.0-16-generic #19-Ubuntu SMP Thu Oct 8 15:35:06 UTC 2015 x86_64 GNU/Linux 原理非常简单 busybox程序通过判断 $0 也就是自身的名字是什么 来执行相应的功能 默认也可以通过将命令作为 $1 传入busybox root@ubuntu:~/busybox-1.24.2/_install# bin/busybox date Wed Apr 20 23:11:01 EDT 2016 root@ubuntu:~/busybox-1.24.2/_install# bin/busybox uname -a Linux ubuntu 4.2.0-16-generic #19-Ubuntu SMP Thu Oct 8 15:35:06 UTC 2015 x86_64 GNU/Linux 当前目录下的文件夹还缺少了很多Linux根文件系统存在的文件夹 现在创建这些文件夹 123456mkdir etc lib64 mnt proc run tmp var dev home lib media opt root sysmkdir var/&#123;log,opt,spool,run&#125;mkdir usr/&#123;include,lib,share,src,local&#125;mkdir usr/local/&#123;bin,sbin,include,lib,share,src&#125;cp /etc/&#123;passwd,shadow,gshadow,group&#125; etc/chmod a+wrxt tmp/ root@ubuntu:~/busybox-1.24.2/_install# ls bin etc lib linuxrc mnt proc run sys usr dev home lib64 media opt root sbin tmp var 现在再看 好像已经像那么回事了 接下来就是将这个rootfs打包为docker镜像 root@ubuntu:~/busybox-1.24.2/_install# tar -cf /dev/stdout *|docker import - busybox:1.24.2 sha256:5b5e476a877a87b5c4c976a2a6db1782c2d89e8177e6f4d9658127320d27c1cb root@ubuntu:~/busybox-1.24.2/_install# docker images REPOSITORY TAG IMAGE ID CREATED SIZE busybox 1.24.2 5b5e476a877a 10 seconds ago 2.635 MB 通过tar命令 将归档数据传入标准输出 通过管道符提交给docker去导入 然后命名新镜像为busybox:1.24.2 可以看到已经导入成功了 大小仅仅2.635 MB 测试Busybox运行效果 从busybox镜像启动一个新的容器 进行简单的命令测试 以后打包服务为docker镜像时就可以使用这个镜像为基础了 root@ubuntu:~/busybox-1.24.2/_install# docker run -ti --rm busybox:1.24.2 sh / # ifconfig eth0 eth0 Link encap:Ethernet HWaddr 02:42:AC:12:00:07 inet addr:172.18.0.7 Bcast:0.0.0.0 Mask:255.255.0.0 inet6 addr: fe80::42:acff:fe12:7/64 Scope:Link UP BROADCAST RUNNING MULTICAST MTU:1500 Metric:1 RX packets:6 errors:0 dropped:0 overruns:0 frame:0 TX packets:6 errors:0 dropped:0 overruns:0 carrier:0 collisions:0 txqueuelen:0 RX bytes:508 (508.0 B) TX bytes:508 (508.0 B) / # ls / bin etc lib linuxrc mnt proc run sys usr dev home lib64 media opt root sbin tmp var 附录Busybox容器通过远程连接访问 buxybox自带了telnetd小程序 这样就可以通过telnet工具远程登录这个容器了 / # telnetd # 启telnetd程序 可以看到已经正常监听23端口 / # netstat -anpt Active Internet connections (servers and established) Proto Recv-Q Send-Q Local Address Foreign Address State PID/Program name tcp 0 0 :::23 :::* LISTEN 8/busybox / # adduser busybox # 然后添加一个远程登录的用户名 默认是禁止root登录 Changing password for busybox New password: Bad password: too weak Retype password: Password for busybox changed by root 添加用户的同时会让你更改用户密码 接下来就可以试试用telnet工具远程登录到这个容器了 root@ubuntu:~# telnet 172.18.0.7 Trying 172.18.0.7... Connected to 172.18.0.7. Escape character is &apos;^]&apos;. ea68afe67966 login: busybox Password: ~ $ date Thu Apr 21 03:50:10 UTC 2016 ~ $ 如果想切换到root用户 需要给busybox添加suid权限 在上一个本地会话中完成添加 / # chmod +s /bin/busybox / # vi /etc/passwd # 由于不存在bash 切换root时会出错 所以需要更改root的默认shell root:x:0:0:root:/root:/bin/sh / # passwd root # 给root配置一个复杂些的密码 Changing password for root New password: Retype password: Password for root changed by root / # 然后回到telnet登录的会话中 用 su 命令切换到root用户 切换成功 ~ $ su Password: /home/busybox # 不仅telnetd服务 busybox还提供了httpd, udhcpd, tftpd, ntpd, dnsd等服务 还包括了linux常用的三四百条命令 真的是麻雀虽小五脏俱全 这样 一个功能强大 大小仅2.6MB的docker镜像就制作完成了]]></content>
      <categories>
        <category>Docker</category>
      </categories>
      <tags>
        <tag>busybox</tag>
        <tag>docker</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL数据误删恢复记录]]></title>
    <url>%2F2016%2F04%2F19%2F2016%2FMySQL%E6%95%B0%E6%8D%AE%E8%AF%AF%E5%88%A0%E6%81%A2%E5%A4%8D%E8%AE%B0%E5%BD%95%2F</url>
    <content type="text"><![CDATA[简介 由于程序出错 导致MySQL数据库三天内的数据混乱 现在需要删除三天内错误的数据 因为大意 where语句条件忘记添加引号 导致条件不生效 删除了表中所有的数据 现在需要通过binlog日志将此表的数据恢复 环境 生产环境 MySQL-5.5.15 已经开启二进制日志 mysql&gt; show variables like &apos;log_bin&apos;; +---------------+-------+ | Variable_name | Value | +---------------+-------+ | log_bin | ON | +---------------+-------+ 1 row in set (0.01 sec) 步骤 大体的数据恢复思路是： 先查询MySQL已经读写到的二进制日志 然后刷新二进制到新的日志文件 读取二进制日志 过滤出关于要恢复表的信息 将所有对要恢复表的操作信息保存为sql文件 然后将sql文件导入MySQL 完成数据恢复 查询已经写到的二进制位置通过 show master status; 查看当前写入到的二进制日志文件 [root@localhost /]# mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 236859 Server version: 5.5.14-log MySQL Community Server (GPL) Copyright (c) 2000, 2012, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. mysql&gt; show master status; +------------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +------------------+----------+--------------+------------------+ | mysql-bin.000037 | 40435151 | | | +------------------+----------+--------------+------------------+ 1 row in set (0.00 sec) 刷新二进制日志文件执行 flush logs; 刷新二进制日志 可以看到 已经打来了一个新的文件开始写入了二进制日志文件的路径一般在数据库目录下 mysql&gt; flush logs; Query OK, 0 rows affected (0.02 sec) mysql&gt; show master status; +------------------+----------+--------------+------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | +------------------+----------+--------------+------------------+ | mysql-bin.000038 | 107 | | | +------------------+----------+--------------+------------------+ 1 row in set (0.00 sec) 使用mysqlbinlog工具查看二进制日志 mysqlbinlog程序就是MySQL 二进制日志文件的查看工具了 先从从二进制中找到最后执行删除指令的语句 最后记录删除操作的二进制日志文件为mysql-bin.000037 要恢复的表存在与dbinfo库中 [root@localhost data]# mysqlbinlog -d dbinfo mysql-bin.000037 | \ grep &apos;delete&apos; -B1 |grep zf_total_increment -B1 SET TIMESTAMP=1460950871/*!*/; delete from zf_total_increment where insert_time &gt; 2016-04-16 这里看到了执行删除语句的时间戳是 1460950871 现在需要将它转换为日期时间 mysql&gt; select FROM_UNIXTIME(1460950871); +---------------------------+ | FROM_UNIXTIME(1460950871) | +---------------------------+ | 2016-04-18 11:41:11 | +---------------------------+ 1 row in set (0.00 sec) 恢复的时候当然不能把这一句也恢复了 否则刚恢复完毕又被删除了继续找到建表的日期 因为表并没有被删除 根据情况 可以先truncate下表 这样就不用重新创建了 [root@localhost data]# mysqlbinlog -d dbinfo mysql-bin.000009|grep zf_total_increment -B1|head SET TIMESTAMP=1389259355/*!*/; DROP TABLE IF EXISTS `zf_total_increment` /* generated by server */ -- SET TIMESTAMP=1389259355/*!*/; CREATE TABLE `zf_total_increment` ( -- -- ---------------------------- -- Records of zf_total_increment -- ---------------------------- INSERT INTO `zf_total_increment` VALUES (......) mysql&gt; select FROM_UNIXTIME(1389259355); +---------------------------+ | FROM_UNIXTIME(1389259355) | +---------------------------+ | 2014-01-09 17:22:35 | +---------------------------+ 1 row in set (0.00 sec) 可以看到 在同一时刻进行了删除已存在的表 创建表 插入第一条语句 那么就从这里开始恢复zf_total_increment这个表的数据存在与mysql-bin.000009到mysql-bin.000037中 需要挨个恢复 由于我并非要恢复所有的数据 原本就是要删除这几天的数据 所以只将数据恢复到2016-04-16之前如果是完全恢复的话 千万不要将delete语句的时间也恢复了 可以恢复到这个时间前一秒钟都行最好可以恢复到这条语句的前一个位置 [root@localhost data]# mkdir recovery [root@localhost data]# mysqlbinlog -d dbinfo \ --start-datetime=&apos;2014-01-09 17:22:35&apos; \ --stop-datetime=&apos;2016-04-16 00:00:00&apos; mysql-bin.000009 | \ grep zf_total_increment &gt;&gt; recovery/zf_total_increment.sql 这样 mysql-bin.000009中所有关于zf_total_increment的语句都被追加到zf_total_increment.sql中了接下来继续将mysql-bin.000010 到 mysql-bin.0000037中的也继续恢复 如果恢复的文件太多 可以使用脚本 等所有的日志都跑完了 最终的目标表的数据就都被保存为sql文件 [root@localhost recovery]# head zf_total_increment.sql DROP TABLE IF EXISTS `zf_total_increment` /* generated by server */ CREATE TABLE `zf_total_increment` ( -- Records of zf_total_increment INSERT INTO `zf_total_increment` VALUES (......) 查看这个文件 发现删除和创建语句也在其中 由于创建语句并没有写在一行 所以并不完整由于过滤的时候只过滤一行 导致写在下一行的 /*!*/; 丢失 下面用sed工具修正 [root@localhost recovery]# sed -i &apos;1,3d&apos; zf_total_increment.sql [root@localhost recovery]# sed -i &apos;s/$/;/g&apos; zf_total_increment.sql 最后就可以将这个sql文件导入MySQL执行了 [root@localhost recovery]# mysql -uroot -p123456 dbinfo &lt; zf_total_increment.sql 最后查看数据库 这个表的数据是否已经完全恢复了呢 这个sql文件也可以作为备份 供以后使用 附录 以下是mysqlbinlog支持的常用选项 --database=db_name, -d db_name 只列出该数据库的条目 只用本地日志 –-host=host_name, -h host_name 获取指定主机上的MySQL服务器的二进制日志 –-user=user_name, -u user_name 远程主机需要用于连接的用户名 –-password[=password], -p[password] 远程主机需要输入密码 注意-p和密码间不能有空格 –-port=port_num, -P port_num 连接远程主机使用的端口号 –-read-from-remote-server, -R 如果未给出该选项 任何远程连接的选项都被忽略 --result-file=name, -r name 输出到给定的文件 --start-datetime=datetime 从二进制中的日志某个日期开始读取往后的日志 --stop-datetime=datetime 读取二进制中的日志某个日期为止 --start-postition=N 从二进制中的某个位置开始读取 (# at 1 中的1就是N) --stop-postition=N 读取到二进制中的某个位置为止 –-disable-logs-bin,-D 如果直接将日志传给MySQL执行 此选项禁用二进制日志 如果数据库配置的有主从同步的话 不可以禁用二进制日志方式恢复否则可能因为没有二进制日志的产生 slave库并没有恢复数据 mysqlbinlog打印出来的数据是可以直接导入mysql的如果想把当时INSERT语句的执行日期也记录 就需要把SET TIMESTAMP也保留下 也可以通过以下方式直接将数据恢复到MySQL mysqlbinlog mysql-bin.000009 \ --start-position=7492 --stop-position=647724 \ |grep zf_total_increment -B1 -A1 |mysql -uroot -p123456 dbinfo 这个例子通过事务在日志中的位置来恢复的 grep的 -B1 参数同时保留了SET TIMESTAMP语句然后直接通过管道符提交给MySQL MySQL选择要恢复到的库 每一个二进制日志文件的position都是从新开始 如果在多个文件内恢复 可能就不如datetime方便了但是可以精确到每一条语句上 datetime的话 可能1秒内就有好多条语句]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>数据恢复</tag>
        <tag>mysqlbinlog</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Dnsmasq安装配置]]></title>
    <url>%2F2016%2F04%2F06%2F2016%2Fdnsmasq%E5%AE%89%E8%A3%85%E9%85%8D%E7%BD%AE%2F</url>
    <content type="text"><![CDATA[简介 DNSmasq是一个小巧且方便地用于配置DNS和DHCP的工具，适用于小型网络，它提供了DNS功能和可选择的DHCP功能。它服务那些只在本地适用的域名，这些域名是不会在全球的DNS服务器中出现的。DHCP服务器和DNS服务器结合，并且允许DHCP分配的地址能在DNS中正常解析，而这些DHCP分配的地址和相关命令可以配置到每台主机中，也可以配置到一台核心设备中（比如路由器），DNSmasq支持静态和动态两种DHCP配置方式。百度百科 环境 dnsmasq几乎没有额外的依赖 只需要系统安装好编译环境即可 软件名称 版本号 下载地址 dnsmasq 2.75 下载地址 步骤编译安装1234tar xf dnsmasq-2.75.tar.xzcd dnsmasq-2.75make &amp;&amp; make install # dnsmasq主程序在/usr/local/dnsmasqcp dnsmasq.conf.example /etc/dnsmasq.conf # 配置文件 一般到这就编译完成了 如果有特殊需求 可以通过修改Makefile文件实现 vim Makefile PREFIX = /usr/local/dnsmasq # 安装的位置 BINDIR = $(PREFIX)/sbin MANDIR = $(PREFIX)/share/man LOCALEDIR = $(PREFIX)/share/locale BUILDDIR = $(SRC) DESTDIR = CFLAGS = -Wall -W -O2 LDFLAGS = -s -static # 去掉编译debug信息 采用静态编译 注意 并不是所有平台修改过Makefile后都可以正常编译 用法详解 dnsmasq程序虽小 可五脏俱全 可以用来做DNS DHCP TFTP服务器 甚至可以用作PXE装机用打开/etc/dnsmasq.conf配置文件 可以看到所有的选项和说明 通过man 8 dnsmasq 可以看到更详细的内容为了方便配置不同的服务 将不同服务的配置文件分开 开启conf-dir=/etc/dnsmasq.d/,*.conf配置项这样 dnsmasq就会在启动的时候加载/etc/dnsmasq.d/内的*.conf文件了 1vim /etc/dnsmasq.conf 修改如下内容 conf-dir=/etc/dnsmasq.d/,\*.conf DNS服务 dnsmasq默认会启动dns服务 并读取系统的/etc/resolv.conf和/etc/hosts/etc/resolv.conf中的nameserver会被dnsmasq作为上行DNS server在遇到dnsmasq找不到的记录就像上行服务器发出请求 然后将结果返回客户机下面是dnsmasq中DNS功能一些常用的配置项 port=53 # port设置为0 会关闭dns功能 resolv-file=/etc/dnsmasq.resolv.conf # 从另一个文件获取上行DNS服务器地址 addn-hosts=/etc/dnsmasq.hosts.conf # 从另一个文件获取主机名IP地址映射 no-resolv # 禁用resolv 不获取上行DNS服务器 同时resolv-file失效 no-hosts # 不使用系统的hosts文件 仅使用addn-hosts配置的 listen-address=127.0.0.1 # 配置监听地址 interface=lo # 配置监听网卡接口 except-interface=eth0 # 配置不监听的网卡接口 如果配置了resolv-file dnsmasq就不会去读取系统的/etc/resolv.conf 而配置了addn-hosts dnsmasq会同时读取系统的/etc/hosts和配置指定的文件 为了能让系统能使用自己启动的DNS服务 并且不影响访问外网等操作 可以将系统的resolv.conf的nameserver改为127.0.0.1 然后在resolv-file指定的文件写入上行DNS服务器 1vim /etc/dnsmasq.d/dns.conf 写入如下内容 resolv-file=/etc/dnsmasq.resolv.conf addn-hosts=/etc/dnsmasq.hosts.conf 1234echo 'nameserver 127.0.0.1' &gt; /etc/resolv.conf # 系统使用本地的DNS服务器echo 'nameserver 180.76.76.76' &gt; /etc/dnsmasq.resolv.conf # dnsmasq去查询的DNS服务器echo '127.0.0.1 test' &gt; /etc/dnsmasq.hosts.conf # 测试dns解析效果/usr/local/dnsmasq/sbin/dnsmasq -d # 默认后台运行 -d 可以阻止 接下来用ping命令检查域名解析服务是否正常了 root@ubuntu:/etc/dnsmasq.d# ping -c4 test PING test (127.0.0.1) 56(84) bytes of data. 64 bytes from localhost (127.0.0.1): icmp_seq=1 ttl=64 time=0.050 ms 64 bytes from localhost (127.0.0.1): icmp_seq=2 ttl=64 time=0.037 ms 64 bytes from localhost (127.0.0.1): icmp_seq=3 ttl=64 time=0.034 ms 64 bytes from localhost (127.0.0.1): icmp_seq=4 ttl=64 time=0.033 ms --- test ping statistics --- 4 packets transmitted, 4 received, 0% packet loss, time 3996ms rtt min/avg/max/mdev = 0.033/0.037/0.050/0.009 ms 用dig命令检查 可以清楚的看到解析的A记录 root@ubuntu:/etc/dnsmasq.d# dig @127.0.0.1 test test. 0 IN A 127.0.0.1 也可以用nslookup命令检查 Windows平台的话 需要将127.0.0.1改为dnsmasq所在服务器的IP root@ubuntu:/etc/dnsmasq.d# nslookup test 127.0.0.1 Server: 127.0.0.1 Address: 127.0.0.1#53 Name: test Address: 127.0.0.1 以后只需要将需要解析的IP和名称写入/etc/dnsmasq.resolv.conf文件就可以了，不过美中不足的一点就是 每次修改了配置文件 都需要重新启动dnsmasq服务。 DHCP服务 DHCP服务在dnsmasq中的配置非常简单 甚至只用一行配置就可以启动一个正常工作的DHCP服务器一下是DHCP服务的常用配置项 dhcp-range=192.168.1.50,192.168.1.100,12h # 起始 结束 还有租约时间 dhcp-range=192.168.0.50,192.168.0.150,255.255.255.0,12h # 网段 dhcp-host=aa:bb:cc:dd:ee:ff,192.168.1.50 # mac地址 IP dhcp-host=00:0e:7b:ca:1c:6e,daunbook,192.168.0.12 # mac地址 主机名 IP dhcp-option=3,192.168.0.1 # 默认网关 dhcp-option=option:router,1.2.3.4 # 默认网关 和上面的一样 dhcp-option=option:ntp-server,192.168.0.4,10.10.0.5 # ntp服务地址 dhcp-option=option:dns-server,180.76.76.76 # dns服务器地址 no-dhcp-interface=eth0 # 不提供dhcp的接口 其中只要有dhcp-range或者dhcp-host的配置 dhcp服务就会启动 接下来 添加dhcp的配置项 并检测dhcp服务是否正常分配IP 123# 由于只能给同网段的主机分配IP 所以这里需要在网卡上绑定一个子接口ifconfig ens32:0 192.168.100.1/24 # 网卡名称根据实际情况来定vim /etc/dnsmasq.d/dhcp.conf 写入如下内容 dhcp-range=192.168.100.10,192.168.100.20,12h # 这里使用和当前局域网不同的网段 dhcp-option=option:router,192.168.100.1 # 自己同时作为网关 1/usr/local/dnsmasq/sbin/dnsmasq -d 可以清楚的看到dnsmasq的输出有DHCP的一些信息 dnsmasq-dhcp: DHCP, IP range 192.168.100.10 -- 192.168.100.20, lease time 12h 接下来检测DHCP服务是否能正常提供服务，在另外一台机器上 强行使用dhclient命令为网卡获取动态IP。 [root@localhost ~]# dhclient -v ens32:0 Internet Systems Consortium DHCP Client 4.2.5 Copyright 2004-2013 Internet Systems Consortium. All rights reserved. For info, please visit https://www.isc.org/software/dhcp/ Listening on LPF/ens32/00:0c:29:44:eb:ec Sending on LPF/ens32/00:0c:29:44:eb:ec Sending on Socket/fallback DHCPREQUEST on ens32 to 255.255.255.255 port 67 (xid=0xba1741) DHCPACK from 192.168.100.1 (xid=0xba1741) bound to 192.168.100.19 -- renewal in 19449 seconds. 可以看到从192.168.100.1获取了192.168.100.19这个IP 同时DHCP server端有这次请求信息。 dnsmasq-dhcp: DHCPREQUEST(ens32) 192.168.100.19 00:0c:29:44:eb:ec dnsmasq-dhcp: DHCPACK(ens32) 192.168.100.19 00:0c:29:44:eb:ec 也可以先将网卡配置为DHCP获取IP 然后重启 看看是否获取到了配置的IP段的IP 以及网关是否正确 TFTP服务 tftp是简单文件传输协议 有区别与一般的ftp服务 tftp使用UDP的69端口 一般用作小文件传输 下面就是如何用dnsmasq配置tftp服务 enable-tftp # 表示启动tftp服务 tftp-root=/tftp # 配置tftp的文件根目录 1vim /etc/dnsmasq.d/tftp.conf 写入如下内容 enable-tftp tftp-root=/tftp 123mkdir /tftpecho &apos;hello&apos; &gt; /tftp/test # 添加测试文件/usr/local/dnsmasq/sbin/dnsmasq -d 启动dnsmasq后 可以看到tftp服务也启动了 dnsmasq-tftp: TFTP root is /tftp 接下来验证tftp服务是否正常工作 通过tftp命令连接tftp服务 如果没有tftp命令 自行安装相应的包 root@ubuntu:/tmp# tftp 127.0.0.1 # 连接本地的tftp服务 tftp&gt; get test # 获取刚才写入的test文件 Received 7 bytes in 0.0 seconds tftp&gt; quit # quit命令退出交互 root@ubuntu:/tmp# cat test # 查看获取的文件 hello # 内容没有问题 tftp是一个非常简单的文件传输协议 只有文件上传下载功能 列出目录之类的功能就不用想了，支持的命令也非常少 可以在ftfp的交互界面 通过输入?来查询支持的命令 或许有些命令 服务端也并不支持。 附录用dnsmasq部署pxe自动装机 由于dnsmasq包含了DHCP和TFTP 所以用dnsmasq搭建pxe自动装机服务是完全可行的 而且只需要简简单单的几项配置就可以了 enable-tftp tftp-root=/tftp dhcp-boot=pxelinux.0 dhcp-range=192.168.100.10,192.168.100.20,12h 记得要将pxe装机需要的pxelinux.0等文件放到tftp-root配置的目录下，还要注意给客户分配的网段要根据实际情况分配。]]></content>
      <categories>
        <category>Dnsmasq</category>
      </categories>
      <tags>
        <tag>dns</tag>
        <tag>dhcp</tag>
        <tag>tftp</tag>
        <tag>pxe</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Zabbix3.0安装文档]]></title>
    <url>%2F2016%2F04%2F02%2F2016%2Fzabbix3.0%E5%AE%89%E8%A3%85%E6%96%87%E6%A1%A3%2F</url>
    <content type="text"><![CDATA[简介 zabbix是一个基于WEB界面的提供分布式系统监视以及网络监视功能的企业级的开源解决方案。zabbix能监视各种网络参数，保证服务器系统的安全运营；并提供灵活的通知机制以让系统管理员快速定位/解决存在的各种问题。zabbix由2部分构成，zabbix server与可选组件zabbix agent。zabbix server可以通过SNMP，zabbix agent，ping，端口监视等方法提供对远程服务器/网络状态的监视，数据收集等功能，它可以运行在Linux，Solaris，HP-UX，AIX，Free BSD，Open BSD，OS X等平台上百度百科 环境 在Linux下编译安装 zabbix3.0版对PHP最低版本要求是5.4 其他软件包无要求 主机环境 身份 系统 IP MySQL 服务器 CentOS 6.7 172.17.0.2 PHP-fpm 服务器 CentOS 6.7 172.17.0.3 Nginx 服务器 CentOS 6.7 172.17.0.4 Zabbix Server CentOS 6.7 172.17.0.5 Zabbix Agent1 CentOS 6.7 172.17.0.6 Zabbix Agent2 Windows 172.17.0.7 软件环境 软件名称 版本号 下载地址 php 5.6.19 下载地址 nginx 1.9.13 点击下载 mysql 5.6.28 点击下载 zabbix 3.0.1 点击下载 zabbix agent win版 3.0.0 点击下载 步骤搭建LNMP环境 由于zabbix自带的web管理界面需要PHP环境 所以只需要提供一个PHP版本不低于5.4的web环境即可以下是在Linux上搭建LNMP环境 服务器 安装文档地址 Nginx 点击打开文档内容 MySQL 点击打开文档内容 PHP-fpm 点击打开文档内容 LNMP 点击打开文档内容 编译安装Zabbix 需要系统先初始化开发环境 以及安装需要的程序开发包 yum -y install gcc mysql-devel libxml2-devel net-snmp-devel libssh2-devel curl-devel 1234567tar xf zabbix-3.0.1.tar.gzcd zabbix-3.0.1./configure --prefix=/usr/local/zabbix \--enable-server --enable-agent \--with-mysql --with-net-snmp \--with-libcurl --with-libxml2 --with-ssh2make -j4 &amp;&amp; make install 配置zabbix server 还需要给zabbix server配置防火墙安全策略 数据库 web服务等 配置防火墙关闭或者配置服务器的iptables和SElinux策略 service iptables stop setenforce 0 vim /etc/selinux/config 修改SELINUX=disabled 导入数据库mysql授权zabbix用户以及创建zabbix库 mysql -uroot -h172.17.0.2 -p mysql&gt; grant all privileges on zabbix.* to zabbix@&quot;%&quot; identified by &quot;123.com&quot;; mysql&gt; create database zabbix default charset utf8; 123mysql -uzabbix -h172.17.0.2 -p123.com zabbix &lt; schema.sqlmysql -uzabbix -h172.17.0.2 -p123.com zabbix &lt; images.sqlmysql -uzabbix -h172.17.0.2 -p123.com zabbix &lt; data.sql 启动zabbix服务修改zabbix_server.conf vim /usr/local/zabbix/etc/zabbix_server.conf DBName=zabbix DBHost=172.17.0.2 # 这里就是MySQL服务器的地址 DBUser=zabbix DBPassword=123.com DBPort=3306 ListenPort=10051 LogFile=/usr/local/zabbix/log/zabbix_server.log LogFileSize=100 DebugLevel=2 Timeout=30 PidFile=/usr/local/zabbix/var/zabbix_server.pid StartPollers=20 StartPollersUnreachable=5 StartTrappers=5 12345678mkdir /usr/local/zabbix/&#123;log,var&#125;useradd -M -s /sbin/nologin zabbix # 创建zabbix运行用户chown -R zabbix:zabbix /usr/local/zabbix/cp misc/init.d/fedora/core/&#123;zabbix_server,zabbix_agentd&#125; /etc/init.d/chmod +x /etc/init.d/&#123;zabbix_server,zabbix_agentd&#125; #服务控制脚本# 修改/etc/init.d/zabbix_server 和 /etc/init.d/zabbix_agentd # 确保BASEDIR的路径正确 BASEDIR=/usr/local/zabbix/usr/local/zabbix/sbin/zabbix_server # 这里直接使用绝对路径启动程序 检测zabbix_server是否正常启动监听 监听端口10051 [root@7938190c2002 zabbix-3.0.1]# netstat -anpt |grep 10051 tcp 0 0 0.0.0.0:10051 0.0.0.0:* LISTEN - 如果没有正常启动服务 请查看日志 /usr/local/zabbix/log/zabbix_server.log 配置web管理界面修改php-fpm服务的配置文件 修改为zabbix需要的值 vim php.ini # 本环境中 php.ini位置在/usr/local/php/lib/php.ini date.timezone = Asia/Shanghai post_max_size = 32M max_execution_time = 300 max_input_time = 300 always_populate_raw_post_data = -1 # php5.6以上版本会出现这个 重启php-fpm服务 service php-fpm restart 1234# 注意 是将php目录复制到php-fpm能访问到的路径 根据实际情况决定# 本环境已经通过NFS让zabbix, nginx 和 php-fpm 共享/var/www/html目录cp -rf frontends/php/ /var/www/html/zabbixchmod -R 777 /var/www/html/zabbix/conf # php页面需要将配置信息写到这个目录 打开浏览器 输入zabbix页面的地址 http://172.17.0.4/zabbix 点击 Next step 进入 Check of pre-requisites 页面确定 Check of pre-requisites 一页都是绿色 然后 Next step 进入 Configure DB connection 页面 输入mysql连接信息如果mysql服务在本地 可以输入使用默认的localhost 然后 Next step 配置zabbix server的信息 输入zabbix server的IP地址 端口 还有名称如果zabbix server在本机 Host使用默认的localhost即可 然后 Next step 确认一次信息是否有误 如果无误就 Next step 完成安装此时所有的信息保存在 /var/www/html/zabbix/conf/zabbix.conf.php 中 进入登陆页面 初始用户名和密码是 admin/zabbix 至此 zabbix server 安装安装完成 如果配置的有错误 还可以重新访问配置页面进行重新配置http://172.17.0.4/zabbix/setup.php web管理界面中文支持zabbix官方提供了中文支持 但是需要修改php页面开启 vim /var/www/html/zabbix/include/locales.inc.php 找到 &apos;zh_CN&apos; =&gt; array(&apos;name&apos; =&gt; _(&apos;Chinese (zh_CN)&apos;), &apos;display&apos; =&gt; false], 修改 &apos;display&apos; =&gt; true 在web管理界面 点击右上角的小人图标 或直接访问 http://172.17.0.4/zabbix/profile.php此时已经打开了zabbix的设置界面 语言选择中找到中文语言 如果中文选择是灰色说明当前系统并未支持zh_CN字符集 需要先安装zh_CN的支持才能正常选择中文 localedef -f UTF-8 -i zh_CN zh_CN.UTF8 通过 locale -a 可以查看当前系统已经支持的字符集 添加字符集后需要重启php-fpm服务 如果想应用以及配置好的字符集 可以通过配置环境变量: export LANG=&apos;zh_CN.UTF-8&apos; export LANGUANE=&apos;zh_CN.UTF-8&apos; 如果想设置为系统默认字符集 可以将环境变量写入到配置文件 CentOS系列: vim /etc/sysconfig/i18n 其实只要将已经添加好中文字符集的其他机器的 locale-archive 文件替换到自己目录即可文件路径: /usr/lib/locale/locale-archive 但是这样 系统可能会缺乏相应的字体 所以并不推荐 自带的中文字体可能会出现乱码 这时需要自己替换中文字体解决从Windows系统 c:\windows\fonts 或网上找一个自己喜欢的字体复制到 /var/www/html/zabbix/fonts/ 中 这里用 msyh.ttf sed -i &apos;s/DejaVuSans/msyh/g&apos; /var/www/html/zabbix/include/defines.inc.php 将默认的 DejaVuSans 替换成自己的 msyh 然后刷新网页 配置zabbix Agentd 通过–enable-agent选项可以安装zabbix_agent 因此 zabbix_server安装的时候已经启用zabbix_agent不需另行安装 其他客户端安装则不需过多编译选项 只需启用–enable-agent即可 Linux主机安装Agentd 以下操作是在Zabbix Agent1主机上进行编译 12345678useradd -M -s /sbin/nologin zabbixtar xf zabbix-2.2.10.tar.gzcd zabbix-2.2.10./configure --prefix=/usr/local/zabbix_agent --enable-agentmake &amp;&amp; make installmkdir /usr/local/zabbix_agent/&#123;log,var&#125;chown -R zabbix:zabbix /usr/local/zabbix_agent//usr/local/zabbix_agent/etc/zabbix_agentd.conf vim /usr/local/zabbix_agent/etc/zabbix_agentd.conf LogFile=/usr/local/zabbix_agent/log/zabbix_agentd.log PidFile=/usr/local/zabbix_agent/var/zabbix_agentd.pid DebugLevel=3 Server=127.0.0.1,172.17.0.5 # 配置允许连接的zabbix_server ServerActive=127.0.0.1,172.17.0.5 # 配置允许主动连接的zabbix_server StartAgents=8 Hostname=localhost Timeout=30 UnsafeUserParameters=1 根据实际情况修改配置文件参数的值 123# 配置服务启动脚本在zabbix_server中已经介绍 agent端只需要zabbix_agentd脚本即可# /usr/local/zabbix/sbin/zabbix_agentd # Server端启动zabbix_agentd/usr/local/zabbix_agent/sbin/zabbix_agentd # Agent端启动zabbix_agentd 检测 10050 端口是否正常监听 [root@13262019d57f ~]# netstat -anpt |grep 10050 tcp 0 0 0.0.0.0:10050 0.0.0.0:* LISTEN - zabbix Agent端自我检测是否可以正常获取监控数据 /usr/local/zabbix_agent/bin/zabbix_get -s 127.0.0.1 -k agent.ping zabbix Server端检测是否可以正常获取Agent端的数据 /usr/local/zabbix/bin/zabbix_get -s 172.17.0.6 -k agent.ping 都返回 1 则正常 这样就可以在web界面上添加server对agent的监控了 Windows主机安装Agentd 当前操作在Zabbix Agent2上进行 Zabbix Agent2是一台windows主机 获取Windwos版zabbix-agent安装包 zabbix_agents_3.0.0.win.zip 解压文件到任意安装目录 这里解压到 C:\Program Files\zabix 配置文件的修改方法大体和Linux下相同 编辑 C:\Program Files\zabix\conf\zabbix_agent.win.conf Server=127.0.0.1,172.17.0.5 ServerActive=127.0.0.1,172.17.0.5 StartAgents=8 Hostname=windows Timeout=30 UnsafeUserParameters=1 将zabbix_agentd注册为服务 以管理员身份运行cmd 到zabbix_agentd.exe的目录下 注意选好32位还是64位的exe &gt; zabbix_agentd.exe --install -c &quot;C:\Program Files\zabix\conf\zabbix_agent.win.conf&quot; 因为路径中有空格 所以用双引号扩起 出现installed successfully则安装成功 可以在服务管理界面启动和停止 &quot;zabbix agent&quot; 也可以用net命令控制 管理员身份运行cmd 控制启动和关闭服务 &gt; net start &quot;zabbix agent&quot; &gt; net stop &quot;zabbix agent&quot; 服务端检测是否正常获取数据 /usr/local/zabbix/bin/zabbix_get -s 172.17.0.7 -k agent.ping 返回1 服务端正常获取数据 附录常见故障处理编译配置报错检测依赖包是否正常安装 gcc等编译工具是否正常安装 无法打开Web界面检查LNMP环境是否正常 以及是否配置了正确的防火墙规则等 Web界面出现 Zabbix server is not running …检测是否关闭Selinux setenforce 0 检测zabbix_server的IP地址和端口号在web界面中是否正确配置 如果zabbix_server在本地 看主机是否正常解析localhost域名 # telnet localhost 10051 如果不能正常解析 # vim /var/www/html/zabbix/conf/zabbix.conf.php 将$ZABBIX_SERVER = &apos;localhost&apos; 换成 &apos;127.0.0.1&apos; 或者修改host文件 添加 localhost 到 127.0.0.1 的域名解析 127.0.0.1 localhost localhost.localdomain localhost4 localhost4.localdomain4 数据库mysql.sock文件无法找到如果MySQL服务器和php-fpm服务器在同一台主机 php-fpm可能会通过mysql.sock套接字和MySQL服务通信 如果有如下错误提醒: Database error: Error connecting to database [Can&apos;t connect to local MySQL server through socket &apos;/var/lib/mysql/mysql.lock&apos;] 确保/var/lib/mysql/mysql.lock存在 如果实际mysql.sock位置与报错中的位置不符 修改zabbix_server.conf中的DBSocket配置 DBSocket的值要为真实mysql.sock的绝对路径 然后重启服务 禁用guests账号 防止非法访问在web管理界面上操作 管理 &gt;&gt; 用户 &gt;&gt; Guests &gt;&gt; 状态:停用的 zabbix总览zabbix_get server和agent之间数据获取 -s 远程agent的主机名或IP地址 -p 远程agent的端口 默认10050 -I 如果有多块网卡 本机出去的IP地址 -k 获取远程agent数据用的KEY zabbix_get -s 127.0.0.1 -p 10050 -k agent.ping zabbix_server zabbix服务端的核心程序 zabbix_proxy abbix代理服务的程序 用于分布式监控proxy模式中 zabbix_agent 用超级服务方式启动用的程序 zabbix_agentd 独立进程方式启动用的程序 zabbix_java_gateway zabbix的java采集服务端 zabbix_sender 将采集到的数据定时发送给zabbix_server]]></content>
      <categories>
        <category>Zabbix</category>
      </categories>
      <tags>
        <tag>LNMP</tag>
        <tag>zabbix</tag>
        <tag>监控</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[LNMP环境部署]]></title>
    <url>%2F2016%2F04%2F01%2F2016%2FLNMP%E7%8E%AF%E5%A2%83%E9%83%A8%E7%BD%B2%2F</url>
    <content type="text"><![CDATA[简介 NMP代表的就是：Linux系统下Nginx+MySQL+PHP这种网站服务器架构。Linux是一类Unix计算机操作系统的统称，是目前最流行的免费操作系统。代表版本有：debian、centos、ubuntu、fedora、gentoo等。Nginx是一个高性能的HTTP和反向代理服务器，也是一个IMAP/POP3/SMTP代理服务器。Mysql是一个小型关系型数据库管理系统。PHP是一种在服务器端执行的嵌入HTML文档的脚本语言。这四种软件均为免费开源软件，组合到一起，成为一个免费、高效、扩展性强的网站服务系统。百度百科 环境 本教程中的各服务搭建在不同的服务器上 当然也可以搭建在同一个服务器上 主机环境 身份 系统 IP Nginx 服务器 CentOS 6.7 172.17.0.7 MySQL 服务器 CentOS 6.7 172.17.0.2 PHP-fpm 服务器 CentOS 6.7 172.17.0.6 软件环境 软件名称 版本号 下载地址 Nginx 1.9.13 点击下载 MySQL 5.6.28 点击下载 PHP 5.6.19 点击下载 步骤编译安装各组件 服务器 安装文档地址 Nginx 点击打开文档内容 MySQL 点击打开文档内容 PHP-fpm 点击打开文档内容 搭配组合 他们之间的搭配其实就是通过修改配置文件能互连起来 协调工作如果跨主机搭建需要让Nginx和PHP-fpm能访问相同的web网页目录或者只将PHP的页面放到PHP-fpm服务能访问到了路径即可因为Nginx收到PHP页面的请求会将请求转发给PHP-fpm去处理 自己并不处理PHP的页面但是如果其他的静态资源等 还是需要放到Nginx能访问到的路径实验中 已经通过NFS共享方式让Nginx和PHP-fpm挂载相同的/var/www/html目录 配置PHP-fpm打开编辑php-fpm.conf vim /usr/local/php/etc/php-fpm.conf 修改listen监听地址为0.0.0.0:9000 listen = 0.0.0.0:9000 配置仅允许连接的客户机 默认运行所有主机连接 172.0.0.7是Nginx服务器的IP listen.allowed_clients = 172.17.0.7 然后启动PHP-fpm的服务 service php-fpm start 配置Nginx打开编辑nginx.conf vim /usr/local/nginx/conf/nginx.conf 更改网站根路径和添加php页面的识别 location / { root /var/www/html; index index.html index.htm index.php; } 去掉php段的注释 并按实际环境修改以下内容 location ~ \.php$ { root /var/www/html; fastcgi_pass 172.17.0.6:9000; fastcgi_index index.php; fastcgi_param SCRIPT_FILENAME /var/www/html$fastcgi_script_name; include fastcgi_params; } 重启或通知Nginx重新加载配置文件 /usr/local/nginx/sbin/nginx -s reload 配置MySQLMySQL创建远程登录用户 php 只允许 172.17.0.6连接 密码 php123 grant all privileges on *.* to &quot;php&quot;@&quot;172.17.0.6&quot; identified by &quot;php123&quot;; 验证是否搭配成功在/var/www/html中编写index.php &lt;?php phpinfo(); ?&gt; 在/var/www/html中编写dbtest.php &lt;?php $link=mysql_connect(&quot;172.17.0.2&quot;,&quot;root&quot;,&quot;123.com&quot;); if(!$link) echo &quot;连接错误!&quot;; else echo &quot;可以连接!&quot;; ?&gt; 分别访问两个php文件 http://172.17.0.7/ 和 http://172.17.0.7/dbtest.php 若浏览器出现大大的PHP Version 5.6.19 则index.php被正常识别 访问dbtest.php若出现 &quot;可以连接!&quot; 则数据库连接成果 以下是用curl访问dbtest.php的结果 [root@45c4f07c6049 etc]# curl http://172.17.0.7/dbtest.php OK!可以连接 附录搭建好LNMP后 好多用到PHP运行环境的页面就可以在上面运行了 比如zabbix的web管理界面]]></content>
      <categories>
        <category>LNMP</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>php</tag>
        <tag>nginx</tag>
        <tag>zabbix</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[PHP-fpm 编译安装]]></title>
    <url>%2F2016%2F04%2F01%2F2016%2Fphp-fpm%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介 PHP（外文名:PHP: Hypertext Preprocessor，中文名：“超文本预处理器”）是一种通用开源脚本语言。语法吸收了C语言、Java和Perl的特点，利于学习，使用广泛，主要适用于Web开发领域。PHP 独特的语法混合了C、Java、Perl以及PHP自创的语法。它可以比CGI或者Perl更快速地执行动态网页。用PHP做出的动态页面与其他的编程语言相比，PHP是将程序嵌入到HTML（标准通用标记语言下的一个应用）文档中去执行，执行效率比完全生成HTML标记的CGI要高许多；PHP还可以执行编译后代码，编译可以达到加密和优化代码运行，使代码运行更快。百度百科 环境 软件名称 版本号 下载地址 php 5.5.33 下载地址 php 5.6.19 下载地址 php 7.0.4 下载地址 libmcrypt 2.5.8 下载地址 步骤 初始化系统编译环境 选择合适的PHP版本 实验用CentOS 6.7 编译安装 php-5.6.19 yum -y install make gcc-c++ gcc bzip2-devel libjpeg-turbo-devel \ libpng-devel freetype-devel curl-devel mysql-devel libxml2-devel 编译安装libmcrypt PHP依赖libmcrypt yum源的基础仓库没有libmcrypt的开发包 如果想yum安装 可以拓展epel仓库 1234tar xf libmcrypt-2.5.8.tar.gzcd libmcrypt-2.5.8./configure --prefix=/usr/local/mcryptmake &amp;&amp; make install 开始编译PHP123456789101112131415161718tar xf php-5.6.19.tar.xzcd php-5.6.19./configure \--prefix=/usr/local/php \--enable-fpm --with-mcrypt \--with-zlib --enable-mbstring \--with-openssl --with-mysql \--with-mysqli --with-mysql-sock \--with-gd --with-jpeg-dir=/usr/lib \--enable-gd-native-ttf \--enable-pdo --with-pdo-mysql \--with-gettext --with-curl \--with-pdo-mysql --enable-sockets \--enable-bcmath --enable-xml \--with-bz2 --enable-zip \--with-freetype-dir=/usr \--with-mcrypt=/usr/local/mcryptmake -j4 &amp;&amp; make install 配置运行环境12345mkdir /etc/phpcp ./php.ini-production /usr/local/php/lib/php.inicp /usr/local/php/etc/&#123;php-fpm.conf.default,php-fpm.conf&#125;cp sapi/fpm/init.d.php-fpm /etc/init.d/php-fpmchmod +x /etc/init.d/php-fpm 启动服务123service php-fpm start # 任意方式启动即可/etc/init.d/php-fpm start/usr/local/php/sbin/php-fpm --daemonize [root@45c4f07c6049 etc]# netstat -anpt |grep php-fpm tcp 0 0 127.0.0.1:9000 0.0.0.0:* LISTEN 49135/php-fpm php-fpm默认使用nobody用户运行 监听127.0.0.1:9000端口 如果想在前端显示调试信息等 可以将 --daemonize 换成 --nodaemonize 这些配置会覆盖掉php-fpm.conf中的配置 附录一般php-fpm能正常监听 就没问题了 不同与Apache的模块方式 fpm方式是通过Fastcgi方式提供服务的 web服务器将需要处理的php页面请求 转发给php-fpm的监听端口 php-fpm将处理好的数据再返回给web服务器 所以php-fpm方式是和web服务器无关的 只要你的web服务器支持Fastcgi 就都可以将php页面转发给php-fpm处理 想要验证 可以搭配Nginx等服务器解析php页面试试]]></content>
      <categories>
        <category>PHP</category>
      </categories>
      <tags>
        <tag>php</tag>
        <tag>LNMP</tag>
        <tag>php-fpm</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[MySQL编译安装]]></title>
    <url>%2F2016%2F04%2F01%2F2016%2FMySQL%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介 MySQL是一个关系型数据库管理系统，由瑞典MySQL AB 公司开发，目前属于 Oracle 旗下公司。MySQL 最流行的关系型数据库管理系统，在 WEB 应用方面MySQL是最好的 RDBMS (Relational Database Management System，关系数据库管理系统) 应用软件之一。MySQL是一种关联数据库管理系统，关联数据库将数据保存在不同的表中，而不是将所有数据放在一个大仓库内，这样就增加了速度并提高了灵活性。MySQL所使用的 SQL 语言是用于访问数据库的最常用标准化语言。MySQL 软件采用了双授权政策，它分为社区版和商业版，由于其体积小、速度快、总体拥有成本低，尤其是开放源码这一特点，一般中小型网站的开发都选择 MySQL 作为网站数据库。由于其社区版的性能卓越，搭配 PHP 和 Apache 可组成良好的开发环境百度百科 环境 初始化系统编译环境 选择合适的MySQL版本进行下载 实验用CentOS 6.7 编译安装 MySQL-5.6.28MySQL5.7对cmake最低版本要求是2.8.2 如果cmake版本不够 需升级cmake yum -y install make gcc-c++ gcc cmake bison-devel ncurses-devel perl 软件名称 版本号 下载地址 mysql 5.5.47 点击下载 mysql 5.6.28 点击下载 mysql 5.7.11 点击下载 步骤开始编译 MySQL 5.5和5.6版本编译过程差不多 5.7版本开始依赖boost库链接中5.7的下载地址是已经包含了boost头文件的源码包 1234567891011121314151617181920tar xf mysql-5.6.28.tar.gzcd mysql-5.6.28cmake \-DCMAKE_INSTALL_PREFIX=/usr/local/mysql \-DMYSQL_DATADIR=/usr/local/mysql/data \-DSYSCONFDIR=/etc \-DWITH_MYISAM_STORAGE_ENGINE=1 \-DWITH_INNOBASE_STORAGE_ENGINE=1 \-DWITH_MEMORY_STORAGE_ENGINE=1 \-DWITH_READLINE=1 \-DMYSQL_UNIX_ADDR=/var/lib/mysql/mysql.sock \-DMYSQL_TCP_PORT=3306 \-DENABLED_LOCAL_INFILE=1 \-DWITH_PARTITION_STORAGE_ENGINE=1 \-DEXTRA_CHARSETS=all \-DDEFAULT_CHARSET=utf8 \-DDEFAULT_COLLATION=utf8_general_ci \# -DWITH_BOOST=boost # 注意 MySQL5.7需要开启此选项make -j4 # MySQL编译是个比较慢的过程 这里启动四个进程去并行编译make install # MySQL被安装到/usr/local/mysql中 配置运行环境12345678910111213141516useradd mysql -M -s /sbin/nologin # 创建mysql运行用户 默认同时创建组chown -R mysql:mysql /usr/local/mysql # 更改mysql基础目录的所有者cd /usr/local/mysqlscripts/mysql_install_db --datadir=/usr/local/mysql/data/ --user=mysql# MySQL5.7版本通过 mysqld --initialize 进行初始化数据库# bin/mysqld --initialize --user=mysql --datadir=/usr/local/mysql/data/# 初始化后会生成一个随机的密码 记住这个随机密码# [Note] A temporary password is generated for root@localhost: h&lt;iJP&gt;aU2C,9echo /usr/local/mysql/lib &gt; /etc/ld.so.conf.d/mysql5.6.confldconfig -v |grep /usr/local/mysql/lib # 查看/usr/local/mysql/lib是否被加入到系统运行库中echo 'export PATH=$PATH:/usr/local/mysql/bin' &gt; /etc/profile.d/mysql5.6.shsource /etc/profile # 将mysql等命令加入到环境变量 并立即生效cp support-files/my-default.cnf /etc/my.cnf # 提供配置文件 cp support-files/mysql.server /etc/init.d/mysqld # 提供mysqld服务控制脚本 vim /etc/my.cnf # 修改如下内容 basedir = /usr/local/mysql # mysql基础目录 datadir = /usr/local/mysql/data # mysql数据库目录 port = 3306 # 服务监听端口 启动服务123/etc/init.d/mysqld startservice mysqld startmysqld_safe &amp; # 三种方式均可启动服务 如果服务启动失败 查看MySQL错误日志 默认路径为：/usr/local/mysql/data/`hostname`.err 输入mysql 查看是否正常连接 [root@8be3d6481fd9 data]# mysql Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 2 Server version: 5.6.28 Source distribution Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. mysql&gt; MySQL5.7 需要通过这个随机密码登录 而且登录后必须修改密码才能正常使用 [root@8be3d6481fd9 data] # mysql -uroot -p Enter password: Welcome to the MySQL monitor. Commands end with ; or \g. Your MySQL connection id is 2 Server version: 5.7.11 Copyright (c) 2000, 2015, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type &apos;help;&apos; or &apos;\h&apos; for help. Type &apos;\c&apos; to clear the current input statement. mysql&gt;set password=password(&apos;yourpassword&apos;); 下次就可以通过新密码登录了 &quot;set password=password(&apos;&apos;);&quot; 可以配置空密码 附录MySQL授权远程登录用户 这样就可以在其他主机远程登录MySQL了 grant all privileges on *.* to &quot;user&quot;@&quot;%&quot; identified by &quot;password&quot;; MySQL忘记登录密码处理 先停掉原来的服务 通过跳过授权表 不使用网络连接启动mysql mysqld_safe --user=mysql --skip-grant-tables --skip-networking &amp; 直接通过mysql命令登录 然后修改mysql.user表的信息 update mysql.user set password=password(&apos;yourpasswd&apos;) where user=&apos;root&apos;; MySQL5.7 的密码字段为authentication_string update mysql.user set authentication_string=password(&apos;yourpasswd&apos;) where user=&apos;root&apos;; 通过修改/etc/my.cnf可以修改mysql的数据库目录等位置 修改完数据库位置后可能需要重新初始化数据库]]></content>
      <categories>
        <category>MySQL</category>
      </categories>
      <tags>
        <tag>mysql</tag>
        <tag>关系型数据库</tag>
        <tag>LNMP</tag>
      </tags>
  </entry>
  <entry>
    <title><![CDATA[Nginx编译安装]]></title>
    <url>%2F2016%2F03%2F31%2F2016%2Fnginx%E7%BC%96%E8%AF%91%E5%AE%89%E8%A3%85%2F</url>
    <content type="text"><![CDATA[简介 Nginx是一款轻量级的Web 服务器/反向代理服务器及电子邮件（IMAP/POP3）代理服务器，并在一个BSD-like 协议下发行。由俄罗斯的程序设计师Igor Sysoev所开发，供俄国大型的入口网站及搜索引擎Rambler使用。其特点是占有内存少，并发能力强，事实上nginx的并发能力确实在同类型的网页服务器中表现较好，中国大陆使用nginx网站用户有：百度、新浪、网易、腾讯等。百度百科 环境 软件名称 版本号 下载地址 pcre 8.38 点击下载 openssl 1.0.1s 点击下载 nginx 1.9.13 点击下载 步骤 需要系统先初始化开发环境 yum install -y gcc gcc-c++ zlib-devel make 解压pcre源码 Nginx的 HTTP rewrite module 依赖pcre库 所以所以nginx需要pcre的源码 1tar xf pcre-8.38.tar.bz2 解压备用 无需编译 解压openssl源码1tar xf openssl-1.0.1s.tar.gz 解压备用 无需编译 编译安装Nginx1234567891011121314151617181920tar xf nginx-1.9.13.tar.gzcd nginx-1.9.13./configure --prefix=/usr/local/nginx \--pid-path=/var/run/nginx/nginx.pid \--lock-path=/var/lock/nginx.lock \--user=nginx --group=nginx \--with-http_ssl_module \--with-http_flv_module \--with-stream \--with-http_stub_status_module \--with-http_gzip_static_module \--with-openssl=/usr/local/ssl \--http-client-body-temp-path=/var/tmp/nginx/client/ \--http-proxy-temp-path=/var/tmp/nginx/proxy/ \--http-fastcgi-temp-path=/var/tmp/nginx/fcgi/ \--http-uwsgi-temp-path=/var/tmp/nginx/uwsgi \--http-scgi-temp-path=/var/tmp/nginx/scgi \--with-pcre=../pcre-8.38 \ # pcre源码的路径--with-openssl=../openssl-1.0.1s # openssl源码的路径make -j4 &amp;&amp; make install # nginx被安装到/usr/local/nginx中 运行Nginx Nginx 默认运行用户是nginx 所以需要先创建nginx用户和组。还需要创建Nginx运行需要的一些目录才能将Nginx正常启动 123useradd nginx -M -s /sbin/nologinmkdir -p /var/tmp/nginx/client//usr/local/nginx/sbin/nginx 检查nginx是否正常启动web服务 netstat -anpt |grep nginx tcp 0 0 0.0.0.0:80 0.0.0.0:* LISTEN 33170/nginx 通过浏览器访问服务器 看是否出现了Welcome to nginx! 附录1/usr/local/nginx/sbin/nginx -h nginx version: nginx/1.9.13 Usage: nginx [-?hvVtTq] [-s signal] [-c filename] [-p prefix] [-g directives] Options: -?,-h : 展示帮助 -v : 展示版本后退出 -V : 展示版本和配置信息后退出 -t : 测试配置文件后退出 -T : 测试配置文件后展示出来 然后退出 -q : 在配置测试过程中抑制非错误消息 -s signal : 向主线程发送信号: stop, quit, reopen, reload -p prefix : 设置主目录 (default: /usr/local/nginx/) -c filename : 设置配置文件 (default: conf/nginx.conf) -g directives : 设置全局指令的配置文件]]></content>
      <categories>
        <category>Nginx</category>
      </categories>
      <tags>
        <tag>代理服务器</tag>
        <tag>负载均衡</tag>
        <tag>LNMP</tag>
        <tag>web服务器</tag>
      </tags>
  </entry>
</search>
